INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:53 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_96_slots_32_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_96_slots_32_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156029424 . Total output tokens: 137504459
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 62.64151424402371,
    "estimated_duration": 3600.0167481789376,
    "input_throughput": 6925.516113949136,
    "output_throughput": 6029.558059967416,
    "total_throughput": 12955.074173916551,
    "itl": 99.28784789645954,
    "ttft": 1532314.9298208228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 161,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0645978541439387,
    "arrivals": 232682,
    "finished_requests": 100775,
    "scheduler_time": 185.41241028249152
}
#Debug simulation 
Total elapsed time: 62.641785468906164. Arrivals time: 0.6151186218485236 Scheduler time: 61.79172789864242 Scheduler overhead time: 0.09147735871374607 Adapter cache time: 0.017744758166372776 Engine time: 0.09351672325283289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_96_slots_32_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_96_slots_32_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156029424 . Total output tokens: 137504459
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 50.45791791193187,
    "estimated_duration": 3600.011565585909,
    "input_throughput": 6831.996384433024,
    "output_throughput": 5951.230880702218,
    "total_throughput": 12783.227265135241,
    "itl": 96.2531971176488,
    "ttft": 1537570.0999923944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1458195318467932,
    "arrivals": 232682,
    "finished_requests": 99354,
    "scheduler_time": 187.59186133598135
}
#Debug simulation 
Total elapsed time: 50.45832785312086. Arrivals time: 0.5852319588884711 Scheduler time: 49.65257292892784 Scheduler overhead time: 0.08662235364317894 Adapter cache time: 0.01616948051378131 Engine time: 0.08642553444951773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_96_slots_32_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_96_slots_32_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156029424 . Total output tokens: 137504459
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 46.156222796067595,
    "estimated_duration": 3600.085064563204,
    "input_throughput": 6655.778563639917,
    "output_throughput": 5797.1719072510805,
    "total_throughput": 12452.950470890997,
    "itl": 90.35763093214217,
    "ttft": 1562687.3274773234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.168059859583155,
    "arrivals": 232682,
    "finished_requests": 96848,
    "scheduler_time": 191.98923589420417
}
#Debug simulation 
Total elapsed time: 46.15647943271324. Arrivals time: 0.5733887413516641 Scheduler time: 45.36480284575373 Scheduler overhead time: 0.08559397654607892 Adapter cache time: 0.015562237240374088 Engine time: 0.08483867766335607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_96_slots_32_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_96_slots_32_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156029424 . Total output tokens: 137504459
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 51.334622158203274,
    "estimated_duration": 3600.098698958914,
    "input_throughput": 6827.948635716149,
    "output_throughput": 5957.774159414727,
    "total_throughput": 12785.722795130876,
    "itl": 96.61163165293038,
    "ttft": 1540379.8242035238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 195,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3434282725164663,
    "arrivals": 232682,
    "finished_requests": 99443,
    "scheduler_time": 187.28590621043298
}
#Debug simulation 
Total elapsed time: 51.334841133095324. Arrivals time: 0.6048591574653983 Scheduler time: 50.5128315561451 Scheduler overhead time: 0.08421011874452233 Adapter cache time: 0.01659319130703807 Engine time: 0.08500934625044465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_96_slots_32_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_96_slots_32_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156029424 . Total output tokens: 137504459
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 46.43781666690484,
    "estimated_duration": 3600.0144674056837,
    "input_throughput": 6658.668240651458,
    "output_throughput": 5801.599184975271,
    "total_throughput": 12460.26742562673,
    "itl": 90.48959697697941,
    "ttft": 1562033.1724938042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 161,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2053319722879692,
    "arrivals": 232682,
    "finished_requests": 96916,
    "scheduler_time": 191.83968416536408
}
#Debug simulation 
Total elapsed time: 46.43803151091561. Arrivals time: 0.5847567152231932 Scheduler time: 45.627056517638266 Scheduler overhead time: 0.08769687172025442 Adapter cache time: 0.016800863668322563 Engine time: 0.08902236679568887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_96_slots_32_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_96_slots_32_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156029424 . Total output tokens: 137504459
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 48.52016277611256,
    "estimated_duration": 3600.0390315975515,
    "input_throughput": 6829.898171712012,
    "output_throughput": 5953.623227937276,
    "total_throughput": 12783.521399649288,
    "itl": 96.4733599298232,
    "ttft": 1537760.7155440955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 167,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0661147970752767,
    "arrivals": 232682,
    "finished_requests": 99414,
    "scheduler_time": 187.51238885694897
}
#Debug simulation 
Total elapsed time: 48.52044831216335. Arrivals time: 0.583780943416059 Scheduler time: 47.7204215079546 Scheduler overhead time: 0.08574335183948278 Adapter cache time: 0.0156387728638947 Engine time: 0.08386563509702682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_96_slots_32_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_96_slots_32_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156029424 . Total output tokens: 137504459
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 45.22302220482379,
    "estimated_duration": 3600.0394351725568,
    "input_throughput": 6660.699815042623,
    "output_throughput": 5801.674780542753,
    "total_throughput": 12462.374595585377,
    "itl": 90.47974072467557,
    "ttft": 1563399.2033859044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 161,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1933191760443163,
    "arrivals": 232682,
    "finished_requests": 96929,
    "scheduler_time": 191.84194121184498
}
#Debug simulation 
Total elapsed time: 45.22320777410641. Arrivals time: 0.5872258646413684 Scheduler time: 44.41863020276651 Scheduler overhead time: 0.08433907199651003 Adapter cache time: 0.016006389632821083 Engine time: 0.08511775499209762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155050838 . Total output tokens: 136674285
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 75.47540368000045,
    "estimated_duration": 3600.018385116988,
    "input_throughput": 6924.257971307539,
    "output_throughput": 6034.610570271858,
    "total_throughput": 12958.868541579397,
    "itl": 99.62871588864702,
    "ttft": 1508612.4759535606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4547299870289845,
    "arrivals": 231202,
    "finished_requests": 100659,
    "scheduler_time": 184.67296643588367
}
#Debug simulation 
Total elapsed time: 75.47561445366591. Arrivals time: 0.6490354472771287 Scheduler time: 74.58116685366258 Scheduler overhead time: 0.09691011207178235 Adapter cache time: 0.01936797145754099 Engine time: 0.09643186815083027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155050838 . Total output tokens: 136674285
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 67.39343405002728,
    "estimated_duration": 3600.024982014367,
    "input_throughput": 6806.980541087312,
    "output_throughput": 5944.191806143027,
    "total_throughput": 12751.17234723034,
    "itl": 96.30105743595945,
    "ttft": 1540737.253801648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9585513292485879,
    "arrivals": 231202,
    "finished_requests": 99198,
    "scheduler_time": 187.4117113407769
}
#Debug simulation 
Total elapsed time: 67.3937070639804. Arrivals time: 0.6212388467974961 Scheduler time: 66.54000474279746 Scheduler overhead time: 0.09185862680897117 Adapter cache time: 0.0179759724996984 Engine time: 0.09077836433425546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155050838 . Total output tokens: 136674285
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 43.819261613767594,
    "estimated_duration": 3600.082238271413,
    "input_throughput": 6648.642840862645,
    "output_throughput": 5810.214216118424,
    "total_throughput": 12458.857056981069,
    "itl": 90.82224525338216,
    "ttft": 1571371.0735959124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2002303476119507,
    "arrivals": 231202,
    "finished_requests": 96850,
    "scheduler_time": 191.1144856491581
}
#Debug simulation 
Total elapsed time: 43.819457517936826. Arrivals time: 0.6297934455797076 Scheduler time: 42.96451853122562 Scheduler overhead time: 0.08749589929357171 Adapter cache time: 0.018066936172544956 Engine time: 0.08718081610277295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155050838 . Total output tokens: 136674285
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 68.31629878096282,
    "estimated_duration": 3600.0131202301927,
    "input_throughput": 6820.067644206271,
    "output_throughput": 5952.213029331916,
    "total_throughput": 12772.280673538187,
    "itl": 96.33406254357757,
    "ttft": 1541194.2027714637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6701226083375498,
    "arrivals": 231202,
    "finished_requests": 99313,
    "scheduler_time": 187.40681185048035
}
#Debug simulation 
Total elapsed time: 68.31648987485096. Arrivals time: 0.6860973183065653 Scheduler time: 67.39809934748337 Scheduler overhead time: 0.09061627089977264 Adapter cache time: 0.018852192908525467 Engine time: 0.09025228023529053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155050838 . Total output tokens: 136674285
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 37.84165141265839,
    "estimated_duration": 3600.0796941901526,
    "input_throughput": 6628.567428246371,
    "output_throughput": 5789.5329466279045,
    "total_throughput": 12418.100374874275,
    "itl": 90.36279284092585,
    "ttft": 1561979.7842602057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5111297398293424,
    "arrivals": 231202,
    "finished_requests": 96523,
    "scheduler_time": 191.86864194854337
}
#Debug simulation 
Total elapsed time: 37.8419188009575. Arrivals time: 0.43225468834862113 Scheduler time: 37.217977865599096 Scheduler overhead time: 0.07473162049427629 Adapter cache time: 0.01376406429335475 Engine time: 0.07294459827244282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155050838 . Total output tokens: 136674285
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 51.63856550306082,
    "estimated_duration": 3600.065247307742,
    "input_throughput": 6816.972558581556,
    "output_throughput": 5955.571504164802,
    "total_throughput": 12772.544062746358,
    "itl": 96.85710732836988,
    "ttft": 1539448.6174270546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.017319017220281,
    "arrivals": 231202,
    "finished_requests": 99267,
    "scheduler_time": 186.98406996605195
}
#Debug simulation 
Total elapsed time: 51.638765081297606. Arrivals time: 0.5857499511912465 Scheduler time: 50.840475948527455 Scheduler overhead time: 0.08203036244958639 Adapter cache time: 0.018105992581695318 Engine time: 0.08168294746428728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155050838 . Total output tokens: 136674285
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 47.77477754699066,
    "estimated_duration": 3600.0613823219114,
    "input_throughput": 6627.790880779609,
    "output_throughput": 5789.243511886425,
    "total_throughput": 12417.034392666035,
    "itl": 90.36591164210387,
    "ttft": 1561964.4380715538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5200312888808585,
    "arrivals": 231202,
    "finished_requests": 96510,
    "scheduler_time": 191.86124131826736
}
#Debug simulation 
Total elapsed time: 47.774955139961094. Arrivals time: 0.5740712601691484 Scheduler time: 46.974122868385166 Scheduler overhead time: 0.089349624235183 Adapter cache time: 0.016791327390819788 Engine time: 0.08766036108136177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_96_slots_32_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_96_slots_32_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154558949 . Total output tokens: 136251051
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 65.22857319517061,
    "estimated_duration": 3600.0929782807275,
    "input_throughput": 6935.307824167276,
    "output_throughput": 6022.549731577878,
    "total_throughput": 12957.857555745155,
    "itl": 99.41767168683192,
    "ttft": 1513862.5204805718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.401830714773385,
    "arrivals": 230450,
    "finished_requests": 100713,
    "scheduler_time": 185.1498550355484
}
#Debug simulation 
Total elapsed time: 65.22903949115425. Arrivals time: 0.6260445546358824 Scheduler time: 64.35993336047977 Scheduler overhead time: 0.09492432978004217 Adapter cache time: 0.018385841511189938 Engine time: 0.09634954109787941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_96_slots_32_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_96_slots_32_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154558949 . Total output tokens: 136251051
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 62.58004402462393,
    "estimated_duration": 3600.1041811845644,
    "input_throughput": 6851.35561601557,
    "output_throughput": 5953.512154458731,
    "total_throughput": 12804.8677704743,
    "itl": 96.58851109504275,
    "ttft": 1516257.039800127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 179,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.30930836515967,
    "arrivals": 230450,
    "finished_requests": 99452,
    "scheduler_time": 187.0786014834988
}
#Debug simulation 
Total elapsed time: 62.58024205174297. Arrivals time: 0.5710429139435291 Scheduler time: 61.77917525963858 Scheduler overhead time: 0.08999448595568538 Adapter cache time: 0.01776851387694478 Engine time: 0.09045966621488333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_96_slots_32_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_96_slots_32_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154558949 . Total output tokens: 136251051
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 61.07309498731047,
    "estimated_duration": 3600.093766048869,
    "input_throughput": 6674.520876819247,
    "output_throughput": 5793.155499638421,
    "total_throughput": 12467.676376457668,
    "itl": 90.40722006332616,
    "ttft": 1536779.7176083913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 228,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.721728281574328,
    "arrivals": 230450,
    "finished_requests": 96828,
    "scheduler_time": 191.68460743411438
}
#Debug simulation 
Total elapsed time: 61.07330282405019. Arrivals time: 0.5528129041194916 Scheduler time: 60.29104280890897 Scheduler overhead time: 0.0895772222429514 Adapter cache time: 0.017138577066361904 Engine time: 0.09004040388390422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_96_slots_32_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_96_slots_32_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154558949 . Total output tokens: 136251051
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 63.44654617924243,
    "estimated_duration": 3600.0514696358205,
    "input_throughput": 6843.034942078784,
    "output_throughput": 5942.964477161851,
    "total_throughput": 12785.999419240636,
    "itl": 96.65095964388958,
    "ttft": 1520053.3723597599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 167,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1438551715807983,
    "arrivals": 230450,
    "finished_requests": 99350,
    "scheduler_time": 187.36181495461756
}
#Debug simulation 
Total elapsed time: 63.44678568188101. Arrivals time: 0.572936674579978 Scheduler time: 62.644743266981095 Scheduler overhead time: 0.0899421670474112 Adapter cache time: 0.017611284274607897 Engine time: 0.08998571615666151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_96_slots_32_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_96_slots_32_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154558949 . Total output tokens: 136251051
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 62.47107232129201,
    "estimated_duration": 3600.0892600129578,
    "input_throughput": 6675.955306706338,
    "output_throughput": 5795.449082816604,
    "total_throughput": 12471.404389522942,
    "itl": 90.39959521276867,
    "ttft": 1536648.8663937205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6773078126227534,
    "arrivals": 230450,
    "finished_requests": 96876,
    "scheduler_time": 191.68748127022224
}
#Debug simulation 
Total elapsed time: 62.471388346049935. Arrivals time: 0.5814210469834507 Scheduler time: 61.64623849419877 Scheduler overhead time: 0.09543076157569885 Adapter cache time: 0.018653581850230694 Engine time: 0.09529835171997547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_96_slots_32_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_96_slots_32_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154558949 . Total output tokens: 136251051
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 62.995818679686636,
    "estimated_duration": 3600.0950347134003,
    "input_throughput": 6860.65361104176,
    "output_throughput": 5959.928222202643,
    "total_throughput": 12820.581833244403,
    "itl": 96.86057179327081,
    "ttft": 1519824.6538890228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3725430022226606,
    "arrivals": 230450,
    "finished_requests": 99637,
    "scheduler_time": 186.85698111230442
}
#Debug simulation 
Total elapsed time: 62.99600041564554. Arrivals time: 0.5945390877313912 Scheduler time: 62.170111594721675 Scheduler overhead time: 0.09079616982489824 Adapter cache time: 0.017379692755639553 Engine time: 0.09100657654926181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_96_slots_32_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_96_slots_32_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154558949 . Total output tokens: 136251051
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 62.65129888197407,
    "estimated_duration": 3600.0779522360763,
    "input_throughput": 6677.062085577781,
    "output_throughput": 5801.068831586929,
    "total_throughput": 12478.13091716471,
    "itl": 90.54643820825503,
    "ttft": 1535495.2338157317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.724984660111373,
    "arrivals": 230450,
    "finished_requests": 96907,
    "scheduler_time": 191.59234248594757
}
#Debug simulation 
Total elapsed time: 62.651565577834845. Arrivals time: 0.5846521551720798 Scheduler time: 61.82349386392161 Scheduler overhead time: 0.0958736203610897 Adapter cache time: 0.01805403269827366 Engine time: 0.09512582933530211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154320683 . Total output tokens: 136051716
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 86.82958989590406,
    "estimated_duration": 3600.0483293769566,
    "input_throughput": 6840.39927993463,
    "output_throughput": 6019.740297139444,
    "total_throughput": 12860.139577074073,
    "itl": 99.47223041167277,
    "ttft": 1529846.0448512502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8596131741534909,
    "arrivals": 230128,
    "finished_requests": 99910,
    "scheduler_time": 185.39905690530065
}
#Debug simulation 
Total elapsed time: 86.82977634994313. Arrivals time: 0.6235467838123441 Scheduler time: 85.9599453303963 Scheduler overhead time: 0.0988606926985085 Adapter cache time: 0.017824570182710886 Engine time: 0.09632327174767852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154320683 . Total output tokens: 136051716
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 58.00998816918582,
    "estimated_duration": 3600.0694182479865,
    "input_throughput": 6771.3249851341625,
    "output_throughput": 5959.785911695454,
    "total_throughput": 12731.110896829618,
    "itl": 97.01254178335557,
    "ttft": 1526504.990445384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1422120528528485,
    "arrivals": 230128,
    "finished_requests": 98965,
    "scheduler_time": 187.04000064133564
}
#Debug simulation 
Total elapsed time: 58.01016982179135. Arrivals time: 0.6003811052069068 Scheduler time: 57.1824816884473 Scheduler overhead time: 0.09172189375385642 Adapter cache time: 0.016260933130979538 Engine time: 0.08725234726443887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154320683 . Total output tokens: 136051716
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 62.18545499118045,
    "estimated_duration": 3600.015380385375,
    "input_throughput": 6583.5388173988495,
    "output_throughput": 5808.949904475512,
    "total_throughput": 12392.488721874362,
    "itl": 90.7127932166955,
    "ttft": 1544805.5181698261,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 193,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.452736164652745,
    "arrivals": 230128,
    "finished_requests": 96309,
    "scheduler_time": 191.72730749881322
}
#Debug simulation 
Total elapsed time: 62.18572141509503. Arrivals time: 0.576595963910222 Scheduler time: 61.36847933707759 Scheduler overhead time: 0.09534257790073752 Adapter cache time: 0.018121541012078524 Engine time: 0.09358063573017716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154320683 . Total output tokens: 136051716
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 63.15427313512191,
    "estimated_duration": 3600.060259158648,
    "input_throughput": 6758.291875282694,
    "output_throughput": 5949.456802982955,
    "total_throughput": 12707.748678265649,
    "itl": 96.91567117049013,
    "ttft": 1527878.3884586736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.01839601079002,
    "arrivals": 230128,
    "finished_requests": 98832,
    "scheduler_time": 187.40067036016774
}
#Debug simulation 
Total elapsed time: 63.15445757098496. Arrivals time: 0.5812235036864877 Scheduler time: 62.343354334589094 Scheduler overhead time: 0.09205853287130594 Adapter cache time: 0.0163583867251873 Engine time: 0.08945624297484756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154320683 . Total output tokens: 136051716
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 51.79124563699588,
    "estimated_duration": 3600.0562796836443,
    "input_throughput": 6596.58881835227,
    "output_throughput": 5805.605628431074,
    "total_throughput": 12402.194446783344,
    "itl": 90.80619988445318,
    "ttft": 1563335.2160589546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0345116745960037,
    "arrivals": 230128,
    "finished_requests": 96314,
    "scheduler_time": 191.50674851292467
}
#Debug simulation 
Total elapsed time: 51.791462435852736. Arrivals time: 0.5436210781335831 Scheduler time: 51.024249428883195 Scheduler overhead time: 0.08736580284312367 Adapter cache time: 0.01770910993218422 Engine time: 0.08668676856905222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154320683 . Total output tokens: 136051716
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 62.96220926102251,
    "estimated_duration": 3600.0519040935887,
    "input_throughput": 6758.01339762226,
    "output_throughput": 5950.968088998712,
    "total_throughput": 12708.981486620973,
    "itl": 96.90376503987174,
    "ttft": 1527579.9258089869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9192846154421551,
    "arrivals": 230128,
    "finished_requests": 98827,
    "scheduler_time": 187.36114141462852
}
#Debug simulation 
Total elapsed time: 62.96243668021634. Arrivals time: 0.580745451617986 Scheduler time: 62.15230437554419 Scheduler overhead time: 0.09213588945567608 Adapter cache time: 0.016582200303673744 Engine time: 0.08865499030798674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154320683 . Total output tokens: 136051716
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 54.022756868973374,
    "estimated_duration": 3600.0052865583807,
    "input_throughput": 6574.367012284715,
    "output_throughput": 5786.205669690535,
    "total_throughput": 12360.572681975249,
    "itl": 90.43127281234209,
    "ttft": 1561346.5297365251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 171,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.261496913488956,
    "arrivals": 230128,
    "finished_requests": 96079,
    "scheduler_time": 192.2665928685608
}
#Debug simulation 
Total elapsed time: 54.02291345782578. Arrivals time: 0.562672667670995 Scheduler time: 53.23049060348421 Scheduler overhead time: 0.09080339409410954 Adapter cache time: 0.016457490157335997 Engine time: 0.08921611122786999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_96_slots_32_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_96_slots_32_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134823443 . Total output tokens: 118836918
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 61.95131256617606,
    "estimated_duration": 3600.046678892481,
    "input_throughput": 6938.4328115668895,
    "output_throughput": 6053.510952448089,
    "total_throughput": 12991.943764014977,
    "itl": 99.73509459936028,
    "ttft": 1358766.3782483065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2777211793418972,
    "arrivals": 200953,
    "finished_requests": 101317,
    "scheduler_time": 180.92997954489982
}
#Debug simulation 
Total elapsed time: 61.95147836999968. Arrivals time: 0.6317580989561975 Scheduler time: 61.07782896049321 Scheduler overhead time: 0.09799018548801541 Adapter cache time: 0.01622158195823431 Engine time: 0.09521178854629397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_96_slots_32_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_96_slots_32_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134823443 . Total output tokens: 118836918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 60.10176280327141,
    "estimated_duration": 3600.076706297368,
    "input_throughput": 6861.923235354387,
    "output_throughput": 5990.520413711043,
    "total_throughput": 12852.44364906543,
    "itl": 97.07550522070949,
    "ttft": 1370899.6106456404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3000537618901581,
    "arrivals": 200953,
    "finished_requests": 100231,
    "scheduler_time": 182.7426400920767
}
#Debug simulation 
Total elapsed time: 60.10199707234278. Arrivals time: 0.6206178260035813 Scheduler time: 59.239429529290646 Scheduler overhead time: 0.0986761674284935 Adapter cache time: 0.016110002528876066 Engine time: 0.09422254422679543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_96_slots_32_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_96_slots_32_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134823443 . Total output tokens: 118836918
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 55.740559502039105,
    "estimated_duration": 3600.059544480355,
    "input_throughput": 6678.628979029989,
    "output_throughput": 5825.020042280146,
    "total_throughput": 12503.649021310135,
    "itl": 90.79665400776004,
    "ttft": 1405264.7356505003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30672776019666353,
    "arrivals": 200953,
    "finished_requests": 97487,
    "scheduler_time": 187.42124639654318
}
#Debug simulation 
Total elapsed time: 55.74071971792728. Arrivals time: 0.6030017253942788 Scheduler time: 54.895891077816486 Scheduler overhead time: 0.09756894363090396 Adapter cache time: 0.015248478390276432 Engine time: 0.09578721597790718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_96_slots_32_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_96_slots_32_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134823443 . Total output tokens: 118836918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 59.72639674274251,
    "estimated_duration": 3600.093734276692,
    "input_throughput": 6862.121606665174,
    "output_throughput": 5990.587632389255,
    "total_throughput": 12852.70923905443,
    "itl": 97.07515548332957,
    "ttft": 1370906.8327692107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2833951102104038,
    "arrivals": 200953,
    "finished_requests": 100233,
    "scheduler_time": 182.74357133766287
}
#Debug simulation 
Total elapsed time: 59.726558852009475. Arrivals time: 0.6240398287773132 Scheduler time: 58.85913049103692 Scheduler overhead time: 0.09890852309763432 Adapter cache time: 0.016449181828647852 Engine time: 0.0955375051125884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_96_slots_32_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_96_slots_32_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134823443 . Total output tokens: 118836918
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 55.86463331896812,
    "estimated_duration": 3600.014011897731,
    "input_throughput": 6678.641783209542,
    "output_throughput": 5825.231215959984,
    "total_throughput": 12503.872999169525,
    "itl": 90.79548263082475,
    "ttft": 1405224.3352436686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3042423540772871,
    "arrivals": 200953,
    "finished_requests": 97488,
    "scheduler_time": 187.4188864994839
}
#Debug simulation 
Total elapsed time: 55.864862523041666. Arrivals time: 0.6047291564755142 Scheduler time: 55.01298311026767 Scheduler overhead time: 0.09921502973884344 Adapter cache time: 0.01687300857156515 Engine time: 0.09679219033569098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_96_slots_32_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_96_slots_32_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134823443 . Total output tokens: 118836918
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 60.025793640874326,
    "estimated_duration": 3600.0438009922527,
    "input_throughput": 6862.273173784966,
    "output_throughput": 5990.635167843174,
    "total_throughput": 12852.90834162814,
    "itl": 97.07540740412327,
    "ttft": 1370865.196374133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.26812467950396235,
    "arrivals": 200953,
    "finished_requests": 100233,
    "scheduler_time": 182.7401700202153
}
#Debug simulation 
Total elapsed time: 60.025961397681385. Arrivals time: 0.6211047288961709 Scheduler time: 59.1588245537132 Scheduler overhead time: 0.10019465303048491 Adapter cache time: 0.01645927131175995 Engine time: 0.09620262589305639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_96_slots_32_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_96_slots_32_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134823443 . Total output tokens: 118836918
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 57.01439158804715,
    "estimated_duration": 3600.060268746941,
    "input_throughput": 6678.62819095768,
    "output_throughput": 5825.281643770764,
    "total_throughput": 12503.909834728443,
    "itl": 90.7943894090705,
    "ttft": 1405226.2711776458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3019640651345254,
    "arrivals": 200953,
    "finished_requests": 97489,
    "scheduler_time": 187.42316715772247
}
#Debug simulation 
Total elapsed time: 57.0145681030117. Arrivals time: 0.6135551109910011 Scheduler time: 56.157570540905 Scheduler overhead time: 0.09831353323534131 Adapter cache time: 0.016486306209117174 Engine time: 0.09422117611393332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_96_slots_32_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_96_slots_32_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132889330 . Total output tokens: 117122441
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 39.64052420295775,
    "estimated_duration": 3600.035742562787,
    "input_throughput": 6931.031185328522,
    "output_throughput": 6046.764131431492,
    "total_throughput": 12977.795316760014,
    "itl": 99.42402683725948,
    "ttft": 1368236.080255494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2909459974057971,
    "arrivals": 198151,
    "finished_requests": 100601,
    "scheduler_time": 180.91922570103026
}
#Debug simulation 
Total elapsed time: 39.64072780776769. Arrivals time: 0.44962368393316865 Scheduler time: 39.00716005032882 Scheduler overhead time: 0.07357495743781328 Adapter cache time: 0.012163069564849138 Engine time: 0.06957658426836133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_96_slots_32_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_96_slots_32_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132889330 . Total output tokens: 117122441
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 50.16745313303545,
    "estimated_duration": 3600.0250234727264,
    "input_throughput": 6859.025934264335,
    "output_throughput": 5983.246743996746,
    "total_throughput": 12842.27267826108,
    "itl": 96.767472845008,
    "ttft": 1381491.5211825697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3169862666912377,
    "arrivals": 198151,
    "finished_requests": 99521,
    "scheduler_time": 182.71946934061847
}
#Debug simulation 
Total elapsed time: 50.16762105515227. Arrivals time: 0.603890719357878 Scheduler time: 49.33461508760229 Scheduler overhead time: 0.09126384044066072 Adapter cache time: 0.015436132904142141 Engine time: 0.08993065729737282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_96_slots_32_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_96_slots_32_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132889330 . Total output tokens: 117122441
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 48.04497780185193,
    "estimated_duration": 3600.0802507974054,
    "input_throughput": 6665.119199685951,
    "output_throughput": 5817.898641387445,
    "total_throughput": 12483.017841073397,
    "itl": 90.5025108197394,
    "ttft": 1415588.0767371268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3245887133385987,
    "arrivals": 198151,
    "finished_requests": 96763,
    "scheduler_time": 187.397925122811
}
#Debug simulation 
Total elapsed time: 48.04517032997683. Arrivals time: 0.6369957332499325 Scheduler time: 47.1670164950192 Scheduler overhead time: 0.09733669692650437 Adapter cache time: 0.015965390019118786 Engine time: 0.09307743608951569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_96_slots_32_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_96_slots_32_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132889330 . Total output tokens: 117122441
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 51.70565844792873,
    "estimated_duration": 3600.0800779338165,
    "input_throughput": 6859.142148352502,
    "output_throughput": 5983.367740076142,
    "total_throughput": 12842.509888428644,
    "itl": 96.77040716803737,
    "ttft": 1381506.5967172708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30032761501148353,
    "arrivals": 198151,
    "finished_requests": 99524,
    "scheduler_time": 182.72154718043282
}
#Debug simulation 
Total elapsed time: 51.705889175180346. Arrivals time: 0.6699247788637877 Scheduler time: 50.79626026377082 Scheduler overhead time: 0.09638354275375605 Adapter cache time: 0.015795199666172266 Engine time: 0.09400133043527603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_96_slots_32_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_96_slots_32_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132889330 . Total output tokens: 117122441
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 47.575093070045114,
    "estimated_duration": 3600.0677319828146,
    "input_throughput": 6665.291818491415,
    "output_throughput": 5818.044981188144,
    "total_throughput": 12483.33679967956,
    "itl": 90.50447354278629,
    "ttft": 1415569.856900137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32210330721922226,
    "arrivals": 198151,
    "finished_requests": 96764,
    "scheduler_time": 187.39504350004117
}
#Debug simulation 
Total elapsed time: 47.575301519129425. Arrivals time: 0.6088302857242525 Scheduler time: 46.72710862709209 Scheduler overhead time: 0.09678566735237837 Adapter cache time: 0.015660507138818502 Engine time: 0.09264047164469957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_96_slots_32_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_96_slots_32_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132889330 . Total output tokens: 117122441
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 51.48315997002646,
    "estimated_duration": 3600.091727892021,
    "input_throughput": 6859.298003070398,
    "output_throughput": 5983.6267040377215,
    "total_throughput": 12842.92470710812,
    "itl": 96.76699460698319,
    "ttft": 1381357.281108707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.28089252138510346,
    "arrivals": 198151,
    "finished_requests": 99528,
    "scheduler_time": 182.72417206577163
}
#Debug simulation 
Total elapsed time: 51.483344096224755. Arrivals time: 0.6483057718724012 Scheduler time: 50.591717382427305 Scheduler overhead time: 0.09853619942441583 Adapter cache time: 0.015659294091165066 Engine time: 0.09495209716260433 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_96_slots_32_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_96_slots_32_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132889330 . Total output tokens: 117122441
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 47.15517777996138,
    "estimated_duration": 3600.099508785141,
    "input_throughput": 6665.41464796831,
    "output_throughput": 5818.125845934798,
    "total_throughput": 12483.540493903109,
    "itl": 90.5028887283694,
    "ttft": 1415630.3887757324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31920366674661643,
    "arrivals": 198151,
    "finished_requests": 96768,
    "scheduler_time": 187.39738264701268
}
#Debug simulation 
Total elapsed time: 47.15546168293804. Arrivals time: 0.6505480757914484 Scheduler time: 46.26537796668708 Scheduler overhead time: 0.09588405024260283 Adapter cache time: 0.016176303382962942 Engine time: 0.09235654957592487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131947573 . Total output tokens: 116280818
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 45.66771024186164,
    "estimated_duration": 3600.0973983234694,
    "input_throughput": 6915.054857013952,
    "output_throughput": 6053.8787117674965,
    "total_throughput": 12968.93356878145,
    "itl": 99.7506627643656,
    "ttft": 1369440.0217730424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2909459974057971,
    "arrivals": 196793,
    "finished_requests": 100951,
    "scheduler_time": 180.6200517748722
}
#Debug simulation 
Total elapsed time: 45.66801012959331. Arrivals time: 0.6304941172711551 Scheduler time: 44.818474440835416 Scheduler overhead time: 0.08751534251496196 Adapter cache time: 0.01428752951323986 Engine time: 0.0861413050442934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131947573 . Total output tokens: 116280818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 44.706675853114575,
    "estimated_duration": 3600.032679687684,
    "input_throughput": 6840.801234653373,
    "output_throughput": 5990.0547908000635,
    "total_throughput": 12830.856025453437,
    "itl": 97.0532549194181,
    "ttft": 1382369.6832791094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 45,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3205937456851825,
    "arrivals": 196793,
    "finished_requests": 99861,
    "scheduler_time": 182.43572808104793
}
#Debug simulation 
Total elapsed time: 44.70684427022934. Arrivals time: 0.6405499107204378 Scheduler time: 43.8424911336042 Scheduler overhead time: 0.08922293782234192 Adapter cache time: 0.014784917701035738 Engine time: 0.08726091962307692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131947573 . Total output tokens: 116280818
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 40.48315009009093,
    "estimated_duration": 3600.0083016187814,
    "input_throughput": 6642.089961083675,
    "output_throughput": 5825.761010209161,
    "total_throughput": 12467.850971292837,
    "itl": 90.75057089848039,
    "ttft": 1415752.4807844567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3211711005494,
    "arrivals": 196793,
    "finished_requests": 97008,
    "scheduler_time": 187.15184866888848
}
#Debug simulation 
Total elapsed time: 40.48340888880193. Arrivals time: 0.6082100667990744 Scheduler time: 39.65390721568838 Scheduler overhead time: 0.08881703577935696 Adapter cache time: 0.014484367799013853 Engine time: 0.0853958185762167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131947573 . Total output tokens: 116280818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 45.83108277292922,
    "estimated_duration": 3600.06961542103,
    "input_throughput": 6841.375204106873,
    "output_throughput": 5990.229441015388,
    "total_throughput": 12831.604645122261,
    "itl": 97.06378437410437,
    "ttft": 1382339.937962641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29755117306485773,
    "arrivals": 196793,
    "finished_requests": 99870,
    "scheduler_time": 182.43420823422557
}
#Debug simulation 
Total elapsed time: 45.83125237701461. Arrivals time: 0.632208688184619 Scheduler time: 44.9762083995156 Scheduler overhead time: 0.08897757343947887 Adapter cache time: 0.014097004197537899 Engine time: 0.0866874372586608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131947573 . Total output tokens: 116280818
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 41.09120744885877,
    "estimated_duration": 3600.088231402565,
    "input_throughput": 6642.16943113195,
    "output_throughput": 5825.637221071431,
    "total_throughput": 12467.80665220338,
    "itl": 90.74647521573618,
    "ttft": 1415771.444250713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3186856944300236,
    "arrivals": 196793,
    "finished_requests": 97010,
    "scheduler_time": 187.1578500330823
}
#Debug simulation 
Total elapsed time: 41.09134142100811. Arrivals time: 0.59282944817096 Scheduler time: 40.27538254065439 Scheduler overhead time: 0.08896651864051819 Adapter cache time: 0.014276830479502678 Engine time: 0.0874505783431232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131947573 . Total output tokens: 116280818
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 44.91228334698826,
    "estimated_duration": 3600.0437126415786,
    "input_throughput": 6840.7811031632,
    "output_throughput": 5989.861990919357,
    "total_throughput": 12830.643094082558,
    "itl": 97.05392937261009,
    "ttft": 1382400.1584618068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 45,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.287276442325674,
    "arrivals": 196793,
    "finished_requests": 99860,
    "scheduler_time": 182.43619534187462
}
#Debug simulation 
Total elapsed time: 44.912532827816904. Arrivals time: 0.6390353571623564 Scheduler time: 44.052216151263565 Scheduler overhead time: 0.08736351365223527 Adapter cache time: 0.014394746161997318 Engine time: 0.0875365692190826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131947573 . Total output tokens: 116280818
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 42.55484210094437,
    "estimated_duration": 3600.0476737023428,
    "input_throughput": 6641.532603764319,
    "output_throughput": 5825.361189851276,
    "total_throughput": 12466.893793615596,
    "itl": 90.74089132471694,
    "ttft": 1415792.6062879735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 45,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3225675552897157,
    "arrivals": 196793,
    "finished_requests": 97003,
    "scheduler_time": 187.15585825468656
}
#Debug simulation 
Total elapsed time: 42.555036541074514. Arrivals time: 0.6078483960591257 Scheduler time: 41.71922262851149 Scheduler overhead time: 0.09063645405694842 Adapter cache time: 0.014813338406383991 Engine time: 0.08854187745600939 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_96_slots_32_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_96_slots_32_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131471813 . Total output tokens: 115846880
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 43.379339542705566,
    "estimated_duration": 3600.06308858183,
    "input_throughput": 6915.174925394681,
    "output_throughput": 6051.394229477769,
    "total_throughput": 12966.56915487245,
    "itl": 99.51145550796382,
    "ttft": 1363586.967698932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 43,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.28433358837384715,
    "arrivals": 196113,
    "finished_requests": 100826,
    "scheduler_time": 180.16387600416022
}
#Debug simulation 
Total elapsed time: 43.37956608599052. Arrivals time: 0.6234166491776705 Scheduler time: 42.53650711197406 Scheduler overhead time: 0.08774002874270082 Adapter cache time: 0.013728068675845861 Engine time: 0.08672712463885546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_96_slots_32_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_96_slots_32_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131471813 . Total output tokens: 115846880
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 42.353683448862284,
    "estimated_duration": 3600.085248361738,
    "input_throughput": 6843.522666917813,
    "output_throughput": 5986.2721333632535,
    "total_throughput": 12829.794800281066,
    "itl": 96.8423376871815,
    "ttft": 1376830.9800466027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 43,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30782590380404157,
    "arrivals": 196113,
    "finished_requests": 99760,
    "scheduler_time": 181.9657975978996
}
#Debug simulation 
Total elapsed time: 42.35393218928948. Arrivals time: 0.6196113568730652 Scheduler time: 41.513641093391925 Scheduler overhead time: 0.08831204939633608 Adapter cache time: 0.014505709055811167 Engine time: 0.08533956622704864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_96_slots_32_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_96_slots_32_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131471813 . Total output tokens: 115846880
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 38.14056924497709,
    "estimated_duration": 3600.0283732277626,
    "input_throughput": 6657.099754609007,
    "output_throughput": 5823.940210004985,
    "total_throughput": 12481.039964613992,
    "itl": 90.55432395985835,
    "ttft": 1410180.1363121192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 43,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3148038335703314,
    "arrivals": 196113,
    "finished_requests": 97032,
    "scheduler_time": 186.66951002702336
}
#Debug simulation 
Total elapsed time: 38.140767531935126. Arrivals time: 0.5905460519716144 Scheduler time: 37.335655230563134 Scheduler overhead time: 0.08581798197701573 Adapter cache time: 0.0135187734849751 Engine time: 0.0834908727556467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_96_slots_32_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_96_slots_32_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131471813 . Total output tokens: 115846880
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 42.237687113229185,
    "estimated_duration": 3600.0156294951425,
    "input_throughput": 6843.681954640592,
    "output_throughput": 5986.29928810121,
    "total_throughput": 12829.981242741802,
    "itl": 96.84195271783538,
    "ttft": 1376874.274076816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 43,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2925554730976001,
    "arrivals": 196113,
    "finished_requests": 99761,
    "scheduler_time": 181.96166239568964
}
#Debug simulation 
Total elapsed time: 42.23792173014954. Arrivals time: 0.6292946203611791 Scheduler time: 41.388634908013046 Scheduler overhead time: 0.08844197355210781 Adapter cache time: 0.013806036673486233 Engine time: 0.08541302848607302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_96_slots_32_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_96_slots_32_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131471813 . Total output tokens: 115846880
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 40.769676932133734,
    "estimated_duration": 3600.0821883203744,
    "input_throughput": 6657.316346208696,
    "output_throughput": 5824.157311748042,
    "total_throughput": 12481.473657956738,
    "itl": 90.55275846538676,
    "ttft": 1410175.357876923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 43,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3125255446275697,
    "arrivals": 196113,
    "finished_requests": 97037,
    "scheduler_time": 186.6726625840681
}
#Debug simulation 
Total elapsed time: 40.76992559898645. Arrivals time: 0.5978793711401522 Scheduler time: 39.94371010037139 Scheduler overhead time: 0.08941028453409672 Adapter cache time: 0.014511356130242348 Engine time: 0.09085999522358179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_96_slots_32_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_96_slots_32_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131471813 . Total output tokens: 115846880
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 42.037230039946735,
    "estimated_duration": 3600.0157202152122,
    "input_throughput": 6843.54372722772,
    "output_throughput": 5986.243304157485,
    "total_throughput": 12829.787031385205,
    "itl": 96.84079722232401,
    "ttft": 1376826.7547031962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 43,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2745086004445329,
    "arrivals": 196113,
    "finished_requests": 99759,
    "scheduler_time": 181.9630921544969
}
#Debug simulation 
Total elapsed time: 42.03741922182962. Arrivals time: 0.5983172301203012 Scheduler time: 41.22290704911575 Scheduler overhead time: 0.08840579586103559 Adapter cache time: 0.014361198525875807 Engine time: 0.08213353110477328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_96_slots_32_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_96_slots_32_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131471813 . Total output tokens: 115846880
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 39.20949747925624,
    "estimated_duration": 3600.037385797254,
    "input_throughput": 6657.010867317054,
    "output_throughput": 5824.000629192575,
    "total_throughput": 12481.011496509629,
    "itl": 90.55242505371172,
    "ttft": 1410186.6984175567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 43,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3098330213315786,
    "arrivals": 196113,
    "finished_requests": 97032,
    "scheduler_time": 186.67136804706962
}
#Debug simulation 
Total elapsed time: 39.20967957191169. Arrivals time: 0.5817206180654466 Scheduler time: 38.4126480021514 Scheduler overhead time: 0.0845517092384398 Adapter cache time: 0.014238351490348577 Engine time: 0.08352884277701378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131242572 . Total output tokens: 115631821
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 43.283270800020546,
    "estimated_duration": 3600.052655809167,
    "input_throughput": 6955.826315371372,
    "output_throughput": 6049.895399406214,
    "total_throughput": 13005.721714777586,
    "itl": 99.52934121386815,
    "ttft": 1360090.437078094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3372328606294466,
    "arrivals": 195753,
    "finished_requests": 101197,
    "scheduler_time": 180.18153923985955
}
#Debug simulation 
Total elapsed time: 43.28352685738355. Arrivals time: 0.6319878930225968 Scheduler time: 42.43000281788409 Scheduler overhead time: 0.08950791880488396 Adapter cache time: 0.014851126819849014 Engine time: 0.08523780247196555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131242572 . Total output tokens: 115631821
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 40.70852743089199,
    "estimated_duration": 3600.0347815074483,
    "input_throughput": 6883.857658070442,
    "output_throughput": 5986.580493807212,
    "total_throughput": 12870.438151877655,
    "itl": 96.86578728270355,
    "ttft": 1373025.1722176995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.36583837619516996,
    "arrivals": 195753,
    "finished_requests": 100156,
    "scheduler_time": 181.97791308383864
}
#Debug simulation 
Total elapsed time: 40.70867570396513. Arrivals time: 0.6087411837652326 Scheduler time: 39.88262580893934 Scheduler overhead time: 0.08772880863398314 Adapter cache time: 0.014201605692505836 Engine time: 0.0832059197127819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131242572 . Total output tokens: 115631821
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 37.404745783191174,
    "estimated_duration": 3600.055227528243,
    "input_throughput": 6689.286268681575,
    "output_throughput": 5824.443702880805,
    "total_throughput": 12513.729971562381,
    "itl": 90.6063661942815,
    "ttft": 1407049.2977497876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3742860013758765,
    "arrivals": 195753,
    "finished_requests": 97396,
    "scheduler_time": 186.67120380393237
}
#Debug simulation 
Total elapsed time: 37.40491570532322. Arrivals time: 0.5886708972975612 Scheduler time: 36.6008375948295 Scheduler overhead time: 0.08594985213130713 Adapter cache time: 0.013895063661038876 Engine time: 0.08324953494593501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131242572 . Total output tokens: 115631821
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 41.1575123956427,
    "estimated_duration": 3600.0619703355183,
    "input_throughput": 6884.020109712246,
    "output_throughput": 5986.600835649334,
    "total_throughput": 12870.62094536158,
    "itl": 96.86525173923648,
    "ttft": 1372995.00129104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.34779150354210286,
    "arrivals": 195753,
    "finished_requests": 100159,
    "scheduler_time": 181.97906788905328
}
#Debug simulation 
Total elapsed time: 41.15776177775115. Arrivals time: 0.623561336658895 Scheduler time: 40.316481991205364 Scheduler overhead time: 0.08839728683233261 Adapter cache time: 0.0137992431409657 Engine time: 0.08337230468168855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131242572 . Total output tokens: 115631821
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 36.361885372083634,
    "estimated_duration": 3600.0692007750786,
    "input_throughput": 6689.278082436661,
    "output_throughput": 5824.346652971469,
    "total_throughput": 12513.62473540813,
    "itl": 90.60530264042924,
    "ttft": 1407048.7537235597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.37159347807988535,
    "arrivals": 195753,
    "finished_requests": 97397,
    "scheduler_time": 186.67149746510196
}
#Debug simulation 
Total elapsed time: 36.362043539993465. Arrivals time: 0.5806418345309794 Scheduler time: 35.5680450364016 Scheduler overhead time: 0.08519443916156888 Adapter cache time: 0.013846388552337885 Engine time: 0.08209147956222296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131242572 . Total output tokens: 115631821
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 41.81162839801982,
    "estimated_duration": 3600.031911482119,
    "input_throughput": 6883.833424075771,
    "output_throughput": 5986.483322901246,
    "total_throughput": 12870.316746977018,
    "itl": 96.86563544277516,
    "ttft": 1372970.385488289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32557996796909733,
    "arrivals": 195753,
    "finished_requests": 100156,
    "scheduler_time": 181.97706695501412
}
#Debug simulation 
Total elapsed time: 41.811791830696166. Arrivals time: 0.6739159827120602 Scheduler time: 40.91897859564051 Scheduler overhead time: 0.08933209488168359 Adapter cache time: 0.013792380690574646 Engine time: 0.08344101626425982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131242572 . Total output tokens: 115631821
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 37.725197929888964,
    "estimated_duration": 3600.013559536112,
    "input_throughput": 6689.432026223575,
    "output_throughput": 5824.496672924175,
    "total_throughput": 12513.92869914775,
    "itl": 90.60479202813599,
    "ttft": 1407030.1279817468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3682796032540501,
    "arrivals": 195753,
    "finished_requests": 97398,
    "scheduler_time": 186.6698299563814
}
#Debug simulation 
Total elapsed time: 37.725390585139394. Arrivals time: 0.6052767103537917 Scheduler time: 36.9027035208419 Scheduler overhead time: 0.08677510637789965 Adapter cache time: 0.014145108871161938 Engine time: 0.08331646956503391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129068469 . Total output tokens: 113695764
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 30.371929332148284,
    "estimated_duration": 3600.050220939315,
    "input_throughput": 6922.820091520082,
    "output_throughput": 6050.521982528526,
    "total_throughput": 12973.342074048607,
    "itl": 99.51570521968597,
    "ttft": 1365565.1170906576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.26449636127799736,
    "arrivals": 192543,
    "finished_requests": 100697,
    "scheduler_time": 179.9839680656635
}
#Debug simulation 
Total elapsed time: 30.3720770990476. Arrivals time: 0.5825908961705863 Scheduler time: 29.601244749035686 Scheduler overhead time: 0.07418820774182677 Adapter cache time: 0.01224447786808014 Engine time: 0.07259970670565963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129068469 . Total output tokens: 113695764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 29.82855353690684,
    "estimated_duration": 3600.054204051047,
    "input_throughput": 6850.0657496351205,
    "output_throughput": 5987.0779100342625,
    "total_throughput": 12837.143659669382,
    "itl": 96.86151983334571,
    "ttft": 1378118.7612025698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.287285920009017,
    "arrivals": 192543,
    "finished_requests": 99607,
    "scheduler_time": 181.78680772285855
}
#Debug simulation 
Total elapsed time: 29.82873891526833. Arrivals time: 0.5600585825741291 Scheduler time: 29.07928519556299 Scheduler overhead time: 0.07548625720664859 Adapter cache time: 0.012028896249830723 Engine time: 0.07258977741003036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129068469 . Total output tokens: 113695764
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 27.872751167975366,
    "estimated_duration": 3600.0442650888926,
    "input_throughput": 6660.35588298744,
    "output_throughput": 5821.977858231271,
    "total_throughput": 12482.33374121871,
    "itl": 90.56308443225002,
    "ttft": 1412409.032262046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2939932262385265,
    "arrivals": 192543,
    "finished_requests": 96837,
    "scheduler_time": 186.49394833465618
}
#Debug simulation 
Total elapsed time: 27.873028353322297. Arrivals time: 0.5395773695781827 Scheduler time: 27.139608458150178 Scheduler overhead time: 0.07574489573016763 Adapter cache time: 0.012307634577155113 Engine time: 0.0742509039118886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129068469 . Total output tokens: 113695764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 29.882567503955215,
    "estimated_duration": 3600.007473098587,
    "input_throughput": 6849.970224860331,
    "output_throughput": 5986.98118297205,
    "total_throughput": 12836.951407832381,
    "itl": 96.86325459287762,
    "ttft": 1378116.4131683966,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2720154893025757,
    "arrivals": 192543,
    "finished_requests": 99603,
    "scheduler_time": 181.78411317677558
}
#Debug simulation 
Total elapsed time: 29.882688615936786. Arrivals time: 0.5628025620244443 Scheduler time: 29.12951399339363 Scheduler overhead time: 0.07556595653295517 Adapter cache time: 0.012193663511425257 Engine time: 0.07266678614541888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129068469 . Total output tokens: 113695764
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 27.158145517110825,
    "estimated_duration": 3600.0324963688677,
    "input_throughput": 6660.499043879508,
    "output_throughput": 5822.094945293076,
    "total_throughput": 12482.593989172585,
    "itl": 90.56371179667279,
    "ttft": 1412332.5515262494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29171493729576475,
    "arrivals": 192543,
    "finished_requests": 96839,
    "scheduler_time": 186.49285143235434
}
#Debug simulation 
Total elapsed time: 27.158366270828992. Arrivals time: 0.5414176289923489 Scheduler time: 26.426424080040306 Scheduler overhead time: 0.07456990890204906 Adapter cache time: 0.012031656689941883 Engine time: 0.073072315659374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129068469 . Total output tokens: 113695764
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 29.782892739400268,
    "estimated_duration": 3600.016503846463,
    "input_throughput": 6850.107485243836,
    "output_throughput": 5987.083941690518,
    "total_throughput": 12837.191426934354,
    "itl": 96.86107987230467,
    "ttft": 1378087.6970051525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.25535683762282124,
    "arrivals": 192543,
    "finished_requests": 99607,
    "scheduler_time": 181.78468597779843
}
#Debug simulation 
Total elapsed time: 29.78315244941041. Arrivals time: 0.5888385167345405 Scheduler time: 29.003140091896057 Scheduler overhead time: 0.0757402228191495 Adapter cache time: 0.012276469729840755 Engine time: 0.0728310588747263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129068469 . Total output tokens: 113695764
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 27.399075279012322,
    "estimated_duration": 3600.032967021213,
    "input_throughput": 6660.310674832415,
    "output_throughput": 5821.904463653346,
    "total_throughput": 12482.215138485763,
    "itl": 90.56394226407188,
    "ttft": 1412329.823784044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 40,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.28922953117638833,
    "arrivals": 192543,
    "finished_requests": 96834,
    "scheduler_time": 186.4949818149687
}
#Debug simulation 
Total elapsed time: 27.399217288009822. Arrivals time: 0.5233050417155027 Scheduler time: 26.68674321519211 Scheduler overhead time: 0.07489950023591518 Adapter cache time: 0.011560483369976282 Engine time: 0.07190839108079672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128086936 . Total output tokens: 112827029
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 25.045920751988888,
    "estimated_duration": 3600.035977273523,
    "input_throughput": 6971.834770109311,
    "output_throughput": 6052.508679788813,
    "total_throughput": 13024.343449898124,
    "itl": 99.61674220599173,
    "ttft": 1358811.280717192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2777211793418972,
    "arrivals": 191076,
    "finished_requests": 101212,
    "scheduler_time": 179.5107541045612
}
#Debug simulation 
Total elapsed time: 25.046061500906944. Arrivals time: 0.561572422273457 Scheduler time: 24.30669072130695 Scheduler overhead time: 0.07040494540706277 Adapter cache time: 0.011276237666606903 Engine time: 0.0669881091453135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128086936 . Total output tokens: 112827029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 23.783533222973347,
    "estimated_duration": 3600.1040739673626,
    "input_throughput": 6900.605229621264,
    "output_throughput": 5987.543847932497,
    "total_throughput": 12888.14907755376,
    "itl": 96.95824067726888,
    "ttft": 1372207.6681475607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3028302038367838,
    "arrivals": 191076,
    "finished_requests": 100157,
    "scheduler_time": 181.29589488939737
}
#Debug simulation 
Total elapsed time: 23.7837522928603. Arrivals time: 0.5411553373560309 Scheduler time: 23.067877701949328 Scheduler overhead time: 0.06893995171412826 Adapter cache time: 0.010975095443427563 Engine time: 0.06630705250427127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128086936 . Total output tokens: 112827029
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 22.381096743047237,
    "estimated_duration": 3600.0643082767824,
    "input_throughput": 6710.155967064671,
    "output_throughput": 5825.89565185831,
    "total_throughput": 12536.05161892298,
    "itl": 90.68219157245099,
    "ttft": 1406863.4737022817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31014537298586226,
    "arrivals": 191076,
    "finished_requests": 97433,
    "scheduler_time": 185.97144171057894
}
#Debug simulation 
Total elapsed time: 22.381267107091844. Arrivals time: 0.5319488714449108 Scheduler time: 21.66885494068265 Scheduler overhead time: 0.07036494323983788 Adapter cache time: 0.011103656142950058 Engine time: 0.06863947259262204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128086936 . Total output tokens: 112827029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 23.770373124163598,
    "estimated_duration": 3600.0868107753136,
    "input_throughput": 6900.631097462299,
    "output_throughput": 5987.505616665339,
    "total_throughput": 12888.136714127639,
    "itl": 96.95576452395188,
    "ttft": 1372221.0330753464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2875597731303423,
    "arrivals": 191076,
    "finished_requests": 100156,
    "scheduler_time": 181.29550862804888
}
#Debug simulation 
Total elapsed time: 23.770548823289573. Arrivals time: 0.5328933047130704 Scheduler time: 23.06341387750581 Scheduler overhead time: 0.06853283429518342 Adapter cache time: 0.010691173374652863 Engine time: 0.06629810994490981 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128086936 . Total output tokens: 112827029
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 22.518558693584055,
    "estimated_duration": 3600.037415229656,
    "input_throughput": 6710.188315767537,
    "output_throughput": 5826.165836852,
    "total_throughput": 12536.354152619537,
    "itl": 90.6803544397186,
    "ttft": 1406835.7340949718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3078670840431005,
    "arrivals": 191076,
    "finished_requests": 97440,
    "scheduler_time": 185.96759590721857
}
#Debug simulation 
Total elapsed time: 22.518769728951156. Arrivals time: 0.5081694978289306 Scheduler time: 21.830174319911748 Scheduler overhead time: 0.07091489201411605 Adapter cache time: 0.011236579157412052 Engine time: 0.06864370591938496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128086936 . Total output tokens: 112827029
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 23.840664237737656,
    "estimated_duration": 3600.0457525901948,
    "input_throughput": 6900.47507927543,
    "output_throughput": 5987.527515307586,
    "total_throughput": 12888.002594583017,
    "itl": 96.95702259796302,
    "ttft": 1372218.838711179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.26812467950396235,
    "arrivals": 191076,
    "finished_requests": 100153,
    "scheduler_time": 181.29345823050912
}
#Debug simulation 
Total elapsed time: 23.840797995682806. Arrivals time: 0.5368636818602681 Scheduler time: 23.12867655744776 Scheduler overhead time: 0.06857167184352875 Adapter cache time: 0.010724341031163931 Engine time: 0.06703074555844069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128086936 . Total output tokens: 112827029
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 22.679649414028972,
    "estimated_duration": 3600.0072867100516,
    "input_throughput": 6710.043640515988,
    "output_throughput": 5825.582097408993,
    "total_throughput": 12535.625737924982,
    "itl": 90.68041373901548,
    "ttft": 1407020.5086477287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30496744357049466,
    "arrivals": 191076,
    "finished_requests": 97429,
    "scheduler_time": 185.96776429483256
}
#Debug simulation 
Total elapsed time: 22.679903607815504. Arrivals time: 0.5322170946747065 Scheduler time: 21.96455928031355 Scheduler overhead time: 0.07159577822312713 Adapter cache time: 0.011342987418174744 Engine time: 0.06946252938359976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127596119 . Total output tokens: 112385386
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 23.137122755870223,
    "estimated_duration": 3600.062061979258,
    "input_throughput": 6953.989283794808,
    "output_throughput": 6053.012316131996,
    "total_throughput": 13007.001599926805,
    "itl": 99.54142410810252,
    "ttft": 1360058.5063621504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24465913418214755,
    "arrivals": 190312,
    "finished_requests": 100996,
    "scheduler_time": 179.4736780894823
}
#Debug simulation 
Total elapsed time: 23.137326641008258. Arrivals time: 0.5952406856231391 Scheduler time: 22.367209356743842 Scheduler overhead time: 0.06910830084234476 Adapter cache time: 0.010354848112910986 Engine time: 0.06645499775186181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127596119 . Total output tokens: 112385386
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 21.618664897978306,
    "estimated_duration": 3600.012280324393,
    "input_throughput": 6876.616542477259,
    "output_throughput": 5990.198732893439,
    "total_throughput": 12866.815275370698,
    "itl": 96.88790553448827,
    "ttft": 1372456.9239561865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2653577152406797,
    "arrivals": 190312,
    "finished_requests": 99874,
    "scheduler_time": 181.27316907756352
}
#Debug simulation 
Total elapsed time: 21.618802829179913. Arrivals time: 0.4845873252488673 Scheduler time: 20.9699180056341 Scheduler overhead time: 0.06352194538339972 Adapter cache time: 0.010139356832951307 Engine time: 0.06298279156908393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127596119 . Total output tokens: 112385386
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 20.235074444208294,
    "estimated_duration": 3600.0502730892445,
    "input_throughput": 6691.511276960109,
    "output_throughput": 5825.794755361207,
    "total_throughput": 12517.306032321316,
    "itl": 90.5831025940702,
    "ttft": 1407080.373734046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.27147381251212216,
    "arrivals": 190312,
    "finished_requests": 97151,
    "scheduler_time": 185.98943627080945
}
#Debug simulation 
Total elapsed time: 20.235241174232215. Arrivals time: 0.46256500482559204 Scheduler time: 19.600543205160648 Scheduler overhead time: 0.06721171643584967 Adapter cache time: 0.010749017354100943 Engine time: 0.06501796189695597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127596119 . Total output tokens: 112385386
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 22.153895798604935,
    "estimated_duration": 3600.029627090977,
    "input_throughput": 6876.442575280617,
    "output_throughput": 5990.153202551694,
    "total_throughput": 12866.595777832312,
    "itl": 96.88674897846032,
    "ttft": 1372428.417540156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2500872845342383,
    "arrivals": 190312,
    "finished_requests": 99874,
    "scheduler_time": 181.27514166167052
}
#Debug simulation 
Total elapsed time: 22.15413317969069. Arrivals time: 0.5254157818853855 Scheduler time: 21.457602229900658 Scheduler overhead time: 0.06683824816718698 Adapter cache time: 0.010497343260794878 Engine time: 0.064838791731745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127596119 . Total output tokens: 112385386
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 21.086886022705585,
    "estimated_duration": 3600.01332552012,
    "input_throughput": 6691.753563584236,
    "output_throughput": 5825.982601597673,
    "total_throughput": 12517.73616518191,
    "itl": 90.5825051982674,
    "ttft": 1407042.2120012317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.26919552356936044,
    "arrivals": 190312,
    "finished_requests": 97154,
    "scheduler_time": 185.98778527195216
}
#Debug simulation 
Total elapsed time: 21.087048510089517. Arrivals time: 0.5122672459110618 Scheduler time: 20.394504924304783 Scheduler overhead time: 0.07056901371106505 Adapter cache time: 0.011271224357187748 Engine time: 0.0681488374248147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127596119 . Total output tokens: 112385386
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 21.440888260956854,
    "estimated_duration": 3600.019282417225,
    "input_throughput": 6876.461779220817,
    "output_throughput": 5990.150970947149,
    "total_throughput": 12866.612750167966,
    "itl": 96.88514450898856,
    "ttft": 1372462.5310021648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23620507480110967,
    "arrivals": 190312,
    "finished_requests": 99872,
    "scheduler_time": 181.27573739592654
}
#Debug simulation 
Total elapsed time: 21.440990841947496. Arrivals time: 0.4898667591623962 Scheduler time: 20.786079307086766 Scheduler overhead time: 0.06428049830719829 Adapter cache time: 0.010133066680282354 Engine time: 0.06289403699338436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127596119 . Total output tokens: 112385386
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 21.131878823041916,
    "estimated_duration": 3600.0320453137388,
    "input_throughput": 6691.84987710311,
    "output_throughput": 5826.083694811147,
    "total_throughput": 12517.933571914258,
    "itl": 90.58332378238957,
    "ttft": 1407025.1495121128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2671243518032134,
    "arrivals": 190312,
    "finished_requests": 97155,
    "scheduler_time": 185.9880193612368
}
#Debug simulation 
Total elapsed time: 21.132034114096314. Arrivals time: 0.5100523857399821 Scheduler time: 20.44465350639075 Scheduler overhead time: 0.06859721569344401 Adapter cache time: 0.010858308523893356 Engine time: 0.06782261282205582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127365839 . Total output tokens: 112176000
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 21.56711232662201,
    "estimated_duration": 3600.0556824126847,
    "input_throughput": 6936.441322836583,
    "output_throughput": 6052.653326016573,
    "total_throughput": 12989.094648853155,
    "itl": 99.6068857223081,
    "ttft": 1360763.9139678418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2711087703099473,
    "arrivals": 189952,
    "finished_requests": 101156,
    "scheduler_time": 179.52848680504994
}
#Debug simulation 
Total elapsed time: 21.567218016833067. Arrivals time: 0.5413881973363459 Scheduler time: 20.855653802864254 Scheduler overhead time: 0.06633023079484701 Adapter cache time: 0.010365271009504795 Engine time: 0.06519897375255823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127365839 . Total output tokens: 112176000
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 20.754009197000414,
    "estimated_duration": 3600.0846673086257,
    "input_throughput": 6864.594664790257,
    "output_throughput": 5989.212752632069,
    "total_throughput": 12853.807417422326,
    "itl": 96.9192657593384,
    "ttft": 1373689.3934847193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.297834503869526,
    "arrivals": 189952,
    "finished_requests": 100127,
    "scheduler_time": 181.3416667641267
}
#Debug simulation 
Total elapsed time: 20.75416910368949. Arrivals time: 0.5248465668410063 Scheduler time: 20.056951413862407 Scheduler overhead time: 0.06769703747704625 Adapter cache time: 0.01092213811352849 Engine time: 0.0651817861944437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127365839 . Total output tokens: 112176000
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 18.98157990258187,
    "estimated_duration": 3600.098872893385,
    "input_throughput": 6676.682738072076,
    "output_throughput": 5823.500059360973,
    "total_throughput": 12500.18279743305,
    "itl": 90.60191228242545,
    "ttft": 1407765.537919336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30548691240139314,
    "arrivals": 189952,
    "finished_requests": 97330,
    "scheduler_time": 186.07221459581777
}
#Debug simulation 
Total elapsed time: 18.98179645370692. Arrivals time: 0.47482609702274203 Scheduler time: 18.330118080601096 Scheduler overhead time: 0.06903531635180116 Adapter cache time: 0.011097464710474014 Engine time: 0.06681810924783349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127365839 . Total output tokens: 112176000
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 20.18120504496619,
    "estimated_duration": 3600.0384579808374,
    "input_throughput": 6864.470001762282,
    "output_throughput": 5988.96213239141,
    "total_throughput": 12853.432134153692,
    "itl": 96.91571302720209,
    "ttft": 1373747.1175617042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.27978763121645894,
    "arrivals": 189952,
    "finished_requests": 100122,
    "scheduler_time": 181.3421338890618
}
#Debug simulation 
Total elapsed time: 20.18131373403594. Arrivals time: 0.4973325119353831 Scheduler time: 19.516261069104075 Scheduler overhead time: 0.06513350829482079 Adapter cache time: 0.010274739935994148 Engine time: 0.06384540116414428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127365839 . Total output tokens: 112176000
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 19.433700527995825,
    "estimated_duration": 3600.0694814391404,
    "input_throughput": 6676.671415350387,
    "output_throughput": 5823.4989930303145,
    "total_throughput": 12500.170408380702,
    "itl": 90.60087771341867,
    "ttft": 1407781.3224047197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30279438910540196,
    "arrivals": 189952,
    "finished_requests": 97328,
    "scheduler_time": 186.07020362311977
}
#Debug simulation 
Total elapsed time: 19.43385127512738. Arrivals time: 0.5363985160365701 Scheduler time: 18.718075060285628 Scheduler overhead time: 0.07035782467573881 Adapter cache time: 0.010974701028317213 Engine time: 0.06762274820357561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127365839 . Total output tokens: 112176000
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 20.76680520037189,
    "estimated_duration": 3600.0903521558134,
    "input_throughput": 6864.583825014624,
    "output_throughput": 5989.2032951585215,
    "total_throughput": 12853.787120173147,
    "itl": 96.91932366560127,
    "ttft": 1373665.0114952188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2617407585633918,
    "arrivals": 189952,
    "finished_requests": 100127,
    "scheduler_time": 181.34222451705224
}
#Debug simulation 
Total elapsed time: 20.767011624295264. Arrivals time: 0.507050534710288 Scheduler time: 20.088395641185343 Scheduler overhead time: 0.06744819227606058 Adapter cache time: 0.010493918787688017 Engine time: 0.06508619105443358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127365839 . Total output tokens: 112176000
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 18.500741203781217,
    "estimated_duration": 3600.018078905975,
    "input_throughput": 6676.766747600487,
    "output_throughput": 5823.582143334998,
    "total_throughput": 12500.348890935486,
    "itl": 90.60270574949611,
    "ttft": 1407735.3233801252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 41,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30010186580941084,
    "arrivals": 189952,
    "finished_requests": 97328,
    "scheduler_time": 186.06766025557744
}
#Debug simulation 
Total elapsed time: 18.50089758588001. Arrivals time: 0.48238482931628823 Scheduler time: 17.845115888863802 Scheduler overhead time: 0.06720563024282455 Adapter cache time: 0.010629966855049133 Engine time: 0.06597635196521878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126214022 . Total output tokens: 111087844
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 16.72672011097893,
    "estimated_duration": 3600.046067615686,
    "input_throughput": 6972.093836739056,
    "output_throughput": 6053.741977372535,
    "total_throughput": 13025.835814111591,
    "itl": 99.53109027063428,
    "ttft": 1358085.7895278865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21820949805434783,
    "arrivals": 188134,
    "finished_requests": 101607,
    "scheduler_time": 178.77785314898392
}
#Debug simulation 
Total elapsed time: 16.726874655112624. Arrivals time: 0.488339904230088 Scheduler time: 16.07816075347364 Scheduler overhead time: 0.061858661472797394 Adapter cache time: 0.00977057870477438 Engine time: 0.06099532078951597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126214022 . Total output tokens: 111087844
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 16.054846132174134,
    "estimated_duration": 3600.041563476864,
    "input_throughput": 6896.524543461582,
    "output_throughput": 5991.833877375351,
    "total_throughput": 12888.358420836932,
    "itl": 96.86922382534519,
    "ttft": 1371535.721171983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2384338105050847,
    "arrivals": 188134,
    "finished_requests": 100487,
    "scheduler_time": 180.58803596860943
}
#Debug simulation 
Total elapsed time: 16.05501650320366. Arrivals time: 0.4510147492401302 Scheduler time: 15.441647280938923 Scheduler overhead time: 0.0631348961032927 Adapter cache time: 0.009989540558308363 Engine time: 0.06126178801059723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126214022 . Total output tokens: 111087844
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 15.364473395980895,
    "estimated_duration": 3600.0856372054673,
    "input_throughput": 6706.072141867252,
    "output_throughput": 5826.084186230965,
    "total_throughput": 12532.156328098217,
    "itl": 90.57970210433304,
    "ttft": 1406316.1429537563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24429593820124867,
    "arrivals": 188134,
    "finished_requests": 97669,
    "scheduler_time": 185.28423117431896
}
#Debug simulation 
Total elapsed time: 15.36463155830279. Arrivals time: 0.463219101075083 Scheduler time: 14.731691150460392 Scheduler overhead time: 0.06546422839164734 Adapter cache time: 0.010585821699351072 Engine time: 0.06398391770198941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126214022 . Total output tokens: 111087844
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 16.41120587196201,
    "estimated_duration": 3600.062129716014,
    "input_throughput": 6896.4857009171965,
    "output_throughput": 5991.907423470388,
    "total_throughput": 12888.393124387585,
    "itl": 96.8698768205939,
    "ttft": 1371432.5826517376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.22455160077195613,
    "arrivals": 188134,
    "finished_requests": 100488,
    "scheduler_time": 180.5893899675612
}
#Debug simulation 
Total elapsed time: 16.411365013103932. Arrivals time: 0.4873588909395039 Scheduler time: 15.759991914965212 Scheduler overhead time: 0.06336653092876077 Adapter cache time: 0.010043160058557987 Engine time: 0.062109410762786865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126214022 . Total output tokens: 111087844
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 14.999211895279586,
    "estimated_duration": 3600.05448502121,
    "input_throughput": 6706.182670415268,
    "output_throughput": 5826.209599679552,
    "total_throughput": 12532.39227009482,
    "itl": 90.58220105520894,
    "ttft": 1406306.1069428576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24222476643510163,
    "arrivals": 188134,
    "finished_requests": 97671,
    "scheduler_time": 185.279837214609
}
#Debug simulation 
Total elapsed time: 14.999354369007051. Arrivals time: 0.4176887394860387 Scheduler time: 14.41620902903378 Scheduler overhead time: 0.06380028184503317 Adapter cache time: 0.00998725974932313 Engine time: 0.0630721258930862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126214022 . Total output tokens: 111087844
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 16.417088948655874,
    "estimated_duration": 3600.0416604457782,
    "input_throughput": 6896.784910240612,
    "output_throughput": 5991.888159796725,
    "total_throughput": 12888.673070037337,
    "itl": 96.86925134847839,
    "ttft": 1371512.2230155275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21066939103882756,
    "arrivals": 188134,
    "finished_requests": 100489,
    "scheduler_time": 180.58882695617635
}
#Debug simulation 
Total elapsed time: 16.417244048789144. Arrivals time: 0.4848144273273647 Scheduler time: 15.766825556755066 Scheduler overhead time: 0.06398994475603104 Adapter cache time: 0.010110646020621061 Engine time: 0.06275896960869431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_96_slots_32_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126214022 . Total output tokens: 111087844
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 15.302935439161956,
    "estimated_duration": 3600.0764013543135,
    "input_throughput": 6706.007958863863,
    "output_throughput": 5826.016634566352,
    "total_throughput": 12532.024593430215,
    "itl": 90.58245153968296,
    "ttft": 1406277.0714559383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2401535946689546,
    "arrivals": 188134,
    "finished_requests": 97668,
    "scheduler_time": 185.28199050492285
}
#Debug simulation 
Total elapsed time: 15.303056648001075. Arrivals time: 0.4417313658632338 Scheduler time: 14.691404378507286 Scheduler overhead time: 0.06580328568816185 Adapter cache time: 0.01052223751321435 Engine time: 0.06403023982420564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125709773 . Total output tokens: 110652460
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 14.961905905045569,
    "estimated_duration": 3600.055094185051,
    "input_throughput": 6948.059222872063,
    "output_throughput": 6052.325986675583,
    "total_throughput": 13000.385209547647,
    "itl": 99.6202601780755,
    "ttft": 1365518.0935249128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21820949805434783,
    "arrivals": 187468,
    "finished_requests": 101003,
    "scheduler_time": 178.97818641591147
}
#Debug simulation 
Total elapsed time: 14.962108145933598. Arrivals time: 0.4573186547495425 Scheduler time: 14.347925666719675 Scheduler overhead time: 0.06054105190560222 Adapter cache time: 0.009596080519258976 Engine time: 0.059587926138192415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125709773 . Total output tokens: 110652460
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 14.748237024992704,
    "estimated_duration": 3600.0444566872466,
    "input_throughput": 6873.821225744327,
    "output_throughput": 5988.46271466278,
    "total_throughput": 12862.283940407107,
    "itl": 96.95226206514195,
    "ttft": 1378637.2407005534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2370455895317719,
    "arrivals": 187468,
    "finished_requests": 99935,
    "scheduler_time": 180.7767330593233
}
#Debug simulation 
Total elapsed time: 14.748458908870816. Arrivals time: 0.45224175276234746 Scheduler time: 14.134633915033191 Scheduler overhead time: 0.062272186391055584 Adapter cache time: 0.00981695530936122 Engine time: 0.061093148309737444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125709773 . Total output tokens: 110652460
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 13.920982130337507,
    "estimated_duration": 3600.005823705048,
    "input_throughput": 6676.721699095038,
    "output_throughput": 5826.436130154027,
    "total_throughput": 12503.157829249065,
    "itl": 90.68388168170338,
    "ttft": 1412429.4973023867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2425871318066493,
    "arrivals": 187468,
    "finished_requests": 97123,
    "scheduler_time": 185.44749527556561
}
#Debug simulation 
Total elapsed time: 13.921104312408715. Arrivals time: 0.42102038068696856 Scheduler time: 13.333237458020449 Scheduler overhead time: 0.06382399518042803 Adapter cache time: 0.010206814855337143 Engine time: 0.06359572941437364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125709773 . Total output tokens: 110652460
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 14.777691189199686,
    "estimated_duration": 3600.0212837923173,
    "input_throughput": 6873.865471687468,
    "output_throughput": 5988.501261661904,
    "total_throughput": 12862.366733349372,
    "itl": 96.94945932989853,
    "ttft": 1378644.9257818125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.22455160077195613,
    "arrivals": 187468,
    "finished_requests": 99935,
    "scheduler_time": 180.77748853368766
}
#Debug simulation 
Total elapsed time: 14.777845384087414. Arrivals time: 0.48903033789247274 Scheduler time: 14.127738596405834 Scheduler overhead time: 0.06207416066899896 Adapter cache time: 0.009866092819720507 Engine time: 0.06105939904227853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125709773 . Total output tokens: 110652460
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 13.74130079196766,
    "estimated_duration": 3600.075539026102,
    "input_throughput": 6676.809900078522,
    "output_throughput": 5826.393855522908,
    "total_throughput": 12503.20375560143,
    "itl": 90.6836210903659,
    "ttft": 1412468.6680191138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24072307721711697,
    "arrivals": 187468,
    "finished_requests": 97125,
    "scheduler_time": 185.4523143976646
}
#Debug simulation 
Total elapsed time: 13.741410435643047. Arrivals time: 0.4236302715726197 Scheduler time: 13.152905963826925 Scheduler overhead time: 0.06347775040194392 Adapter cache time: 0.010041594039648771 Engine time: 0.0625527510419488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125709773 . Total output tokens: 110652460
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 14.486206525936723,
    "estimated_duration": 3600.0224289735816,
    "input_throughput": 6873.8635628599295,
    "output_throughput": 5988.531023165525,
    "total_throughput": 12862.394586025453,
    "itl": 96.9509884542983,
    "ttft": 1378596.1234766487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21066939103882756,
    "arrivals": 187468,
    "finished_requests": 99936,
    "scheduler_time": 180.77619664277807
}
#Debug simulation 
Total elapsed time: 14.486315325833857. Arrivals time: 0.43568443274125457 Scheduler time: 13.892621934879571 Scheduler overhead time: 0.06083294237032533 Adapter cache time: 0.009795964229851961 Engine time: 0.059822387993335724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_96_slots_32_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125709773 . Total output tokens: 110652460
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 14.081669291947037,
    "estimated_duration": 3600.013831714552,
    "input_throughput": 6677.038790307056,
    "output_throughput": 5826.527058094695,
    "total_throughput": 12503.565848401751,
    "itl": 90.6824302757043,
    "ttft": 1412512.8358651977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23865190545096995,
    "arrivals": 187468,
    "finished_requests": 97124,
    "scheduler_time": 185.45002506728602
}
#Debug simulation 
Total elapsed time: 14.081920140888542. Arrivals time: 0.4290858409367502 Scheduler time: 13.484804960899055 Scheduler overhead time: 0.06466413335874677 Adapter cache time: 0.01034128200262785 Engine time: 0.06353364093229175 
