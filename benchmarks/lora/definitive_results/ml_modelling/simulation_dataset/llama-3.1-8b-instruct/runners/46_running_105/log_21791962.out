INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972636 . Total output tokens: 21965048
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.844536276999861,
    "estimated_duration": 3600.0054109441144,
    "input_throughput": 2601.977755789938,
    "output_throughput": 2228.1069288438684,
    "total_throughput": 4830.084684633806,
    "itl": 33.95672553728745,
    "ttft": 10013.519233406909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 37601,
    "finished_requests": 37496,
    "scheduler_time": 13.493517132684095
}
#Debug simulation 
Total elapsed time: 2.8446651808917522. Arrivals time: 0.09640544978901744 Scheduler time: 2.4469299875199795 Scheduler overhead time: 0.10191178321838379 Adapter cache time: 0.0494110519066453 Engine time: 0.10167317604646087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972636 . Total output tokens: 21965048
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.807954213116318,
    "estimated_duration": 3600.00511824998,
    "input_throughput": 2601.9779673406447,
    "output_throughput": 2228.1071099974524,
    "total_throughput": 4830.085077338097,
    "itl": 33.956887600993625,
    "ttft": 10013.487295199513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489667,
    "arrivals": 37601,
    "finished_requests": 37496,
    "scheduler_time": 13.493771955590693
}
#Debug simulation 
Total elapsed time: 2.8080523791722953. Arrivals time: 0.09390982566401362 Scheduler time: 2.415399928111583 Scheduler overhead time: 0.10217432025820017 Adapter cache time: 0.05008465377613902 Engine time: 0.09849082585424185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972636 . Total output tokens: 21965048
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.81504845386371,
    "estimated_duration": 3600.0306562154487,
    "input_throughput": 2601.9595093801922,
    "output_throughput": 2228.0913042091497,
    "total_throughput": 4830.0508135893415,
    "itl": 33.94022985267874,
    "ttft": 10109.031209544146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 37601,
    "finished_requests": 37496,
    "scheduler_time": 13.483775275318742
}
#Debug simulation 
Total elapsed time: 2.815134568605572. Arrivals time: 0.09486073302105069 Scheduler time: 2.422195323277265 Scheduler overhead time: 0.09998290194198489 Adapter cache time: 0.04970811540260911 Engine time: 0.10030731605365872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972636 . Total output tokens: 21965048
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.8251187801361084,
    "estimated_duration": 3600.038101025833,
    "input_throughput": 2601.95412857737,
    "output_throughput": 2228.086696558671,
    "total_throughput": 4830.040825136041,
    "itl": 33.95664062326557,
    "ttft": 10109.06271340088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4391118016093971,
    "arrivals": 37601,
    "finished_requests": 37496,
    "scheduler_time": 13.493829416889152
}
#Debug simulation 
Total elapsed time: 2.825199780985713. Arrivals time: 0.09511775756254792 Scheduler time: 2.4306954531930387 Scheduler overhead time: 0.10136297205463052 Adapter cache time: 0.04980622138828039 Engine time: 0.09978395653888583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972636 . Total output tokens: 21965048
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8239324409514666,
    "estimated_duration": 3600.0250103156336,
    "input_throughput": 2601.963590019263,
    "output_throughput": 2228.09479851273,
    "total_throughput": 4830.058388531993,
    "itl": 33.95726328929935,
    "ttft": 10109.040477611818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 37601,
    "finished_requests": 37496,
    "scheduler_time": 13.493957182774519
}
#Debug simulation 
Total elapsed time: 2.824026429094374. Arrivals time: 0.09760131174698472 Scheduler time: 2.430383889004588 Scheduler overhead time: 0.10015464341267943 Adapter cache time: 0.04984382214024663 Engine time: 0.09773826831951737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972636 . Total output tokens: 21965048
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.81150387506932,
    "estimated_duration": 3600.0235407969067,
    "input_throughput": 2601.964652132935,
    "output_throughput": 2228.095708014291,
    "total_throughput": 4830.060360147227,
    "itl": 33.939286340364994,
    "ttft": 10108.95043394469,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 37601,
    "finished_requests": 37496,
    "scheduler_time": 13.483329637570277
}
#Debug simulation 
Total elapsed time: 2.8115907427854836. Arrivals time: 0.09589697746559978 Scheduler time: 2.4175946451723576 Scheduler overhead time: 0.10021189786493778 Adapter cache time: 0.04990797070786357 Engine time: 0.10016752826049924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972636 . Total output tokens: 21965048
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.838503057602793,
    "estimated_duration": 3600.024991861252,
    "input_throughput": 2601.9636033574006,
    "output_throughput": 2228.094809934348,
    "total_throughput": 4830.058413291748,
    "itl": 33.95719260949635,
    "ttft": 10109.152647228872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 37601,
    "finished_requests": 37496,
    "scheduler_time": 13.493978240800786
}
#Debug simulation 
Total elapsed time: 2.8385955719277263. Arrivals time: 0.09529176540672779 Scheduler time: 2.442404360510409 Scheduler overhead time: 0.10287306690588593 Adapter cache time: 0.04999003792181611 Engine time: 0.09990771068260074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24344640 . Total output tokens: 21401087
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.769909642636776,
    "estimated_duration": 3599.8386759342466,
    "input_throughput": 2506.840948270548,
    "output_throughput": 2202.9381630391845,
    "total_throughput": 4709.779111309733,
    "itl": 33.11797286003135,
    "ttft": 8409.459228361948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 36626,
    "finished_requests": 36541,
    "scheduler_time": 12.627786530504634
}
#Debug simulation 
Total elapsed time: 2.7699906369671226. Arrivals time: 0.09196913475170732 Scheduler time: 2.3806386860087514 Scheduler overhead time: 0.10177931096404791 Adapter cache time: 0.04624235164374113 Engine time: 0.10080302087590098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24344640 . Total output tokens: 21401087
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.812274593859911,
    "estimated_duration": 3599.851815029824,
    "input_throughput": 2506.9568036997744,
    "output_throughput": 2202.930678115788,
    "total_throughput": 4709.887481815563,
    "itl": 33.13497817684344,
    "ttft": 8311.16785150766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 36626,
    "finished_requests": 36542,
    "scheduler_time": 12.638980473956694
}
#Debug simulation 
Total elapsed time: 2.8123560566455126. Arrivals time: 0.09231124771758914 Scheduler time: 2.4214291810058057 Scheduler overhead time: 0.10252701817080379 Adapter cache time: 0.04590191692113876 Engine time: 0.1014289534650743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24344640 . Total output tokens: 21401087
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8664694810286164,
    "estimated_duration": 3599.8702164172537,
    "input_throughput": 2506.9439889368414,
    "output_throughput": 2202.91941743736,
    "total_throughput": 4709.863406374201,
    "itl": 33.13515047755273,
    "ttft": 8311.195035721217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 36626,
    "finished_requests": 36542,
    "scheduler_time": 12.639139764320364
}
#Debug simulation 
Total elapsed time: 2.8666124576702714. Arrivals time: 0.09330939780920744 Scheduler time: 2.474822951015085 Scheduler overhead time: 0.10245784604921937 Adapter cache time: 0.046348418574780226 Engine time: 0.10084136296063662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24344640 . Total output tokens: 21401087
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.862156451214105,
    "estimated_duration": 3599.838378641817,
    "input_throughput": 2506.8411552978523,
    "output_throughput": 2202.9383449686966,
    "total_throughput": 4709.779500266549,
    "itl": 33.118457090955346,
    "ttft": 8409.580916161463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939717,
    "arrivals": 36626,
    "finished_requests": 36541,
    "scheduler_time": 12.627947488840256
}
#Debug simulation 
Total elapsed time: 2.8622452621348202. Arrivals time: 0.09396858140826225 Scheduler time: 2.466070528142154 Scheduler overhead time: 0.10265165707096457 Adapter cache time: 0.046585937961936 Engine time: 0.10326347453519702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24344640 . Total output tokens: 21401087
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.839785946998745,
    "estimated_duration": 3599.840956803724,
    "input_throughput": 2506.839359928987,
    "output_throughput": 2202.9367672512935,
    "total_throughput": 4709.776127180281,
    "itl": 33.11842355637825,
    "ttft": 8409.390159198652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 36626,
    "finished_requests": 36541,
    "scheduler_time": 12.628092267943739
}
#Debug simulation 
Total elapsed time: 2.83986723376438. Arrivals time: 0.0932109896093607 Scheduler time: 2.446297475602478 Scheduler overhead time: 0.10316193010658026 Adapter cache time: 0.04657932836562395 Engine time: 0.1013407614082098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24344640 . Total output tokens: 21401087
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.854630770161748,
    "estimated_duration": 3599.8523252045975,
    "input_throughput": 2506.9564484112784,
    "output_throughput": 2202.930365914187,
    "total_throughput": 4709.886814325465,
    "itl": 33.11765163809149,
    "ttft": 8311.208759554678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 36626,
    "finished_requests": 36542,
    "scheduler_time": 12.627767140450393
}
#Debug simulation 
Total elapsed time: 2.854718097951263. Arrivals time: 0.09396331198513508 Scheduler time: 2.4583311285823584 Scheduler overhead time: 0.10258974926546216 Adapter cache time: 0.04664153791964054 Engine time: 0.10393058508634567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24344640 . Total output tokens: 21401087
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8687232830561697,
    "estimated_duration": 3599.8394260299906,
    "input_throughput": 2506.8404259220474,
    "output_throughput": 2202.9377040146715,
    "total_throughput": 4709.778129936719,
    "itl": 33.11848869451892,
    "ttft": 8409.448313772346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 36626,
    "finished_requests": 36541,
    "scheduler_time": 12.628093935915773
}
#Debug simulation 
Total elapsed time: 2.8688054527156055. Arrivals time: 0.09414485050365329 Scheduler time: 2.4748186776414514 Scheduler overhead time: 0.10226312279701233 Adapter cache time: 0.046876830980181694 Engine time: 0.1016937349922955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24033613 . Total output tokens: 21116913
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.8156660199165344,
    "estimated_duration": 3599.9387507423903,
    "input_throughput": 2467.2319767019235,
    "output_throughput": 2164.2740444940246,
    "total_throughput": 4631.506021195948,
    "itl": 32.649798099912836,
    "ttft": 7522.814336586202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 36150,
    "finished_requests": 36075,
    "scheduler_time": 11.762072602742544
}
#Debug simulation 
Total elapsed time: 2.815748924855143. Arrivals time: 0.09300932101905346 Scheduler time: 2.421442541759461 Scheduler overhead time: 0.10439380118623376 Adapter cache time: 0.04456117795780301 Engine time: 0.10259338188916445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24033613 . Total output tokens: 21116913
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8098414596170187,
    "estimated_duration": 3599.943476283626,
    "input_throughput": 2467.2287380381717,
    "output_throughput": 2164.2712035143513,
    "total_throughput": 4631.4999415525235,
    "itl": 32.628755602453836,
    "ttft": 7522.818880845933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489666,
    "arrivals": 36150,
    "finished_requests": 36075,
    "scheduler_time": 11.748145578406605
}
#Debug simulation 
Total elapsed time: 2.809920236002654. Arrivals time: 0.09352934267371893 Scheduler time: 2.4129102071747184 Scheduler overhead time: 0.10345777217298746 Adapter cache time: 0.04512414801865816 Engine time: 0.10530445631593466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24033613 . Total output tokens: 21116913
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.840126780793071,
    "estimated_duration": 3599.9267221289983,
    "input_throughput": 2467.240220586282,
    "output_throughput": 2164.2812760900447,
    "total_throughput": 4631.521496676326,
    "itl": 32.62900981121645,
    "ttft": 7522.804647890784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 36150,
    "finished_requests": 36075,
    "scheduler_time": 11.74816425959673
}
#Debug simulation 
Total elapsed time: 2.840207210741937. Arrivals time: 0.09341667080298066 Scheduler time: 2.4436960495077074 Scheduler overhead time: 0.10382931819185615 Adapter cache time: 0.04506177082657814 Engine time: 0.10394021589308977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24033613 . Total output tokens: 21116913
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.8164381301030517,
    "estimated_duration": 3599.9274526322215,
    "input_throughput": 2467.239719929822,
    "output_throughput": 2164.280836910514,
    "total_throughput": 4631.520556840336,
    "itl": 32.63884311642196,
    "ttft": 7522.816293823351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.439111801609397,
    "arrivals": 36150,
    "finished_requests": 36075,
    "scheduler_time": 11.75481625898456
}
#Debug simulation 
Total elapsed time: 2.8165283519774675. Arrivals time: 0.09652463998645544 Scheduler time: 2.419451816473156 Scheduler overhead time: 0.1033290782943368 Adapter cache time: 0.04464155901223421 Engine time: 0.1029645660892129 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24033613 . Total output tokens: 21116913
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8150982670485973,
    "estimated_duration": 3599.9255734100784,
    "input_throughput": 2467.2410078707585,
    "output_throughput": 2164.2819667017807,
    "total_throughput": 4631.522974572539,
    "itl": 32.62881650922133,
    "ttft": 7522.691771559294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 36150,
    "finished_requests": 36075,
    "scheduler_time": 11.748167470418803
}
#Debug simulation 
Total elapsed time: 2.8151842020452023. Arrivals time: 0.0926793017424643 Scheduler time: 2.422829729039222 Scheduler overhead time: 0.10325493570417166 Adapter cache time: 0.04499382944777608 Engine time: 0.10184090817347169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24033613 . Total output tokens: 21116913
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.8245860040187836,
    "estimated_duration": 3599.91907681401,
    "input_throughput": 2467.245460378687,
    "output_throughput": 2164.2858724744983,
    "total_throughput": 4631.531332853185,
    "itl": 32.6381548419777,
    "ttft": 7522.780208846007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 36150,
    "finished_requests": 36075,
    "scheduler_time": 11.754627820978675
}
#Debug simulation 
Total elapsed time: 2.8246656483970582. Arrivals time: 0.09349770890548825 Scheduler time: 2.4258885332383215 Scheduler overhead time: 0.10479999333620071 Adapter cache time: 0.044834366999566555 Engine time: 0.10541015630587935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24033613 . Total output tokens: 21116913
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8069959762506187,
    "estimated_duration": 3599.943732267953,
    "input_throughput": 2467.2285625987943,
    "output_throughput": 2164.2710496176383,
    "total_throughput": 4631.499612216432,
    "itl": 32.62871651119505,
    "ttft": 7522.823431076387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 36150,
    "finished_requests": 36075,
    "scheduler_time": 11.748145578406595
}
#Debug simulation 
Total elapsed time: 2.8070789389312267. Arrivals time: 0.09318050974979997 Scheduler time: 2.4104532753117383 Scheduler overhead time: 0.10375452507287264 Adapter cache time: 0.045067481230944395 Engine time: 0.10478638717904687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23864987 . Total output tokens: 20980197
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.8257294106297195,
    "estimated_duration": 3599.954692238956,
    "input_throughput": 2459.0142812309605,
    "output_throughput": 2139.599427905447,
    "total_throughput": 4598.613709136408,
    "itl": 32.34664629394239,
    "ttft": 8570.291048648072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 35929,
    "finished_requests": 35844,
    "scheduler_time": 11.256393957972064
}
#Debug simulation 
Total elapsed time: 2.825824816711247. Arrivals time: 0.0981058063916862 Scheduler time: 2.4238446089439094 Scheduler overhead time: 0.10461090225726366 Adapter cache time: 0.04340410325676203 Engine time: 0.10550115676596761 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23864987 . Total output tokens: 20980197
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.800827437080443,
    "estimated_duration": 3599.941040810214,
    "input_throughput": 2459.023606122078,
    "output_throughput": 2139.607541535308,
    "total_throughput": 4598.6311476573865,
    "itl": 32.33543360178823,
    "ttft": 8570.276606298869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489666,
    "arrivals": 35929,
    "finished_requests": 35844,
    "scheduler_time": 11.249083488859505
}
#Debug simulation 
Total elapsed time: 2.8009994463063776. Arrivals time: 0.09206559415906668 Scheduler time: 2.408102058339864 Scheduler overhead time: 0.10460435692220926 Adapter cache time: 0.04349704785272479 Engine time: 0.10236457269638777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23864987 . Total output tokens: 20980197
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.791264015249908,
    "estimated_duration": 3599.9548224599484,
    "input_throughput": 2459.0141922811554,
    "output_throughput": 2139.59935050982,
    "total_throughput": 4598.613542790975,
    "itl": 32.347245229685825,
    "ttft": 8570.303475517865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 35929,
    "finished_requests": 35844,
    "scheduler_time": 11.256863864568823
}
#Debug simulation 
Total elapsed time: 2.791345729958266. Arrivals time: 0.09290208807215095 Scheduler time: 2.3959095892496407 Scheduler overhead time: 0.10466798394918442 Adapter cache time: 0.04354741610586643 Engine time: 0.10397685877978802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23864987 . Total output tokens: 20980197
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.7933906237594783,
    "estimated_duration": 3599.9502367106497,
    "input_throughput": 2459.017324664068,
    "output_throughput": 2139.6020760103343,
    "total_throughput": 4598.619400674402,
    "itl": 32.346693007004895,
    "ttft": 8570.285776617065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 35929,
    "finished_requests": 35844,
    "scheduler_time": 11.2565128002552
}
#Debug simulation 
Total elapsed time: 2.7934755575843155. Arrivals time: 0.09266138356178999 Scheduler time: 2.396979823242873 Scheduler overhead time: 0.10518393479287624 Adapter cache time: 0.043390678241848946 Engine time: 0.10481394920498133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23864987 . Total output tokens: 20980197
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.789244974963367,
    "estimated_duration": 3599.955548117936,
    "input_throughput": 2459.013696607454,
    "output_throughput": 2139.598919221895,
    "total_throughput": 4598.612615829349,
    "itl": 32.347001687497304,
    "ttft": 8570.22420359571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 35929,
    "finished_requests": 35844,
    "scheduler_time": 11.256663292138775
}
#Debug simulation 
Total elapsed time: 2.789313857909292. Arrivals time: 0.09207107499241829 Scheduler time: 2.3976307935081422 Scheduler overhead time: 0.10357065452262759 Adapter cache time: 0.04328549327328801 Engine time: 0.10281102452427149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23864987 . Total output tokens: 20980197
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.82737070415169,
    "estimated_duration": 3599.956586396977,
    "input_throughput": 2459.0129873926844,
    "output_throughput": 2139.5983021309216,
    "total_throughput": 4598.611289523606,
    "itl": 32.335222246064376,
    "ttft": 8570.124724623502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 35929,
    "finished_requests": 35844,
    "scheduler_time": 11.248806065076742
}
#Debug simulation 
Total elapsed time: 2.827442997135222. Arrivals time: 0.09249671548604965 Scheduler time: 2.430460591800511 Scheduler overhead time: 0.10478485096246004 Adapter cache time: 0.04417385859414935 Engine time: 0.10537763265892863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23864987 . Total output tokens: 20980197
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8021263661794364,
    "estimated_duration": 3599.939384942116,
    "input_throughput": 2459.0247372018844,
    "output_throughput": 2139.608525692954,
    "total_throughput": 4598.6332628948385,
    "itl": 32.33540829598164,
    "ttft": 8570.232356422443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 35929,
    "finished_requests": 35844,
    "scheduler_time": 11.249063264819291
}
#Debug simulation 
Total elapsed time: 2.802211555186659. Arrivals time: 0.09436717536300421 Scheduler time: 2.4056238629855216 Scheduler overhead time: 0.10414146166294813 Adapter cache time: 0.04375148890540004 Engine time: 0.10432195290923119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23105715 . Total output tokens: 20279491
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.6799421519972384,
    "estimated_duration": 3599.895227610048,
    "input_throughput": 2379.482306680033,
    "output_throughput": 2057.4709905980394,
    "total_throughput": 4436.953297278073,
    "itl": 31.25761513448809,
    "ttft": 5134.60198210004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 34705,
    "finished_requests": 34656,
    "scheduler_time": 9.338496657182528
}
#Debug simulation 
Total elapsed time: 2.6800145148299634. Arrivals time: 0.08987395884469151 Scheduler time: 2.2819510512053967 Scheduler overhead time: 0.10778083419427276 Adapter cache time: 0.041964109521359205 Engine time: 0.10706944204866886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23105715 . Total output tokens: 20279491
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6744213779456913,
    "estimated_duration": 3599.895255224699,
    "input_throughput": 2379.4822884271202,
    "output_throughput": 2057.4709748152623,
    "total_throughput": 4436.9532632423825,
    "itl": 31.258554083111992,
    "ttft": 5134.6273692233135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489666,
    "arrivals": 34705,
    "finished_requests": 34656,
    "scheduler_time": 9.338758735719193
}
#Debug simulation 
Total elapsed time: 2.6744921621866524. Arrivals time: 0.08953541470691562 Scheduler time: 2.2737835310399532 Scheduler overhead time: 0.10674793366342783 Adapter cache time: 0.0419495664536953 Engine time: 0.1111465860158205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23105715 . Total output tokens: 20279491
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.713940266985446,
    "estimated_duration": 3599.8856576616568,
    "input_throughput": 2379.4886323039664,
    "output_throughput": 2057.4764601859843,
    "total_throughput": 4436.965092489951,
    "itl": 31.258732558467347,
    "ttft": 5134.4875569361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 34705,
    "finished_requests": 34656,
    "scheduler_time": 9.338855227370075
}
#Debug simulation 
Total elapsed time: 2.7140111890621483. Arrivals time: 0.08979442529380322 Scheduler time: 2.317875161767006 Scheduler overhead time: 0.10710028512403369 Adapter cache time: 0.042112449649721384 Engine time: 0.10578890889883041 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23105715 . Total output tokens: 20279491
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.678084710147232,
    "estimated_duration": 3599.8953437756854,
    "input_throughput": 2379.568343510647,
    "output_throughput": 2057.6048169864657,
    "total_throughput": 4437.173160497113,
    "itl": 31.240719605119388,
    "ttft": 5030.793937418391,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 34705,
    "finished_requests": 34657,
    "scheduler_time": 9.32662806477354
}
#Debug simulation 
Total elapsed time: 2.6781540950760245. Arrivals time: 0.08956037182360888 Scheduler time: 2.27977613825351 Scheduler overhead time: 0.1076755658723414 Adapter cache time: 0.04212024714797735 Engine time: 0.10709075257182121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23105715 . Total output tokens: 20279491
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6719880239106715,
    "estimated_duration": 3599.8991679101596,
    "input_throughput": 2379.479702197529,
    "output_throughput": 2057.468738575748,
    "total_throughput": 4436.948440773277,
    "itl": 31.25847572107307,
    "ttft": 5134.514904139941,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924963,
    "arrivals": 34705,
    "finished_requests": 34656,
    "scheduler_time": 9.33877253811533
}
#Debug simulation 
Total elapsed time: 2.6720590526238084. Arrivals time: 0.08956314017996192 Scheduler time: 2.274690433871001 Scheduler overhead time: 0.10694383131340146 Adapter cache time: 0.04161075735464692 Engine time: 0.10770040331408381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23105715 . Total output tokens: 20279491
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.6665991242043674,
    "estimated_duration": 3599.9122270372145,
    "input_throughput": 2379.5571835511437,
    "output_throughput": 2057.5951670066725,
    "total_throughput": 4437.152350557816,
    "itl": 31.240529637371257,
    "ttft": 5030.771691894491,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 34705,
    "finished_requests": 34657,
    "scheduler_time": 9.326350515868581
}
#Debug simulation 
Total elapsed time: 2.66667112801224. Arrivals time: 0.08946383651345968 Scheduler time: 2.265204689465463 Scheduler overhead time: 0.10863500041887164 Adapter cache time: 0.042383793741464615 Engine time: 0.10812177555635571 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23105715 . Total output tokens: 20279491
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6731609380804002,
    "estimated_duration": 3599.8954527155925,
    "input_throughput": 2379.4821578883066,
    "output_throughput": 2057.4708619420453,
    "total_throughput": 4436.953019830352,
    "itl": 31.25861697377392,
    "ttft": 5134.520388802272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337262,
    "arrivals": 34705,
    "finished_requests": 34656,
    "scheduler_time": 9.33874922837511
}
#Debug simulation 
Total elapsed time: 2.6732324701733887. Arrivals time: 0.08909751800820231 Scheduler time: 2.276779013220221 Scheduler overhead time: 0.10798055492341518 Adapter cache time: 0.041965749114751816 Engine time: 0.10564709827303886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22777251 . Total output tokens: 19994543
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.6994063309393823,
    "estimated_duration": 3599.7618747832394,
    "input_throughput": 2344.393960922255,
    "output_throughput": 2061.5524743416154,
    "total_throughput": 4405.946435263871,
    "itl": 30.96670512188003,
    "ttft": 9200.324748231695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 34232,
    "finished_requests": 34145,
    "scheduler_time": 9.187186233010173
}
#Debug simulation 
Total elapsed time: 2.699514194391668. Arrivals time: 0.08855726523324847 Scheduler time: 2.2995500932447612 Scheduler overhead time: 0.1104782884940505 Adapter cache time: 0.039887228049337864 Engine time: 0.10811389936134219 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22777251 . Total output tokens: 19994543
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6662842370569706,
    "estimated_duration": 3599.7412849373536,
    "input_throughput": 2344.4070926188433,
    "output_throughput": 2061.5637104401376,
    "total_throughput": 4405.970803058981,
    "itl": 30.96789079272247,
    "ttft": 9305.630491188938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 34232,
    "finished_requests": 34144,
    "scheduler_time": 9.18751861613355
}
#Debug simulation 
Total elapsed time: 2.666359488386661. Arrivals time: 0.08844502316787839 Scheduler time: 2.270806632936001 Scheduler overhead time: 0.10797054087743163 Adapter cache time: 0.03957734350115061 Engine time: 0.10808100877329707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22777251 . Total output tokens: 19994543
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6603949018754065,
    "estimated_duration": 3599.7510749619855,
    "input_throughput": 2344.400716677089,
    "output_throughput": 2061.5581037303723,
    "total_throughput": 4405.958820407461,
    "itl": 30.96775238149331,
    "ttft": 9305.602472474979,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 34232,
    "finished_requests": 34144,
    "scheduler_time": 9.187586461934403
}
#Debug simulation 
Total elapsed time: 2.6604662030003965. Arrivals time: 0.08814187860116363 Scheduler time: 2.264994626864791 Scheduler overhead time: 0.10782223334535956 Adapter cache time: 0.03989470936357975 Engine time: 0.10770508646965027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22777251 . Total output tokens: 19994543
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.70012324815616,
    "estimated_duration": 3599.751093810162,
    "input_throughput": 2344.4007044018854,
    "output_throughput": 2061.558092936123,
    "total_throughput": 4405.9587973380085,
    "itl": 30.967337736288737,
    "ttft": 9305.521485326362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939695,
    "arrivals": 34232,
    "finished_requests": 34144,
    "scheduler_time": 9.187236313556662
}
#Debug simulation 
Total elapsed time: 2.7001950200647116. Arrivals time: 0.08826861344277859 Scheduler time: 2.3033345066942275 Scheduler overhead time: 0.10927546862512827 Adapter cache time: 0.03992812801152468 Engine time: 0.10751728247851133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22777251 . Total output tokens: 19994543
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.68270877096802,
    "estimated_duration": 3599.7413334776165,
    "input_throughput": 2344.4070610059784,
    "output_throughput": 2061.563682641239,
    "total_throughput": 4405.970743647217,
    "itl": 30.967940144763066,
    "ttft": 9305.617697847074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 34232,
    "finished_requests": 34144,
    "scheduler_time": 9.187535504229722
}
#Debug simulation 
Total elapsed time: 2.682778358925134. Arrivals time: 0.08978273533284664 Scheduler time: 2.28712404333055 Scheduler overhead time: 0.10795262409374118 Adapter cache time: 0.03961714310571551 Engine time: 0.10651693539693952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22777251 . Total output tokens: 19994543
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.6630250536836684,
    "estimated_duration": 3599.7449638732537,
    "input_throughput": 2344.4046966370433,
    "output_throughput": 2061.561603524003,
    "total_throughput": 4405.966300161047,
    "itl": 30.967029207903014,
    "ttft": 9305.713074793797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 34232,
    "finished_requests": 34144,
    "scheduler_time": 9.187119641037583
}
#Debug simulation 
Total elapsed time: 2.6630934909917414. Arrivals time: 0.08809156995266676 Scheduler time: 2.2672660313546658 Scheduler overhead time: 0.10761443572118878 Adapter cache time: 0.039666203781962395 Engine time: 0.10820917738601565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22777251 . Total output tokens: 19994543
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.7061508391052485,
    "estimated_duration": 3599.741618991503,
    "input_throughput": 2344.406875059085,
    "output_throughput": 2061.563519128098,
    "total_throughput": 4405.970394187183,
    "itl": 30.967959401532536,
    "ttft": 9305.616493634227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 34232,
    "finished_requests": 34144,
    "scheduler_time": 9.187538715051762
}
#Debug simulation 
Total elapsed time: 2.706235112156719. Arrivals time: 0.0897423131391406 Scheduler time: 2.3089448753744364 Scheduler overhead time: 0.10820653382688761 Adapter cache time: 0.0399391264654696 Engine time: 0.10764445783570409 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22610988 . Total output tokens: 19863471
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.6193963792175055,
    "estimated_duration": 3600.017688272808,
    "input_throughput": 2345.6534748448403,
    "output_throughput": 2019.297856141289,
    "total_throughput": 4364.951330986129,
    "itl": 30.59547358002059,
    "ttft": 9474.942057203873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 33997,
    "finished_requests": 33908,
    "scheduler_time": 8.391546888938052
}
#Debug simulation 
Total elapsed time: 2.6194669222459197. Arrivals time: 0.08767400681972504 Scheduler time: 2.2237463206984103 Scheduler overhead time: 0.10942125832661986 Adapter cache time: 0.03834426403045654 Engine time: 0.10809524869546294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22610988 . Total output tokens: 19863471
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.625402173027396,
    "estimated_duration": 3600.021615820328,
    "input_throughput": 2345.650915786459,
    "output_throughput": 2019.2956531299924,
    "total_throughput": 4364.946568916452,
    "itl": 30.596045255931383,
    "ttft": 9474.945833224396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 33997,
    "finished_requests": 33908,
    "scheduler_time": 8.391788868556553
}
#Debug simulation 
Total elapsed time: 2.62547214794904. Arrivals time: 0.08681315742433071 Scheduler time: 2.229796314612031 Scheduler overhead time: 0.10850590886548162 Adapter cache time: 0.038221416994929314 Engine time: 0.11010372126474977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22610988 . Total output tokens: 19863471
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.624185288324952,
    "estimated_duration": 3600.007118132665,
    "input_throughput": 2345.6603620217656,
    "output_throughput": 2019.3037850910464,
    "total_throughput": 4364.9641471128125,
    "itl": 30.596230655092473,
    "ttft": 9369.222423778934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 33997,
    "finished_requests": 33908,
    "scheduler_time": 8.391785532612511
}
#Debug simulation 
Total elapsed time: 2.6242570052854717. Arrivals time: 0.0877335169352591 Scheduler time: 2.22826260747388 Scheduler overhead time: 0.10900938883423805 Adapter cache time: 0.0382958403788507 Engine time: 0.10867641028016806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22610988 . Total output tokens: 19863471
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.6171231069602072,
    "estimated_duration": 3600.0177035024485,
    "input_throughput": 2345.6534649217056,
    "output_throughput": 2019.2978475987807,
    "total_throughput": 4364.951312520487,
    "itl": 30.595851876533413,
    "ttft": 9475.018192536747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.439111801609397,
    "arrivals": 33997,
    "finished_requests": 33908,
    "scheduler_time": 8.391673945959353
}
#Debug simulation 
Total elapsed time: 2.6171937896870077. Arrivals time: 0.0877013960853219 Scheduler time: 2.222144760657102 Scheduler overhead time: 0.10835912078619003 Adapter cache time: 0.03844977915287018 Engine time: 0.10864080395549536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22610988 . Total output tokens: 19863471
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6158549301326275,
    "estimated_duration": 3600.033209734171,
    "input_throughput": 2345.72558307693,
    "output_throughput": 2019.4005378458203,
    "total_throughput": 4365.1261209227505,
    "itl": 30.596327679985126,
    "ttft": 9368.985841059248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 33997,
    "finished_requests": 33909,
    "scheduler_time": 8.391872141553405
}
#Debug simulation 
Total elapsed time: 2.6159251374192536. Arrivals time: 0.08767475141212344 Scheduler time: 2.2200974808074534 Scheduler overhead time: 0.108572649769485 Adapter cache time: 0.03856978891417384 Engine time: 0.1085132947191596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22610988 . Total output tokens: 19863471
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.6295361812226474,
    "estimated_duration": 3600.0144247173353,
    "input_throughput": 2345.655601272496,
    "output_throughput": 2019.2996867146678,
    "total_throughput": 4364.9552879871635,
    "itl": 30.59576105144499,
    "ttft": 9474.985090239,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 33997,
    "finished_requests": 33908,
    "scheduler_time": 8.391550224882094
}
#Debug simulation 
Total elapsed time: 2.6296093240380287. Arrivals time: 0.08727245451882482 Scheduler time: 2.2351493830792606 Scheduler overhead time: 0.10857285326346755 Adapter cache time: 0.038394562900066376 Engine time: 0.10807307623326778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22610988 . Total output tokens: 19863471
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6234887717291713,
    "estimated_duration": 3600.0215080287007,
    "input_throughput": 2345.6509860197975,
    "output_throughput": 2019.2957135916213,
    "total_throughput": 4364.946699611419,
    "itl": 30.595895549296422,
    "ttft": 9474.973522541595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 33997,
    "finished_requests": 33908,
    "scheduler_time": 8.391788868556546
}
#Debug simulation 
Total elapsed time: 2.6236213259398937. Arrivals time: 0.0881403498351574 Scheduler time: 2.22868913738057 Scheduler overhead time: 0.10795151023194194 Adapter cache time: 0.03818953549489379 Engine time: 0.10835000220686197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22131967 . Total output tokens: 19445509
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.5877335220575333,
    "estimated_duration": 3599.9328725319338,
    "input_throughput": 2274.5976911066314,
    "output_throughput": 2003.0854061254538,
    "total_throughput": 4277.683097232085,
    "itl": 30.127374940263994,
    "ttft": 6213.044892369318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 33294,
    "finished_requests": 33237,
    "scheduler_time": 7.7768612954764125
}
#Debug simulation 
Total elapsed time: 2.5878041652031243. Arrivals time: 0.08619337202981114 Scheduler time: 2.192050348035991 Scheduler overhead time: 0.10963694052770734 Adapter cache time: 0.03614551015198231 Engine time: 0.10945438453927636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22131967 . Total output tokens: 19445509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.5909528508782387,
    "estimated_duration": 3599.931032309501,
    "input_throughput": 2274.5988538416004,
    "output_throughput": 2003.086430068042,
    "total_throughput": 4277.685283909643,
    "itl": 30.127786972780612,
    "ttft": 6213.034402948646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896656,
    "arrivals": 33294,
    "finished_requests": 33237,
    "scheduler_time": 7.777158109313423
}
#Debug simulation 
Total elapsed time: 2.591023303102702. Arrivals time: 0.08654639311134815 Scheduler time: 2.1912131761200726 Scheduler overhead time: 0.11090880678966641 Adapter cache time: 0.03631018893793225 Engine time: 0.11282218107953668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22131967 . Total output tokens: 19445509
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6130322231911123,
    "estimated_duration": 3599.922204734823,
    "input_throughput": 2274.6044315152562,
    "output_throughput": 2003.0913419505891,
    "total_throughput": 4277.695773465845,
    "itl": 30.12801008116789,
    "ttft": 6213.1093949872775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 33294,
    "finished_requests": 33237,
    "scheduler_time": 7.7772906288707295
}
#Debug simulation 
Total elapsed time: 2.613102530129254. Arrivals time: 0.08677635015919805 Scheduler time: 2.2183620701543987 Scheduler overhead time: 0.1090745497494936 Adapter cache time: 0.03612204547971487 Engine time: 0.10951494425535202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22131967 . Total output tokens: 19445509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.6065056058578193,
    "estimated_duration": 3599.924654845786,
    "input_throughput": 2274.602883418063,
    "output_throughput": 2003.0899786453738,
    "total_throughput": 4277.692862063437,
    "itl": 30.127314428435707,
    "ttft": 6213.020753184537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 33294,
    "finished_requests": 33237,
    "scheduler_time": 7.776962165433399
}
#Debug simulation 
Total elapsed time: 2.6065765251405537. Arrivals time: 0.08557014865800738 Scheduler time: 2.21311062714085 Scheduler overhead time: 0.10986145958304405 Adapter cache time: 0.03628988843411207 Engine time: 0.10846756584942341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22131967 . Total output tokens: 19445509
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.622260859236121,
    "estimated_duration": 3599.9395693369665,
    "input_throughput": 2274.5934597752516,
    "output_throughput": 2003.0816798761182,
    "total_throughput": 4277.67513965137,
    "itl": 30.127597381017264,
    "ttft": 6213.044599744394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 33294,
    "finished_requests": 33237,
    "scheduler_time": 7.777180585067645
}
#Debug simulation 
Total elapsed time: 2.622329576872289. Arrivals time: 0.08572406368330121 Scheduler time: 2.2216239194385707 Scheduler overhead time: 0.10989374574273825 Adapter cache time: 0.036429017316550016 Engine time: 0.11543194251134992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22131967 . Total output tokens: 19445509
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.5942687722854316,
    "estimated_duration": 3599.9209470064607,
    "input_throughput": 2274.605226208959,
    "output_throughput": 2003.092041783955,
    "total_throughput": 4277.697267992914,
    "itl": 30.12697795134455,
    "ttft": 6213.096386257021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 33294,
    "finished_requests": 33237,
    "scheduler_time": 7.776868300862444
}
#Debug simulation 
Total elapsed time: 2.5943389208987355. Arrivals time: 0.08668141812086105 Scheduler time: 2.193619551602751 Scheduler overhead time: 0.113846973516047 Adapter cache time: 0.036261904053390026 Engine time: 0.11031529633328319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22131967 . Total output tokens: 19445509
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6185223455540836,
    "estimated_duration": 3599.9326359017505,
    "input_throughput": 2274.5978406201148,
    "output_throughput": 2003.085537791936,
    "total_throughput": 4277.683378412051,
    "itl": 30.12765432113598,
    "ttft": 6213.008957683141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 33294,
    "finished_requests": 33237,
    "scheduler_time": 7.777147517739328
}
#Debug simulation 
Total elapsed time: 2.618593498598784. Arrivals time: 0.08740232698619366 Scheduler time: 2.2195778391323984 Scheduler overhead time: 0.11110735405236483 Adapter cache time: 0.03647199412807822 Engine time: 0.11088213184848428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21971033 . Total output tokens: 19315384
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.5813145097345114,
    "estimated_duration": 3599.695994142269,
    "input_throughput": 2255.834385240885,
    "output_throughput": 1977.1325166296017,
    "total_throughput": 4232.966901870486,
    "itl": 29.83837855871265,
    "ttft": 7457.427604145532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 33045,
    "finished_requests": 32977,
    "scheduler_time": 7.257945153275648
}
#Debug simulation 
Total elapsed time: 2.581384733784944. Arrivals time: 0.08447814453393221 Scheduler time: 2.1903801183216274 Scheduler overhead time: 0.11047830805182457 Adapter cache time: 0.03453282918781042 Engine time: 0.10796223487704992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21971033 . Total output tokens: 19315384
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.573757889214903,
    "estimated_duration": 3599.6961847539897,
    "input_throughput": 2255.834265789561,
    "output_throughput": 1977.1324119361466,
    "total_throughput": 4232.966677725707,
    "itl": 29.83872987260182,
    "ttft": 7457.402553654259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 33045,
    "finished_requests": 32977,
    "scheduler_time": 7.258201519032255
}
#Debug simulation 
Total elapsed time: 2.573853210080415. Arrivals time: 0.0851578488945961 Scheduler time: 2.1771685094572604 Scheduler overhead time: 0.11134813399985433 Adapter cache time: 0.034794863779097795 Engine time: 0.11176929250359535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21971033 . Total output tokens: 19315384
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.571092452853918,
    "estimated_duration": 3599.6811088973773,
    "input_throughput": 2255.8437134692035,
    "output_throughput": 1977.140692382065,
    "total_throughput": 4232.984405851268,
    "itl": 29.83877802435285,
    "ttft": 7457.399071306397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 33045,
    "finished_requests": 32977,
    "scheduler_time": 7.258267195068887
}
#Debug simulation 
Total elapsed time: 2.5711622769013047. Arrivals time: 0.08526497427374125 Scheduler time: 2.175188234075904 Scheduler overhead time: 0.11133986478671432 Adapter cache time: 0.03492806991562247 Engine time: 0.11096264654770494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21971033 . Total output tokens: 19315384
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.6128980480134487,
    "estimated_duration": 3599.6918025767627,
    "input_throughput": 2255.837011987316,
    "output_throughput": 1977.134818849045,
    "total_throughput": 4232.971830836361,
    "itl": 29.8385622645092,
    "ttft": 7457.358864977187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.439111801609397,
    "arrivals": 33045,
    "finished_requests": 32977,
    "scheduler_time": 7.258050902026721
}
#Debug simulation 
Total elapsed time: 2.612967678811401. Arrivals time: 0.08565879659727216 Scheduler time: 2.216327122412622 Scheduler overhead time: 0.11143151996657252 Adapter cache time: 0.03470069356262684 Engine time: 0.11134458472952247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21971033 . Total output tokens: 19315384
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.577469688374549,
    "estimated_duration": 3599.673480815853,
    "input_throughput": 2255.848493836046,
    "output_throughput": 1977.1448821482943,
    "total_throughput": 4232.993375984341,
    "itl": 29.83866006355751,
    "ttft": 7457.328678017423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 33045,
    "finished_requests": 32977,
    "scheduler_time": 7.258201769276211
}
#Debug simulation 
Total elapsed time: 2.5775426463223994. Arrivals time: 0.08664487581700087 Scheduler time: 2.183557779993862 Scheduler overhead time: 0.11034499201923609 Adapter cache time: 0.03454809356480837 Engine time: 0.10956628993153572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21971033 . Total output tokens: 19315384
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.576588816009462,
    "estimated_duration": 3599.6879327865495,
    "input_throughput": 2255.839437090868,
    "output_throughput": 1977.1369443380083,
    "total_throughput": 4232.976381428876,
    "itl": 29.838424029552662,
    "ttft": 7457.3599742044435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 33045,
    "finished_requests": 32977,
    "scheduler_time": 7.257980847683963
}
#Debug simulation 
Total elapsed time: 2.5767150837928057. Arrivals time: 0.08560875244438648 Scheduler time: 2.181210646405816 Scheduler overhead time: 0.1103287530131638 Adapter cache time: 0.03496211301535368 Engine time: 0.11105691315606236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21971033 . Total output tokens: 19315384
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.5831483961082995,
    "estimated_duration": 3599.6947060809985,
    "input_throughput": 2255.8351924351446,
    "output_throughput": 1977.1332240973259,
    "total_throughput": 4232.968416532471,
    "itl": 29.838691832732632,
    "ttft": 7457.406889298277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 33045,
    "finished_requests": 32977,
    "scheduler_time": 7.2581338415255665
}
#Debug simulation 
Total elapsed time: 2.583219372201711. Arrivals time: 0.08552144281566143 Scheduler time: 2.182271207217127 Scheduler overhead time: 0.11476189736276865 Adapter cache time: 0.03479246096685529 Engine time: 0.11187602113932371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21650533 . Total output tokens: 19030301
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.549656087998301,
    "estimated_duration": 3599.9336120734197,
    "input_throughput": 2246.7325433097585,
    "output_throughput": 1954.9004949418138,
    "total_throughput": 4201.6330382515725,
    "itl": 29.410735725466807,
    "ttft": 5689.581971088794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 32548,
    "finished_requests": 32497,
    "scheduler_time": 6.6597280084934205
}
#Debug simulation 
Total elapsed time: 2.549724990967661. Arrivals time: 0.08499537035822868 Scheduler time: 2.155103014782071 Scheduler overhead time: 0.11211201781406999 Adapter cache time: 0.03216682747006416 Engine time: 0.11181644815951586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21650533 . Total output tokens: 19030301
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.552090227138251,
    "estimated_duration": 3599.9278267818286,
    "input_throughput": 2246.7361539385033,
    "output_throughput": 1954.9036365796296,
    "total_throughput": 4201.639790518133,
    "itl": 29.422759737560753,
    "ttft": 5689.5408797492555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 32548,
    "finished_requests": 32497,
    "scheduler_time": 6.669044368896436
}
#Debug simulation 
Total elapsed time: 2.5521649811416864. Arrivals time: 0.08463429845869541 Scheduler time: 2.1559232329018414 Scheduler overhead time: 0.11220811493694782 Adapter cache time: 0.03271169401705265 Engine time: 0.11257804790511727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21650533 . Total output tokens: 19030301
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.545601629652083,
    "estimated_duration": 3599.9469389985,
    "input_throughput": 2246.7242259548675,
    "output_throughput": 1954.8932579428033,
    "total_throughput": 4201.61748389767,
    "itl": 29.423144346447557,
    "ttft": 5689.605681380897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 32548,
    "finished_requests": 32497,
    "scheduler_time": 6.669304195719074
}
#Debug simulation 
Total elapsed time: 2.5456708827987313. Arrivals time: 0.08529918594285846 Scheduler time: 2.15218443563208 Scheduler overhead time: 0.1115482565946877 Adapter cache time: 0.03194312285631895 Engine time: 0.11136883869767189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21650533 . Total output tokens: 19030301
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.5714228050783277,
    "estimated_duration": 3599.9278316604955,
    "input_throughput": 2246.7361508936983,
    "output_throughput": 1954.90363393032,
    "total_throughput": 4201.6397848240185,
    "itl": 29.422628441975252,
    "ttft": 5689.503451391874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 32548,
    "finished_requests": 32497,
    "scheduler_time": 6.668917311875137
}
#Debug simulation 
Total elapsed time: 2.5714925792999566. Arrivals time: 0.08487374521791935 Scheduler time: 2.177373907994479 Scheduler overhead time: 0.11197427147999406 Adapter cache time: 0.03187320753931999 Engine time: 0.11149416072294116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21650533 . Total output tokens: 19030301
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.5535404859110713,
    "estimated_duration": 3599.929707479376,
    "input_throughput": 2246.734980184703,
    "output_throughput": 1954.9026152867787,
    "total_throughput": 4201.637595471482,
    "itl": 29.42261671452258,
    "ttft": 5689.542472686876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 32548,
    "finished_requests": 32497,
    "scheduler_time": 6.669141444289417
}
#Debug simulation 
Total elapsed time: 2.5536106121726334. Arrivals time: 0.08374619530513883 Scheduler time: 2.161026294808835 Scheduler overhead time: 0.11160135362297297 Adapter cache time: 0.03183621261268854 Engine time: 0.11144062783569098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21650533 . Total output tokens: 19030301
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.572077830787748,
    "estimated_duration": 3599.9360857383363,
    "input_throughput": 2246.7309994869415,
    "output_throughput": 1954.8991516488625,
    "total_throughput": 4201.630151135804,
    "itl": 29.411001464288876,
    "ttft": 5689.486534384492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 32548,
    "finished_requests": 32497,
    "scheduler_time": 6.659693982057052
}
#Debug simulation 
Total elapsed time: 2.572148264851421. Arrivals time: 0.08592996560037136 Scheduler time: 2.174405138939619 Scheduler overhead time: 0.11317199748009443 Adapter cache time: 0.0322044538334012 Engine time: 0.11206149309873581 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21650533 . Total output tokens: 19030301
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.5514787160791457,
    "estimated_duration": 3599.9279267427873,
    "input_throughput": 2246.7360915522822,
    "output_throughput": 1954.9035822968647,
    "total_throughput": 4201.639673849147,
    "itl": 29.422640652050546,
    "ttft": 5689.554179390581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 32548,
    "finished_requests": 32497,
    "scheduler_time": 6.669013678404111
}
#Debug simulation 
Total elapsed time: 2.551577517297119. Arrivals time: 0.08468164270743728 Scheduler time: 2.157945239916444 Scheduler overhead time: 0.11156159499660134 Adapter cache time: 0.03167792037129402 Engine time: 0.11194369895383716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9042678 . Total output tokens: 8015864
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.4160133451223373,
    "estimated_duration": 3599.617531040674,
    "input_throughput": 939.5645428535903,
    "output_throughput": 834.6500632614159,
    "total_throughput": 1774.214606115006,
    "itl": 24.945948885856513,
    "ttft": 6042.830812219725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 13796,
    "finished_requests": 13773,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4160792147740722. Arrivals time: 0.04635529173538089 Scheduler time: 0.9920330247841775 Scheduler overhead time: 0.12300258362665772 Adapter cache time: 0.06932935724034905 Engine time: 0.12383072962984443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9042678 . Total output tokens: 8015864
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4129289630800486,
    "estimated_duration": 3599.622554777121,
    "input_throughput": 939.5632315703747,
    "output_throughput": 834.6488983998562,
    "total_throughput": 1774.212129970231,
    "itl": 24.946118111544948,
    "ttft": 6042.894286565225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489666,
    "arrivals": 13796,
    "finished_requests": 13773,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.412987592164427. Arrivals time: 0.04539549956098199 Scheduler time: 0.9893947821110487 Scheduler overhead time: 0.12393740005791187 Adapter cache time: 0.0693432129919529 Engine time: 0.12353938538581133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9042678 . Total output tokens: 8015864
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.392883122432977,
    "estimated_duration": 3599.6188799397823,
    "input_throughput": 939.5641907669343,
    "output_throughput": 834.6497504897687,
    "total_throughput": 1774.213941256703,
    "itl": 24.94592610010174,
    "ttft": 6042.844601704402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 13796,
    "finished_requests": 13773,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3929399852640927. Arrivals time: 0.04494003998115659 Scheduler time: 0.973066782578826 Scheduler overhead time: 0.12289896234869957 Adapter cache time: 0.06910609127953649 Engine time: 0.12231991346925497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9042678 . Total output tokens: 8015864
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3995848968625069,
    "estimated_duration": 3599.6175337283485,
    "input_throughput": 939.5645421520592,
    "output_throughput": 834.6500626382198,
    "total_throughput": 1774.2146047902788,
    "itl": 24.94573326387639,
    "ttft": 6042.824510693627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.439111801609397,
    "arrivals": 13796,
    "finished_requests": 13773,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3996541816741228. Arrivals time: 0.04463981604203582 Scheduler time: 0.9780401499010623 Scheduler overhead time: 0.1232935986481607 Adapter cache time: 0.06935297045856714 Engine time: 0.12352920975536108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9042678 . Total output tokens: 8015864
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3888306999579072,
    "estimated_duration": 3599.617535165695,
    "input_throughput": 939.564541776886,
    "output_throughput": 834.6500623049395,
    "total_throughput": 1774.2146040818257,
    "itl": 24.946074527450353,
    "ttft": 6042.783277062946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 13796,
    "finished_requests": 13773,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.388937572017312. Arrivals time: 0.04496039682999253 Scheduler time: 0.9659672756679356 Scheduler overhead time: 0.12388949887827039 Adapter cache time: 0.0697871814481914 Engine time: 0.12176304683089256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9042678 . Total output tokens: 8015864
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.3967719366773963,
    "estimated_duration": 3599.629650398951,
    "input_throughput": 939.5613794950158,
    "output_throughput": 834.6472531325595,
    "total_throughput": 1774.2086326275753,
    "itl": 24.945780479918042,
    "ttft": 6042.800313160594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 13796,
    "finished_requests": 13773,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3968426720239222. Arrivals time: 0.04487050510942936 Scheduler time: 0.9755325200967491 Scheduler overhead time: 0.12304542865604162 Adapter cache time: 0.06898132711648941 Engine time: 0.12337259855121374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9042678 . Total output tokens: 8015864
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4120149980299175,
    "estimated_duration": 3599.6296470351695,
    "input_throughput": 939.5613803730171,
    "output_throughput": 834.6472539125206,
    "total_throughput": 1774.2086342855378,
    "itl": 24.946071091658716,
    "ttft": 6042.827580973901,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 13796,
    "finished_requests": 13773,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4121113861910999. Arrivals time: 0.0450724414549768 Scheduler time: 0.9901758492924273 Scheduler overhead time: 0.12361607514321804 Adapter cache time: 0.06924659246578813 Engine time: 0.122675986494869 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8403910 . Total output tokens: 7439174
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.3279458400793374,
    "estimated_duration": 3599.539119343358,
    "input_throughput": 870.0563867107842,
    "output_throughput": 759.8931166773867,
    "total_throughput": 1629.9495033881708,
    "itl": 24.23890250997536,
    "ttft": 3980.5153141451788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 12790,
    "finished_requests": 12776,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3280496071092784. Arrivals time: 0.0425776201300323 Scheduler time: 0.907598870806396 Scheduler overhead time: 0.12605490116402507 Adapter cache time: 0.06421396369114518 Engine time: 0.12515995930880308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8403910 . Total output tokens: 7439174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.322758404072374,
    "estimated_duration": 3599.5454151270155,
    "input_throughput": 870.0548649389633,
    "output_throughput": 759.891787586595,
    "total_throughput": 1629.9466525255582,
    "itl": 24.238982851989622,
    "ttft": 3980.595361106868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896656,
    "arrivals": 12790,
    "finished_requests": 12776,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3228338910266757. Arrivals time: 0.04368997737765312 Scheduler time: 0.9007031489163637 Scheduler overhead time: 0.12459166347980499 Adapter cache time: 0.06783250300213695 Engine time: 0.1242522532120347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8403910 . Total output tokens: 7439174
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3234351254068315,
    "estimated_duration": 3599.5273656971303,
    "input_throughput": 870.0592277323763,
    "output_throughput": 759.8955979795013,
    "total_throughput": 1629.9548257118777,
    "itl": 24.239690615908557,
    "ttft": 3980.6141953942792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 12790,
    "finished_requests": 12776,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.323500644415617. Arrivals time: 0.042560551315546036 Scheduler time: 0.9032816360704601 Scheduler overhead time: 0.12558959145098925 Adapter cache time: 0.06398916989564896 Engine time: 0.1253211055882275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8403910 . Total output tokens: 7439174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3434609449468553,
    "estimated_duration": 3599.527405928248,
    "input_throughput": 870.0592180079177,
    "output_throughput": 759.8955894863171,
    "total_throughput": 1629.954807494235,
    "itl": 24.238925763340742,
    "ttft": 3980.5998732561275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4391118016093969,
    "arrivals": 12790,
    "finished_requests": 12776,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.343532018829137. Arrivals time: 0.04369452968239784 Scheduler time: 0.9207709315232933 Scheduler overhead time: 0.12649052683264017 Adapter cache time: 0.06416476797312498 Engine time: 0.12602080265060067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8403910 . Total output tokens: 7439174
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3353683967143297,
    "estimated_duration": 3599.523518483969,
    "input_throughput": 870.0601576619337,
    "output_throughput": 759.8964101648728,
    "total_throughput": 1629.9565678268063,
    "itl": 24.239136140417454,
    "ttft": 3980.4878683653174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 12790,
    "finished_requests": 12776,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.335440119728446. Arrivals time: 0.04300597356632352 Scheduler time: 0.9138692934066057 Scheduler overhead time: 0.12600783677771688 Adapter cache time: 0.06406546151265502 Engine time: 0.1259577269665897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8403910 . Total output tokens: 7439174
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.3194628078490496,
    "estimated_duration": 3599.544143732071,
    "input_throughput": 870.0551722510319,
    "output_throughput": 759.8920559879643,
    "total_throughput": 1629.947228238996,
    "itl": 24.23854847428068,
    "ttft": 3980.6688129410713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 12790,
    "finished_requests": 12776,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3195329797454178. Arrivals time: 0.04231688333675265 Scheduler time: 0.8985630655661225 Scheduler overhead time: 0.12661709589883685 Adapter cache time: 0.0638955938629806 Engine time: 0.12532822182402015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8403910 . Total output tokens: 7439174
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3099581901915371,
    "estimated_duration": 3599.54418518821,
    "input_throughput": 870.0551622305608,
    "output_throughput": 759.8920472362477,
    "total_throughput": 1629.9472094668085,
    "itl": 24.239050241466803,
    "ttft": 3980.605413310952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 12790,
    "finished_requests": 12776,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.31002851203084. Arrivals time: 0.04249240504577756 Scheduler time: 0.8913965057581663 Scheduler overhead time: 0.12536044651642442 Adapter cache time: 0.06358678126707673 Engine time: 0.12521612364798784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8090413 . Total output tokens: 7145923
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2956471550278366,
    "estimated_duration": 3599.5431546591212,
    "input_throughput": 842.1277005878995,
    "output_throughput": 730.5404844490678,
    "total_throughput": 1572.6681850369673,
    "itl": 24.14581631522794,
    "ttft": 4420.768905825579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 12326,
    "finished_requests": 12311,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2957465397194028. Arrivals time: 0.04138520732522011 Scheduler time: 0.8810003097169101 Scheduler overhead time: 0.1261384543031454 Adapter cache time: 0.060511695221066475 Engine time: 0.12444197246804833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8090413 . Total output tokens: 7145923
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2883634339086711,
    "estimated_duration": 3599.5470529957597,
    "input_throughput": 842.126788557241,
    "output_throughput": 730.5396932682067,
    "total_throughput": 1572.6664818254478,
    "itl": 24.14599236008243,
    "ttft": 4420.897212055777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 12326,
    "finished_requests": 12311,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2884264709427953. Arrivals time: 0.04075582139194012 Scheduler time: 0.872790074441582 Scheduler overhead time: 0.12553098937496543 Adapter cache time: 0.060108364559710026 Engine time: 0.12630853336304426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8090413 . Total output tokens: 7145923
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2872339701279998,
    "estimated_duration": 3599.5410418412716,
    "input_throughput": 842.1281948904834,
    "output_throughput": 730.5409132534508,
    "total_throughput": 1572.6691081439342,
    "itl": 24.14690060444404,
    "ttft": 4420.866797965361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 12326,
    "finished_requests": 12311,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2873066142201424. Arrivals time: 0.04115427518263459 Scheduler time: 0.872952236328274 Scheduler overhead time: 0.12625293526798487 Adapter cache time: 0.0597668862901628 Engine time: 0.12502343812957406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8090413 . Total output tokens: 7145923
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2774796299636364,
    "estimated_duration": 3599.541091963313,
    "input_throughput": 842.1281831642151,
    "output_throughput": 730.5409030809867,
    "total_throughput": 1572.669086245202,
    "itl": 24.14594518533996,
    "ttft": 4420.839942630969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939695,
    "arrivals": 12326,
    "finished_requests": 12311,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.277552321087569. Arrivals time: 0.04228574549779296 Scheduler time: 0.8642973760142922 Scheduler overhead time: 0.12482836004346609 Adapter cache time: 0.05951176444068551 Engine time: 0.12436139490455389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8090413 . Total output tokens: 7145923
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2915032566525042,
    "estimated_duration": 3599.5392389172266,
    "input_throughput": 842.1286166925727,
    "output_throughput": 730.5412791641106,
    "total_throughput": 1572.6698958566833,
    "itl": 24.145935240062567,
    "ttft": 4420.792263538625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 12326,
    "finished_requests": 12311,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2915721526369452. Arrivals time: 0.041254693642258644 Scheduler time: 0.8765225801616907 Scheduler overhead time: 0.12651389790698886 Adapter cache time: 0.05971716437488794 Engine time: 0.12479563243687153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8090413 . Total output tokens: 7145923
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2885742951184511,
    "estimated_duration": 3599.5608250568794,
    "input_throughput": 842.1235665470664,
    "output_throughput": 730.5368981946423,
    "total_throughput": 1572.6604647417087,
    "itl": 24.14596406716887,
    "ttft": 4420.78577627543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 12326,
    "finished_requests": 12311,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.288637521211058. Arrivals time: 0.04126143641769886 Scheduler time: 0.8732705772854388 Scheduler overhead time: 0.12610987620428205 Adapter cache time: 0.060116615146398544 Engine time: 0.1253027687780559 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8090413 . Total output tokens: 7145923
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.287768717855215,
    "estimated_duration": 3599.558296743145,
    "input_throughput": 842.1241580509131,
    "output_throughput": 730.5374113205096,
    "total_throughput": 1572.6615693714227,
    "itl": 24.146039674116672,
    "ttft": 4420.809214884267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 12326,
    "finished_requests": 12311,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2878296705894172. Arrivals time: 0.04112872527912259 Scheduler time: 0.8730390365235507 Scheduler overhead time: 0.1264656945131719 Adapter cache time: 0.05971274524927139 Engine time: 0.12465594196692109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7932571 . Total output tokens: 7011702
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2691653887741268,
    "estimated_duration": 3599.6223405846226,
    "input_throughput": 830.0151286189524,
    "output_throughput": 718.3514700545045,
    "total_throughput": 1548.3665986734568,
    "itl": 23.78197998887826,
    "ttft": 6307.365078834339,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.269235952757299. Arrivals time: 0.04088548570871353 Scheduler time: 0.853663023095578 Scheduler overhead time: 0.1259631710126996 Adapter cache time: 0.05843834299594164 Engine time: 0.12660740315914154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7932571 . Total output tokens: 7011702
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2988642160780728,
    "estimated_duration": 3599.6258065776424,
    "input_throughput": 830.0143294173696,
    "output_throughput": 718.35077837117,
    "total_throughput": 1548.3651077885395,
    "itl": 23.782178101545306,
    "ttft": 6307.475729447467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489667,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2989343740046024. Arrivals time: 0.04202226176857948 Scheduler time: 0.877444529440254 Scheduler overhead time: 0.12785021401941776 Adapter cache time: 0.05942755937576294 Engine time: 0.12899044854566455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7932571 . Total output tokens: 7011702
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.30589281860739,
    "estimated_duration": 3599.6192574989554,
    "input_throughput": 830.0158395296247,
    "output_throughput": 718.3520853248881,
    "total_throughput": 1548.367924854513,
    "itl": 23.782477041941267,
    "ttft": 6307.563652241058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3059625797905028. Arrivals time: 0.04302271641790867 Scheduler time: 0.8702534940093756 Scheduler overhead time: 0.1359624844044447 Adapter cache time: 0.05962367216125131 Engine time: 0.12766067124903202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7932571 . Total output tokens: 7011702
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2790268012322485,
    "estimated_duration": 3599.6192940949168,
    "input_throughput": 830.0158310911692,
    "output_throughput": 718.3520780216754,
    "total_throughput": 1548.3679091128447,
    "itl": 23.782126551781047,
    "ttft": 6307.336822058733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939695,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2791165453381836. Arrivals time: 0.04098504036664963 Scheduler time: 0.8607645630836487 Scheduler overhead time: 0.1291317348368466 Adapter cache time: 0.05942814191803336 Engine time: 0.1254563075490296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7932571 . Total output tokens: 7011702
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2701716860756278,
    "estimated_duration": 3599.6194522360834,
    "input_throughput": 830.0157946262946,
    "output_throughput": 718.3520464624962,
    "total_throughput": 1548.3678410887908,
    "itl": 23.782512971815084,
    "ttft": 6307.607547321428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2702227211557329. Arrivals time: 0.04083453817293048 Scheduler time: 0.8546749716624618 Scheduler overhead time: 0.1273270850069821 Adapter cache time: 0.05855899769812822 Engine time: 0.12549635907635093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7932571 . Total output tokens: 7011702
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2855109223164618,
    "estimated_duration": 3599.6290417316122,
    "input_throughput": 830.0135834449036,
    "output_throughput": 718.3501327559287,
    "total_throughput": 1548.3637162008324,
    "itl": 23.7818403901901,
    "ttft": 6307.455056691849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.285582517273724. Arrivals time: 0.04118085978552699 Scheduler time: 0.8653686428442597 Scheduler overhead time: 0.12845485331490636 Adapter cache time: 0.05898434296250343 Engine time: 0.12770924624055624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7932571 . Total output tokens: 7011702
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2788851438090205,
    "estimated_duration": 3599.627692488725,
    "input_throughput": 830.0138945576128,
    "output_throughput": 718.3504020139992,
    "total_throughput": 1548.364296571612,
    "itl": 23.78228559625311,
    "ttft": 6307.371889799816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.278955995105207. Arrivals time: 0.040929730981588364 Scheduler time: 0.8580220369622111 Scheduler overhead time: 0.12848844472318888 Adapter cache time: 0.0587674449197948 Engine time: 0.12933695642277598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7152847 . Total output tokens: 6336847
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2245251769199967,
    "estimated_duration": 3599.353779792303,
    "input_throughput": 745.8085990521615,
    "output_throughput": 652.2129092115704,
    "total_throughput": 1398.021508263732,
    "itl": 23.388735925423838,
    "ttft": 5983.500467081857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 10900,
    "finished_requests": 10882,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2245937772095203. Arrivals time: 0.03894610796123743 Scheduler time: 0.8065609699115157 Scheduler overhead time: 0.12885338813066483 Adapter cache time: 0.05842626327648759 Engine time: 0.12728774826973677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7152847 . Total output tokens: 6336847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2131339726038277,
    "estimated_duration": 3599.3536460088517,
    "input_throughput": 745.8086267729299,
    "output_throughput": 652.2129334535045,
    "total_throughput": 1398.0215602264343,
    "itl": 23.388994032548176,
    "ttft": 5983.505825486765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 10900,
    "finished_requests": 10882,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2131847846321762. Arrivals time: 0.0384711972437799 Scheduler time: 0.7980236187577248 Scheduler overhead time: 0.12818615045398474 Adapter cache time: 0.05779364658519626 Engine time: 0.12714516511186957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7152847 . Total output tokens: 6336847
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2213692772202194,
    "estimated_duration": 3599.3518098896266,
    "input_throughput": 745.8090072285314,
    "output_throughput": 652.213266163606,
    "total_throughput": 1398.0222733921373,
    "itl": 23.38902928221518,
    "ttft": 5983.498261631068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 10900,
    "finished_requests": 10882,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2214280129410326. Arrivals time: 0.03877485450357199 Scheduler time: 0.8019780204631388 Scheduler overhead time: 0.1277301562950015 Adapter cache time: 0.05748179368674755 Engine time: 0.13125135051086545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7152847 . Total output tokens: 6336847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2141494960524142,
    "estimated_duration": 3599.3517901135565,
    "input_throughput": 745.8090113262612,
    "output_throughput": 652.2132697470888,
    "total_throughput": 1398.02228107335,
    "itl": 23.388739865180913,
    "ttft": 5983.456695565905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4391118016093972,
    "arrivals": 10900,
    "finished_requests": 10882,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2142196861095726. Arrivals time: 0.03853102121502161 Scheduler time: 0.7954860790632665 Scheduler overhead time: 0.13034729193896055 Adapter cache time: 0.05680979462340474 Engine time: 0.12805967219173908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7152847 . Total output tokens: 6336847
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2285399241372943,
    "estimated_duration": 3599.3455732958523,
    "input_throughput": 745.8102994933936,
    "output_throughput": 652.2143962549275,
    "total_throughput": 1398.024695748321,
    "itl": 23.389127484159804,
    "ttft": 5983.3480873268145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 10900,
    "finished_requests": 10882,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2286422359757125. Arrivals time: 0.038632380310446024 Scheduler time: 0.8046091822907329 Scheduler overhead time: 0.13329516677185893 Adapter cache time: 0.05782388150691986 Engine time: 0.12897462444379926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7152847 . Total output tokens: 6336847
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2012765472754836,
    "estimated_duration": 3599.3588729063636,
    "input_throughput": 745.8075437285897,
    "output_throughput": 652.2119863264523,
    "total_throughput": 1398.019530055042,
    "itl": 23.388678999641048,
    "ttft": 5983.450261359557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 10900,
    "finished_requests": 10882,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2013267814181745. Arrivals time: 0.037779299542307854 Scheduler time: 0.7845972934737802 Scheduler overhead time: 0.12927271472290158 Adapter cache time: 0.05703131482005119 Engine time: 0.1278363955207169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7152847 . Total output tokens: 6336847
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.218655512202531,
    "estimated_duration": 3599.35996354441,
    "input_throughput": 745.807317742278,
    "output_throughput": 652.211788700426,
    "total_throughput": 1398.019106442704,
    "itl": 23.389051533064947,
    "ttft": 5983.463401281297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 10900,
    "finished_requests": 10882,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2187580564059317. Arrivals time: 0.03908777283504605 Scheduler time: 0.7984339143149555 Scheduler overhead time: 0.12864344520494342 Adapter cache time: 0.05752427317202091 Engine time: 0.13001064583659172 
