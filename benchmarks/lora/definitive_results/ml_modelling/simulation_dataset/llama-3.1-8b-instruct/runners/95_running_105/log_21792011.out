INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8557825428433716,
    "estimated_duration": 3599.627387526262,
    "input_throughput": 1388.8854211201397,
    "output_throughput": 1234.563892751685,
    "total_throughput": 2623.4493138718244,
    "itl": 29.431279529050542,
    "ttft": 5897.263629434334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 70.2965204186612,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.050883876328724924
}
#Debug simulation 
Total elapsed time: 1.855897509958595. Arrivals time: 0.06107154441997409 Scheduler time: 1.438536839094013 Scheduler overhead time: 0.11011253669857979 Adapter cache time: 0.07963879918679595 Engine time: 0.11197980027645826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8429369386285543,
    "estimated_duration": 3599.6211066420224,
    "input_throughput": 1388.8878445497987,
    "output_throughput": 1234.5660469097663,
    "total_throughput": 2623.453891459565,
    "itl": 29.513726286951254,
    "ttft": 5913.03403233236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 77.7541373487534,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.053063845495546595
}
#Debug simulation 
Total elapsed time: 1.843043573666364. Arrivals time: 0.05975733697414398 Scheduler time: 1.4360478995367885 Scheduler overhead time: 0.10887178173288703 Adapter cache time: 0.0784686584956944 Engine time: 0.10580478236079216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.829822240397334,
    "estimated_duration": 3599.6309669177504,
    "input_throughput": 1388.88404004394,
    "output_throughput": 1234.5626651293176,
    "total_throughput": 2623.4467051732577,
    "itl": 29.533715550012097,
    "ttft": 5916.1398436005475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10610,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 79.90453765529381,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.05335803026540692
}
#Debug simulation 
Total elapsed time: 1.829955954104662. Arrivals time: 0.059021344408392906 Scheduler time: 1.421485386788845 Scheduler overhead time: 0.11095332074910402 Adapter cache time: 0.07808080362156034 Engine time: 0.10649459529668093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.8405618998222053,
    "estimated_duration": 3599.636787939883,
    "input_throughput": 1388.8817940604665,
    "output_throughput": 1234.5606687010606,
    "total_throughput": 2623.442462761527,
    "itl": 29.466099922808738,
    "ttft": 5904.047413575195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 73.4320387972191,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.051667198698916575
}
#Debug simulation 
Total elapsed time: 1.8406483349390328. Arrivals time: 0.06013868935406208 Scheduler time: 1.4308514543808997 Scheduler overhead time: 0.10975602362304926 Adapter cache time: 0.07854792568832636 Engine time: 0.10753318527713418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.876806226093322,
    "estimated_duration": 3599.6180706892033,
    "input_throughput": 1388.8890159512875,
    "output_throughput": 1234.567088154753,
    "total_throughput": 2623.4561041060406,
    "itl": 29.530895834626687,
    "ttft": 5916.281997993003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 79.26526731726861,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.053498507187985093
}
#Debug simulation 
Total elapsed time: 1.8768800520338118. Arrivals time: 0.059957670979201794 Scheduler time: 1.4631204227916896 Scheduler overhead time: 0.1093344921246171 Adapter cache time: 0.08134483592584729 Engine time: 0.10945492843165994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8336092070676386,
    "estimated_duration": 3599.61175026278,
    "input_throughput": 1388.8914546506376,
    "output_throughput": 1234.5692558858827,
    "total_throughput": 2623.4607105365203,
    "itl": 29.405494049261755,
    "ttft": 5892.464236590087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10635,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.89299920297124,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.05015128037685508
}
#Debug simulation 
Total elapsed time: 1.833749630022794. Arrivals time: 0.059073634911328554 Scheduler time: 1.4271139772608876 Scheduler overhead time: 0.10924916481599212 Adapter cache time: 0.07819069037213922 Engine time: 0.10646374570205808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.90293881110847,
    "estimated_duration": 3599.6270613726624,
    "input_throughput": 1388.885546963726,
    "output_throughput": 1234.5640046125668,
    "total_throughput": 2623.449551576293,
    "itl": 29.51860562964492,
    "ttft": 5914.39499919688,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 78.38280037926619,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.053288726964214495
}
#Debug simulation 
Total elapsed time: 1.903032346162945. Arrivals time: 0.06336098164319992 Scheduler time: 1.4892765716649592 Scheduler overhead time: 0.10875185718759894 Adapter cache time: 0.07964559737592936 Engine time: 0.10804994776844978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8428921569138765,
    "estimated_duration": 3600.0025922319182,
    "input_throughput": 1366.2187384567164,
    "output_throughput": 1187.3827561190335,
    "total_throughput": 2553.6014945757497,
    "itl": 28.913320119232402,
    "ttft": 7013.465374204251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.79702980458606,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.038574958938461766
}
#Debug simulation 
Total elapsed time: 1.8429835950955749. Arrivals time: 0.059990013018250465 Scheduler time: 1.4259426197968423 Scheduler overhead time: 0.11031201528385282 Adapter cache time: 0.07847255188971758 Engine time: 0.11335805198177695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8187623722478747,
    "estimated_duration": 3600.0184388873627,
    "input_throughput": 1366.2127245992938,
    "output_throughput": 1187.3775294665215,
    "total_throughput": 2553.5902540658153,
    "itl": 28.990233489141804,
    "ttft": 7021.334674351769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 75.09250472362712,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.03988369873225075
}
#Debug simulation 
Total elapsed time: 1.8189114350825548. Arrivals time: 0.05945521220564842 Scheduler time: 1.4084408143535256 Scheduler overhead time: 0.10956294322386384 Adapter cache time: 0.07850344385951757 Engine time: 0.10855155671015382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8328034151345491,
    "estimated_duration": 3600.001701502448,
    "input_throughput": 1366.0790765591964,
    "output_throughput": 1187.351661032845,
    "total_throughput": 2553.430737592041,
    "itl": 29.014494822087634,
    "ttft": 7024.146446366629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 77.15733220867398,
    "arrivals": 19983,
    "finished_requests": 19945,
    "scheduler_time": 0.04019228444609707
}
#Debug simulation 
Total elapsed time: 1.8328927648253739. Arrivals time: 0.06034831143915653 Scheduler time: 1.4183768210932612 Scheduler overhead time: 0.1103154425509274 Adapter cache time: 0.07807293953374028 Engine time: 0.11139695905148983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.8307804698124528,
    "estimated_duration": 3600.0198746672954,
    "input_throughput": 1366.2121797187426,
    "output_throughput": 1187.3770559100165,
    "total_throughput": 2553.589235628759,
    "itl": 28.95024297924132,
    "ttft": 7017.158156665304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 71.13661317824395,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.03905808532363286
}
#Debug simulation 
Total elapsed time: 1.830869804136455. Arrivals time: 0.05948736611753702 Scheduler time: 1.417623396962881 Scheduler overhead time: 0.1102008898742497 Adapter cache time: 0.07834868831560016 Engine time: 0.11070781573653221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8265420808456838,
    "estimated_duration": 3600.0068860113465,
    "input_throughput": 1366.0771092159794,
    "output_throughput": 1187.349951081879,
    "total_throughput": 2553.4270602978586,
    "itl": 29.006859219778676,
    "ttft": 7203.237360305509,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 76.60406138186839,
    "arrivals": 19983,
    "finished_requests": 19945,
    "scheduler_time": 0.040197405797673516
}
#Debug simulation 
Total elapsed time: 1.8266863101162016. Arrivals time: 0.05988304549828172 Scheduler time: 1.412508808542043 Scheduler overhead time: 0.10970372194424272 Adapter cache time: 0.0783955859951675 Engine time: 0.11152655631303787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8306463779881597,
    "estimated_duration": 3600.0105716864814,
    "input_throughput": 1366.2157102210683,
    "output_throughput": 1187.3801242748866,
    "total_throughput": 2553.595834495955,
    "itl": 28.8856819150806,
    "ttft": 7011.174528788529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.40965395709173,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.03808685113430471
}
#Debug simulation 
Total elapsed time: 1.830737286247313. Arrivals time: 0.05977935250848532 Scheduler time: 1.416175551712513 Scheduler overhead time: 0.11052283877506852 Adapter cache time: 0.07812007796019316 Engine time: 0.11162575054913759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8253472652286291,
    "estimated_duration": 3600.015573218224,
    "input_throughput": 1366.2138121261564,
    "output_throughput": 1187.37847463775,
    "total_throughput": 2553.5922867639065,
    "itl": 28.99624278633449,
    "ttft": 7022.046329047965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 75.73660577025255,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.04006130004753756
}
#Debug simulation 
Total elapsed time: 1.8254649671725929. Arrivals time: 0.059423781000077724 Scheduler time: 1.414266531355679 Scheduler overhead time: 0.11009070044383407 Adapter cache time: 0.07800117414444685 Engine time: 0.10919036343693733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.6929916110821068,
    "estimated_duration": 3600.007434517607,
    "input_throughput": 1279.0806918477988,
    "output_throughput": 1115.492974124401,
    "total_throughput": 2394.5736659721997,
    "itl": 27.996749655122454,
    "ttft": 7078.738987429697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.870277611455045,
    "arrivals": 18589,
    "finished_requests": 18552,
    "scheduler_time": 0.011729693664541732
}
#Debug simulation 
Total elapsed time: 1.693081029690802. Arrivals time: 0.055096286814659834 Scheduler time: 1.287031955551356 Scheduler overhead time: 0.11262751976028085 Adapter cache time: 0.07299290783703327 Engine time: 0.11008149432018399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6858162959106266,
    "estimated_duration": 3600.0330480205416,
    "input_throughput": 1279.0715914488255,
    "output_throughput": 1115.4850376187674,
    "total_throughput": 2394.556629067593,
    "itl": 28.068180212789155,
    "ttft": 7274.310307763653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.39941665665512,
    "arrivals": 18589,
    "finished_requests": 18552,
    "scheduler_time": 0.012140651676070284
}
#Debug simulation 
Total elapsed time: 1.685905649792403. Arrivals time: 0.05520235374569893 Scheduler time: 1.2803973061963916 Scheduler overhead time: 0.11208891402930021 Adapter cache time: 0.07252278970554471 Engine time: 0.11047071916982532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7179337092675269,
    "estimated_duration": 3600.0326226301145,
    "input_throughput": 1279.071742587681,
    "output_throughput": 1115.4851694277554,
    "total_throughput": 2394.5569120154364,
    "itl": 28.09033454831885,
    "ttft": 7274.993920902619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8906,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.19895097842051,
    "arrivals": 18589,
    "finished_requests": 18552,
    "scheduler_time": 0.012233430578022533
}
#Debug simulation 
Total elapsed time: 1.7180091831833124. Arrivals time: 0.055861514527350664 Scheduler time: 1.3070612279698253 Scheduler overhead time: 0.11269293213263154 Adapter cache time: 0.07330304849892855 Engine time: 0.11365160439163446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.681638713926077,
    "estimated_duration": 3600.030953907548,
    "input_throughput": 1279.0723354758836,
    "output_throughput": 1115.4856864886638,
    "total_throughput": 2394.558021964547,
    "itl": 28.029193559446806,
    "ttft": 7273.108959749936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 61.81087491832804,
    "arrivals": 18589,
    "finished_requests": 18552,
    "scheduler_time": 0.011923147838105145
}
#Debug simulation 
Total elapsed time: 1.681730545591563. Arrivals time: 0.055731242056936026 Scheduler time: 1.2756932005286217 Scheduler overhead time: 0.11172371823340654 Adapter cache time: 0.07220268342643976 Engine time: 0.1096358853392303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6884735319763422,
    "estimated_duration": 3600.0006928888406,
    "input_throughput": 1279.083087149334,
    "output_throughput": 1115.495063079422,
    "total_throughput": 2394.578150228756,
    "itl": 28.0803127751588,
    "ttft": 7081.43980211066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8899,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.61452865059535,
    "arrivals": 18589,
    "finished_requests": 18552,
    "scheduler_time": 0.01225241532605545
}
#Debug simulation 
Total elapsed time: 1.6885619526728988. Arrivals time: 0.054948539938777685 Scheduler time: 1.2814892777241766 Scheduler overhead time: 0.11260510608553886 Adapter cache time: 0.07256910158321261 Engine time: 0.11152239516377449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.6836374248377979,
    "estimated_duration": 3600.035096484077,
    "input_throughput": 1279.0708636416114,
    "output_throughput": 1115.484402894282,
    "total_throughput": 2394.5552665358937,
    "itl": 27.977104892287784,
    "ttft": 7271.315486645297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8906,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.85519989672765,
    "arrivals": 18589,
    "finished_requests": 18552,
    "scheduler_time": 0.011649369556505942
}
#Debug simulation 
Total elapsed time: 1.6837252536788583. Arrivals time: 0.05534589011222124 Scheduler time: 1.276934230234474 Scheduler overhead time: 0.11210729088634253 Adapter cache time: 0.07304941583424807 Engine time: 0.11031601577997208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.680785465054214,
    "estimated_duration": 3600.026931350968,
    "input_throughput": 1279.0737646709804,
    "output_throughput": 1115.4869328971972,
    "total_throughput": 2394.5606975681776,
    "itl": 28.072695929905052,
    "ttft": 7274.597404608165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.90364464541449,
    "arrivals": 18589,
    "finished_requests": 18552,
    "scheduler_time": 0.012212261678013493
}
#Debug simulation 
Total elapsed time: 1.6808745809830725. Arrivals time: 0.05554842669516802 Scheduler time: 1.2719898005016148 Scheduler overhead time: 0.11165410047397017 Adapter cache time: 0.07268466427922249 Engine time: 0.11352648632600904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.6648148940876126,
    "estimated_duration": 3599.854569529013,
    "input_throughput": 1231.7842052658684,
    "output_throughput": 1095.43341927725,
    "total_throughput": 2327.2176245431183,
    "itl": 28.02087693143789,
    "ttft": 7286.101297245972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.69479503994286,
    "arrivals": 18102,
    "finished_requests": 18066,
    "scheduler_time": 0.011772598328514454
}
#Debug simulation 
Total elapsed time: 1.6649022456258535. Arrivals time: 0.05419520195573568 Scheduler time: 1.2620428600348532 Scheduler overhead time: 0.11177535774186254 Adapter cache time: 0.07064754934981465 Engine time: 0.11052803555503488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6746107512153685,
    "estimated_duration": 3599.8481981764357,
    "input_throughput": 1231.786385394318,
    "output_throughput": 1095.4353580791537,
    "total_throughput": 2327.2217434734716,
    "itl": 27.82856450894817,
    "ttft": 7252.643953296631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 61.57890384931354,
    "arrivals": 18102,
    "finished_requests": 18066,
    "scheduler_time": 0.013273891392619147
}
#Debug simulation 
Total elapsed time: 1.6747033153660595. Arrivals time: 0.054197919089347124 Scheduler time: 1.2619974673725665 Scheduler overhead time: 0.11706065060570836 Adapter cache time: 0.07039422122761607 Engine time: 0.11374854808673263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6556055550463498,
    "estimated_duration": 3599.831833704526,
    "input_throughput": 1231.7919849708076,
    "output_throughput": 1095.4403378176453,
    "total_throughput": 2327.232322788453,
    "itl": 27.848559545164594,
    "ttft": 7253.106818884229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.30541107133922,
    "arrivals": 18102,
    "finished_requests": 18066,
    "scheduler_time": 0.013430372237643633
}
#Debug simulation 
Total elapsed time: 1.6556991660036147. Arrivals time: 0.05437362054362893 Scheduler time: 1.2521321293897927 Scheduler overhead time: 0.11235889233648777 Adapter cache time: 0.07076970161870122 Engine time: 0.11052255239337683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.6887233811430633,
    "estimated_duration": 3599.832647189704,
    "input_throughput": 1231.791706612167,
    "output_throughput": 1095.4400902715606,
    "total_throughput": 2327.2317968837274,
    "itl": 27.920824548310318,
    "ttft": 7267.430516757779,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.98325140751534,
    "arrivals": 18102,
    "finished_requests": 18066,
    "scheduler_time": 0.012286011473430789
}
#Debug simulation 
Total elapsed time: 1.6888214368373156. Arrivals time: 0.055413118563592434 Scheduler time: 1.2726248214021325 Scheduler overhead time: 0.11983109964057803 Adapter cache time: 0.070565574336797 Engine time: 0.11327523924410343 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6689667720347643,
    "estimated_duration": 3599.848398015926,
    "input_throughput": 1231.7863170137819,
    "output_throughput": 1095.4352972679142,
    "total_throughput": 2327.221614281696,
    "itl": 27.842214062400057,
    "ttft": 7252.9487638107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8395,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.82976330283996,
    "arrivals": 18102,
    "finished_requests": 18066,
    "scheduler_time": 0.013400687043072618
}
#Debug simulation 
Total elapsed time: 1.6690451237373054. Arrivals time: 0.05437951209023595 Scheduler time: 1.2594072865322232 Scheduler overhead time: 0.11270117294043303 Adapter cache time: 0.07278169691562653 Engine time: 0.1137505704537034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.6603451510891318,
    "estimated_duration": 3599.844317816132,
    "input_throughput": 1231.7877131670132,
    "output_throughput": 1095.4365388757392,
    "total_throughput": 2327.2242520427526,
    "itl": 27.745265488644424,
    "ttft": 7250.674036642925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8395,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.59301629609567,
    "arrivals": 18102,
    "finished_requests": 18066,
    "scheduler_time": 0.012640783065865455
}
#Debug simulation 
Total elapsed time: 1.6604351908899844. Arrivals time: 0.053539115004241467 Scheduler time: 1.2523900684900582 Scheduler overhead time: 0.11596872750669718 Adapter cache time: 0.07053280947729945 Engine time: 0.11122599896043539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6611609780229628,
    "estimated_duration": 3599.848873564932,
    "input_throughput": 1231.78615429174,
    "output_throughput": 1095.4351525581817,
    "total_throughput": 2327.221306849922,
    "itl": 27.83440421274089,
    "ttft": 7252.799753476675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.0939856983486,
    "arrivals": 18102,
    "finished_requests": 18066,
    "scheduler_time": 0.01334651181504309
}
#Debug simulation 
Total elapsed time: 1.6612536292523146. Arrivals time: 0.053720591589808464 Scheduler time: 1.2570998035371304 Scheduler overhead time: 0.11274124775081873 Adapter cache time: 0.07068268954753876 Engine time: 0.11134160216897726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.5805027349852026,
    "estimated_duration": 3600.01304148875,
    "input_throughput": 1185.8276486227949,
    "output_throughput": 1019.9365829190357,
    "total_throughput": 2205.76423154183,
    "itl": 26.83785835238387,
    "ttft": 5717.332199178027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.92623319924369,
    "arrivals": 17157,
    "finished_requests": 17130,
    "scheduler_time": 0.0013243045970529914
}
#Debug simulation 
Total elapsed time: 1.5805927217006683. Arrivals time: 0.05296778026968241 Scheduler time: 1.1745745223015547 Scheduler overhead time: 0.11667117942124605 Adapter cache time: 0.0647168536670506 Engine time: 0.11435765121132135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.609280512202531,
    "estimated_duration": 3600.0064872894286,
    "input_throughput": 1185.8298075496737,
    "output_throughput": 1019.9384398233726,
    "total_throughput": 2205.7682473730465,
    "itl": 26.886908424581563,
    "ttft": 5508.406879785351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6639,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.86861951176353,
    "arrivals": 17157,
    "finished_requests": 17130,
    "scheduler_time": 0.001374887632942925
}
#Debug simulation 
Total elapsed time: 1.6093694171868265. Arrivals time: 0.052359001245349646 Scheduler time: 1.199999900534749 Scheduler overhead time: 0.11980725405737758 Adapter cache time: 0.06481888284906745 Engine time: 0.11426434153690934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.5666185491718352,
    "estimated_duration": 3600.0157736210417,
    "input_throughput": 1185.8267486717348,
    "output_throughput": 1019.9358088664067,
    "total_throughput": 2205.7625575381417,
    "itl": 26.899212615015117,
    "ttft": 5718.074478956729,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6638,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 50.24946168262267,
    "arrivals": 17157,
    "finished_requests": 17130,
    "scheduler_time": 0.0013733117214015198
}
#Debug simulation 
Total elapsed time: 1.5667112860828638. Arrivals time: 0.05170319648459554 Scheduler time: 1.1642864299938083 Scheduler overhead time: 0.115753382910043 Adapter cache time: 0.06445498205721378 Engine time: 0.11356464168056846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.5866701821796596,
    "estimated_duration": 3600.0063425143417,
    "input_throughput": 1185.8298552380934,
    "output_throughput": 1019.9384808404327,
    "total_throughput": 2205.7683360785263,
    "itl": 26.72489401638522,
    "ttft": 5506.352677459371,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.456098969486405,
    "arrivals": 17157,
    "finished_requests": 17130,
    "scheduler_time": 0.001193440202501326
}
#Debug simulation 
Total elapsed time: 1.5867652520537376. Arrivals time: 0.05277311569079757 Scheduler time: 1.1728973230347037 Scheduler overhead time: 0.11658108234405518 Adapter cache time: 0.06528221722692251 Engine time: 0.12115189526230097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.5941835991106927,
    "estimated_duration": 3600.0135212058035,
    "input_throughput": 1185.8274906062368,
    "output_throughput": 1019.9364470081649,
    "total_throughput": 2205.7639376144016,
    "itl": 26.896792944315173,
    "ttft": 5717.8903849831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6642,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.89424973867129,
    "arrivals": 17157,
    "finished_requests": 17130,
    "scheduler_time": 0.0013995689114597854
}
#Debug simulation 
Total elapsed time: 1.5942762740887702. Arrivals time: 0.05217099329456687 Scheduler time: 1.1896358444355428 Scheduler overhead time: 0.11584974220022559 Adapter cache time: 0.06495275208726525 Engine time: 0.1143656624481082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.568494654726237,
    "estimated_duration": 3600.0154143444224,
    "input_throughput": 1185.826867015624,
    "output_throughput": 1019.9359106546068,
    "total_throughput": 2205.7627776702307,
    "itl": 26.82069205100821,
    "ttft": 5717.166533785476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.421154650095744,
    "arrivals": 17157,
    "finished_requests": 17130,
    "scheduler_time": 0.0012835361468477814
}
#Debug simulation 
Total elapsed time: 1.5685778288170695. Arrivals time: 0.05155963031575084 Scheduler time: 1.1654609818942845 Scheduler overhead time: 0.11584057938307524 Adapter cache time: 0.0646934057585895 Engine time: 0.11417578207328916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.5840806378982961,
    "estimated_duration": 3600.0164172105765,
    "input_throughput": 1185.8265366766777,
    "output_throughput": 1019.9356265283458,
    "total_throughput": 2205.7621632050236,
    "itl": 26.890221384292303,
    "ttft": 5717.793320919796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6635,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.26120674332377,
    "arrivals": 17157,
    "finished_requests": 17130,
    "scheduler_time": 0.0013817547688039702
}
#Debug simulation 
Total elapsed time: 1.5841735168360174. Arrivals time: 0.051984438207000494 Scheduler time: 1.178469244390726 Scheduler overhead time: 0.11564727732911706 Adapter cache time: 0.06449304847046733 Engine time: 0.11627068370580673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.354880812112242,
    "estimated_duration": 3599.5522748843528,
    "input_throughput": 925.3461946477812,
    "output_throughput": 809.5459594606448,
    "total_throughput": 1734.892154108426,
    "itl": 25.85552487422067,
    "ttft": 5556.8493559518965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.507102579028604,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3549521560780704. Arrivals time: 0.04451461276039481 Scheduler time: 0.9447954869829118 Scheduler overhead time: 0.11851404700428247 Adapter cache time: 0.0717764226719737 Engine time: 0.11653850832954049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.380376448854804,
    "estimated_duration": 3599.551600318593,
    "input_throughput": 925.3463680601748,
    "output_throughput": 809.5461111717593,
    "total_throughput": 1734.8924792319342,
    "itl": 25.924547202577045,
    "ttft": 5557.827002565748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 69.27068906766752,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3804549290798604. Arrivals time: 0.046088422648608685 Scheduler time: 0.9663256350904703 Scheduler overhead time: 0.1192144793458283 Adapter cache time: 0.07254126388579607 Engine time: 0.11740948678925633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3685792787000537,
    "estimated_duration": 3599.5576031061128,
    "input_throughput": 925.3448249100875,
    "output_throughput": 809.544761135497,
    "total_throughput": 1734.8895860455843,
    "itl": 25.94429194832668,
    "ttft": 5558.202581738038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 71.20628655111203,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3686525668017566. Arrivals time: 0.04481628863140941 Scheduler time: 0.9550598501227796 Scheduler overhead time: 0.11829783115535975 Adapter cache time: 0.07307398179545999 Engine time: 0.11887582438066602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.3652553739957511,
    "estimated_duration": 3599.53768321989,
    "input_throughput": 925.3499457798356,
    "output_throughput": 809.5492411662545,
    "total_throughput": 1734.8991869460901,
    "itl": 25.886330789177318,
    "ttft": 5557.313978194807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.27149829667671,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3653509560972452. Arrivals time: 0.0448205778375268 Scheduler time: 0.9531835420057178 Scheduler overhead time: 0.11907673813402653 Adapter cache time: 0.07240790640935302 Engine time: 0.11697748163715005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3858235920779407,
    "estimated_duration": 3599.539915990993,
    "input_throughput": 925.3493717913071,
    "output_throughput": 809.5487390081471,
    "total_throughput": 1734.8981107994543,
    "itl": 25.938904934995342,
    "ttft": 5558.065593661209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 70.56418077246045,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3859132211655378. Arrivals time: 0.04461520630866289 Scheduler time: 0.9727339376695454 Scheduler overhead time: 0.12023915629833937 Adapter cache time: 0.07282012840732932 Engine time: 0.11677908850833774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.3894247538410127,
    "estimated_duration": 3599.551116484245,
    "input_throughput": 925.3464924407829,
    "output_throughput": 809.5462199870539,
    "total_throughput": 1734.8927124278366,
    "itl": 25.836770105827867,
    "ttft": 5556.539962149884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.385508176863624,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3895069626159966. Arrivals time: 0.04483177186921239 Scheduler time: 0.9752287287265062 Scheduler overhead time: 0.11895526805892587 Adapter cache time: 0.07287055300548673 Engine time: 0.118788942694664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3641256848350167,
    "estimated_duration": 3599.545660006588,
    "input_throughput": 925.3478951546078,
    "output_throughput": 809.5474471616138,
    "total_throughput": 1734.8953423162218,
    "itl": 25.93125157623913,
    "ttft": 5558.03315326611,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 69.86774160414662,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3642139150761068. Arrivals time: 0.044083322398364544 Scheduler time: 0.9550493061542511 Scheduler overhead time: 0.11882733833044767 Adapter cache time: 0.07188365142792463 Engine time: 0.1156347319483757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.3228681958280504,
    "estimated_duration": 3599.9343574796203,
    "input_throughput": 863.953808918197,
    "output_throughput": 758.013821649371,
    "total_throughput": 1621.967630567568,
    "itl": 25.151641452721833,
    "ttft": 5986.4379566282705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.56559933165434,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.322958170901984. Arrivals time: 0.042593412566930056 Scheduler time: 0.9089576727710664 Scheduler overhead time: 0.1225851527415216 Adapter cache time: 0.06762728793546557 Engine time: 0.12085590604692698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.31945537077263,
    "estimated_duration": 3599.9459910318233,
    "input_throughput": 863.9510169730505,
    "output_throughput": 758.0113720589086,
    "total_throughput": 1621.9623890319592,
    "itl": 25.207396076423304,
    "ttft": 5987.104435220276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.439165952236074,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.319542511831969. Arrivals time: 0.04271223209798336 Scheduler time: 0.9104601256549358 Scheduler overhead time: 0.12112887389957905 Adapter cache time: 0.0674656298942864 Engine time: 0.11813240265473723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3170347521081567,
    "estimated_duration": 3599.9395259493513,
    "input_throughput": 863.952568530941,
    "output_throughput": 758.0127333612305,
    "total_throughput": 1621.9653018921715,
    "itl": 25.224377164155797,
    "ttft": 5987.272015623248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.12862302637184,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3171021840535104. Arrivals time: 0.042324946727603674 Scheduler time: 0.9069331563077867 Scheduler overhead time: 0.12063404032960534 Adapter cache time: 0.06733082747086883 Engine time: 0.11995518067851663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.323957550805062,
    "estimated_duration": 3599.9333548593527,
    "input_throughput": 863.9540495386512,
    "output_throughput": 758.0140327643961,
    "total_throughput": 1621.9680823030474,
    "itl": 25.174544849757638,
    "ttft": 5986.802738940829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.987217575536654,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3240346778184175. Arrivals time: 0.04266141029074788 Scheduler time: 0.9132953532971442 Scheduler overhead time: 0.12106118351221085 Adapter cache time: 0.06685573980212212 Engine time: 0.12017225474119186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3182016690261662,
    "estimated_duration": 3599.933715913206,
    "input_throughput": 863.9539628887395,
    "output_throughput": 758.0139567396943,
    "total_throughput": 1621.9679196284337,
    "itl": 25.219991248653262,
    "ttft": 5987.184382777862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 61.59374758668242,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3182861269451678. Arrivals time: 0.042414501775056124 Scheduler time: 0.9061852628365159 Scheduler overhead time: 0.12172953737899661 Adapter cache time: 0.06735126068815589 Engine time: 0.120736722368747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.3062080671079457,
    "estimated_duration": 3599.9297329221704,
    "input_throughput": 863.9549187743107,
    "output_throughput": 758.0147954123959,
    "total_throughput": 1621.9697141867066,
    "itl": 25.136738961838706,
    "ttft": 5986.391152640943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.654579917831676,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3062945171259344. Arrivals time: 0.04212785279378295 Scheduler time: 0.8944933856837451 Scheduler overhead time: 0.12096972530707717 Adapter cache time: 0.0670280777849257 Engine time: 0.12139415834099054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3158607450313866,
    "estimated_duration": 3599.9523495232147,
    "input_throughput": 863.9494910014346,
    "output_throughput": 758.010033205414,
    "total_throughput": 1621.9595242068485,
    "itl": 25.212774449284577,
    "ttft": 5987.236383152021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.97539309046704,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.315951636992395. Arrivals time: 0.042588688898831606 Scheduler time: 0.9062571474350989 Scheduler overhead time: 0.12069971766322851 Adapter cache time: 0.06732835806906223 Engine time: 0.11939984699711204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2849248559214175,
    "estimated_duration": 3599.9517399673,
    "input_throughput": 834.1667380316818,
    "output_throughput": 732.561209285532,
    "total_throughput": 1566.7279473172136,
    "itl": 24.86764247494164,
    "ttft": 7089.953148427606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 50.803138592473694,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2849879399873316. Arrivals time: 0.04099113494157791 Scheduler time: 0.8762412867508829 Scheduler overhead time: 0.12199438083916903 Adapter cache time: 0.06469410751014948 Engine time: 0.1207851693034172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.290305318776518,
    "estimated_duration": 3599.961231720393,
    "input_throughput": 834.1645386455757,
    "output_throughput": 732.5592777952529,
    "total_throughput": 1566.7238164408286,
    "itl": 24.913527095106875,
    "ttft": 7090.620383081336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.284460520281385,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.290371858049184. Arrivals time: 0.041433076839894056 Scheduler time: 0.8803569776937366 Scheduler overhead time: 0.1218510721810162 Adapter cache time: 0.06522484449669719 Engine time: 0.1209876025095582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2844039131887257,
    "estimated_duration": 3599.9400389570237,
    "input_throughput": 834.1694493528339,
    "output_throughput": 732.5635903547011,
    "total_throughput": 1566.733039707535,
    "itl": 24.92957010957544,
    "ttft": 7090.710574662081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7681,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.81327659487338,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2844899762421846. Arrivals time: 0.04150444222614169 Scheduler time: 0.8742122324183583 Scheduler overhead time: 0.12204191321507096 Adapter cache time: 0.06468779454007745 Engine time: 0.12200204096734524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.2808648711070418,
    "estimated_duration": 3599.945585527862,
    "input_throughput": 834.1681641167569,
    "output_throughput": 732.5624616665722,
    "total_throughput": 1566.730625783329,
    "itl": 24.88705948087431,
    "ttft": 7090.09502708522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7681,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.16763058207588,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2809420200064778. Arrivals time: 0.041452054399996996 Scheduler time: 0.8727232892997563 Scheduler overhead time: 0.12174734845757484 Adapter cache time: 0.06456257356330752 Engine time: 0.12026129150763154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2762445430271327,
    "estimated_duration": 3599.945496332867,
    "input_throughput": 834.1681847847434,
    "output_throughput": 732.5624798170983,
    "total_throughput": 1566.7306646018417,
    "itl": 24.923693069162603,
    "ttft": 7090.533133707438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7685,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.37775469662706,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2763302084058523. Arrivals time: 0.04112910712137818 Scheduler time: 0.8678334318101406 Scheduler overhead time: 0.12215999327600002 Adapter cache time: 0.06408612662926316 Engine time: 0.120980444829911 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2919104606844485,
    "estimated_duration": 3599.9494527412207,
    "input_throughput": 834.1672680191004,
    "output_throughput": 732.5616747179288,
    "total_throughput": 1566.7289427370292,
    "itl": 24.848080076499045,
    "ttft": 7089.631130223133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.04128066546827,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.292017949745059. Arrivals time: 0.04150717472657561 Scheduler time: 0.882446011994034 Scheduler overhead time: 0.1220190548337996 Adapter cache time: 0.06487454753369093 Engine time: 0.12097336305305362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2796986340545118,
    "estimated_duration": 3599.95059287167,
    "input_throughput": 834.1670038322798,
    "output_throughput": 732.561442710336,
    "total_throughput": 1566.7284465426158,
    "itl": 24.915128973558797,
    "ttft": 7090.663884190597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.741650826554775,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2798133832402527. Arrivals time: 0.041540564969182014 Scheduler time: 0.869450218975544 Scheduler overhead time: 0.12164558796212077 Adapter cache time: 0.0647121756337583 Engine time: 0.12229359056800604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.1764658982865512,
    "estimated_duration": 3600.0146551531066,
    "input_throughput": 725.3339916998051,
    "output_throughput": 648.2006945887714,
    "total_throughput": 1373.5346862885765,
    "itl": 23.973603089145644,
    "ttft": 6065.209315917733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.35247984963913,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1765284859575331. Arrivals time: 0.03706960938870907 Scheduler time: 0.7734961379319429 Scheduler overhead time: 0.12435008399188519 Adapter cache time: 0.05817388743162155 Engine time: 0.12205548165366054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1965294289402664,
    "estimated_duration": 3600.0109290999358,
    "input_throughput": 725.3347424289203,
    "output_throughput": 648.2013654840273,
    "total_throughput": 1373.5361079129475,
    "itl": 24.013463745575823,
    "ttft": 6065.979459852097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.9319395211835,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.196609462145716. Arrivals time: 0.037769319489598274 Scheduler time: 0.7854075185023248 Scheduler overhead time: 0.12471647234633565 Adapter cache time: 0.059193266090005636 Engine time: 0.12762674083933234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2033264520578086,
    "estimated_duration": 3600.017852180584,
    "input_throughput": 725.3333475605821,
    "output_throughput": 648.2001189484505,
    "total_throughput": 1373.5334665090327,
    "itl": 24.02248235960902,
    "ttft": 6065.956250080605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.23522257697581,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2034086803905666. Arrivals time: 0.03803760698065162 Scheduler time: 0.7956839296966791 Scheduler overhead time: 0.12397076562047005 Adapter cache time: 0.05935359699651599 Engine time: 0.12483130628243089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.197316073346883,
    "estimated_duration": 3600.007291243966,
    "input_throughput": 725.3354753894699,
    "output_throughput": 648.2020205002582,
    "total_throughput": 1373.537495889728,
    "itl": 23.990416711094014,
    "ttft": 6065.543447302768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6404,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.27405354121805,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1973920268937945. Arrivals time: 0.037811709102243185 Scheduler time: 0.7902678051032126 Scheduler overhead time: 0.12408793298527598 Adapter cache time: 0.05878259101882577 Engine time: 0.12478996394202113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1893467716872692,
    "estimated_duration": 3600.0084405581442,
    "input_throughput": 725.3352438238056,
    "output_throughput": 648.2018135596954,
    "total_throughput": 1373.5370573835012,
    "itl": 24.01905682387888,
    "ttft": 6065.935660898317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.826894235683675,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1894103726372123. Arrivals time: 0.037292561028152704 Scheduler time: 0.7834598692134023 Scheduler overhead time: 0.12437962181866169 Adapter cache time: 0.058981327805668116 Engine time: 0.12367989448830485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2010800680145621,
    "estimated_duration": 3600.013632902631,
    "input_throughput": 725.3341976637523,
    "output_throughput": 648.2008786501489,
    "total_throughput": 1373.5350763139013,
    "itl": 23.96017910221571,
    "ttft": 6065.234173801327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.908165387180325,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2011671559885144. Arrivals time: 0.03816235112026334 Scheduler time: 0.7931982497684658 Scheduler overhead time: 0.12478789687156677 Adapter cache time: 0.059362408705055714 Engine time: 0.12392051424831152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2029927647672594,
    "estimated_duration": 3599.9975798262735,
    "input_throughput": 725.3374320673878,
    "output_throughput": 648.203769101592,
    "total_throughput": 1373.5412011689798,
    "itl": 24.011904550674668,
    "ttft": 6065.941038355278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.34280503541058,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2030768007971346. Arrivals time: 0.03801757609471679 Scheduler time: 0.7942448691464961 Scheduler overhead time: 0.12473067687824368 Adapter cache time: 0.05928644863888621 Engine time: 0.12510372791439295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.1858079046942294,
    "estimated_duration": 3600.024646399819,
    "input_throughput": 695.5160716757824,
    "output_throughput": 612.452195905086,
    "total_throughput": 1307.9682675808685,
    "itl": 23.600570024886544,
    "ttft": 4602.7821569827265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.51880884728227,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1858634306117892. Arrivals time: 0.03670542500913143 Scheduler time: 0.7765172887593508 Scheduler overhead time: 0.12707254756242037 Adapter cache time: 0.05641645425930619 Engine time: 0.1262201862409711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.15876300400123,
    "estimated_duration": 3600.0214790576565,
    "input_throughput": 695.5166835991811,
    "output_throughput": 612.4527347478885,
    "total_throughput": 1307.9694183470694,
    "itl": 23.633174652015864,
    "ttft": 4603.329448023859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.59755902546318,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1588363270275295. Arrivals time: 0.036595371551811695 Scheduler time: 0.7514805099926889 Scheduler overhead time: 0.12699191784486175 Adapter cache time: 0.05583972204476595 Engine time: 0.1253434494137764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.161834522150457,
    "estimated_duration": 3600.0179459439946,
    "input_throughput": 695.5173661900831,
    "output_throughput": 612.4533358185378,
    "total_throughput": 1307.970702008621,
    "itl": 23.645325789889778,
    "ttft": 4603.278677969599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.75881453947557,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1619200492277741. Arrivals time: 0.03655526228249073 Scheduler time: 0.7558704009279609 Scheduler overhead time: 0.1262020282447338 Adapter cache time: 0.05594509560614824 Engine time: 0.12484424654394388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.1671792678534985,
    "estimated_duration": 3600.019839835133,
    "input_throughput": 695.5170002937172,
    "output_throughput": 612.4530136203286,
    "total_throughput": 1307.970013914046,
    "itl": 23.61871303236539,
    "ttft": 4602.965285100955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.30338694050523,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1672433437779546. Arrivals time: 0.036233747377991676 Scheduler time: 0.7583379652351141 Scheduler overhead time: 0.12854548543691635 Adapter cache time: 0.056159399915486574 Engine time: 0.12490793131291866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1505743181332946,
    "estimated_duration": 3600.0122507341434,
    "input_throughput": 695.5184664967153,
    "output_throughput": 612.4543047180939,
    "total_throughput": 1307.9727712148092,
    "itl": 23.6464120816983,
    "ttft": 4252.9287204669145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.414689171155246,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1506537250243127. Arrivals time: 0.036046378780156374 Scheduler time: 0.7460346068255603 Scheduler overhead time: 0.12604575278237462 Adapter cache time: 0.0557207097299397 Engine time: 0.12443111138418317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.1578418100252748,
    "estimated_duration": 3600.0199726106634,
    "input_throughput": 695.5169746417376,
    "output_throughput": 612.4529910319056,
    "total_throughput": 1307.9699656736434,
    "itl": 23.591143476562667,
    "ttft": 4602.503485763058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.22236741680093,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1579323508776724. Arrivals time: 0.03691560821607709 Scheduler time: 0.7501912917941809 Scheduler overhead time: 0.12678079726174474 Adapter cache time: 0.056000785902142525 Engine time: 0.1256200335919857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1545860338956118,
    "estimated_duration": 3600.015477574876,
    "input_throughput": 695.5178430751406,
    "output_throughput": 612.4537557503158,
    "total_throughput": 1307.9715988254566,
    "itl": 23.63696047513841,
    "ttft": 4603.2876377612765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5675,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.94727906903194,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1546948528848588. Arrivals time: 0.03642933489754796 Scheduler time: 0.7499599889852107 Scheduler overhead time: 0.12575390608981252 Adapter cache time: 0.05622147582471371 Engine time: 0.1238772482611239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.0936798830516636,
    "estimated_duration": 3599.9332955174723,
    "input_throughput": 630.3780691785837,
    "output_throughput": 555.0791739636281,
    "total_throughput": 1185.4572431422118,
    "itl": 23.02599004982631,
    "ttft": 4294.434130238089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.317895411487527,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0937407282181084. Arrivals time: 0.034498665016144514 Scheduler time: 0.6897438378073275 Scheduler overhead time: 0.1278009326197207 Adapter cache time: 0.051644010934978724 Engine time: 0.12675423361361027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1079266020096838,
    "estimated_duration": 3599.928934434814,
    "input_throughput": 630.3788328411214,
    "output_throughput": 555.0798464063912,
    "total_throughput": 1185.4586792475127,
    "itl": 23.05475290788743,
    "ttft": 4294.834452514504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.64567616727557,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1080099130049348. Arrivals time: 0.03481941903010011 Scheduler time: 0.7025512079708278 Scheduler overhead time: 0.1275901310145855 Adapter cache time: 0.051576762460172176 Engine time: 0.1278739687986672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.093787007033825,
    "estimated_duration": 3599.9411758863316,
    "input_throughput": 630.3766892638953,
    "output_throughput": 555.0779588802633,
    "total_throughput": 1185.4546481441587,
    "itl": 23.059237862695515,
    "ttft": 4294.860809476551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.5729366986323,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0938503784127533. Arrivals time: 0.034372401889413595 Scheduler time: 0.6900209607556462 Scheduler overhead time: 0.12731881439685822 Adapter cache time: 0.051385147497057915 Engine time: 0.1274892590008676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.1103990618139505,
    "estimated_duration": 3599.9343520086727,
    "input_throughput": 630.3778841782981,
    "output_throughput": 555.0790110616956,
    "total_throughput": 1185.4568952399939,
    "itl": 23.03752160516089,
    "ttft": 4294.576477713999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.84625845505911,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1104868319816887. Arrivals time: 0.0367396199144423 Scheduler time: 0.7003072025254369 Scheduler overhead time: 0.12824391527101398 Adapter cache time: 0.05202349554747343 Engine time: 0.12787540443241596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.087324419990182,
    "estimated_duration": 3599.9257912842286,
    "input_throughput": 630.3793832345774,
    "output_throughput": 555.0803310551438,
    "total_throughput": 1185.4597142897212,
    "itl": 23.054658907061008,
    "ttft": 4294.864452124584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.30482369287968,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0874131857417524. Arrivals time: 0.03432130441069603 Scheduler time: 0.6829216699115932 Scheduler overhead time: 0.12794617377221584 Adapter cache time: 0.05158305028453469 Engine time: 0.126954588573426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.0940987560898066,
    "estimated_duration": 3599.9347854751013,
    "input_throughput": 630.3778082747981,
    "output_throughput": 555.0789442248969,
    "total_throughput": 1185.456752499695,
    "itl": 23.017111310748536,
    "ttft": 4294.204496998874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.276661433459264,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.094169116113335. Arrivals time: 0.03467094385996461 Scheduler time: 0.6906200535595417 Scheduler overhead time: 0.1272541843354702 Adapter cache time: 0.05151800764724612 Engine time: 0.12662879889830947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0989123350009322,
    "estimated_duration": 3599.9431705735637,
    "input_throughput": 630.3763399794,
    "output_throughput": 555.0776513179311,
    "total_throughput": 1185.4539912973312,
    "itl": 23.057337037981384,
    "ttft": 4294.710281205996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.93589313931871,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0989977777935565. Arrivals time: 0.034484983421862125 Scheduler time: 0.6935926764272153 Scheduler overhead time: 0.12824206240475178 Adapter cache time: 0.051335642114281654 Engine time: 0.1279267924837768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9359930204227567,
    "estimated_duration": 3598.574990936121,
    "input_throughput": 457.5244379086016,
    "output_throughput": 406.4850680295204,
    "total_throughput": 864.0095059381221,
    "itl": 22.29613451790252,
    "ttft": 3205.5009684385286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4701,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.084934859193538,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9360499451868236. Arrivals time: 0.02888476848602295 Scheduler time: 0.5335238268598914 Scheduler overhead time: 0.130932389292866 Adapter cache time: 0.046549548860639334 Engine time: 0.13086388958618045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9438602062873542,
    "estimated_duration": 3598.5789607728498,
    "input_throughput": 457.5239331823367,
    "output_throughput": 406.48461960824903,
    "total_throughput": 864.0085527905858,
    "itl": 22.317498570101662,
    "ttft": 3205.8733105871393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.4686637400499,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9439470372162759. Arrivals time: 0.028929573483765125 Scheduler time: 0.5393725172616541 Scheduler overhead time: 0.13040514942258596 Adapter cache time: 0.046878589782863855 Engine time: 0.1329550752416253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9346209149807692,
    "estimated_duration": 3598.570288951785,
    "input_throughput": 457.52503572177955,
    "output_throughput": 406.48559915334715,
    "total_throughput": 864.0106348751267,
    "itl": 22.3235229181606,
    "ttft": 3206.237904222734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4702,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.408778604693524,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9346789899282157. Arrivals time: 0.028886581305414438 Scheduler time: 0.5350536266341805 Scheduler overhead time: 0.12973287142813206 Adapter cache time: 0.04665210144594312 Engine time: 0.12922197580337524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.9327750308439136,
    "estimated_duration": 3598.5734946171146,
    "input_throughput": 457.52462815135016,
    "output_throughput": 406.485237049643,
    "total_throughput": 864.0098652009931,
    "itl": 22.303387864717315,
    "ttft": 3205.7458786730203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4700,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.417156472300036,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9328518081456423. Arrivals time: 0.028363369405269623 Scheduler time: 0.5332474652677774 Scheduler overhead time: 0.1306944158859551 Adapter cache time: 0.046592190861701965 Engine time: 0.12898697331547737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9410432106815279,
    "estimated_duration": 3598.5765223127055,
    "input_throughput": 457.5242432087789,
    "output_throughput": 406.48489504953477,
    "total_throughput": 864.0091382583137,
    "itl": 22.323584170714728,
    "ttft": 3206.174253206298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4701,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.09960602550383,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9411072116345167. Arrivals time: 0.02838799450546503 Scheduler time: 0.5393892461434007 Scheduler overhead time: 0.1302700568921864 Adapter cache time: 0.046772202011197805 Engine time: 0.13095976784825325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9434210499748588,
    "estimated_duration": 3598.5791182729254,
    "input_throughput": 457.5239131577515,
    "output_throughput": 406.4846018175166,
    "total_throughput": 864.0085149752681,
    "itl": 22.28347311013318,
    "ttft": 3205.390550005587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4701,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.010812341624973,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9434961820952594. Arrivals time: 0.029069736134260893 Scheduler time: 0.5375160537660122 Scheduler overhead time: 0.1309647634625435 Adapter cache time: 0.04657422471791506 Engine time: 0.13389110146090388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9399719289503992,
    "estimated_duration": 3598.565763320368,
    "input_throughput": 457.5256111148144,
    "output_throughput": 406.48611035812127,
    "total_throughput": 864.0117214729356,
    "itl": 22.32025943277539,
    "ttft": 3205.997021243065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4700,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.73306198839189,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9400339438579977. Arrivals time: 0.03218914894387126 Scheduler time: 0.5365627100691199 Scheduler overhead time: 0.13006254890933633 Adapter cache time: 0.046819739043712616 Engine time: 0.1294258339330554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9064060039818287,
    "estimated_duration": 3600.012558322476,
    "input_throughput": 428.2651726966267,
    "output_throughput": 376.3284094295771,
    "total_throughput": 804.5935821262038,
    "itl": 21.77127942692105,
    "ttft": 6293.353596369332,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.203450757439843,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9064795207232237. Arrivals time: 0.027452969923615456 Scheduler time: 0.5064061037264764 Scheduler overhead time: 0.13093475764617324 Adapter cache time: 0.044586678966879845 Engine time: 0.13156605046242476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9067043168470263,
    "estimated_duration": 3600.004224156423,
    "input_throughput": 428.2661641490922,
    "output_throughput": 376.32928064618113,
    "total_throughput": 804.5954447952734,
    "itl": 21.79602164388178,
    "ttft": 6293.85982956141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.19489254592824,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9067632798105478. Arrivals time: 0.027863388881087303 Scheduler time: 0.5062466538511217 Scheduler overhead time: 0.13102094968780875 Adapter cache time: 0.0444642691873014 Engine time: 0.13174065621569753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9077274678274989,
    "estimated_duration": 3600.024494616313,
    "input_throughput": 428.26375273436,
    "output_throughput": 376.3271616696019,
    "total_throughput": 804.5909144039618,
    "itl": 21.79653025893969,
    "ttft": 6293.967869164999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.034276061394692,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9078101790510118. Arrivals time: 0.02792738936841488 Scheduler time: 0.5069033675827086 Scheduler overhead time: 0.13061215076595545 Adapter cache time: 0.04479860560968518 Engine time: 0.13205091375857592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.9099066788330674,
    "estimated_duration": 3600.017033744387,
    "input_throughput": 428.26464029155204,
    "output_throughput": 376.3279415905659,
    "total_throughput": 804.592581882118,
    "itl": 21.777479948574914,
    "ttft": 6293.649588299667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.471279281001177,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9099628352560103. Arrivals time: 0.027703348081558943 Scheduler time: 0.5103778326883912 Scheduler overhead time: 0.1306800846941769 Adapter cache time: 0.044639366678893566 Engine time: 0.1312313717789948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9099179562181234,
    "estimated_duration": 3600.010574579972,
    "input_throughput": 428.2654086869963,
    "output_throughput": 376.3286168008183,
    "total_throughput": 804.5940254878146,
    "itl": 21.797775654977343,
    "ttft": 6294.03484265039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.77020315772524,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9099905672483146. Arrivals time: 0.027857637032866478 Scheduler time: 0.507542640902102 Scheduler overhead time: 0.13156322948634624 Adapter cache time: 0.04478548327460885 Engine time: 0.13284257147461176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9116421374492347,
    "estimated_duration": 3600.0050324464487,
    "input_throughput": 428.26606799276306,
    "output_throughput": 376.3291961509648,
    "total_throughput": 804.5952641437278,
    "itl": 21.763209941016022,
    "ttft": 6293.122636260475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.26345074950957,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9116970864124596. Arrivals time: 0.028129777405411005 Scheduler time: 0.5098961186595261 Scheduler overhead time: 0.13196891825646162 Adapter cache time: 0.044981024228036404 Engine time: 0.13085471093654633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9076295220293105,
    "estimated_duration": 3600.0063950407834,
    "input_throughput": 428.26590589501825,
    "output_throughput": 376.3290537112093,
    "total_throughput": 804.5949596062276,
    "itl": 21.79440291872007,
    "ttft": 6293.9268021675425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.447720217221818,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9077002359554172. Arrivals time: 0.027973240241408348 Scheduler time: 0.5066351774148643 Scheduler overhead time: 0.13042578473687172 Adapter cache time: 0.04485795367509127 Engine time: 0.13220167579129338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.8501673652790487,
    "estimated_duration": 3599.4453827876564,
    "input_throughput": 355.09803985693725,
    "output_throughput": 326.82729556766265,
    "total_throughput": 681.9253354245999,
    "itl": 21.43582514499918,
    "ttft": 7428.729439847573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.87537531386525,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8502289238385856. Arrivals time: 0.025676020421087742 Scheduler time: 0.4543912401422858 Scheduler overhead time: 0.1320257056504488 Adapter cache time: 0.04036210710182786 Engine time: 0.1314581553451717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8540513697080314,
    "estimated_duration": 3599.4534843286897,
    "input_throughput": 355.09724061300943,
    "output_throughput": 326.82655995467104,
    "total_throughput": 681.9238005676805,
    "itl": 21.453490764684183,
    "ttft": 7429.185288395143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.125388476196044,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8541205506771803. Arrivals time: 0.025591979268938303 Scheduler time: 0.4558990150690079 Scheduler overhead time: 0.13183075981214643 Adapter cache time: 0.04076621634885669 Engine time: 0.13335938146337867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8543546781875193,
    "estimated_duration": 3599.4475629732624,
    "input_throughput": 355.0978247740331,
    "output_throughput": 326.82709760835,
    "total_throughput": 681.9249223823831,
    "itl": 21.454884739416038,
    "ttft": 7429.5182656806855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.784712522477445,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.854450074955821. Arrivals time: 0.025868096388876438 Scheduler time: 0.4550330163910985 Scheduler overhead time: 0.13169420883059502 Adapter cache time: 0.04116688296198845 Engine time: 0.13232855359092355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.8594360090792179,
    "estimated_duration": 3599.4335362279976,
    "input_throughput": 355.0992085658665,
    "output_throughput": 326.82837123110136,
    "total_throughput": 681.9275797969678,
    "itl": 21.441668530438942,
    "ttft": 7428.853116087248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.787974494970825,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8595416392199695. Arrivals time: 0.0259885061532259 Scheduler time: 0.45852442644536495 Scheduler overhead time: 0.13242364674806595 Adapter cache time: 0.04043435165658593 Engine time: 0.13539272593334317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.855858638882637,
    "estimated_duration": 3599.4428538837606,
    "input_throughput": 355.0982893424418,
    "output_throughput": 326.82752519065,
    "total_throughput": 681.9258145330919,
    "itl": 21.45942746287477,
    "ttft": 7429.404151123556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.567863831590447,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8559233751147985. Arrivals time: 0.026048270985484123 Scheduler time: 0.45970782171934843 Scheduler overhead time: 0.13193967938423157 Adapter cache time: 0.04031311394646764 Engine time: 0.13151215901598334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.8562804977409542,
    "estimated_duration": 3599.441642278672,
    "input_throughput": 355.09840887178467,
    "output_throughput": 326.8276352037943,
    "total_throughput": 681.926044075579,
    "itl": 21.432299832924226,
    "ttft": 7428.708357673464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.154038409382753,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8563622198998928. Arrivals time: 0.02564469026401639 Scheduler time: 0.4580626622773707 Scheduler overhead time: 0.13272652495652437 Adapter cache time: 0.04036121070384979 Engine time: 0.13313764333724976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8510011839680374,
    "estimated_duration": 3599.4565336238693,
    "input_throughput": 355.09693979084534,
    "output_throughput": 326.82628308213634,
    "total_throughput": 681.9232228729817,
    "itl": 21.44896043861129,
    "ttft": 7429.1965213073745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.31621795851786,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.851067443843931. Arrivals time: 0.025527150370180607 Scheduler time: 0.4557634647935629 Scheduler overhead time: 0.13210966903716326 Adapter cache time: 0.040221189614385366 Engine time: 0.13140918454155326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.7173928101547062,
    "estimated_duration": 3598.3564432235075,
    "input_throughput": 222.4404426380177,
    "output_throughput": 202.45798644321493,
    "total_throughput": 424.8984290812326,
    "itl": 20.7094184968707,
    "ttft": 3314.294160678348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.003556093494824,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7174483351409435. Arrivals time: 0.021150326821953058 Scheduler time: 0.32764322496950626 Scheduler overhead time: 0.13319755531847477 Adapter cache time: 0.033321330323815346 Engine time: 0.13488694466650486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7195832510478795,
    "estimated_duration": 3598.353691674909,
    "input_throughput": 222.4406127312716,
    "output_throughput": 202.45814125650918,
    "total_throughput": 424.8987539877808,
    "itl": 20.71842578786742,
    "ttft": 3314.695966950473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.598546119462355,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7196786943823099. Arrivals time: 0.020775396842509508 Scheduler time: 0.3306665257550776 Scheduler overhead time: 0.13375036790966988 Adapter cache time: 0.03305045189335942 Engine time: 0.1340141212567687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7166607910767198,
    "estimated_duration": 3598.355416034865,
    "input_throughput": 222.4405061359966,
    "output_throughput": 202.45804423699022,
    "total_throughput": 424.89855037298685,
    "itl": 20.72124458491233,
    "ttft": 3314.8644234159365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.05030887308041,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7167331399396062. Arrivals time: 0.02121831802651286 Scheduler time: 0.32719733053818345 Scheduler overhead time: 0.13196469144895673 Adapter cache time: 0.033105581533163786 Engine time: 0.13644631253555417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.7153341858647764,
    "estimated_duration": 3598.354154225155,
    "input_throughput": 222.44058413765472,
    "output_throughput": 202.45811523153802,
    "total_throughput": 424.89869936919274,
    "itl": 20.715919761837295,
    "ttft": 3314.7018511582296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.64206186885036,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7153949090279639. Arrivals time: 0.021132018882781267 Scheduler time: 0.32583884382620454 Scheduler overhead time: 0.1323938607238233 Adapter cache time: 0.03331718174740672 Engine time: 0.13561888365074992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7129254601895809,
    "estimated_duration": 3598.370876452564,
    "input_throughput": 222.43955041929698,
    "output_throughput": 202.45717437503382,
    "total_throughput": 424.8967247943308,
    "itl": 20.71856260311591,
    "ttft": 3314.7811522686115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.907605138392864,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7130123861134052. Arrivals time: 0.021150652784854174 Scheduler time: 0.3253580401651561 Scheduler overhead time: 0.13152855867519975 Adapter cache time: 0.03342781262472272 Engine time: 0.13450995553284883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.7171538728289306,
    "estimated_duration": 3598.3724334047924,
    "input_throughput": 222.43945417363034,
    "output_throughput": 202.45708677538852,
    "total_throughput": 424.89654094901886,
    "itl": 20.708301312607617,
    "ttft": 3313.9647112836888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.485116614155364,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7172281970269978. Arrivals time: 0.021107059437781572 Scheduler time: 0.3258551536127925 Scheduler overhead time: 0.132864142768085 Adapter cache time: 0.033295062836259604 Engine time: 0.1337584494613111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_128_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7134705889038742,
    "estimated_duration": 3598.3608615944017,
    "input_throughput": 222.44016950688516,
    "output_throughput": 202.4577378482271,
    "total_throughput": 424.89790735511224,
    "itl": 20.723630989001883,
    "ttft": 3314.6157880552696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.73404094438972,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.713540107011795. Arrivals time: 0.02123637916520238 Scheduler time: 0.3227667068131268 Scheduler overhead time: 0.13304660422727466 Adapter cache time: 0.03329314151778817 Engine time: 0.1359876529313624 
