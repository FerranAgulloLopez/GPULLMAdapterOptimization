INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_192_slots_32_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_192_slots_32_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 61.44892409583554,
    "estimated_duration": 3600.0994441621497,
    "input_throughput": 6458.462706552048,
    "output_throughput": 5647.729268415237,
    "total_throughput": 12106.191974967285,
    "itl": 91.51197283194114,
    "ttft": 1983981.6218260156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9913283429108615,
    "arrivals": 750836,
    "finished_requests": 94238,
    "scheduler_time": 242.20012402017588
}
#Debug simulation 
Total elapsed time: 61.449123410042375. Arrivals time: 0.4363190736621618 Scheduler time: 60.81771741108969 Scheduler overhead time: 0.07376336259767413 Adapter cache time: 0.014869482722133398 Engine time: 0.0751766418106854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_192_slots_32_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_192_slots_32_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 66.60118786990643,
    "estimated_duration": 3600.060473789081,
    "input_throughput": 6809.12395179842,
    "output_throughput": 5946.8753805312635,
    "total_throughput": 12755.999332329684,
    "itl": 101.04230711730578,
    "ttft": 1964435.005842869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.559002295364641,
    "arrivals": 749460,
    "finished_requests": 99493,
    "scheduler_time": 228.75987425521302
}
#Debug simulation 
Total elapsed time: 66.60137363383546. Arrivals time: 0.5028696772642434 Scheduler time: 65.90798410028219 Scheduler overhead time: 0.07187921414151788 Adapter cache time: 0.01584168104454875 Engine time: 0.07331797108054161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_192_slots_32_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_192_slots_32_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 63.96155591867864,
    "estimated_duration": 3600.062607793657,
    "input_throughput": 6713.502411785079,
    "output_throughput": 5857.573408403532,
    "total_throughput": 12571.075820188611,
    "itl": 97.81143796857334,
    "ttft": 1971342.9860051451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9135805518599245,
    "arrivals": 749460,
    "finished_requests": 98033,
    "scheduler_time": 232.81884983951096
}
#Debug simulation 
Total elapsed time: 63.9617152470164. Arrivals time: 0.5130908056162298 Scheduler time: 63.25621368177235 Scheduler overhead time: 0.07278783712536097 Adapter cache time: 0.014936347957700491 Engine time: 0.07445789268240333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_192_slots_32_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_192_slots_32_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 64.80825040489435,
    "estimated_duration": 3600.0428704485207,
    "input_throughput": 6547.379808580825,
    "output_throughput": 5716.258872616187,
    "total_throughput": 12263.638681197011,
    "itl": 91.90714053516335,
    "ttft": 1982267.4795305484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6781014270475283,
    "arrivals": 749460,
    "finished_requests": 95649,
    "scheduler_time": 239.0311543425675
}
#Debug simulation 
Total elapsed time: 64.8084006300196. Arrivals time: 0.4826298775151372 Scheduler time: 64.12448050128296 Scheduler overhead time: 0.07598796067759395 Adapter cache time: 0.01591260777786374 Engine time: 0.07748392457142472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_192_slots_32_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_192_slots_32_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 69.21480489801615,
    "estimated_duration": 3600.0220058596233,
    "input_throughput": 6733.21106386181,
    "output_throughput": 5878.870730665544,
    "total_throughput": 12612.081794527354,
    "itl": 98.24391968696438,
    "ttft": 1963137.3962968453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0420615746686206,
    "arrivals": 749460,
    "finished_requests": 98318,
    "scheduler_time": 231.84309595241666
}
#Debug simulation 
Total elapsed time: 69.21497409697622. Arrivals time: 0.43272131821140647 Scheduler time: 68.58615795476362 Scheduler overhead time: 0.07423185370862484 Adapter cache time: 0.015415060799568892 Engine time: 0.07582950359210372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_192_slots_32_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_192_slots_32_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 62.629118017852306,
    "estimated_duration": 3600.0624942480727,
    "input_throughput": 6561.416930328513,
    "output_throughput": 5727.648348589786,
    "total_throughput": 12289.065278918299,
    "itl": 92.12803485780294,
    "ttft": 1988507.5153407513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1712420400139187,
    "arrivals": 749460,
    "finished_requests": 95917,
    "scheduler_time": 238.58732562030303
}
#Debug simulation 
Total elapsed time: 62.62927183881402. Arrivals time: 0.48704665806144476 Scheduler time: 61.94499273132533 Scheduler overhead time: 0.0744934706017375 Adapter cache time: 0.01658024825155735 Engine time: 0.07526758126914501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_192_slots_32_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_192_slots_32_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 60.961655479855835,
    "estimated_duration": 3600.0669507144457,
    "input_throughput": 6745.047337294944,
    "output_throughput": 5887.73466998816,
    "total_throughput": 12632.782007283104,
    "itl": 98.37563415395454,
    "ttft": 1973034.3455655836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8066496261814544,
    "arrivals": 749460,
    "finished_requests": 98531,
    "scheduler_time": 231.5213232775157
}
#Debug simulation 
Total elapsed time: 60.96181587781757. Arrivals time: 0.42935007670894265 Scheduler time: 60.345690896268934 Scheduler overhead time: 0.07047154475003481 Adapter cache time: 0.014789614826440811 Engine time: 0.0721701318398118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_192_slots_32_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_192_slots_32_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 62.93358915718272,
    "estimated_duration": 3600.0909665032323,
    "input_throughput": 6558.390390599815,
    "output_throughput": 5726.609186218598,
    "total_throughput": 12284.999576818413,
    "itl": 92.16958417349507,
    "ttft": 1987827.2299200601,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1898736068234097,
    "arrivals": 749460,
    "finished_requests": 95871,
    "scheduler_time": 238.48568452978782
}
#Debug simulation 
Total elapsed time: 62.93383520003408. Arrivals time: 0.5007306635379791 Scheduler time: 62.236152925528586 Scheduler overhead time: 0.07413035677745938 Adapter cache time: 0.01660526730120182 Engine time: 0.07499059801921248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 63.50460872100666,
    "estimated_duration": 3600.0431376905212,
    "input_throughput": 6772.127462794817,
    "output_throughput": 5877.143464890018,
    "total_throughput": 12649.270927684835,
    "itl": 100.3430124259077,
    "ttft": 1963103.832168945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4679548050928843,
    "arrivals": 748703,
    "finished_requests": 98730,
    "scheduler_time": 231.98308016992
}
#Debug simulation 
Total elapsed time: 63.50476345606148. Arrivals time: 0.4327770001254976 Scheduler time: 62.887649120762944 Scheduler overhead time: 0.07026152918115258 Adapter cache time: 0.014011839870363474 Engine time: 0.07084279600530863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 63.852474986575544,
    "estimated_duration": 3600.0972678871503,
    "input_throughput": 6674.296057034532,
    "output_throughput": 5792.790707635323,
    "total_throughput": 12467.086764669855,
    "itl": 97.27715556065938,
    "ttft": 1966831.972613273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5582907595252635,
    "arrivals": 748703,
    "finished_requests": 97250,
    "scheduler_time": 235.8028032944327
}
#Debug simulation 
Total elapsed time: 63.85263804765418. Arrivals time: 0.41324909310787916 Scheduler time: 63.24873295240104 Scheduler overhead time: 0.07287362031638622 Adapter cache time: 0.013968141283839941 Engine time: 0.07338193198665977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 61.99764124210924,
    "estimated_duration": 3600.0969761707634,
    "input_throughput": 6545.369793083677,
    "output_throughput": 5681.069186573457,
    "total_throughput": 12226.438979657134,
    "itl": 91.81630295265708,
    "ttft": 1982820.1135439465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1637436492601636,
    "arrivals": 748703,
    "finished_requests": 95367,
    "scheduler_time": 240.6598656693579
}
#Debug simulation 
Total elapsed time: 61.99780227383599. Arrivals time: 0.4188898093998432 Scheduler time: 61.38218243373558 Scheduler overhead time: 0.07419437728822231 Adapter cache time: 0.016189088579267263 Engine time: 0.07525889342650771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 61.48453253088519,
    "estimated_duration": 3600.1082181356683,
    "input_throughput": 6712.444886591277,
    "output_throughput": 5824.659907267759,
    "total_throughput": 12537.104793859036,
    "itl": 97.78667434138472,
    "ttft": 1969342.449738548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.53189560566563,
    "arrivals": 748703,
    "finished_requests": 97807,
    "scheduler_time": 234.32871148792492
}
#Debug simulation 
Total elapsed time: 61.48469946300611. Arrivals time: 0.4247606126591563 Scheduler time: 60.872152434661984 Scheduler overhead time: 0.07113547809422016 Adapter cache time: 0.014256817754358053 Engine time: 0.07233390910550952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 62.445067517925054,
    "estimated_duration": 3600.0385642054584,
    "input_throughput": 6593.777143395415,
    "output_throughput": 5723.960072229927,
    "total_throughput": 12317.737215625342,
    "itl": 92.10611918624785,
    "ttft": 1985693.3417401672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8820643778192054,
    "arrivals": 748703,
    "finished_requests": 96074,
    "scheduler_time": 238.71507237421486
}
#Debug simulation 
Total elapsed time: 62.445227826945484. Arrivals time: 0.7499162913300097 Scheduler time: 61.499117142986506 Scheduler overhead time: 0.07441765628755093 Adapter cache time: 0.015769778285175562 Engine time: 0.07492610765621066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 61.265940757934004,
    "estimated_duration": 3600.0639106341487,
    "input_throughput": 6712.701385277116,
    "output_throughput": 5824.756037818851,
    "total_throughput": 12537.457423095966,
    "itl": 97.7840202335208,
    "ttft": 1969412.8236926717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.417230448806654,
    "arrivals": 748703,
    "finished_requests": 97809,
    "scheduler_time": 234.33313361490525
}
#Debug simulation 
Total elapsed time: 61.266103133093566. Arrivals time: 0.43597669154405594 Scheduler time: 60.64125022245571 Scheduler overhead time: 0.07125619007274508 Adapter cache time: 0.014032718725502491 Engine time: 0.07331004133448005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_192_slots_32_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_192_slots_32_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 59.49129721103236,
    "estimated_duration": 3600.014066900211,
    "input_throughput": 6603.219753657403,
    "output_throughput": 5728.528171490515,
    "total_throughput": 12331.747925147918,
    "itl": 92.30223630777213,
    "ttft": 1984274.538526964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.03173262232918,
    "arrivals": 748703,
    "finished_requests": 96203,
    "scheduler_time": 238.27706202737613
}
#Debug simulation 
Total elapsed time: 59.49145713914186. Arrivals time: 0.41040288424119353 Scheduler time: 58.88533345842734 Scheduler overhead time: 0.07321017049252987 Adapter cache time: 0.0171662624925375 Engine time: 0.07415326964110136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 69.39824824919924,
    "estimated_duration": 3600.0613848466633,
    "input_throughput": 6853.939797765687,
    "output_throughput": 5968.585449804824,
    "total_throughput": 12822.525247570511,
    "itl": 101.41649418425507,
    "ttft": 1961470.6023239316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.109358481192031,
    "arrivals": 745105,
    "finished_requests": 99813,
    "scheduler_time": 227.73408001237723
}
#Debug simulation 
Total elapsed time: 69.39853401808068. Arrivals time: 0.44629493867978454 Scheduler time: 68.75891547976062 Scheduler overhead time: 0.07320141745731235 Adapter cache time: 0.015765731688588858 Engine time: 0.07410945603623986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 70.42807288188487,
    "estimated_duration": 3600.0955565968675,
    "input_throughput": 6745.164293070789,
    "output_throughput": 5877.610376542973,
    "total_throughput": 12622.774669613764,
    "itl": 98.38389968419305,
    "ttft": 1966227.102014162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.713544507380578,
    "arrivals": 745105,
    "finished_requests": 98270,
    "scheduler_time": 231.73481636216061
}
#Debug simulation 
Total elapsed time: 70.42824091482908. Arrivals time: 0.44505699537694454 Scheduler time: 69.78620830690488 Scheduler overhead time: 0.07469205092638731 Adapter cache time: 0.016610106453299522 Engine time: 0.07495884643867612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 63.34430390689522,
    "estimated_duration": 3600.1030140762928,
    "input_throughput": 6566.986252215889,
    "output_throughput": 5729.410219471816,
    "total_throughput": 12296.396471687705,
    "itl": 92.27139413180734,
    "ttft": 1989938.277269907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7921104686055656,
    "arrivals": 745105,
    "finished_requests": 95703,
    "scheduler_time": 238.56937695426092
}
#Debug simulation 
Total elapsed time: 63.344457221683115. Arrivals time: 0.4216289543546736 Scheduler time: 62.72324754297733 Scheduler overhead time: 0.07434077188372612 Adapter cache time: 0.017489406745880842 Engine time: 0.07629864849150181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 65.36277585523203,
    "estimated_duration": 3600.04064321818,
    "input_throughput": 6740.265848306816,
    "output_throughput": 5887.823249976402,
    "total_throughput": 12628.089098283217,
    "itl": 98.52139808599047,
    "ttft": 1973595.4417068725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 444,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.031588275823738,
    "arrivals": 745105,
    "finished_requests": 98277,
    "scheduler_time": 231.3186436648088
}
#Debug simulation 
Total elapsed time: 65.36293660709634. Arrivals time: 0.4344246299006045 Scheduler time: 64.73589689983055 Scheduler overhead time: 0.07271325960755348 Adapter cache time: 0.016176021192222834 Engine time: 0.0737015726044774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 58.172338420990855,
    "estimated_duration": 3600.043380189524,
    "input_throughput": 6552.595763098311,
    "output_throughput": 5716.680835917191,
    "total_throughput": 12269.276599015502,
    "itl": 92.24429488142553,
    "ttft": 1985770.8347831278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.642787410309553,
    "arrivals": 745105,
    "finished_requests": 95447,
    "scheduler_time": 239.02147453521906
}
#Debug simulation 
Total elapsed time: 58.17250982904807. Arrivals time: 0.4033622615970671 Scheduler time: 57.57063919166103 Scheduler overhead time: 0.0751165933907032 Adapter cache time: 0.015735683031380177 Engine time: 0.07623543357476592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 62.588713546749204,
    "estimated_duration": 3600.0454766719567,
    "input_throughput": 6759.280725113278,
    "output_throughput": 5897.788552279094,
    "total_throughput": 12657.069277392371,
    "itl": 98.65507725981475,
    "ttft": 1974758.574236687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 450,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8727644232567275,
    "arrivals": 745105,
    "finished_requests": 98468,
    "scheduler_time": 230.8963651277696
}
#Debug simulation 
Total elapsed time: 62.58898311806843. Arrivals time: 0.7275974797084928 Scheduler time: 61.67278895294294 Scheduler overhead time: 0.07100252527743578 Adapter cache time: 0.01600382663309574 Engine time: 0.07207219768315554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_192_slots_32_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_192_slots_32_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 61.000108431093395,
    "estimated_duration": 3600.0390206038096,
    "input_throughput": 6548.585408400907,
    "output_throughput": 5724.718505007582,
    "total_throughput": 12273.303913408488,
    "itl": 92.1783514420307,
    "ttft": 1989140.5907843271,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3285114399343985,
    "arrivals": 745105,
    "finished_requests": 95473,
    "scheduler_time": 238.501255434696
}
#Debug simulation 
Total elapsed time: 61.000263296067715. Arrivals time: 0.4455582033842802 Scheduler time: 60.35898996004835 Scheduler overhead time: 0.07327914470806718 Adapter cache time: 0.016614426393061876 Engine time: 0.07475203415378928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_192_slots_32_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_192_slots_32_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 61.16031536087394,
    "estimated_duration": 3600.0658539494625,
    "input_throughput": 6753.638957278172,
    "output_throughput": 5904.452269027409,
    "total_throughput": 12658.091226305582,
    "itl": 100.62644838921162,
    "ttft": 1963632.4613776782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 259,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7126139392750317,
    "arrivals": 743742,
    "finished_requests": 98541,
    "scheduler_time": 230.73195502209737
}
#Debug simulation 
Total elapsed time: 61.16047464776784. Arrivals time: 0.417666626162827 Scheduler time: 60.55857748165727 Scheduler overhead time: 0.06991019332781434 Adapter cache time: 0.014172003138810396 Engine time: 0.07062325906008482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_192_slots_32_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_192_slots_32_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 60.96279216790572,
    "estimated_duration": 3600.0354062019505,
    "input_throughput": 6671.104667089146,
    "output_throughput": 5829.9182179828385,
    "total_throughput": 12501.022885071985,
    "itl": 97.83653491391635,
    "ttft": 1968862.2590144267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7775728072086372,
    "arrivals": 743742,
    "finished_requests": 97305,
    "scheduler_time": 234.08858697783634
}
#Debug simulation 
Total elapsed time: 60.962943743914366. Arrivals time: 0.4128142115660012 Scheduler time: 60.36275265365839 Scheduler overhead time: 0.07098453585058451 Adapter cache time: 0.01430886471644044 Engine time: 0.07220474723726511 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_192_slots_32_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_192_slots_32_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 58.75285046827048,
    "estimated_duration": 3600.0742342257377,
    "input_throughput": 6486.9354020480605,
    "output_throughput": 5672.473863415204,
    "total_throughput": 12159.409265463264,
    "itl": 91.57741023582471,
    "ttft": 1983487.8564495854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8402246585860897,
    "arrivals": 743742,
    "finished_requests": 94630,
    "scheduler_time": 241.1258595242313
}
#Debug simulation 
Total elapsed time: 58.75300297001377. Arrivals time: 0.40921482676640153 Scheduler time: 58.14966317359358 Scheduler overhead time: 0.07348813582211733 Adapter cache time: 0.014638276770710945 Engine time: 0.07491455366834998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_192_slots_32_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_192_slots_32_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 63.92665067687631,
    "estimated_duration": 3600.097583079111,
    "input_throughput": 6613.05602156419,
    "output_throughput": 5776.904242193422,
    "total_throughput": 12389.960263757612,
    "itl": 97.3443307011465,
    "ttft": 1965231.6382808455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5327266427129491,
    "arrivals": 743742,
    "finished_requests": 96461,
    "scheduler_time": 236.37283459513242
}
#Debug simulation 
Total elapsed time: 63.926808496937156. Arrivals time: 0.4263142249546945 Scheduler time: 63.309846624266356 Scheduler overhead time: 0.07207639142870903 Adapter cache time: 0.014297143556177616 Engine time: 0.07406882103532553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_192_slots_32_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_192_slots_32_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 57.27261484507471,
    "estimated_duration": 3600.046030322782,
    "input_throughput": 6544.109103484901,
    "output_throughput": 5723.687371339665,
    "total_throughput": 12267.796474824567,
    "itl": 92.08449935087917,
    "ttft": 1985832.2290186926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.957529063755652,
    "arrivals": 743742,
    "finished_requests": 95457,
    "scheduler_time": 238.75700145583326
}
#Debug simulation 
Total elapsed time: 57.272772666066885. Arrivals time: 0.4081379375420511 Scheduler time: 56.67217492964119 Scheduler overhead time: 0.07253947388380766 Adapter cache time: 0.01465617772191763 Engine time: 0.074410954490304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_192_slots_32_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_192_slots_32_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 64.014816978015,
    "estimated_duration": 3600.0437122523117,
    "input_throughput": 6661.638279107427,
    "output_throughput": 5823.065405748821,
    "total_throughput": 12484.703684856247,
    "itl": 97.69322174728171,
    "ttft": 1967276.7819484968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 230,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.468301816331218,
    "arrivals": 743742,
    "finished_requests": 97153,
    "scheduler_time": 234.331718022257
}
#Debug simulation 
Total elapsed time: 64.01497742999345. Arrivals time: 0.4391640485264361 Scheduler time: 63.386973828077316 Scheduler overhead time: 0.07155421609058976 Adapter cache time: 0.014373038429766893 Engine time: 0.07305058278143406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_192_slots_32_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_192_slots_32_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 60.94965473935008,
    "estimated_duration": 3600.0137642817363,
    "input_throughput": 6468.941933239082,
    "output_throughput": 5654.113381997345,
    "total_throughput": 12123.055315236426,
    "itl": 91.39357116225324,
    "ttft": 1981493.7288622777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8976815375499485,
    "arrivals": 743742,
    "finished_requests": 94294,
    "scheduler_time": 242.04717560504494
}
#Debug simulation 
Total elapsed time: 60.949910385068506. Arrivals time: 0.410860029514879 Scheduler time: 60.34359145304188 Scheduler overhead time: 0.07414188887923956 Adapter cache time: 0.014936958439648151 Engine time: 0.07518930733203888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 66.61558856675401,
    "estimated_duration": 3600.044555015866,
    "input_throughput": 6821.391409110427,
    "output_throughput": 5939.540934349842,
    "total_throughput": 12760.93234346027,
    "itl": 100.97794983145212,
    "ttft": 1961490.2270706461,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.856560701802398,
    "arrivals": 743017,
    "finished_requests": 99437,
    "scheduler_time": 228.88233314192453
}
#Debug simulation 
Total elapsed time: 66.61574665177613. Arrivals time: 0.4394330559298396 Scheduler time: 65.98641637107357 Scheduler overhead time: 0.07103243563324213 Adapter cache time: 0.015965421218425035 Engine time: 0.07328584464266896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 65.47895833896473,
    "estimated_duration": 3600.0468169732317,
    "input_throughput": 6757.2501794442305,
    "output_throughput": 5883.954036411495,
    "total_throughput": 12641.204215855725,
    "itl": 98.12542053638782,
    "ttft": 1966286.784970131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.386009656828831,
    "arrivals": 743017,
    "finished_requests": 98386,
    "scheduler_time": 231.85578411915935
}
#Debug simulation 
Total elapsed time: 65.47911913879216. Arrivals time: 0.48642007866874337 Scheduler time: 64.80338049726561 Scheduler overhead time: 0.07154742861166596 Adapter cache time: 0.01528919069096446 Engine time: 0.07265874929726124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 61.62225412297994,
    "estimated_duration": 3600.09576266137,
    "input_throughput": 6498.416026218511,
    "output_throughput": 5665.959559064836,
    "total_throughput": 12164.375585283347,
    "itl": 91.79159544949059,
    "ttft": 1980698.2994550443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8150605212664268,
    "arrivals": 743017,
    "finished_requests": 94759,
    "scheduler_time": 241.6105998089898
}
#Debug simulation 
Total elapsed time: 61.62240765383467. Arrivals time: 0.41131766932085156 Scheduler time: 61.01683979900554 Scheduler overhead time: 0.07332229288294911 Adapter cache time: 0.014557794202119112 Engine time: 0.07503745332360268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 61.086804835125804,
    "estimated_duration": 3600.105520439175,
    "input_throughput": 6769.006869839533,
    "output_throughput": 5893.457255500594,
    "total_throughput": 12662.464125340126,
    "itl": 98.71399505696998,
    "ttft": 1968249.9909985375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.340727115585466,
    "arrivals": 743017,
    "finished_requests": 98652,
    "scheduler_time": 231.02714603284366
}
#Debug simulation 
Total elapsed time: 61.086964163929224. Arrivals time: 0.43172142328694463 Scheduler time: 60.46869240002707 Scheduler overhead time: 0.0710212760604918 Adapter cache time: 0.014665781520307064 Engine time: 0.07150622177869081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 56.0577107029967,
    "estimated_duration": 3600.03786794387,
    "input_throughput": 6577.0285948473165,
    "output_throughput": 5722.613415665663,
    "total_throughput": 12299.64201051298,
    "itl": 92.07495063069666,
    "ttft": 1984160.472066058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6794767978088965,
    "arrivals": 743017,
    "finished_requests": 95698,
    "scheduler_time": 238.84913544671025
}
#Debug simulation 
Total elapsed time: 56.05787194380537. Arrivals time: 0.4079518411308527 Scheduler time: 55.45821153279394 Scheduler overhead time: 0.07277648709714413 Adapter cache time: 0.014420771040022373 Engine time: 0.0736643304117024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 63.77072003996,
    "estimated_duration": 3600.0226504066336,
    "input_throughput": 6727.61044913546,
    "output_throughput": 5858.835359721306,
    "total_throughput": 12586.445808856766,
    "itl": 98.02371473458246,
    "ttft": 1968020.7470091132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3301311433082352,
    "arrivals": 743017,
    "finished_requests": 98043,
    "scheduler_time": 232.71009363386096
}
#Debug simulation 
Total elapsed time: 63.770879935938865. Arrivals time: 0.42336956365033984 Scheduler time: 63.15921741304919 Scheduler overhead time: 0.0708606792613864 Adapter cache time: 0.015321184415370226 Engine time: 0.0721097462810576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_192_slots_32_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_192_slots_32_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 63.3611472886987,
    "estimated_duration": 3600.0926505807897,
    "input_throughput": 6513.069044547306,
    "output_throughput": 5677.005561704878,
    "total_throughput": 12190.074606252183,
    "itl": 91.68185001909123,
    "ttft": 1980908.239846193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4847714166529498,
    "arrivals": 743017,
    "finished_requests": 94912,
    "scheduler_time": 240.96716651343573
}
#Debug simulation 
Total elapsed time: 63.36130838096142. Arrivals time: 0.40872630942612886 Scheduler time: 62.75807479629293 Scheduler overhead time: 0.07404844043776393 Adapter cache time: 0.014116351958364248 Engine time: 0.07547898311167955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 62.21646126639098,
    "estimated_duration": 3600.049373443199,
    "input_throughput": 6786.313037877415,
    "output_throughput": 5909.095902108089,
    "total_throughput": 12695.408939985504,
    "itl": 100.87728076295694,
    "ttft": 1960241.6831636904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.692776712179182,
    "arrivals": 740854,
    "finished_requests": 99012,
    "scheduler_time": 230.4276549438736
}
#Debug simulation 
Total elapsed time: 62.216718055307865. Arrivals time: 0.4766586613841355 Scheduler time: 61.554711907636374 Scheduler overhead time: 0.07001028349623084 Adapter cache time: 0.01437670225277543 Engine time: 0.07155406754463911 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 62.535284218378365,
    "estimated_duration": 3600.0642311346824,
    "input_throughput": 6676.566710151229,
    "output_throughput": 5815.3431871968105,
    "total_throughput": 12491.90989734804,
    "itl": 98.13603941107446,
    "ttft": 1964514.3623494788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9799223500909309,
    "arrivals": 740854,
    "finished_requests": 97422,
    "scheduler_time": 234.5866010196623
}
#Debug simulation 
Total elapsed time: 62.53544252505526. Arrivals time: 0.4065091875381768 Scheduler time: 61.94059422519058 Scheduler overhead time: 0.07158802077174187 Adapter cache time: 0.014271246269345284 Engine time: 0.07249092403799295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 59.6199283991009,
    "estimated_duration": 3600.0283068983445,
    "input_throughput": 6487.045658849439,
    "output_throughput": 5651.691671705104,
    "total_throughput": 12138.737330554542,
    "itl": 91.90782123563537,
    "ttft": 1978576.239132251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9846580621134546,
    "arrivals": 740854,
    "finished_requests": 94683,
    "scheduler_time": 241.86662214647168
}
#Debug simulation 
Total elapsed time: 59.620088290888816. Arrivals time: 0.3987147370353341 Scheduler time: 59.02564423158765 Scheduler overhead time: 0.07406871765851974 Adapter cache time: 0.015083768870681524 Engine time: 0.07534375740215182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 61.4332847497426,
    "estimated_duration": 3600.0327967233115,
    "input_throughput": 6677.263335456086,
    "output_throughput": 5820.224754360866,
    "total_throughput": 12497.488089816952,
    "itl": 98.22735427940921,
    "ttft": 1965223.0837495064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.857201720513401,
    "arrivals": 740854,
    "finished_requests": 97480,
    "scheduler_time": 234.39444977262912
}
#Debug simulation 
Total elapsed time: 61.43344702664763. Arrivals time: 0.405160388443619 Scheduler time: 60.84161822358146 Scheduler overhead time: 0.07096245046705008 Adapter cache time: 0.01432466646656394 Engine time: 0.07156453654170036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 60.13688231213018,
    "estimated_duration": 3600.054570247249,
    "input_throughput": 6482.983950545252,
    "output_throughput": 5654.428176793428,
    "total_throughput": 12137.412127338679,
    "itl": 91.9505533547582,
    "ttft": 1978320.3741439877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9564397536264788,
    "arrivals": 740854,
    "finished_requests": 94681,
    "scheduler_time": 241.72540414191968
}
#Debug simulation 
Total elapsed time: 60.13704027514905. Arrivals time: 0.392554662656039 Scheduler time: 59.54995676642284 Scheduler overhead time: 0.07398495869711041 Adapter cache time: 0.014617870096117258 Engine time: 0.07461918843910098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 62.91788706416264,
    "estimated_duration": 3600.021849400127,
    "input_throughput": 6670.15590585964,
    "output_throughput": 5813.091663176188,
    "total_throughput": 12483.247569035828,
    "itl": 98.12237180420698,
    "ttft": 1963868.1814507977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7300425748946084,
    "arrivals": 740854,
    "finished_requests": 97375,
    "scheduler_time": 234.6664156708476
}
#Debug simulation 
Total elapsed time: 62.91803851723671. Arrivals time: 0.4130695383064449 Scheduler time: 62.31632365239784 Scheduler overhead time: 0.07187678245827556 Adapter cache time: 0.014312422834336758 Engine time: 0.07271349290385842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 59.95607700198889,
    "estimated_duration": 3600.063069742346,
    "input_throughput": 6495.283428929909,
    "output_throughput": 5660.018617801139,
    "total_throughput": 12155.302046731047,
    "itl": 92.06868560451741,
    "ttft": 1979749.007791533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0213024784810902,
    "arrivals": 740854,
    "finished_requests": 94821,
    "scheduler_time": 241.46312535706824
}
#Debug simulation 
Total elapsed time: 59.95623028697446. Arrivals time: 0.40221146773546934 Scheduler time: 59.358763036783785 Scheduler overhead time: 0.07397108851000667 Adapter cache time: 0.014678563456982374 Engine time: 0.07525407383218408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 61.50556325959042,
    "estimated_duration": 3600.0559728621065,
    "input_throughput": 6762.780407729106,
    "output_throughput": 5908.360636706891,
    "total_throughput": 12671.141044435997,
    "itl": 100.87776461250066,
    "ttft": 1965977.3090781025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7060015302430818,
    "arrivals": 740135,
    "finished_requests": 98536,
    "scheduler_time": 230.49284463492006
}
#Debug simulation 
Total elapsed time: 61.50571603467688. Arrivals time: 0.4209760269150138 Scheduler time: 60.90019872272387 Scheduler overhead time: 0.06953054806217551 Adapter cache time: 0.013865463435649872 Engine time: 0.07178280362859368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 56.823469073046,
    "estimated_duration": 3600.025291413018,
    "input_throughput": 6756.502255141919,
    "output_throughput": 5903.3096380438255,
    "total_throughput": 12659.811893185744,
    "itl": 98.56156368321881,
    "ttft": 1972381.091823068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9446691195154582,
    "arrivals": 740135,
    "finished_requests": 98497,
    "scheduler_time": 230.70402657391952
}
#Debug simulation 
Total elapsed time: 56.823714015074074. Arrivals time: 0.4714264185167849 Scheduler time: 56.16651265323162 Scheduler overhead time: 0.0704560955055058 Adapter cache time: 0.014274393673986197 Engine time: 0.07162180542945862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 58.82044484233484,
    "estimated_duration": 3600.049106880254,
    "input_throughput": 6474.047799919425,
    "output_throughput": 5660.915280586441,
    "total_throughput": 12134.963080505866,
    "itl": 91.78738436477761,
    "ttft": 1983920.6545267997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 217,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6175122169125855,
    "arrivals": 740135,
    "finished_requests": 94355,
    "scheduler_time": 241.57011898717712
}
#Debug simulation 
Total elapsed time: 58.82059708517045. Arrivals time: 0.40800948766991496 Scheduler time: 58.21794626209885 Scheduler overhead time: 0.07393715577200055 Adapter cache time: 0.014412112534046173 Engine time: 0.07512653898447752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 54.81792635237798,
    "estimated_duration": 3600.0498199601734,
    "input_throughput": 6755.905116965594,
    "output_throughput": 5904.9771706312595,
    "total_throughput": 12660.882287596853,
    "itl": 98.63159127350391,
    "ttft": 1972555.2057265316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7828139272471866,
    "arrivals": 740135,
    "finished_requests": 98524,
    "scheduler_time": 230.59470333458967
}
#Debug simulation 
Total elapsed time: 54.81809900328517. Arrivals time: 0.42738693207502365 Scheduler time: 54.204260382801294 Scheduler overhead time: 0.07045900681987405 Adapter cache time: 0.014172209426760674 Engine time: 0.07220292882993817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 59.88837648695335,
    "estimated_duration": 3600.0223193126035,
    "input_throughput": 6475.9395726334105,
    "output_throughput": 5659.562689569759,
    "total_throughput": 12135.50226220317,
    "itl": 91.76463197721314,
    "ttft": 1983666.607030931,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5891920257266638,
    "arrivals": 740135,
    "finished_requests": 94353,
    "scheduler_time": 241.63688884250223
}
#Debug simulation 
Total elapsed time: 59.88853161595762. Arrivals time: 0.4056946011260152 Scheduler time: 59.287098268512636 Scheduler overhead time: 0.07440090412274003 Adapter cache time: 0.014294483233243227 Engine time: 0.07593537261709571 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 60.68375710211694,
    "estimated_duration": 3600.0492852549514,
    "input_throughput": 6698.058023472954,
    "output_throughput": 5851.462391440055,
    "total_throughput": 12549.52041491301,
    "itl": 98.1993126173522,
    "ttft": 1972202.8485741152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6151319979643395,
    "arrivals": 740135,
    "finished_requests": 97607,
    "scheduler_time": 233.17591742304967
}
#Debug simulation 
Total elapsed time: 60.68391823815182. Arrivals time: 0.46820461098104715 Scheduler time: 60.029765603132546 Scheduler overhead time: 0.0702776676043868 Adapter cache time: 0.014188134111464024 Engine time: 0.0716674062423408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 59.332844445016235,
    "estimated_duration": 3600.065566359632,
    "input_throughput": 6465.024753294999,
    "output_throughput": 5656.515034139168,
    "total_throughput": 12121.539787434167,
    "itl": 91.64188953628266,
    "ttft": 1982857.0191626656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6361437837220765,
    "arrivals": 740135,
    "finished_requests": 94213,
    "scheduler_time": 241.78142591547584
}
#Debug simulation 
Total elapsed time: 59.33300586929545. Arrivals time: 0.41319410642609 Scheduler time: 58.72408601036295 Scheduler overhead time: 0.07434864994138479 Adapter cache time: 0.014576767571270466 Engine time: 0.07546916138380766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 65.89191327989101,
    "estimated_duration": 3600.0967283943005,
    "input_throughput": 6800.422001694225,
    "output_throughput": 5927.997109543938,
    "total_throughput": 12728.419111238163,
    "itl": 100.38962746851954,
    "ttft": 1961142.3310577145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3753810786455853,
    "arrivals": 738702,
    "finished_requests": 99066,
    "scheduler_time": 229.65313782536333
}
#Debug simulation 
Total elapsed time: 65.89207135606557. Arrivals time: 0.7524266475811601 Scheduler time: 64.95468894112855 Scheduler overhead time: 0.07028584508225322 Adapter cache time: 0.013799365609884262 Engine time: 0.07172604836523533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 61.73006167402491,
    "estimated_duration": 3600.055752384888,
    "input_throughput": 6734.141543207998,
    "output_throughput": 5867.071360216489,
    "total_throughput": 12601.212903424486,
    "itl": 98.04447425981087,
    "ttft": 1966870.9138595744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.639893510779367,
    "arrivals": 738702,
    "finished_requests": 98070,
    "scheduler_time": 232.3091075217513
}
#Debug simulation 
Total elapsed time: 61.730225653387606. Arrivals time: 0.41162356501445174 Scheduler time: 61.13183411769569 Scheduler overhead time: 0.07103934651240706 Adapter cache time: 0.014152880758047104 Engine time: 0.07216214528307319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 60.1668940698728,
    "estimated_duration": 3600.0978034482205,
    "input_throughput": 6539.074293329429,
    "output_throughput": 5703.207835168834,
    "total_throughput": 12242.282128498262,
    "itl": 91.815517002608,
    "ttft": 1979722.9820943011,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.704172259029004,
    "arrivals": 738702,
    "finished_requests": 95289,
    "scheduler_time": 239.62535277087184
}
#Debug simulation 
Total elapsed time: 60.16715384880081. Arrivals time: 0.412463597021997 Scheduler time: 59.56020202068612 Scheduler overhead time: 0.07335756905376911 Adapter cache time: 0.014501111581921577 Engine time: 0.07506712200120091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 62.43368357187137,
    "estimated_duration": 3600.037088978576,
    "input_throughput": 6729.973164491524,
    "output_throughput": 5867.488439124163,
    "total_throughput": 12597.461603615688,
    "itl": 98.02944476083402,
    "ttft": 1966533.957926723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5449373006680962,
    "arrivals": 738702,
    "finished_requests": 98038,
    "scheduler_time": 232.33695226242082
}
#Debug simulation 
Total elapsed time: 62.433847807813436. Arrivals time: 0.4302727170288563 Scheduler time: 61.8166888570413 Scheduler overhead time: 0.07092181500047445 Adapter cache time: 0.013810410629957914 Engine time: 0.07217110740020871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 61.23528232006356,
    "estimated_duration": 3600.0091240591646,
    "input_throughput": 6527.783733365279,
    "output_throughput": 5697.9263921618,
    "total_throughput": 12225.710125527079,
    "itl": 91.60500542461729,
    "ttft": 1978875.3367931554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6633765200432424,
    "arrivals": 738702,
    "finished_requests": 95166,
    "scheduler_time": 239.87635740526818
}
#Debug simulation 
Total elapsed time: 61.23544975183904. Arrivals time: 0.40852253790944815 Scheduler time: 60.63003022130579 Scheduler overhead time: 0.07499520294368267 Adapter cache time: 0.014527886640280485 Engine time: 0.07617566687986255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 63.02297671092674,
    "estimated_duration": 3600.0256158633015,
    "input_throughput": 6735.864293061403,
    "output_throughput": 5863.352168103437,
    "total_throughput": 12599.21646116484,
    "itl": 97.89026274317031,
    "ttft": 1966374.9830365304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.442766132568936,
    "arrivals": 738702,
    "finished_requests": 98074,
    "scheduler_time": 232.56274591414723
}
#Debug simulation 
Total elapsed time: 63.02314465492964. Arrivals time: 0.41528772562742233 Scheduler time: 62.41905754478648 Scheduler overhead time: 0.07145910058170557 Adapter cache time: 0.014255774207413197 Engine time: 0.07290321309119463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 59.59038500394672,
    "estimated_duration": 3600.0760907481417,
    "input_throughput": 6545.128604518833,
    "output_throughput": 5707.056873825773,
    "total_throughput": 12252.185478344605,
    "itl": 91.86504439052266,
    "ttft": 1980282.5845251195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6773507640324568,
    "arrivals": 738702,
    "finished_requests": 95344,
    "scheduler_time": 239.4705652148124
}
#Debug simulation 
Total elapsed time: 59.59055240917951. Arrivals time: 0.40314437728375196 Scheduler time: 58.993545041419566 Scheduler overhead time: 0.07335875555872917 Adapter cache time: 0.01412925310432911 Engine time: 0.0751492497511208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_192_slots_32_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_192_slots_32_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 80.44763111881912,
    "estimated_duration": 3600.0437835376456,
    "input_throughput": 6635.971792688667,
    "output_throughput": 5784.933531984701,
    "total_throughput": 12420.905324673367,
    "itl": 95.47288291523462,
    "ttft": 1951010.8323606262,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2151570257032334,
    "arrivals": 644931,
    "finished_requests": 96774,
    "scheduler_time": 235.18062684466014
}
#Debug simulation 
Total elapsed time: 80.44779886025935. Arrivals time: 0.4918603957630694 Scheduler time: 79.74964721640572 Scheduler overhead time: 0.0789476209320128 Adapter cache time: 0.016508333384990692 Engine time: 0.0791181200183928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_192_slots_32_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_192_slots_32_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 76.80750416219234,
    "estimated_duration": 3600.041862910904,
    "input_throughput": 6677.551238407625,
    "output_throughput": 5820.513982317151,
    "total_throughput": 12498.065220724775,
    "itl": 96.6725319272254,
    "ttft": 1953013.4549496055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5558824110822784,
    "arrivals": 644931,
    "finished_requests": 97415,
    "scheduler_time": 233.42347812057534
}
#Debug simulation 
Total elapsed time: 76.80767557490617. Arrivals time: 0.48620217107236385 Scheduler time: 76.11828109854832 Scheduler overhead time: 0.07770297070965171 Adapter cache time: 0.016856258735060692 Engine time: 0.07813263172283769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_192_slots_32_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_192_slots_32_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 73.63661996368319,
    "estimated_duration": 3600.0743517143037,
    "input_throughput": 6499.672705053324,
    "output_throughput": 5668.840697771113,
    "total_throughput": 12168.513402824437,
    "itl": 90.8893979103747,
    "ttft": 1966819.3408083164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 359,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.682291929032669,
    "arrivals": 644931,
    "finished_requests": 94832,
    "scheduler_time": 240.32098266049405
}
#Debug simulation 
Total elapsed time: 73.63678766181692. Arrivals time: 0.47210749750956893 Scheduler time: 72.95576703641564 Scheduler overhead time: 0.07939481781795621 Adapter cache time: 0.01664914470165968 Engine time: 0.07984939450398088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_192_slots_32_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_192_slots_32_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 76.7840870982036,
    "estimated_duration": 3600.0195357291145,
    "input_throughput": 6708.922482307704,
    "output_throughput": 5830.274194817407,
    "total_throughput": 12539.196677125112,
    "itl": 96.99443763318958,
    "ttft": 1947809.22705028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6427168046915863,
    "arrivals": 644931,
    "finished_requests": 97630,
    "scheduler_time": 233.10479244873983
}
#Debug simulation 
Total elapsed time: 76.78424393199384. Arrivals time: 0.4870801465585828 Scheduler time: 76.09510215232149 Scheduler overhead time: 0.0772560853511095 Adapter cache time: 0.016439023427665234 Engine time: 0.07768396520987153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_192_slots_32_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_192_slots_32_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 75.34845537971705,
    "estimated_duration": 3600.063567603827,
    "input_throughput": 6418.311945358061,
    "output_throughput": 5601.916638772898,
    "total_throughput": 12020.22858413096,
    "itl": 88.48901107362606,
    "ttft": 1967640.691447362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.510984802776961,
    "arrivals": 644931,
    "finished_requests": 93617,
    "scheduler_time": 243.28236148825812
}
#Debug simulation 
Total elapsed time: 75.34862105408683. Arrivals time: 0.46415214613080025 Scheduler time: 74.67229854827747 Scheduler overhead time: 0.0809348076581955 Adapter cache time: 0.016842578072100878 Engine time: 0.08139112964272499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_192_slots_32_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_192_slots_32_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 77.06918801087886,
    "estimated_duration": 3600.02190839843,
    "input_throughput": 6694.446759831422,
    "output_throughput": 5830.562017145628,
    "total_throughput": 12525.008776977049,
    "itl": 96.90257956016585,
    "ttft": 1949439.185381035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3109793804865237,
    "arrivals": 644931,
    "finished_requests": 97600,
    "scheduler_time": 233.18831957329883
}
#Debug simulation 
Total elapsed time: 77.06934626773. Arrivals time: 0.4841971225105226 Scheduler time: 76.38302222453058 Scheduler overhead time: 0.076301584020257 Adapter cache time: 0.01630660891532898 Engine time: 0.07818578276783228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_192_slots_32_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_192_slots_32_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 72.69027454825118,
    "estimated_duration": 3600.01025886414,
    "input_throughput": 6521.259472023627,
    "output_throughput": 5683.878247184799,
    "total_throughput": 12205.137719208426,
    "itl": 91.22624749915924,
    "ttft": 1966099.8223991233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6657165688462716,
    "arrivals": 644931,
    "finished_requests": 95059,
    "scheduler_time": 239.58319699195835
}
#Debug simulation 
Total elapsed time: 72.69043189985678. Arrivals time: 0.46403633803129196 Scheduler time: 72.01970085594803 Scheduler overhead time: 0.07852442096918821 Adapter cache time: 0.016683391761034727 Engine time: 0.07962955115363002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_192_slots_32_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_192_slots_32_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 79.19711370905861,
    "estimated_duration": 3600.083417309274,
    "input_throughput": 6710.955886143701,
    "output_throughput": 5900.098286021258,
    "total_throughput": 12611.054172164959,
    "itl": 99.49069362077891,
    "ttft": 1914993.0123818177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3870796605339373,
    "arrivals": 576087,
    "finished_requests": 98369,
    "scheduler_time": 229.78671317700284
}
#Debug simulation 
Total elapsed time: 79.1972713121213. Arrivals time: 0.47218649508431554 Scheduler time: 78.52415375225246 Scheduler overhead time: 0.07641301956027746 Adapter cache time: 0.016392764169722795 Engine time: 0.07738212123513222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_192_slots_32_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_192_slots_32_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 78.41000114567578,
    "estimated_duration": 3600.100323841071,
    "input_throughput": 6656.555052452455,
    "output_throughput": 5847.99119640573,
    "total_throughput": 12504.546248858185,
    "itl": 97.20946681665298,
    "ttft": 1916549.8774611186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.463173892041671,
    "arrivals": 576087,
    "finished_requests": 97433,
    "scheduler_time": 232.1865082549094
}
#Debug simulation 
Total elapsed time: 78.41015964373946. Arrivals time: 0.5339124565944076 Scheduler time: 77.6731777866371 Scheduler overhead time: 0.07729756040498614 Adapter cache time: 0.01614967780187726 Engine time: 0.07807068293914199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_192_slots_32_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_192_slots_32_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 75.55187851097435,
    "estimated_duration": 3600.075991035591,
    "input_throughput": 6447.27446248246,
    "output_throughput": 5655.799224988833,
    "total_throughput": 12103.073687471293,
    "itl": 90.69404663815608,
    "ttft": 1934637.0507694315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3207404616149248,
    "arrivals": 576087,
    "finished_requests": 94264,
    "scheduler_time": 240.34007767499065
}
#Debug simulation 
Total elapsed time: 75.55205267388374. Arrivals time: 0.46464566281065345 Scheduler time: 74.87632478307933 Scheduler overhead time: 0.08058975078165531 Adapter cache time: 0.0165124936029315 Engine time: 0.08143182704225183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_192_slots_32_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_192_slots_32_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 77.55476560536772,
    "estimated_duration": 3600.0717294888727,
    "input_throughput": 6638.879665709692,
    "output_throughput": 5832.237404608884,
    "total_throughput": 12471.117070318576,
    "itl": 97.00462319076796,
    "ttft": 1917164.1086449104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4159459458989994,
    "arrivals": 576087,
    "finished_requests": 97200,
    "scheduler_time": 232.4666835559901
}
#Debug simulation 
Total elapsed time: 77.55494196899235. Arrivals time: 0.45955768320709467 Scheduler time: 76.89044135110453 Scheduler overhead time: 0.07812636718153954 Adapter cache time: 0.016668262891471386 Engine time: 0.07841688254848123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_192_slots_32_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_192_slots_32_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 71.85237320233136,
    "estimated_duration": 3600.0845512959136,
    "input_throughput": 6465.761475413385,
    "output_throughput": 5681.1082374823045,
    "total_throughput": 12146.86971289569,
    "itl": 91.05630100634951,
    "ttft": 1937542.240409622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6429426585044866,
    "arrivals": 576087,
    "finished_requests": 94592,
    "scheduler_time": 239.30220426506526
}
#Debug simulation 
Total elapsed time: 71.85254039801657. Arrivals time: 0.4571854481473565 Scheduler time: 71.18741466011852 Scheduler overhead time: 0.07884174911305308 Adapter cache time: 0.01656233286485076 Engine time: 0.08027406642213464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_192_slots_32_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_192_slots_32_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 75.19041687622666,
    "estimated_duration": 3600.0608158485556,
    "input_throughput": 6642.35223325348,
    "output_throughput": 5832.915907297095,
    "total_throughput": 12475.268140550575,
    "itl": 96.8730289396863,
    "ttft": 1923379.1041684577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.406738194595081,
    "arrivals": 576087,
    "finished_requests": 97167,
    "scheduler_time": 232.7107838120183
}
#Debug simulation 
Total elapsed time: 75.19058639835566. Arrivals time: 0.46911742677912116 Scheduler time: 74.52093848353252 Scheduler overhead time: 0.07598477369174361 Adapter cache time: 0.016113563906401396 Engine time: 0.07754461653530598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_192_slots_32_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_192_slots_32_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 73.02141545107588,
    "estimated_duration": 3600.0634589161414,
    "input_throughput": 6454.389280958854,
    "output_throughput": 5681.39262916155,
    "total_throughput": 12135.781910120404,
    "itl": 91.11434724465484,
    "ttft": 1937478.467279726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.691185636762545,
    "arrivals": 576087,
    "finished_requests": 94494,
    "scheduler_time": 239.30600908652082
}
#Debug simulation 
Total elapsed time: 73.02158182300627. Arrivals time: 0.5128963980823755 Scheduler time: 72.29923052107915 Scheduler overhead time: 0.07962142629548907 Adapter cache time: 0.016859357710927725 Engine time: 0.08058183919638395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_192_slots_32_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_192_slots_32_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 76.26927162427455,
    "estimated_duration": 3600.0788230972303,
    "input_throughput": 6730.8640145698155,
    "output_throughput": 5874.468598941791,
    "total_throughput": 12605.332613511608,
    "itl": 99.838323908939,
    "ttft": 1908442.9325883621,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5325526592368406,
    "arrivals": 564621,
    "finished_requests": 98087,
    "scheduler_time": 230.4950157089399
}
#Debug simulation 
Total elapsed time: 76.26944546913728. Arrivals time: 0.47589422250166535 Scheduler time: 75.59250963199884 Scheduler overhead time: 0.07653410406783223 Adapter cache time: 0.016336096916347742 Engine time: 0.0773527193814516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_192_slots_32_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_192_slots_32_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 73.92274169111624,
    "estimated_duration": 3600.0613542777073,
    "input_throughput": 6698.4227841967495,
    "output_throughput": 5841.374890739656,
    "total_throughput": 12539.797674936404,
    "itl": 97.64880670507698,
    "ttft": 1914949.9895044265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.830683820014823,
    "arrivals": 564621,
    "finished_requests": 97753,
    "scheduler_time": 231.9973594096699
}
#Debug simulation 
Total elapsed time: 73.92291296692565. Arrivals time: 0.4815759854391217 Scheduler time: 73.23807658907026 Scheduler overhead time: 0.07806537300348282 Adapter cache time: 0.016463295556604862 Engine time: 0.07781987451016903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_192_slots_32_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_192_slots_32_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 70.37648252397776,
    "estimated_duration": 3600.0474244452907,
    "input_throughput": 6491.304209305184,
    "output_throughput": 5663.452892746703,
    "total_throughput": 12154.757102051886,
    "itl": 91.07667954871485,
    "ttft": 1930348.274826849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7201906003104694,
    "arrivals": 564621,
    "finished_requests": 94637,
    "scheduler_time": 239.9673448429563
}
#Debug simulation 
Total elapsed time: 70.37665016204119. Arrivals time: 0.4529496650211513 Scheduler time: 69.7178217722103 Scheduler overhead time: 0.07834623195230961 Adapter cache time: 0.01653793314471841 Engine time: 0.07877843733876944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_192_slots_32_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_192_slots_32_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 73.35359013918787,
    "estimated_duration": 3600.00879529144,
    "input_throughput": 6683.078116772291,
    "output_throughput": 5825.21965708206,
    "total_throughput": 12508.29777385435,
    "itl": 97.24885714050086,
    "ttft": 1915710.0801301152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.473401234364134,
    "arrivals": 564621,
    "finished_requests": 97422,
    "scheduler_time": 232.73248078879612
}
#Debug simulation 
Total elapsed time: 73.35375171108171. Arrivals time: 0.51661382522434 Scheduler time: 72.63563991198316 Scheduler overhead time: 0.07692449307069182 Adapter cache time: 0.01605057856068015 Engine time: 0.07728241803124547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_192_slots_32_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_192_slots_32_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 69.44909673091024,
    "estimated_duration": 3600.091565471322,
    "input_throughput": 6497.842228337163,
    "output_throughput": 5669.42524344596,
    "total_throughput": 12167.267471783123,
    "itl": 91.2095530428645,
    "ttft": 1933078.0873238517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.933008438195123,
    "arrivals": 564621,
    "finished_requests": 94849,
    "scheduler_time": 239.6563801726113
}
#Debug simulation 
Total elapsed time: 69.44933994393796. Arrivals time: 0.5138757820241153 Scheduler time: 68.72781868930906 Scheduler overhead time: 0.07850881572812796 Adapter cache time: 0.01694337883964181 Engine time: 0.079929961822927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_192_slots_32_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_192_slots_32_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 74.00412484491244,
    "estimated_duration": 3600.093706515518,
    "input_throughput": 6680.637216879157,
    "output_throughput": 5817.844119472149,
    "total_throughput": 12498.481336351306,
    "itl": 97.18580920338077,
    "ttft": 1917681.34668107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3875864317733697,
    "arrivals": 564621,
    "finished_requests": 97384,
    "scheduler_time": 233.13534815973125
}
#Debug simulation 
Total elapsed time: 74.00429467018694. Arrivals time: 0.47471989365294576 Scheduler time: 73.32870605029166 Scheduler overhead time: 0.07642964133992791 Adapter cache time: 0.01641114568337798 Engine time: 0.0766678350046277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_192_slots_32_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_192_slots_32_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 71.13567564636469,
    "estimated_duration": 3600.0250930280554,
    "input_throughput": 6505.084102150589,
    "output_throughput": 5670.083533454116,
    "total_throughput": 12175.167635604706,
    "itl": 91.18593298882769,
    "ttft": 1931830.0929430805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5166265599988544,
    "arrivals": 564621,
    "finished_requests": 94905,
    "scheduler_time": 239.75928546268366
}
#Debug simulation 
Total elapsed time: 71.13585374923423. Arrivals time: 0.4574757074005902 Scheduler time: 70.47004422312602 Scheduler overhead time: 0.0796314268372953 Adapter cache time: 0.016361520625650883 Engine time: 0.08006071392446756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_192_slots_32_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_192_slots_32_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 79.13926211511716,
    "estimated_duration": 3600.0757106463866,
    "input_throughput": 6745.253975683739,
    "output_throughput": 5903.276683085146,
    "total_throughput": 12648.530658768885,
    "itl": 100.11095241919588,
    "ttft": 1898616.4269108498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6648008398758436,
    "arrivals": 558945,
    "finished_requests": 98736,
    "scheduler_time": 228.97429768362278
}
#Debug simulation 
Total elapsed time: 79.13942121341825. Arrivals time: 0.536797437351197 Scheduler time: 78.40298768877983 Scheduler overhead time: 0.07580171478912234 Adapter cache time: 0.016585429199039936 Engine time: 0.07688626321032643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_192_slots_32_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_192_slots_32_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 74.40451571531594,
    "estimated_duration": 3600.0776743800425,
    "input_throughput": 6684.831044414705,
    "output_throughput": 5849.099354120517,
    "total_throughput": 12533.930398535222,
    "itl": 97.88360899978099,
    "ttft": 1904159.5772751865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 488,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.57485456116498,
    "arrivals": 558945,
    "finished_requests": 97706,
    "scheduler_time": 231.22837902288452
}
#Debug simulation 
Total elapsed time: 74.40468053193763. Arrivals time: 0.4804254323244095 Scheduler time: 73.72135014925152 Scheduler overhead time: 0.07688323315232992 Adapter cache time: 0.017497223801910877 Engine time: 0.07757272012531757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_192_slots_32_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_192_slots_32_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 65.02002357132733,
    "estimated_duration": 3600.0154062107636,
    "input_throughput": 6500.017183157031,
    "output_throughput": 5694.850351093118,
    "total_throughput": 12194.867534250148,
    "itl": 91.70508958706934,
    "ttft": 1929928.89818471,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.482901012818357,
    "arrivals": 558945,
    "finished_requests": 95107,
    "scheduler_time": 238.18639302664818
}
#Debug simulation 
Total elapsed time: 65.02028334094211. Arrivals time: 0.4431969546712935 Scheduler time: 64.3730892771855 Scheduler overhead time: 0.07680519949644804 Adapter cache time: 0.016762565355747938 Engine time: 0.07869491400197148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_192_slots_32_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_192_slots_32_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 74.29547905363142,
    "estimated_duration": 3600.0377478931614,
    "input_throughput": 6673.744188949269,
    "output_throughput": 5850.78448478121,
    "total_throughput": 12524.52867373048,
    "itl": 97.67774251672627,
    "ttft": 1908701.5803870247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.811758521897714,
    "arrivals": 558945,
    "finished_requests": 97691,
    "scheduler_time": 231.386313447546
}
#Debug simulation 
Total elapsed time: 74.29563571885228. Arrivals time: 0.47867202665656805 Scheduler time: 73.6147830975242 Scheduler overhead time: 0.07687960332259536 Adapter cache time: 0.017053953371942043 Engine time: 0.07764385594055057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_192_slots_32_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_192_slots_32_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 71.7676192196086,
    "estimated_duration": 3600.0730772382426,
    "input_throughput": 6477.3879584380475,
    "output_throughput": 5669.087144102265,
    "total_throughput": 12146.475102540313,
    "itl": 91.05420907270108,
    "ttft": 1927816.3788204992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 352,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6261232157889913,
    "arrivals": 558945,
    "finished_requests": 94789,
    "scheduler_time": 239.68013999629807
}
#Debug simulation 
Total elapsed time: 71.76777872489765. Arrivals time: 0.515112416818738 Scheduler time: 71.04426540574059 Scheduler overhead time: 0.07905595563352108 Adapter cache time: 0.01703911554068327 Engine time: 0.08018995448946953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_192_slots_32_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_192_slots_32_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 75.38580777402967,
    "estimated_duration": 3600.0508688521118,
    "input_throughput": 6689.9838022787035,
    "output_throughput": 5852.978962688537,
    "total_throughput": 12542.96276496724,
    "itl": 97.75303951418196,
    "ttft": 1907670.293447702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.64932719033676,
    "arrivals": 558945,
    "finished_requests": 97855,
    "scheduler_time": 231.42700356192842
}
#Debug simulation 
Total elapsed time: 75.38596267905086. Arrivals time: 0.46751806046813726 Scheduler time: 74.71696114819497 Scheduler overhead time: 0.07647458929568529 Adapter cache time: 0.016531921457499266 Engine time: 0.07752786157652736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_192_slots_32_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_192_slots_32_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 64.70957572385669,
    "estimated_duration": 3600.031313832294,
    "input_throughput": 6518.553577529576,
    "output_throughput": 5707.733130278328,
    "total_throughput": 12226.286707807903,
    "itl": 91.89238227423007,
    "ttft": 1930020.1430905745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5930525721982427,
    "arrivals": 558945,
    "finished_requests": 95304,
    "scheduler_time": 237.75799112832073
}
#Debug simulation 
Total elapsed time: 64.70973562588915. Arrivals time: 0.49568264884874225 Scheduler time: 64.00903933960944 Scheduler overhead time: 0.0775223751552403 Adapter cache time: 0.0175073710270226 Engine time: 0.07832508347928524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_192_slots_32_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_192_slots_32_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 72.64620852516964,
    "estimated_duration": 3600.0387086879045,
    "input_throughput": 6792.208078482586,
    "output_throughput": 5904.690121442477,
    "total_throughput": 12696.898199925063,
    "itl": 99.89764409308621,
    "ttft": 1902782.4470052538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7507621572911956,
    "arrivals": 556042,
    "finished_requests": 98700,
    "scheduler_time": 228.9532025204301
}
#Debug simulation 
Total elapsed time: 72.64645169908181. Arrivals time: 0.47674035793170333 Scheduler time: 71.97293101483956 Scheduler overhead time: 0.07408158760517836 Adapter cache time: 0.016349251847714186 Engine time: 0.07572534820064902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_192_slots_32_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_192_slots_32_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 81.07806730829179,
    "estimated_duration": 3600.0112455348553,
    "input_throughput": 6391.72420045631,
    "output_throughput": 5553.6470961855575,
    "total_throughput": 11945.371296641868,
    "itl": 87.91110715073754,
    "ttft": 1928497.3582031329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2833097378537084,
    "arrivals": 556042,
    "finished_requests": 92889,
    "scheduler_time": 245.07005697757097
}
#Debug simulation 
Total elapsed time: 81.07822052529082. Arrivals time: 0.4541281214915216 Scheduler time: 80.41034498438239 Scheduler overhead time: 0.08110367273911834 Adapter cache time: 0.0167369213886559 Engine time: 0.0826687510125339 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_192_slots_32_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_192_slots_32_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 72.22094925167039,
    "estimated_duration": 3600.007048476504,
    "input_throughput": 6483.39925053131,
    "output_throughput": 5640.355623357198,
    "total_throughput": 12123.754873888507,
    "itl": 90.72378959778473,
    "ttft": 1923539.292934722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8021921818424196,
    "arrivals": 556042,
    "finished_requests": 94294,
    "scheduler_time": 240.82043221967172
}
#Debug simulation 
Total elapsed time: 72.22110716067255. Arrivals time: 0.4390155542641878 Scheduler time: 71.5762287392281 Scheduler overhead time: 0.07785710319876671 Adapter cache time: 0.016782317776232958 Engine time: 0.07911915006116033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_192_slots_32_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_192_slots_32_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 77.18351820390671,
    "estimated_duration": 3600.01001926131,
    "input_throughput": 6710.868267238115,
    "output_throughput": 5832.660155848269,
    "total_throughput": 12543.528423086384,
    "itl": 96.68127169201165,
    "ttft": 1907795.456204385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3854145621694594,
    "arrivals": 556042,
    "finished_requests": 97578,
    "scheduler_time": 232.38068963788626
}
#Debug simulation 
Total elapsed time: 77.18368565896526. Arrivals time: 0.4529428933747113 Scheduler time: 76.5274809775874 Scheduler overhead time: 0.07792129460722208 Adapter cache time: 0.01600499777123332 Engine time: 0.0780743402428925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_192_slots_32_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_192_slots_32_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 71.4546057577245,
    "estimated_duration": 3600.036897348084,
    "input_throughput": 6527.838927793013,
    "output_throughput": 5672.477139065695,
    "total_throughput": 12200.316066858708,
    "itl": 91.02382817254957,
    "ttft": 1925524.942849349,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.01474917830436,
    "arrivals": 556042,
    "finished_requests": 94889,
    "scheduler_time": 239.39538860439015
}
#Debug simulation 
Total elapsed time: 71.45477335015312. Arrivals time: 0.43337532132864 Scheduler time: 70.81664886558428 Scheduler overhead time: 0.07773301284760237 Adapter cache time: 0.016565827187150717 Engine time: 0.07825547363609076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_192_slots_32_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_192_slots_32_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 75.93709831312299,
    "estimated_duration": 3600.0050058956494,
    "input_throughput": 6716.51732717087,
    "output_throughput": 5839.559935492312,
    "total_throughput": 12556.077262663182,
    "itl": 97.16369690548115,
    "ttft": 1905829.6385211276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.866380502316157,
    "arrivals": 556042,
    "finished_requests": 97670,
    "scheduler_time": 231.90939051515258
}
#Debug simulation 
Total elapsed time: 75.93735104100779. Arrivals time: 0.4737695609219372 Scheduler time: 75.26184573583305 Scheduler overhead time: 0.07612846652045846 Adapter cache time: 0.016798640601336956 Engine time: 0.07735553802922368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_192_slots_32_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_192_slots_32_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 71.8302396191284,
    "estimated_duration": 3600.0735739580305,
    "input_throughput": 6513.59715802113,
    "output_throughput": 5660.0634907573,
    "total_throughput": 12173.66064877843,
    "itl": 90.70471898689,
    "ttft": 1925667.6732896112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9193853664770923,
    "arrivals": 556042,
    "finished_requests": 94707,
    "scheduler_time": 239.913018390444
}
#Debug simulation 
Total elapsed time: 71.83040071418509. Arrivals time: 0.4596830219961703 Scheduler time: 71.16346441861242 Scheduler overhead time: 0.0782840526662767 Adapter cache time: 0.016623642295598984 Engine time: 0.07973013119772077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_192_slots_32_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_192_slots_32_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 73.6536240321584,
    "estimated_duration": 3600.0180332311975,
    "input_throughput": 6764.8727798569835,
    "output_throughput": 5903.6576494379715,
    "total_throughput": 12668.530429294955,
    "itl": 100.09576494811319,
    "ttft": 1905323.3448015247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.281281116022735,
    "arrivals": 554638,
    "finished_requests": 98582,
    "scheduler_time": 229.11940746491518
}
#Debug simulation 
Total elapsed time: 73.65378792025149. Arrivals time: 0.47005206253379583 Scheduler time: 72.98767818510532 Scheduler overhead time: 0.0742219421081245 Adapter cache time: 0.015553727746009827 Engine time: 0.07565324194729328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_192_slots_32_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_192_slots_32_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 72.54160749306902,
    "estimated_duration": 3600.0816337770693,
    "input_throughput": 6677.112200586431,
    "output_throughput": 5826.775371755075,
    "total_throughput": 12503.887572341506,
    "itl": 97.07559881084147,
    "ttft": 1912381.9999148988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5520010789670082,
    "arrivals": 554638,
    "finished_requests": 97294,
    "scheduler_time": 232.5542709069018
}
#Debug simulation 
Total elapsed time: 72.54177432274446. Arrivals time: 0.45549859944730997 Scheduler time: 71.88782451068982 Scheduler overhead time: 0.07550571020692587 Adapter cache time: 0.015622675884515047 Engine time: 0.07645360240712762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_192_slots_32_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_192_slots_32_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 71.62513797404245,
    "estimated_duration": 3600.0333289757455,
    "input_throughput": 6520.844629702083,
    "output_throughput": 5697.440308375042,
    "total_throughput": 12218.284938077124,
    "itl": 91.46449074240415,
    "ttft": 1924978.588537482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5179838353721564,
    "arrivals": 554638,
    "finished_requests": 95102,
    "scheduler_time": 238.29349036173576
}
#Debug simulation 
Total elapsed time: 71.62530419230461. Arrivals time: 0.4459998612292111 Scheduler time: 70.973841201514 Scheduler overhead time: 0.07848570542410016 Adapter cache time: 0.0160386860370636 Engine time: 0.07928592944517732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_192_slots_32_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_192_slots_32_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 74.19489867100492,
    "estimated_duration": 3600.0049334509995,
    "input_throughput": 6680.315845274755,
    "output_throughput": 5832.497562683075,
    "total_throughput": 12512.81340795783,
    "itl": 97.31495198986234,
    "ttft": 1913070.3176425067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2416346756042884,
    "arrivals": 554638,
    "finished_requests": 97403,
    "scheduler_time": 232.33210243045292
}
#Debug simulation 
Total elapsed time: 74.19518976705149. Arrivals time: 0.47424484649673104 Scheduler time: 73.5222566765733 Scheduler overhead time: 0.07552391057834029 Adapter cache time: 0.015772069804370403 Engine time: 0.07644827896729112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_192_slots_32_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_192_slots_32_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 71.71145488880575,
    "estimated_duration": 3600.001040311665,
    "input_throughput": 6500.123121623915,
    "output_throughput": 5683.446690956697,
    "total_throughput": 12183.569812580612,
    "itl": 91.2705022016482,
    "ttft": 1928254.2105618962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4775452547148,
    "arrivals": 554638,
    "finished_requests": 94857,
    "scheduler_time": 238.95281736135493
}
#Debug simulation 
Total elapsed time: 71.71161740273237. Arrivals time: 0.46265927655622363 Scheduler time: 71.04444660525769 Scheduler overhead time: 0.07763044815510511 Adapter cache time: 0.016203624196350574 Engine time: 0.07896944927051663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_192_slots_32_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_192_slots_32_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 75.26975343097001,
    "estimated_duration": 3600.099773622239,
    "input_throughput": 6665.563597937658,
    "output_throughput": 5814.8780079328535,
    "total_throughput": 12480.441605870512,
    "itl": 96.69557694331634,
    "ttft": 1913245.6035952729,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1003099894476973,
    "arrivals": 554638,
    "finished_requests": 97133,
    "scheduler_time": 233.08345038741575
}
#Debug simulation 
Total elapsed time: 75.2699092887342. Arrivals time: 0.4546520044095814 Scheduler time: 74.61510576820001 Scheduler overhead time: 0.07596566434949636 Adapter cache time: 0.015827092807739973 Engine time: 0.07715288549661636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_192_slots_32_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_192_slots_32_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 71.45237940084189,
    "estimated_duration": 3600.066257875426,
    "input_throughput": 6513.594561961928,
    "output_throughput": 5684.034274434758,
    "total_throughput": 12197.628836396685,
    "itl": 91.40319858956978,
    "ttft": 1927146.3408960346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6698611263930956,
    "arrivals": 554638,
    "finished_requests": 94890,
    "scheduler_time": 238.8900245632837
}
#Debug simulation 
Total elapsed time: 71.45253103971481. Arrivals time: 0.4567035655491054 Scheduler time: 70.78778365254402 Scheduler overhead time: 0.07822737330570817 Adapter cache time: 0.018453719560056925 Engine time: 0.07945359125733376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_192_slots_32_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_192_slots_32_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 75.22792630176991,
    "estimated_duration": 3600.0592102681326,
    "input_throughput": 6807.208873149274,
    "output_throughput": 5912.0410962393,
    "total_throughput": 12719.249969388575,
    "itl": 100.20410179083797,
    "ttft": 1897082.8658837387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2746687069907847,
    "arrivals": 553841,
    "finished_requests": 99058,
    "scheduler_time": 229.05565945547949
}
#Debug simulation 
Total elapsed time: 75.22807711316273. Arrivals time: 0.4730440629646182 Scheduler time: 74.55874888645485 Scheduler overhead time: 0.07419295702129602 Adapter cache time: 0.015505156479775906 Engine time: 0.07599383359774947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_192_slots_32_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_192_slots_32_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 72.62359555903822,
    "estimated_duration": 3600.0457892007403,
    "input_throughput": 6739.489556711056,
    "output_throughput": 5854.393314447031,
    "total_throughput": 12593.882871158086,
    "itl": 97.69886933941324,
    "ttft": 1903755.5310945928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.454570713080469,
    "arrivals": 553841,
    "finished_requests": 98044,
    "scheduler_time": 231.59569220763905
}
#Debug simulation 
Total elapsed time: 72.6238464503549. Arrivals time: 0.4562227209098637 Scheduler time: 71.96968400338665 Scheduler overhead time: 0.07557791890576482 Adapter cache time: 0.015460707247257233 Engine time: 0.0762214926071465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_192_slots_32_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_192_slots_32_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 72.75928879203275,
    "estimated_duration": 3600.0614757826074,
    "input_throughput": 6559.234379425894,
    "output_throughput": 5695.2349669370205,
    "total_throughput": 12254.469346362916,
    "itl": 91.44862074417331,
    "ttft": 1916622.9326119253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4448312164098147,
    "arrivals": 553841,
    "finished_requests": 95360,
    "scheduler_time": 238.7563406082187
}
#Debug simulation 
Total elapsed time: 72.75943891424686. Arrivals time: 0.4744345215149224 Scheduler time: 72.07723102113232 Scheduler overhead time: 0.07897402253001928 Adapter cache time: 0.01591272046789527 Engine time: 0.0804944415576756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_192_slots_32_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_192_slots_32_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 74.27800777601078,
    "estimated_duration": 3600.081837267243,
    "input_throughput": 6734.104138699989,
    "output_throughput": 5851.29004067034,
    "total_throughput": 12585.394179370329,
    "itl": 97.60098441587779,
    "ttft": 1901332.3030576704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3465538526000422,
    "arrivals": 553841,
    "finished_requests": 97911,
    "scheduler_time": 231.96315927404657
}
#Debug simulation 
Total elapsed time: 74.27818251773715. Arrivals time: 0.45641346694901586 Scheduler time: 73.62336781900376 Scheduler overhead time: 0.07517491932958364 Adapter cache time: 0.015671017579734325 Engine time: 0.07705495320260525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_192_slots_32_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_192_slots_32_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 72.26784865604714,
    "estimated_duration": 3600.0763820298343,
    "input_throughput": 6550.424907013701,
    "output_throughput": 5696.78607442114,
    "total_throughput": 12247.21098143484,
    "itl": 91.49073967925872,
    "ttft": 1917528.1902751448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.471126118754049,
    "arrivals": 553841,
    "finished_requests": 95348,
    "scheduler_time": 238.7818417917113
}
#Debug simulation 
Total elapsed time: 72.26800850592554. Arrivals time: 0.4530479609966278 Scheduler time: 71.60767096607015 Scheduler overhead time: 0.07847137795761228 Adapter cache time: 0.016293028835207224 Engine time: 0.07997804088518023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_192_slots_32_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_192_slots_32_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 72.98583422601223,
    "estimated_duration": 3600.076193247621,
    "input_throughput": 6745.448067334747,
    "output_throughput": 5855.905783200171,
    "total_throughput": 12601.353850534917,
    "itl": 97.62540100643099,
    "ttft": 1904752.5376969576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0747743056854153,
    "arrivals": 553841,
    "finished_requests": 98121,
    "scheduler_time": 231.7589338200554
}
#Debug simulation 
Total elapsed time: 72.9859858630225. Arrivals time: 0.4570686435326934 Scheduler time: 72.3310677986592 Scheduler overhead time: 0.07538755610585213 Adapter cache time: 0.015631675254553556 Engine time: 0.07592969620600343 
