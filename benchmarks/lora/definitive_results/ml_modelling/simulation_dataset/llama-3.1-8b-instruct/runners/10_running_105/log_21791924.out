INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85822682 . Total output tokens: 75577275
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.288518803659827,
    "estimated_duration": 3600.012578448894,
    "input_throughput": 8107.787226836867,
    "output_throughput": 7018.402699827867,
    "total_throughput": 15126.189926664734,
    "itl": 86.99753962742835,
    "ttft": 414809.79146893864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5905381043488647,
    "arrivals": 127929,
    "finished_requests": 117464,
    "scheduler_time": 111.69084675551619
}
#Debug simulation 
Total elapsed time: 8.288659037090838. Arrivals time: 0.270384609233588 Scheduler time: 7.846141909714788 Scheduler overhead time: 0.06358289904892445 Adapter cache time: 0.013719862792640924 Engine time: 0.06556971091777086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85822682 . Total output tokens: 75577275
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.315601172856987,
    "estimated_duration": 3600.095435988192,
    "input_throughput": 8068.3472192527925,
    "output_throughput": 6982.146014443169,
    "total_throughput": 15050.493233695963,
    "itl": 85.86826078683394,
    "ttft": 438207.17638873105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.056160698216414,
    "arrivals": 127929,
    "finished_requests": 116872,
    "scheduler_time": 112.32282585307283
}
#Debug simulation 
Total elapsed time: 8.315706309862435. Arrivals time: 0.27816301118582487 Scheduler time: 7.863200924359262 Scheduler overhead time: 0.06456291722133756 Adapter cache time: 0.013810074422508478 Engine time: 0.06636292859911919 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85822682 . Total output tokens: 75577275
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.115664788056165,
    "estimated_duration": 3600.003822869319,
    "input_throughput": 7987.725128880744,
    "output_throughput": 6912.385993014352,
    "total_throughput": 14900.111121895095,
    "itl": 83.59927702851336,
    "ttft": 485714.3533425619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.275270995227654,
    "arrivals": 127929,
    "finished_requests": 115669,
    "scheduler_time": 113.70545058987274
}
#Debug simulation 
Total elapsed time: 8.11575911520049. Arrivals time: 0.27546620462089777 Scheduler time: 7.66374743077904 Scheduler overhead time: 0.06556157069280744 Adapter cache time: 0.014140720013529062 Engine time: 0.06677421508356929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85822682 . Total output tokens: 75577275
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.219288935884833,
    "estimated_duration": 3600.0365270257944,
    "input_throughput": 8068.912851836702,
    "output_throughput": 6983.044425043378,
    "total_throughput": 15051.95727688008,
    "itl": 85.86460287268379,
    "ttft": 437726.14113071054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7665702210366643,
    "arrivals": 127929,
    "finished_requests": 116884,
    "scheduler_time": 112.30996207137498
}
#Debug simulation 
Total elapsed time: 8.219408615957946. Arrivals time: 0.27272272668778896 Scheduler time: 7.773137184325606 Scheduler overhead time: 0.06437306012958288 Adapter cache time: 0.013852390460669994 Engine time: 0.06589533109217882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85822682 . Total output tokens: 75577275
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.195038496982306,
    "estimated_duration": 3600.0132865369897,
    "input_throughput": 7987.699408648985,
    "output_throughput": 6912.492821363455,
    "total_throughput": 14900.192230012439,
    "itl": 83.59689161475858,
    "ttft": 485595.59756698954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.216399344601703,
    "arrivals": 127929,
    "finished_requests": 115671,
    "scheduler_time": 113.7017950517314
}
#Debug simulation 
Total elapsed time: 8.19515288900584. Arrivals time: 0.26644272077828646 Scheduler time: 7.751189643517137 Scheduler overhead time: 0.06590087059885263 Adapter cache time: 0.014182085637003183 Engine time: 0.06722878850996494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85822682 . Total output tokens: 75577275
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.209204685874283,
    "estimated_duration": 3600.076742106677,
    "input_throughput": 8069.3849273336355,
    "output_throughput": 6983.198915167752,
    "total_throughput": 15052.583842501386,
    "itl": 85.85658580422452,
    "ttft": 437454.595728878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.568611805778912,
    "arrivals": 127929,
    "finished_requests": 116892,
    "scheduler_time": 112.30970554189706
}
#Debug simulation 
Total elapsed time: 8.209324608091265. Arrivals time: 0.2741002291440964 Scheduler time: 7.762063908390701 Scheduler overhead time: 0.06402573874220252 Adapter cache time: 0.0138445352204144 Engine time: 0.06581696076318622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85822682 . Total output tokens: 75577275
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.240474172402173,
    "estimated_duration": 3600.00050225739,
    "input_throughput": 7987.869996675907,
    "output_throughput": 6912.57236891929,
    "total_throughput": 14900.442365595196,
    "itl": 83.59758524978436,
    "ttft": 485549.0505417751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.209715236425434,
    "arrivals": 127929,
    "finished_requests": 115672,
    "scheduler_time": 113.70048594507442
}
#Debug simulation 
Total elapsed time: 8.24065387295559. Arrivals time: 0.2773235449567437 Scheduler time: 7.785368573386222 Scheduler overhead time: 0.06578647997230291 Adapter cache time: 0.014199307654052973 Engine time: 0.06764633860439062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85669836 . Total output tokens: 75449695
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.17892694985494,
    "estimated_duration": 3600.0088061594456,
    "input_throughput": 8027.6561964387665,
    "output_throughput": 7034.967791375538,
    "total_throughput": 15062.623987814304,
    "itl": 87.34810384176832,
    "ttft": 418733.4606547637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7624607391795686,
    "arrivals": 127708,
    "finished_requests": 117164,
    "scheduler_time": 112.08320677623409
}
#Debug simulation 
Total elapsed time: 8.179060196969658. Arrivals time: 0.2753156782127917 Scheduler time: 7.734370896592736 Scheduler overhead time: 0.06247399561107159 Adapter cache time: 0.013514245394617319 Engine time: 0.06447447557002306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85669836 . Total output tokens: 75449695
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.198399716988206,
    "estimated_duration": 3600.084552115847,
    "input_throughput": 7993.47309303806,
    "output_throughput": 7001.253341449,
    "total_throughput": 14994.72643448706,
    "itl": 86.20078752885328,
    "ttft": 440188.9084930021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.257405350930064,
    "arrivals": 127708,
    "finished_requests": 116639,
    "scheduler_time": 112.69615642067981
}
#Debug simulation 
Total elapsed time: 8.198514310177416. Arrivals time: 0.2834890796802938 Scheduler time: 7.742796376347542 Scheduler overhead time: 0.06348391296342015 Adapter cache time: 0.013831374701112509 Engine time: 0.06560841295868158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85669836 . Total output tokens: 75449695
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.106296862941235,
    "estimated_duration": 3600.047055273335,
    "input_throughput": 7915.13765306507,
    "output_throughput": 6935.92100787254,
    "total_throughput": 14851.05866093761,
    "itl": 83.87368636614973,
    "ttft": 486318.0304660746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.4810584009578776,
    "arrivals": 127708,
    "finished_requests": 115479,
    "scheduler_time": 114.07360786605362
}
#Debug simulation 
Total elapsed time: 8.106399370823056. Arrivals time: 0.2881274917162955 Scheduler time: 7.642317097168416 Scheduler overhead time: 0.06492847390472889 Adapter cache time: 0.014173631090670824 Engine time: 0.06685375468805432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85669836 . Total output tokens: 75449695
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.184856622014195,
    "estimated_duration": 3600.0624920529644,
    "input_throughput": 7993.655683346015,
    "output_throughput": 7001.52512786691,
    "total_throughput": 14995.180811212926,
    "itl": 86.19758387628971,
    "ttft": 440116.1101380687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.912295512501142,
    "arrivals": 127708,
    "finished_requests": 116642,
    "scheduler_time": 112.69510181614899
}
#Debug simulation 
Total elapsed time: 8.184949691873044. Arrivals time: 0.27768675051629543 Scheduler time: 7.734503203071654 Scheduler overhead time: 0.06361402478069067 Adapter cache time: 0.013951232191175222 Engine time: 0.065829505212605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85669836 . Total output tokens: 75449695
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.105202625971287,
    "estimated_duration": 3600.09313932774,
    "input_throughput": 7915.282993295315,
    "output_throughput": 6936.220268085326,
    "total_throughput": 14851.50326138064,
    "itl": 83.87343112621873,
    "ttft": 486173.3523680429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.441392289232495,
    "arrivals": 127708,
    "finished_requests": 115484,
    "scheduler_time": 114.06538447896939
}
#Debug simulation 
Total elapsed time: 8.105294205714017. Arrivals time: 0.27465838799253106 Scheduler time: 7.654301915783435 Scheduler overhead time: 0.0649511618539691 Adapter cache time: 0.014328864868730307 Engine time: 0.06709685223177075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85669836 . Total output tokens: 75449695
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.183559900149703,
    "estimated_duration": 3600.055227570188,
    "input_throughput": 7993.947364919673,
    "output_throughput": 7001.681198377829,
    "total_throughput": 14995.628563297501,
    "itl": 86.19391610716868,
    "ttft": 439997.0646261836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7218259083526037,
    "arrivals": 127708,
    "finished_requests": 116644,
    "scheduler_time": 112.69271408477448
}
#Debug simulation 
Total elapsed time: 8.18365900637582. Arrivals time: 0.2743952847085893 Scheduler time: 7.737748680636287 Scheduler overhead time: 0.06326485238969326 Adapter cache time: 0.01378561370074749 Engine time: 0.06501452438533306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85669836 . Total output tokens: 75449695
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.179964635986835,
    "estimated_duration": 3600.0097383795555,
    "input_throughput": 7915.219977384332,
    "output_throughput": 6936.0790149527575,
    "total_throughput": 14851.29899233709,
    "itl": 83.87270140088518,
    "ttft": 486222.14120698924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 587,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.344268160779063,
    "arrivals": 127708,
    "finished_requests": 115480,
    "scheduler_time": 114.06396454472382
}
#Debug simulation 
Total elapsed time: 8.18011144734919. Arrivals time: 0.2694848058745265 Scheduler time: 7.733992002904415 Scheduler overhead time: 0.06496675219386816 Adapter cache time: 0.014222329948097467 Engine time: 0.06734609790146351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85595068 . Total output tokens: 75377246
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.201784471049905,
    "estimated_duration": 3600.0563516900575,
    "input_throughput": 8031.761221300289,
    "output_throughput": 7050.633245805729,
    "total_throughput": 15082.394467106018,
    "itl": 87.00980812761526,
    "ttft": 409433.2751957706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.570700877253014,
    "arrivals": 127594,
    "finished_requests": 117269,
    "scheduler_time": 111.83677827987157
}
#Debug simulation 
Total elapsed time: 8.201899214182049. Arrivals time: 0.27407523710280657 Scheduler time: 7.758057521190494 Scheduler overhead time: 0.06231449544429779 Adapter cache time: 0.013628913089632988 Engine time: 0.06483971327543259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85595068 . Total output tokens: 75377246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.166943737771362,
    "estimated_duration": 3600.0501858407974,
    "input_throughput": 7993.487733360333,
    "output_throughput": 7016.555796735511,
    "total_throughput": 15010.043530095843,
    "itl": 85.85711280684362,
    "ttft": 432687.667540687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.07810785835144,
    "arrivals": 127594,
    "finished_requests": 116676,
    "scheduler_time": 112.44420708713604
}
#Debug simulation 
Total elapsed time: 8.167071966920048. Arrivals time: 0.27467208355665207 Scheduler time: 7.721690746024251 Scheduler overhead time: 0.06302183168008924 Adapter cache time: 0.01375189470127225 Engine time: 0.06472047558054328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85595068 . Total output tokens: 75377246
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.107703960034996,
    "estimated_duration": 3600.059299979205,
    "input_throughput": 7921.2267420608105,
    "output_throughput": 6951.518270864192,
    "total_throughput": 14872.745012925003,
    "itl": 83.50330826214399,
    "ttft": 475899.1931387368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.241746979346536,
    "arrivals": 127594,
    "finished_requests": 115613,
    "scheduler_time": 113.77458651381626
}
#Debug simulation 
Total elapsed time: 8.107813545968384. Arrivals time: 0.2755495379678905 Scheduler time: 7.656922904308885 Scheduler overhead time: 0.06440321495756507 Adapter cache time: 0.014185058418661356 Engine time: 0.06684410898014903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85595068 . Total output tokens: 75377246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.150003045797348,
    "estimated_duration": 3600.032949462209,
    "input_throughput": 7994.618494894452,
    "output_throughput": 7017.879934619529,
    "total_throughput": 15012.49842951398,
    "itl": 85.84970532146143,
    "ttft": 432067.5504524238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.701342790657646,
    "arrivals": 127594,
    "finished_requests": 116694,
    "scheduler_time": 112.43879991452623
}
#Debug simulation 
Total elapsed time: 8.150111958850175. Arrivals time: 0.2777099013328552 Scheduler time: 7.701412416063249 Scheduler overhead time: 0.06287227757275105 Adapter cache time: 0.013777530752122402 Engine time: 0.06516933534294367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85595068 . Total output tokens: 75377246
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.19328784616664,
    "estimated_duration": 3600.009183723915,
    "input_throughput": 7921.523125255175,
    "output_throughput": 6951.927820948393,
    "total_throughput": 14873.450946203568,
    "itl": 83.50362918524495,
    "ttft": 475851.90045993536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.1920373604447025,
    "arrivals": 127594,
    "finished_requests": 115617,
    "scheduler_time": 113.77577570094887
}
#Debug simulation 
Total elapsed time: 8.193406540900469. Arrivals time: 0.28205859707668424 Scheduler time: 7.735495114699006 Scheduler overhead time: 0.06472431123256683 Adapter cache time: 0.014230836648494005 Engine time: 0.0668746973387897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85595068 . Total output tokens: 75377246
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.105701757129282,
    "estimated_duration": 3600.005812165872,
    "input_throughput": 7995.524591301344,
    "output_throughput": 7019.068112225517,
    "total_throughput": 15014.592703526861,
    "itl": 85.84159054853409,
    "ttft": 431581.2185086456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.504772596373207,
    "arrivals": 127594,
    "finished_requests": 116708,
    "scheduler_time": 112.42940653082339
}
#Debug simulation 
Total elapsed time: 8.105802827049047. Arrivals time: 0.2672578669153154 Scheduler time: 7.667607887182385 Scheduler overhead time: 0.06298022158443928 Adapter cache time: 0.013798742555081844 Engine time: 0.0650949222035706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85595068 . Total output tokens: 75377246
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.027423237916082,
    "estimated_duration": 3600.0462082354625,
    "input_throughput": 7921.441378936544,
    "output_throughput": 6951.75938096268,
    "total_throughput": 14873.200759899224,
    "itl": 83.50164548447313,
    "ttft": 475811.5899023155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.170909911915698,
    "arrivals": 127594,
    "finished_requests": 115616,
    "scheduler_time": 113.77163810373807
}
#Debug simulation 
Total elapsed time: 8.027598157059401. Arrivals time: 0.2767494386062026 Scheduler time: 7.576430352870375 Scheduler overhead time: 0.06396800465881824 Adapter cache time: 0.014005064032971859 Engine time: 0.06661359360441566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85336343 . Total output tokens: 75145456
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.22361239278689,
    "estimated_duration": 3600.034548755492,
    "input_throughput": 8138.060511149229,
    "output_throughput": 7107.387069061657,
    "total_throughput": 15245.447580210885,
    "itl": 86.37060899487898,
    "ttft": 340363.5236514791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3657161972625596,
    "arrivals": 127174,
    "finished_requests": 118657,
    "scheduler_time": 109.89257358045408
}
#Debug simulation 
Total elapsed time: 8.223706759978086. Arrivals time: 0.2700130669400096 Scheduler time: 7.784840628039092 Scheduler overhead time: 0.06195207731798291 Adapter cache time: 0.013527045026421547 Engine time: 0.06445827754214406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85336343 . Total output tokens: 75145456
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.220395261887461,
    "estimated_duration": 3600.0129810962085,
    "input_throughput": 8100.452179791922,
    "output_throughput": 7075.577264236334,
    "total_throughput": 15176.029444028256,
    "itl": 85.21104264342922,
    "ttft": 362187.8091441172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7161413365881946,
    "arrivals": 127174,
    "finished_requests": 118117,
    "scheduler_time": 110.45058567081367
}
#Debug simulation 
Total elapsed time: 8.220503942109644. Arrivals time: 0.27212829189375043 Scheduler time: 7.777404140681028 Scheduler overhead time: 0.06271556718274951 Adapter cache time: 0.01370790833607316 Engine time: 0.06516859866678715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85336343 . Total output tokens: 75145456
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.132513707038015,
    "estimated_duration": 3600.0469576771216,
    "input_throughput": 8028.360001906449,
    "output_throughput": 7011.974926095954,
    "total_throughput": 15040.334928002403,
    "itl": 82.88433044946633,
    "ttft": 405568.26073856786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8084256433556187,
    "arrivals": 127174,
    "finished_requests": 117051,
    "scheduler_time": 111.69716261127377
}
#Debug simulation 
Total elapsed time: 8.13264228310436. Arrivals time: 0.2691804156638682 Scheduler time: 7.688400256913155 Scheduler overhead time: 0.0641615018248558 Adapter cache time: 0.013964256271719933 Engine time: 0.0670039439573884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85336343 . Total output tokens: 75145456
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.22993269469589,
    "estimated_duration": 3600.0182162464585,
    "input_throughput": 8101.055674770349,
    "output_throughput": 7075.7980848661655,
    "total_throughput": 15176.853759636515,
    "itl": 85.20500439170087,
    "ttft": 361826.45033381466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4218384902458565,
    "arrivals": 127174,
    "finished_requests": 118126,
    "scheduler_time": 110.44442950083594
}
#Debug simulation 
Total elapsed time: 8.230029077734798. Arrivals time: 0.27373023936524987 Scheduler time: 7.783604764379561 Scheduler overhead time: 0.0627488000318408 Adapter cache time: 0.013782240450382233 Engine time: 0.06674349075183272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85336343 . Total output tokens: 75145456
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.17099303426221,
    "estimated_duration": 3600.057210564221,
    "input_throughput": 8028.454079892296,
    "output_throughput": 7012.027177213572,
    "total_throughput": 15040.481257105868,
    "itl": 82.88507315598328,
    "ttft": 405512.00823375565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7645168019133015,
    "arrivals": 127174,
    "finished_requests": 117053,
    "scheduler_time": 111.69632824898937
}
#Debug simulation 
Total elapsed time: 8.171093970071524. Arrivals time: 0.2733625224791467 Scheduler time: 7.722505904734135 Scheduler overhead time: 0.06426856946200132 Adapter cache time: 0.013975560665130615 Engine time: 0.06680599134415388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85336343 . Total output tokens: 75145456
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.240883293095976,
    "estimated_duration": 3600.0801259519776,
    "input_throughput": 8102.027449260467,
    "output_throughput": 7076.58805045714,
    "total_throughput": 15178.615499717607,
    "itl": 85.20019292754121,
    "ttft": 361407.76077401044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.236647916869246,
    "arrivals": 127174,
    "finished_requests": 118139,
    "scheduler_time": 110.43641810035331
}
#Debug simulation 
Total elapsed time: 8.240983764175326. Arrivals time: 0.2666263277642429 Scheduler time: 7.802384173497558 Scheduler overhead time: 0.06325892684981227 Adapter cache time: 0.01376060163602233 Engine time: 0.06554273981601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85336343 . Total output tokens: 75145456
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.157683521974832,
    "estimated_duration": 3600.0002081133844,
    "input_throughput": 8028.559813652569,
    "output_throughput": 7012.0770946369175,
    "total_throughput": 15040.636908289485,
    "itl": 82.88282296160456,
    "ttft": 405578.87823133054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7301887160912486,
    "arrivals": 127174,
    "finished_requests": 117052,
    "scheduler_time": 111.69318252087078
}
#Debug simulation 
Total elapsed time: 8.157868257723749. Arrivals time: 0.2720304527319968 Scheduler time: 7.710823690518737 Scheduler overhead time: 0.06418271502479911 Adapter cache time: 0.01389679266139865 Engine time: 0.06705181673169136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85274519 . Total output tokens: 75076635
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.278665754012764,
    "estimated_duration": 3600.0351331477086,
    "input_throughput": 8154.321253618593,
    "output_throughput": 7140.864477487096,
    "total_throughput": 15295.185731105688,
    "itl": 85.90622190747841,
    "ttft": 322454.0325533926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6515760218119433,
    "arrivals": 127046,
    "finished_requests": 119014,
    "scheduler_time": 109.73822519816879
}
#Debug simulation 
Total elapsed time: 8.278787886258215. Arrivals time: 0.27204545494168997 Scheduler time: 7.8380049569532275 Scheduler overhead time: 0.06218907469883561 Adapter cache time: 0.012923885602504015 Engine time: 0.06453122152015567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85274519 . Total output tokens: 75076635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.279712539166212,
    "estimated_duration": 3600.081078940371,
    "input_throughput": 8114.475301928015,
    "output_throughput": 7108.450737318483,
    "total_throughput": 15222.926039246498,
    "itl": 84.7690826320652,
    "ttft": 344724.74694260437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.934498106841933,
    "arrivals": 127046,
    "finished_requests": 118454,
    "scheduler_time": 110.27314544812606
}
#Debug simulation 
Total elapsed time: 8.279808222781867. Arrivals time: 0.2960689337924123 Scheduler time: 7.812073532026261 Scheduler overhead time: 0.0632022563368082 Adapter cache time: 0.013077715411782265 Engine time: 0.06597682926803827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85274519 . Total output tokens: 75076635
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.169659553095698,
    "estimated_duration": 3600.041590639434,
    "input_throughput": 8041.394320352299,
    "output_throughput": 7044.39167201276,
    "total_throughput": 15085.785992365058,
    "itl": 82.45877480913919,
    "ttft": 388264.18438902765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.019005315136186,
    "arrivals": 127046,
    "finished_requests": 117391,
    "scheduler_time": 111.4908453138333
}
#Debug simulation 
Total elapsed time: 8.169743268750608. Arrivals time: 0.2643527630716562 Scheduler time: 7.730483328923583 Scheduler overhead time: 0.06432931730523705 Adapter cache time: 0.013269778806716204 Engine time: 0.06720909848809242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85274519 . Total output tokens: 75076635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.246069381944835,
    "estimated_duration": 3600.0842275654245,
    "input_throughput": 8114.948471568527,
    "output_throughput": 7108.7831234734385,
    "total_throughput": 15223.731595041965,
    "itl": 84.76325734238995,
    "ttft": 344572.7137554657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.686006552618923,
    "arrivals": 127046,
    "finished_requests": 118459,
    "scheduler_time": 110.26806358003847
}
#Debug simulation 
Total elapsed time: 8.246198260691017. Arrivals time: 0.2740114745683968 Scheduler time: 7.800570311956108 Scheduler overhead time: 0.06329732993617654 Adapter cache time: 0.013177751563489437 Engine time: 0.06563613936305046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85274519 . Total output tokens: 75076635
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.146564464084804,
    "estimated_duration": 3600.0193815080993,
    "input_throughput": 8041.276707758433,
    "output_throughput": 7044.378185924204,
    "total_throughput": 15085.654893682637,
    "itl": 82.45776599768485,
    "ttft": 388274.51712834794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.973855267148486,
    "arrivals": 127046,
    "finished_requests": 117390,
    "scheduler_time": 111.49331775000326
}
#Debug simulation 
Total elapsed time: 8.146682478953153. Arrivals time: 0.27202271251007915 Scheduler time: 7.700159032829106 Scheduler overhead time: 0.06421086424961686 Adapter cache time: 0.013315366115421057 Engine time: 0.0669686459004879 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85274519 . Total output tokens: 75076635
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.21823481284082,
    "estimated_duration": 3600.0492974513386,
    "input_throughput": 8115.38692558554,
    "output_throughput": 7109.1007054038655,
    "total_throughput": 15224.487630989404,
    "itl": 84.75788061906334,
    "ttft": 344320.7201687732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.547184455287632,
    "arrivals": 127046,
    "finished_requests": 118464,
    "scheduler_time": 110.26323480904654
}
#Debug simulation 
Total elapsed time: 8.218328394927084. Arrivals time: 0.2708316738717258 Scheduler time: 7.777175249531865 Scheduler overhead time: 0.0627351007424295 Adapter cache time: 0.013121410738676786 Engine time: 0.06514285644516349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85274519 . Total output tokens: 75076635
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.16919269086793,
    "estimated_duration": 3600.0900164040117,
    "input_throughput": 8041.118935385891,
    "output_throughput": 7044.239973013509,
    "total_throughput": 15085.3589083994,
    "itl": 82.45796241362136,
    "ttft": 388333.799280867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.961012505684069,
    "arrivals": 127046,
    "finished_requests": 117390,
    "scheduler_time": 111.49647872244873
}
#Debug simulation 
Total elapsed time: 8.169330097734928. Arrivals time: 0.26504967268556356 Scheduler time: 7.729569828603417 Scheduler overhead time: 0.06432586535811424 Adapter cache time: 0.013254466466605663 Engine time: 0.06711086025461555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 85092058 . Total output tokens: 74934019
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.385531948879361,
    "estimated_duration": 3600.07260940629,
    "input_throughput": 8274.762270673426,
    "output_throughput": 7221.023801596933,
    "total_throughput": 15495.786072270359,
    "itl": 84.74474719579176,
    "ttft": 252574.6672328553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.778738029594531,
    "arrivals": 126799,
    "finished_requests": 120371,
    "scheduler_time": 107.53716935394998
}
#Debug simulation 
Total elapsed time: 8.385656400118023. Arrivals time: 0.27261036494746804 Scheduler time: 7.942425089888275 Scheduler overhead time: 0.06326227588579059 Adapter cache time: 0.012234644964337349 Engine time: 0.06573818484321237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 85092058 . Total output tokens: 74934019
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.345065192785114,
    "estimated_duration": 3600.0475817306096,
    "input_throughput": 8234.900880323532,
    "output_throughput": 7188.044716775744,
    "total_throughput": 15422.945597099275,
    "itl": 83.63335204555456,
    "ttft": 276040.7173322367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9854752339841821,
    "arrivals": 126799,
    "finished_requests": 119787,
    "scheduler_time": 108.06968863428891
}
#Debug simulation 
Total elapsed time: 8.34518070705235. Arrivals time: 0.2858890062198043 Scheduler time: 7.887278962414712 Scheduler overhead time: 0.06375353457406163 Adapter cache time: 0.012456465046852827 Engine time: 0.06618851749226451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 85092058 . Total output tokens: 74934019
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.238624417223036,
    "estimated_duration": 3600.0497405814617,
    "input_throughput": 8154.676772676582,
    "output_throughput": 7118.063039834866,
    "total_throughput": 15272.739812511449,
    "itl": 81.3921938596816,
    "ttft": 323534.8335029849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0335824609547917,
    "arrivals": 126799,
    "finished_requests": 118614,
    "scheduler_time": 109.25284462015524
}
#Debug simulation 
Total elapsed time: 8.23871580325067. Arrivals time: 0.2707265466451645 Scheduler time: 7.792325177229941 Scheduler overhead time: 0.06503263907507062 Adapter cache time: 0.012487714644521475 Engine time: 0.06784532964229584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 85092058 . Total output tokens: 74934019
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.329766743816435,
    "estimated_duration": 3600.017415584042,
    "input_throughput": 8235.101828025561,
    "output_throughput": 7188.153837250761,
    "total_throughput": 15423.255665276323,
    "itl": 83.62884012693715,
    "ttft": 275979.587549222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8266608591005173,
    "arrivals": 126799,
    "finished_requests": 119788,
    "scheduler_time": 108.06886492598822
}
#Debug simulation 
Total elapsed time: 8.32986422162503. Arrivals time: 0.2761897905729711 Scheduler time: 7.880361726041883 Scheduler overhead time: 0.06401244038715959 Adapter cache time: 0.012398898601531982 Engine time: 0.06727098347619176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 85092058 . Total output tokens: 74934019
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.200049452949315,
    "estimated_duration": 3600.056229880781,
    "input_throughput": 8154.449854515791,
    "output_throughput": 7118.049098041062,
    "total_throughput": 15272.498952556853,
    "itl": 81.39288829987778,
    "ttft": 323608.0169715162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.001066560740589,
    "arrivals": 126799,
    "finished_requests": 118612,
    "scheduler_time": 109.25330880416669
}
#Debug simulation 
Total elapsed time: 8.200163891073316. Arrivals time: 0.2677504983730614 Scheduler time: 7.757145315408707 Scheduler overhead time: 0.06492915842682123 Adapter cache time: 0.012459087185561657 Engine time: 0.06758877355605364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 85092058 . Total output tokens: 74934019
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.373782553244382,
    "estimated_duration": 3600.0210740476614,
    "input_throughput": 8235.451790471237,
    "output_throughput": 7188.6693071223335,
    "total_throughput": 15424.12109759357,
    "itl": 83.62698674869578,
    "ttft": 275699.6268154489,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.736426495835179,
    "arrivals": 126799,
    "finished_requests": 119796,
    "scheduler_time": 108.06382263344348
}
#Debug simulation 
Total elapsed time: 8.373902721330523. Arrivals time: 0.2728781783953309 Scheduler time: 7.928329697810113 Scheduler overhead time: 0.06380949914455414 Adapter cache time: 0.012365819420665503 Engine time: 0.06665384583175182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 85092058 . Total output tokens: 74934019
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.285094438120723,
    "estimated_duration": 3600.087001020151,
    "input_throughput": 8154.592372817958,
    "output_throughput": 7117.989368795414,
    "total_throughput": 15272.581741613372,
    "itl": 81.39154859849761,
    "ttft": 323534.40796259814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9876039442606332,
    "arrivals": 126799,
    "finished_requests": 118614,
    "scheduler_time": 109.25212563390295
}
#Debug simulation 
Total elapsed time: 8.285272561945021. Arrivals time: 0.27571800956502557 Scheduler time: 7.832059453707188 Scheduler overhead time: 0.06514585809782147 Adapter cache time: 0.012539432849735022 Engine time: 0.06928529031574726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73276919 . Total output tokens: 64428052
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 100.37844704091549,
    "estimated_duration": 3600.017370970779,
    "input_throughput": 6526.454619207644,
    "output_throughput": 5659.237970428495,
    "total_throughput": 12185.692589636139,
    "itl": 68.0874419659971,
    "ttft": 819621.2459478404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.390132132885046,
    "arrivals": 109373,
    "finished_requests": 94780,
    "scheduler_time": 127.53793416372318
}
#Debug simulation 
Total elapsed time: 100.37861706689. Arrivals time: 0.3643596745096147 Scheduler time: 99.72399161336944 Scheduler overhead time: 0.11642571445554495 Adapter cache time: 0.01863225968554616 Engine time: 0.1114775356836617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73276919 . Total output tokens: 64428052
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 100.52491823397577,
    "estimated_duration": 3600.008409373522,
    "input_throughput": 6516.906721360325,
    "output_throughput": 5650.667355952099,
    "total_throughput": 12167.574077312423,
    "itl": 67.45016107739092,
    "ttft": 824907.4537624161,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43356839539948827,
    "arrivals": 109373,
    "finished_requests": 94644,
    "scheduler_time": 127.69800646719779
}
#Debug simulation 
Total elapsed time: 100.52509640995413. Arrivals time: 0.36264333315193653 Scheduler time: 99.87306652730331 Scheduler overhead time: 0.1167531544342637 Adapter cache time: 0.018651175312697887 Engine time: 0.11083309724926949 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73276919 . Total output tokens: 64428052
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 102.64738158974797,
    "estimated_duration": 3600.060158274967,
    "input_throughput": 6416.312501585627,
    "output_throughput": 5565.318944447961,
    "total_throughput": 11981.631446033589,
    "itl": 65.50589967522724,
    "ttft": 881459.8403282992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 60,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4520970809226856,
    "arrivals": 109373,
    "finished_requests": 93178,
    "scheduler_time": 129.29236292932202
}
#Debug simulation 
Total elapsed time: 102.64754635374993. Arrivals time: 0.36395460832864046 Scheduler time: 101.98657827824354 Scheduler overhead time: 0.12027954682707787 Adapter cache time: 0.019258281216025352 Engine time: 0.11241821572184563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73276919 . Total output tokens: 64428052
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 99.92858399637043,
    "estimated_duration": 3600.063394506813,
    "input_throughput": 6515.657206423566,
    "output_throughput": 5649.169964904492,
    "total_throughput": 12164.827171328057,
    "itl": 67.47414263543202,
    "ttft": 825771.8674023685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4058039759332315,
    "arrivals": 109373,
    "finished_requests": 94620,
    "scheduler_time": 127.67398579562754
}
#Debug simulation 
Total elapsed time: 99.92874830029905. Arrivals time: 0.35712373489513993 Scheduler time: 99.27769286790863 Scheduler overhead time: 0.11974070547148585 Adapter cache time: 0.018373677507042885 Engine time: 0.11240236414596438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73276919 . Total output tokens: 64428052
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 99.7174038561061,
    "estimated_duration": 3600.0920288150855,
    "input_throughput": 6468.284925389634,
    "output_throughput": 5609.308828320855,
    "total_throughput": 12077.59375371049,
    "itl": 66.05505623313162,
    "ttft": 852245.0017370124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.441587470411323,
    "arrivals": 109373,
    "finished_requests": 93938,
    "scheduler_time": 128.4223834397233
}
#Debug simulation 
Total elapsed time: 99.7175656198524. Arrivals time: 0.3577937437221408 Scheduler time: 99.06497088307515 Scheduler overhead time: 0.1198469907976687 Adapter cache time: 0.018845522310584784 Engine time: 0.11226420104503632 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73276919 . Total output tokens: 64428052
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 99.2113445722498,
    "estimated_duration": 3600.0573342359235,
    "input_throughput": 6517.059541491867,
    "output_throughput": 5650.961946226273,
    "total_throughput": 12168.021487718139,
    "itl": 67.45272801222032,
    "ttft": 824800.0050978328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.37665133549366175,
    "arrivals": 109373,
    "finished_requests": 94648,
    "scheduler_time": 127.69980884176115
}
#Debug simulation 
Total elapsed time: 99.21152080409229. Arrivals time: 0.3438834701664746 Scheduler time: 98.58071483066306 Scheduler overhead time: 0.11758340895175934 Adapter cache time: 0.018000897951424122 Engine time: 0.10829137172549963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73276919 . Total output tokens: 64428052
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 99.22727549215779,
    "estimated_duration": 3600.070748600708,
    "input_throughput": 6468.171496088197,
    "output_throughput": 5609.165877600839,
    "total_throughput": 12077.337373689037,
    "itl": 66.05223676691764,
    "ttft": 852297.7414306313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4372380097024143,
    "arrivals": 109373,
    "finished_requests": 93936,
    "scheduler_time": 128.42159872762429
}
#Debug simulation 
Total elapsed time: 99.2275212132372. Arrivals time: 0.3402562979608774 Scheduler time: 98.60185521701351 Scheduler overhead time: 0.11600427236407995 Adapter cache time: 0.018307534512132406 Engine time: 0.10759067488834262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66096526 . Total output tokens: 58014848
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 54.863629086874425,
    "estimated_duration": 3600.0136632839335,
    "input_throughput": 6374.5460841019185,
    "output_throughput": 5521.292933613046,
    "total_throughput": 11895.839017714965,
    "itl": 66.15480433907038,
    "ttft": 368497.2696584169,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.667853312226943,
    "arrivals": 98647,
    "finished_requests": 92530,
    "scheduler_time": 94.74471317486946
}
#Debug simulation 
Total elapsed time: 54.86379707604647. Arrivals time: 0.287783307954669 Scheduler time: 54.3116356334649 Scheduler overhead time: 0.10674415063112974 Adapter cache time: 0.016962995752692223 Engine time: 0.09886221261695027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66096526 . Total output tokens: 58014848
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 89.54787596594542,
    "estimated_duration": 3600.011982202614,
    "input_throughput": 5951.223525342755,
    "output_throughput": 5167.970298981326,
    "total_throughput": 11119.193824324082,
    "itl": 59.151286399822936,
    "ttft": 554375.1579664588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48380872587673346,
    "arrivals": 98647,
    "finished_requests": 86531,
    "scheduler_time": 99.75434944483278
}
#Debug simulation 
Total elapsed time: 89.54805727908388. Arrivals time: 0.31693142047151923 Scheduler time: 88.92280035698786 Scheduler overhead time: 0.1268059564754367 Adapter cache time: 0.018974135629832745 Engine time: 0.11618913197889924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66096526 . Total output tokens: 58014848
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 54.205990416929126,
    "estimated_duration": 3600.0377903846984,
    "input_throughput": 6362.048215486241,
    "output_throughput": 5516.528202299177,
    "total_throughput": 11878.576417785418,
    "itl": 64.89963341293819,
    "ttft": 375524.3598190115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 98,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7401909987814725,
    "arrivals": 98647,
    "finished_requests": 92403,
    "scheduler_time": 95.13881716046312
}
#Debug simulation 
Total elapsed time: 54.20615518465638. Arrivals time: 0.2885404056869447 Scheduler time: 53.64759582420811 Scheduler overhead time: 0.1097848261706531 Adapter cache time: 0.017156819812953472 Engine time: 0.1004160544835031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66096526 . Total output tokens: 58014848
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 84.82937913388014,
    "estimated_duration": 3600.0279836483946,
    "input_throughput": 5880.475400789997,
    "output_throughput": 5099.719247569351,
    "total_throughput": 10980.19464835935,
    "itl": 59.01751848724448,
    "ttft": 624505.3164847181,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 80,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5440309786051515,
    "arrivals": 98647,
    "finished_requests": 85354,
    "scheduler_time": 101.51680284227416
}
#Debug simulation 
Total elapsed time: 84.8295374349691. Arrivals time: 0.31551576079800725 Scheduler time: 84.20354994107038 Scheduler overhead time: 0.12684882199391723 Adapter cache time: 0.019508905243128538 Engine time: 0.11718680243939161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66096526 . Total output tokens: 58014848
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 53.73161126719788,
    "estimated_duration": 3600.0329399678467,
    "input_throughput": 6367.11229653491,
    "output_throughput": 5523.834456964055,
    "total_throughput": 11890.946753498965,
    "itl": 64.94182578895251,
    "ttft": 371956.9636191342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 99,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7391020474024118,
    "arrivals": 98647,
    "finished_requests": 92504,
    "scheduler_time": 95.14547088166533
}
#Debug simulation 
Total elapsed time: 53.7317615672946. Arrivals time: 0.28577741188928485 Scheduler time: 53.17891973303631 Scheduler overhead time: 0.10858048312366009 Adapter cache time: 0.016645724419504404 Engine time: 0.09938654815778136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66096526 . Total output tokens: 58014848
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 97.77570511773229,
    "estimated_duration": 3600.0764503870305,
    "input_throughput": 5875.965772261815,
    "output_throughput": 5080.855990720295,
    "total_throughput": 10956.82176298211,
    "itl": 58.67632261884161,
    "ttft": 603858.6567041178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 70,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.44687446583993784,
    "arrivals": 98647,
    "finished_requests": 85426,
    "scheduler_time": 101.71674102188432
}
#Debug simulation 
Total elapsed time: 97.77585754171014. Arrivals time: 0.32506929244846106 Scheduler time: 97.1347183054313 Scheduler overhead time: 0.13112461753189564 Adapter cache time: 0.019791211001574993 Engine time: 0.11799753131344914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66096526 . Total output tokens: 58014848
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 53.850703922100365,
    "estimated_duration": 3600.0253145909596,
    "input_throughput": 6362.0702629982325,
    "output_throughput": 5516.5473196836365,
    "total_throughput": 11878.617582681869,
    "itl": 64.90593932841209,
    "ttft": 375473.08546662546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 98,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7261070307716728,
    "arrivals": 98647,
    "finished_requests": 92403,
    "scheduler_time": 95.14217748671754
}
#Debug simulation 
Total elapsed time: 53.8509302791208. Arrivals time: 0.2863364890217781 Scheduler time: 53.295270330738276 Scheduler overhead time: 0.10899760434404016 Adapter cache time: 0.016715914476662874 Engine time: 0.10096663981676102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64870906 . Total output tokens: 56951984
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 102.72733638668433,
    "estimated_duration": 3600.015551224579,
    "input_throughput": 6068.533785241178,
    "output_throughput": 5248.200940013485,
    "total_throughput": 11316.734725254662,
    "itl": 60.92693741683389,
    "ttft": 613148.1902109062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 53,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.35045767869334643,
    "arrivals": 96919,
    "finished_requests": 88016,
    "scheduler_time": 110.16701913787163
}
#Debug simulation 
Total elapsed time: 102.72749032592401. Arrivals time: 0.3224418554455042 Scheduler time: 102.0987963154912 Scheduler overhead time: 0.12669998733326793 Adapter cache time: 0.019464778248220682 Engine time: 0.11472913017496467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64870906 . Total output tokens: 56951984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 77.84672342473641,
    "estimated_duration": 3600.018838794893,
    "input_throughput": 6196.475073854729,
    "output_throughput": 5390.15762664612,
    "total_throughput": 11586.63270050085,
    "itl": 62.446875345540114,
    "ttft": 439264.71283368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 61,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4477244582539423,
    "arrivals": 96919,
    "finished_requests": 90019,
    "scheduler_time": 100.38177843657651
}
#Debug simulation 
Total elapsed time: 77.8468781649135. Arrivals time: 0.304311232175678 Scheduler time: 77.25408367812634 Scheduler overhead time: 0.11892305826768279 Adapter cache time: 0.018078503664582968 Engine time: 0.10713593987748027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64870906 . Total output tokens: 56951984
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 77.70396815426648,
    "estimated_duration": 3600.0318547570478,
    "input_throughput": 6205.308425391028,
    "output_throughput": 5373.10412252044,
    "total_throughput": 11578.412547911468,
    "itl": 62.018352779593876,
    "ttft": 465774.8733126054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5710614165337757,
    "arrivals": 96919,
    "finished_requests": 90115,
    "scheduler_time": 101.3957586394236
}
#Debug simulation 
Total elapsed time: 77.70409603230655. Arrivals time: 0.3062855969183147 Scheduler time: 77.10564995370805 Scheduler overhead time: 0.119538479950279 Adapter cache time: 0.01874064514413476 Engine time: 0.10988835757598281 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64870906 . Total output tokens: 56951984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 81.99978586332873,
    "estimated_duration": 3600.0033563871084,
    "input_throughput": 6113.875410963164,
    "output_throughput": 5318.2875416022935,
    "total_throughput": 11432.162952565457,
    "itl": 61.28679957090812,
    "ttft": 477272.79695976054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 56,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38387577116489424,
    "arrivals": 96919,
    "finished_requests": 88822,
    "scheduler_time": 100.50153009573734
}
#Debug simulation 
Total elapsed time: 81.99992256611586. Arrivals time: 0.31167369754984975 Scheduler time: 81.38710338110104 Scheduler overhead time: 0.12466588616371155 Adapter cache time: 0.0185456071048975 Engine time: 0.11261886917054653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64870906 . Total output tokens: 56951984
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 77.74989447603002,
    "estimated_duration": 3600.0515233746514,
    "input_throughput": 6205.228968239742,
    "output_throughput": 5373.078378019361,
    "total_throughput": 11578.307346259102,
    "itl": 62.019104892285334,
    "ttft": 465776.6789231831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5652621355885641,
    "arrivals": 96919,
    "finished_requests": 90116,
    "scheduler_time": 101.39651061731281
}
#Debug simulation 
Total elapsed time: 77.75002295617014. Arrivals time: 0.30736804055050015 Scheduler time: 77.14990122197196 Scheduler overhead time: 0.12129652267321944 Adapter cache time: 0.018395057879388332 Engine time: 0.10864999843761325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64870906 . Total output tokens: 56951984
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 80.60193280922249,
    "estimated_duration": 3600.0167332039714,
    "input_throughput": 6140.450347386628,
    "output_throughput": 5340.529898839969,
    "total_throughput": 11480.980246226596,
    "itl": 61.65184924762433,
    "ttft": 465189.0745185852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.37665133549366175,
    "arrivals": 96919,
    "finished_requests": 89207,
    "scheduler_time": 100.30999857260383
}
#Debug simulation 
Total elapsed time: 80.6020681289956. Arrivals time: 0.30623924266546965 Scheduler time: 80.00196408946067 Scheduler overhead time: 0.12072482332587242 Adapter cache time: 0.01794406957924366 Engine time: 0.1102331425063312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64870906 . Total output tokens: 56951984
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 102.70959158893675,
    "estimated_duration": 3600.0773844239743,
    "input_throughput": 6038.074651964207,
    "output_throughput": 5224.887409749296,
    "total_throughput": 11262.962061713502,
    "itl": 59.40701621495245,
    "ttft": 633176.5017834512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 52,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38816207319498064,
    "arrivals": 96919,
    "finished_requests": 87576,
    "scheduler_time": 110.36832010289983
}
#Debug simulation 
Total elapsed time: 102.70975458901376. Arrivals time: 0.31954568484798074 Scheduler time: 102.07896556798369 Scheduler overhead time: 0.12834720220416784 Adapter cache time: 0.01897514797747135 Engine time: 0.11732645845040679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64282371 . Total output tokens: 56405100
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 101.7401294959709,
    "estimated_duration": 3600.0357197573667,
    "input_throughput": 5765.953067098738,
    "output_throughput": 5063.91225507859,
    "total_throughput": 10829.865322177327,
    "itl": 57.613743465618356,
    "ttft": 621852.6194723565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 50,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.33062045159749665,
    "arrivals": 96050,
    "finished_requests": 84036,
    "scheduler_time": 103.33420369837496
}
#Debug simulation 
Total elapsed time: 101.74028041306883. Arrivals time: 0.32660778099671006 Scheduler time: 101.08607121603563 Scheduler overhead time: 0.13584095379337668 Adapter cache time: 0.021301815286278725 Engine time: 0.12175936764106154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64282371 . Total output tokens: 56405100
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 100.91798488190398,
    "estimated_duration": 3600.0194538681653,
    "input_throughput": 5765.799675803678,
    "output_throughput": 5063.936801900294,
    "total_throughput": 10829.736477703971,
    "itl": 57.31643781683866,
    "ttft": 622748.4496436827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 49,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.35862341820728016,
    "arrivals": 96050,
    "finished_requests": 84031,
    "scheduler_time": 103.42587960460361
}
#Debug simulation 
Total elapsed time: 100.91812280192971. Arrivals time: 0.3264576434157789 Scheduler time: 100.2651976714842 Scheduler overhead time: 0.13559758057817817 Adapter cache time: 0.020893242675811052 Engine time: 0.12101879063993692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64282371 . Total output tokens: 56405100
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 100.76118354080245,
    "estimated_duration": 3600.036128392623,
    "input_throughput": 5766.109077707592,
    "output_throughput": 5063.983346228175,
    "total_throughput": 10830.092423935768,
    "itl": 56.775339153725454,
    "ttft": 623868.0827477083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 50,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3781715727644042,
    "arrivals": 96050,
    "finished_requests": 84036,
    "scheduler_time": 103.58402443191379
}
#Debug simulation 
Total elapsed time: 100.76132775098085. Arrivals time: 0.3270368450321257 Scheduler time: 100.11349645536393 Scheduler overhead time: 0.13379829237237573 Adapter cache time: 0.02022525668144226 Engine time: 0.1192880179733038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64282371 . Total output tokens: 56405100
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 76.16353641776368,
    "estimated_duration": 3600.081250930074,
    "input_throughput": 6255.650478494556,
    "output_throughput": 5478.801900624968,
    "total_throughput": 11734.452379119524,
    "itl": 64.54700168233917,
    "ttft": 409388.6049635386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5226599577628078,
    "arrivals": 96050,
    "finished_requests": 91266,
    "scheduler_time": 103.23140726054129
}
#Debug simulation 
Total elapsed time: 76.16367353964597. Arrivals time: 0.30105095403268933 Scheduler time: 75.57662485120818 Scheduler overhead time: 0.11648504296317697 Adapter cache time: 0.01864977553486824 Engine time: 0.10701698577031493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64282371 . Total output tokens: 56405100
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 100.50588349997997,
    "estimated_duration": 3600.0149678099338,
    "input_throughput": 5766.142970407769,
    "output_throughput": 5064.013111892844,
    "total_throughput": 10830.156082300613,
    "itl": 56.77510357648743,
    "ttft": 623867.221813561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 50,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3740292292321102,
    "arrivals": 96050,
    "finished_requests": 84036,
    "scheduler_time": 103.58302743621647
}
#Debug simulation 
Total elapsed time: 100.5060272961855. Arrivals time: 0.32452050503343344 Scheduler time: 99.85928344121203 Scheduler overhead time: 0.13503438932821155 Adapter cache time: 0.019950682763010263 Engine time: 0.11958153871819377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64282371 . Total output tokens: 56405100
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 101.37829525675625,
    "estimated_duration": 3600.017333680939,
    "input_throughput": 5765.803071502556,
    "output_throughput": 5063.939784245413,
    "total_throughput": 10829.742855747969,
    "itl": 57.31602531089967,
    "ttft": 622745.8487605847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 49,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3128121260879562,
    "arrivals": 96050,
    "finished_requests": 84031,
    "scheduler_time": 103.42630425184142
}
#Debug simulation 
Total elapsed time: 101.37843935657293. Arrivals time: 0.32387347100302577 Scheduler time: 100.73172415792942 Scheduler overhead time: 0.1337816589511931 Adapter cache time: 0.020715102087706327 Engine time: 0.12025256734341383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64282371 . Total output tokens: 56405100
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 101.71286968328059,
    "estimated_duration": 3600.013011932655,
    "input_throughput": 5766.146103137563,
    "output_throughput": 5064.015863157396,
    "total_throughput": 10830.16196629496,
    "itl": 56.77516220882587,
    "ttft": 623866.9948266435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 50,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.37092247158288966,
    "arrivals": 96050,
    "finished_requests": 84036,
    "scheduler_time": 103.58298454596972
}
#Debug simulation 
Total elapsed time: 101.71307908836752. Arrivals time: 0.32273167138919234 Scheduler time: 101.069078898523 Scheduler overhead time: 0.13381946831941605 Adapter cache time: 0.02011009817942977 Engine time: 0.11939481273293495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63989941 . Total output tokens: 56147875
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 173.19531227694824,
    "estimated_duration": 3600.0340261461397,
    "input_throughput": 5309.510927168129,
    "output_throughput": 4701.456952094078,
    "total_throughput": 10010.967879262205,
    "itl": 45.03768933011261,
    "ttft": 678025.7670926243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12563577160704884,
    "arrivals": 95612,
    "finished_requests": 77606,
    "scheduler_time": 113.45632278842271
}
#Debug simulation 
Total elapsed time: 173.1954614999704. Arrivals time: 0.3610176984220743 Scheduler time: 172.45981948263943 Scheduler overhead time: 0.15640671737492085 Adapter cache time: 0.02411298779770732 Engine time: 0.14028125768527389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63989941 . Total output tokens: 56147875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 172.56229649297893,
    "estimated_duration": 3600.0191037468526,
    "input_throughput": 5309.532935563026,
    "output_throughput": 4701.476440051182,
    "total_throughput": 10011.009375614209,
    "itl": 45.03754962650451,
    "ttft": 678025.6619148297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14211781247053293,
    "arrivals": 95612,
    "finished_requests": 77606,
    "scheduler_time": 113.45572365163198
}
#Debug simulation 
Total elapsed time: 172.5624425536953. Arrivals time: 0.3606325117871165 Scheduler time: 171.82923663873225 Scheduler overhead time: 0.15662070084363222 Adapter cache time: 0.023619615007191896 Engine time: 0.13877203688025475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63989941 . Total output tokens: 56147875
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 175.28122805897146,
    "estimated_duration": 3600.030987662624,
    "input_throughput": 5309.5154084799515,
    "output_throughput": 4701.460920198657,
    "total_throughput": 10010.97632867861,
    "itl": 45.03780680402472,
    "ttft": 678025.744313393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1466101685212925,
    "arrivals": 95612,
    "finished_requests": 77606,
    "scheduler_time": 113.45627831658058
}
#Debug simulation 
Total elapsed time: 175.28137702075765. Arrivals time: 0.361636848654598 Scheduler time: 174.54875938920304 Scheduler overhead time: 0.1554421386681497 Adapter cache time: 0.02409716323018074 Engine time: 0.13845219695940614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63989941 . Total output tokens: 56147875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 173.57688400615007,
    "estimated_duration": 3600.0520032091413,
    "input_throughput": 5309.638022717622,
    "output_throughput": 4701.523196029431,
    "total_throughput": 10011.161218747055,
    "itl": 45.03781174041124,
    "ttft": 677988.1535857865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13378848663065582,
    "arrivals": 95612,
    "finished_requests": 77607,
    "scheduler_time": 113.4572196913494
}
#Debug simulation 
Total elapsed time: 173.57703300286084. Arrivals time: 0.36104739690199494 Scheduler time: 172.84499986516312 Scheduler overhead time: 0.1552818357013166 Adapter cache time: 0.02428255509585142 Engine time: 0.13827994745224714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63989941 . Total output tokens: 56147875
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 172.19504985399544,
    "estimated_duration": 3600.026050174086,
    "input_throughput": 5309.522690558221,
    "output_throughput": 4701.467368321277,
    "total_throughput": 10010.990058879499,
    "itl": 45.03758619974345,
    "ttft": 678025.6939957046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14536746546160428,
    "arrivals": 95612,
    "finished_requests": 77606,
    "scheduler_time": 113.45603877547204
}
#Debug simulation 
Total elapsed time: 172.1952022430487. Arrivals time: 0.36045359121635556 Scheduler time: 171.4584668870084 Scheduler overhead time: 0.15743645932525396 Adapter cache time: 0.023302933666855097 Engine time: 0.14112519519403577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63989941 . Total output tokens: 56147875
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 173.8409070079215,
    "estimated_duration": 3600.023869293631,
    "input_throughput": 5309.525907046412,
    "output_throughput": 4701.4702164519185,
    "total_throughput": 10010.996123498331,
    "itl": 45.037533530068224,
    "ttft": 678025.6919658311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12129449787084019,
    "arrivals": 95612,
    "finished_requests": 77606,
    "scheduler_time": 113.45584554480872
}
#Debug simulation 
Total elapsed time: 173.84106151433662. Arrivals time: 0.3638074304908514 Scheduler time: 173.1013914020732 Scheduler overhead time: 0.15695909224450588 Adapter cache time: 0.02438295865431428 Engine time: 0.1404141839593649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63989941 . Total output tokens: 56147875
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 172.63839634601027,
    "estimated_duration": 3600.021449989909,
    "input_throughput": 5309.529475179538,
    "output_throughput": 4701.473375956536,
    "total_throughput": 10011.002851136074,
    "itl": 45.037571608734915,
    "ttft": 678025.6879812406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14350341087207197,
    "arrivals": 95612,
    "finished_requests": 77606,
    "scheduler_time": 113.45583092642828
}
#Debug simulation 
Total elapsed time: 172.63862898526713. Arrivals time: 0.35898339841514826 Scheduler time: 171.91032595280558 Scheduler overhead time: 0.15444217855110765 Adapter cache time: 0.023406744934618473 Engine time: 0.138830638024956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63828119 . Total output tokens: 56011401
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 53.33343526115641,
    "estimated_duration": 3600.015050689338,
    "input_throughput": 6058.38133810683,
    "output_throughput": 5334.06242185655,
    "total_throughput": 11392.44375996338,
    "itl": 63.52849529883156,
    "ttft": 382859.3857716024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7538146296422921,
    "arrivals": 95376,
    "finished_requests": 88528,
    "scheduler_time": 89.8260484605255
}
#Debug simulation 
Total elapsed time: 53.33357068197802. Arrivals time: 0.2743518673814833 Scheduler time: 52.78805205738172 Scheduler overhead time: 0.11084365285933018 Adapter cache time: 0.017120403703302145 Engine time: 0.0999819878488779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63828119 . Total output tokens: 56011401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 56.187260726932436,
    "estimated_duration": 3600.037600963646,
    "input_throughput": 6133.706490757007,
    "output_throughput": 5376.954672589674,
    "total_throughput": 11510.661163346682,
    "itl": 63.996162810690095,
    "ttft": 386441.80820797314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 116,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8349338552914557,
    "arrivals": 95376,
    "finished_requests": 89611,
    "scheduler_time": 93.41163898144714
}
#Debug simulation 
Total elapsed time: 56.187398676760495. Arrivals time: 0.27924786461517215 Scheduler time: 55.63346960069612 Scheduler overhead time: 0.11109653627499938 Adapter cache time: 0.017034500371664762 Engine time: 0.10290631465613842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63828119 . Total output tokens: 56011401
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 53.03065027529374,
    "estimated_duration": 3600.017188024565,
    "input_throughput": 6037.147287045591,
    "output_throughput": 5315.672953911858,
    "total_throughput": 11352.82024095745,
    "itl": 62.2154540310295,
    "ttft": 398119.1951228856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9291952711623165,
    "arrivals": 95376,
    "finished_requests": 88181,
    "scheduler_time": 90.3676545958857
}
#Debug simulation 
Total elapsed time: 53.03078649332747. Arrivals time: 0.2751351296901703 Scheduler time: 52.480875726789236 Scheduler overhead time: 0.11195581872016191 Adapter cache time: 0.01765209110453725 Engine time: 0.10180593840777874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63828119 . Total output tokens: 56011401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 54.93628754187375,
    "estimated_duration": 3600.0620686222205,
    "input_throughput": 6166.792565467206,
    "output_throughput": 5404.550985268506,
    "total_throughput": 11571.343550735714,
    "itl": 63.78731181915408,
    "ttft": 362221.9403541429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 102,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7011358909774568,
    "arrivals": 95376,
    "finished_requests": 90087,
    "scheduler_time": 92.8069908775076
}
#Debug simulation 
Total elapsed time: 54.93641470372677. Arrivals time: 0.2649659323506057 Scheduler time: 54.40058410447091 Scheduler overhead time: 0.11041009752079844 Adapter cache time: 0.017503668554127216 Engine time: 0.10013457806780934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63828119 . Total output tokens: 56011401
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 50.62373090907931,
    "estimated_duration": 3600.018122661361,
    "input_throughput": 6206.384867719102,
    "output_throughput": 5461.8280603165695,
    "total_throughput": 11668.212928035671,
    "itl": 64.37605369425384,
    "ttft": 327452.9416100713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 123,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.900046252519824,
    "arrivals": 95376,
    "finished_requests": 90639,
    "scheduler_time": 92.29896930196406
}
#Debug simulation 
Total elapsed time: 50.623859520070255. Arrivals time: 0.2613550713285804 Scheduler time: 50.09842116152868 Scheduler overhead time: 0.10688253818079829 Adapter cache time: 0.01705755339935422 Engine time: 0.0977468523196876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63828119 . Total output tokens: 56011401
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 70.60814742697403,
    "estimated_duration": 3600.001693761021,
    "input_throughput": 5895.788059428888,
    "output_throughput": 5191.050613222448,
    "total_throughput": 11086.838672651336,
    "itl": 60.368121214894906,
    "ttft": 464968.44547550316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 84,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5362493590079253,
    "arrivals": 95376,
    "finished_requests": 86104,
    "scheduler_time": 93.45154921683847
}
#Debug simulation 
Total elapsed time: 70.60838292306289. Arrivals time: 0.280238376930356 Scheduler time: 70.03131648758426 Scheduler overhead time: 0.12119773682206869 Adapter cache time: 0.018413979560136795 Engine time: 0.11143815889954567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63828119 . Total output tokens: 56011401
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 50.10788641683757,
    "estimated_duration": 3599.998193708482,
    "input_throughput": 6206.3539473568035,
    "output_throughput": 5461.765518205758,
    "total_throughput": 11668.11946556256,
    "itl": 64.37587354744007,
    "ttft": 327487.36389376846,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 123,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8927971513383094,
    "arrivals": 95376,
    "finished_requests": 90638,
    "scheduler_time": 92.29804436611543
}
#Debug simulation 
Total elapsed time: 50.108048339840025. Arrivals time: 0.25864031352102757 Scheduler time: 49.583129630889744 Scheduler overhead time: 0.10818245634436607 Adapter cache time: 0.016458344645798206 Engine time: 0.09891696739941835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63748350 . Total output tokens: 55952342
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 64.41842808993533,
    "estimated_duration": 3600.0036210927824,
    "input_throughput": 6318.674477637071,
    "output_throughput": 5460.640896253518,
    "total_throughput": 11779.315373890588,
    "itl": 62.70529464037052,
    "ttft": 316566.64505305164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 74,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48931826836429493,
    "arrivals": 95267,
    "finished_requests": 91494,
    "scheduler_time": 95.37564855997972
}
#Debug simulation 
Total elapsed time: 64.41854874510318. Arrivals time: 0.27689469140022993 Scheduler time: 63.859581062570214 Scheduler overhead time: 0.11538653448224068 Adapter cache time: 0.01798466546460986 Engine time: 0.10450597573071718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63748350 . Total output tokens: 55952342
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 63.97871716786176,
    "estimated_duration": 3600.0064171875483,
    "input_throughput": 6319.614568291134,
    "output_throughput": 5458.392770130523,
    "total_throughput": 11778.007338421656,
    "itl": 62.231179369549196,
    "ttft": 316371.7773312941,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 73,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5354372773272915,
    "arrivals": 95267,
    "finished_requests": 91508,
    "scheduler_time": 95.42525668466648
}
#Debug simulation 
Total elapsed time: 63.978846753016114. Arrivals time: 0.27336572064086795 Scheduler time: 63.42561356956139 Scheduler overhead time: 0.11344953998923302 Adapter cache time: 0.01751816738396883 Engine time: 0.10495405690744519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63748350 . Total output tokens: 55952342
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 64.00715689826757,
    "estimated_duration": 3600.014696597306,
    "input_throughput": 6291.303483123939,
    "output_throughput": 5435.840031013346,
    "total_throughput": 11727.143514137284,
    "itl": 61.157818334431305,
    "ttft": 335414.7748970912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5727702229283751,
    "arrivals": 95267,
    "finished_requests": 91025,
    "scheduler_time": 95.3958156905906
}
#Debug simulation 
Total elapsed time: 64.00727901095524. Arrivals time: 0.27393256733193994 Scheduler time: 63.45136876311153 Scheduler overhead time: 0.11616576835513115 Adapter cache time: 0.01746599469333887 Engine time: 0.10454824985936284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63748350 . Total output tokens: 55952342
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 63.92367831384763,
    "estimated_duration": 3600.010670126279,
    "input_throughput": 6317.352664735922,
    "output_throughput": 5458.11882255081,
    "total_throughput": 11775.471487286732,
    "itl": 62.28899308493356,
    "ttft": 317980.35603334004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 73,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5021199739677832,
    "arrivals": 95267,
    "finished_requests": 91472,
    "scheduler_time": 95.44188256438224
}
#Debug simulation 
Total elapsed time: 63.92380423890427. Arrivals time: 0.2731057247146964 Scheduler time: 63.366083555389196 Scheduler overhead time: 0.11614099843427539 Adapter cache time: 0.017970059532672167 Engine time: 0.10639500664547086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63748350 . Total output tokens: 55952342
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 63.98836762737483,
    "estimated_duration": 3600.028736744314,
    "input_throughput": 6291.278946979303,
    "output_throughput": 5435.818831184475,
    "total_throughput": 11727.09777816378,
    "itl": 61.15795096507514,
    "ttft": 335414.7214565186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5684207622194664,
    "arrivals": 95267,
    "finished_requests": 91025,
    "scheduler_time": 95.3964278440284
}
#Debug simulation 
Total elapsed time: 63.98848778614774. Arrivals time: 0.2744476613588631 Scheduler time: 63.42677112482488 Scheduler overhead time: 0.11663369974121451 Adapter cache time: 0.017929621506482363 Engine time: 0.10798818664625287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63748350 . Total output tokens: 55952342
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 63.770874090027064,
    "estimated_duration": 3600.0181442645126,
    "input_throughput": 6317.3395490333905,
    "output_throughput": 5458.1074907372085,
    "total_throughput": 11775.447039770599,
    "itl": 62.28672812331099,
    "ttft": 318013.82084361126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 74,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47241014960222005,
    "arrivals": 95267,
    "finished_requests": 91472,
    "scheduler_time": 95.44174617442671
}
#Debug simulation 
Total elapsed time: 63.770999119151384. Arrivals time: 0.27502143988385797 Scheduler time: 63.21334250504151 Scheduler overhead time: 0.11565733980387449 Adapter cache time: 0.017494891304522753 Engine time: 0.10523244412615895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63748350 . Total output tokens: 55952342
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 64.07975412998348,
    "estimated_duration": 3600.010055940043,
    "input_throughput": 6308.264323464497,
    "output_throughput": 5441.523411213009,
    "total_throughput": 11749.787734677506,
    "itl": 61.36254012175701,
    "ttft": 324279.2581332573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 74,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5462622173503042,
    "arrivals": 95267,
    "finished_requests": 91337,
    "scheduler_time": 95.56524301286396
}
#Debug simulation 
Total elapsed time: 64.07991900574416. Arrivals time: 0.27923722052946687 Scheduler time: 63.51293161092326 Scheduler overhead time: 0.11814668076112866 Adapter cache time: 0.017756684217602015 Engine time: 0.1071479320526123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55399217 . Total output tokens: 48703791
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 18.615491976961493,
    "estimated_duration": 3600.0096029156343,
    "input_throughput": 5636.459964875134,
    "output_throughput": 4896.449161058833,
    "total_throughput": 10532.909125933966,
    "itl": 47.39569129755426,
    "ttft": 93610.63300883732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9125124464090903,
    "arrivals": 83017,
    "finished_requests": 81644,
    "scheduler_time": 62.99966594881873
}
#Debug simulation 
Total elapsed time: 18.61560582695529. Arrivals time: 0.20153190614655614 Scheduler time: 18.14256060682237 Scheduler overhead time: 0.10752353630959988 Adapter cache time: 0.016924106050282717 Engine time: 0.10135958949103951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55399217 . Total output tokens: 48703791
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 18.65793531993404,
    "estimated_duration": 3600.035492114152,
    "input_throughput": 5636.419430988374,
    "output_throughput": 4896.413948865887,
    "total_throughput": 10532.83337985426,
    "itl": 47.39774567188257,
    "ttft": 93610.44369721848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9989798725303265,
    "arrivals": 83017,
    "finished_requests": 81644,
    "scheduler_time": 63.00044089384502
}
#Debug simulation 
Total elapsed time: 18.65803753817454. Arrivals time: 0.20096122846007347 Scheduler time: 18.187714295927435 Scheduler overhead time: 0.10579131403937936 Adapter cache time: 0.016542404424399137 Engine time: 0.10110484901815653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55399217 . Total output tokens: 48703791
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 18.69909669365734,
    "estimated_duration": 3599.9964268682493,
    "input_throughput": 5636.39837210944,
    "output_throughput": 4896.440971007972,
    "total_throughput": 10532.839343117412,
    "itl": 47.398085642299826,
    "ttft": 93654.90919226148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0239313866524031,
    "arrivals": 83017,
    "finished_requests": 81643,
    "scheduler_time": 63.000145579914076
}
#Debug simulation 
Total elapsed time: 18.699195970781147. Arrivals time: 0.2046890310011804 Scheduler time: 18.222252518404275 Scheduler overhead time: 0.10724200727418065 Adapter cache time: 0.01706360001116991 Engine time: 0.10211541270837188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55399217 . Total output tokens: 48703791
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 18.54057198483497,
    "estimated_duration": 3599.998004816435,
    "input_throughput": 5636.395901567908,
    "output_throughput": 4896.438824803964,
    "total_throughput": 10532.834726371873,
    "itl": 47.396682951916915,
    "ttft": 93653.74582785761,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9295688238646825,
    "arrivals": 83017,
    "finished_requests": 81643,
    "scheduler_time": 62.999583074508664
}
#Debug simulation 
Total elapsed time: 18.54067223984748. Arrivals time: 0.20101735647767782 Scheduler time: 18.069188848137856 Scheduler overhead time: 0.10768283158540726 Adapter cache time: 0.0167983565479517 Engine time: 0.10019540134817362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55399217 . Total output tokens: 48703791
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 18.615355427842587,
    "estimated_duration": 3600.0202559840386,
    "input_throughput": 5636.443285637437,
    "output_throughput": 4896.434671638179,
    "total_throughput": 10532.877957275616,
    "itl": 47.39850579558242,
    "ttft": 93610.3645596352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.013575527821668,
    "arrivals": 83017,
    "finished_requests": 81644,
    "scheduler_time": 63.000295330029495
}
#Debug simulation 
Total elapsed time: 18.615460657980293. Arrivals time: 0.2012119498103857 Scheduler time: 18.14490631921217 Scheduler overhead time: 0.10574595117941499 Adapter cache time: 0.01663373177871108 Engine time: 0.101206976454705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55399217 . Total output tokens: 48703791
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 18.703536619897932,
    "estimated_duration": 3599.9969359908127,
    "input_throughput": 5636.397574992765,
    "output_throughput": 4896.440278538333,
    "total_throughput": 10532.837853531097,
    "itl": 47.394919911358066,
    "ttft": 93654.04889843102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8809810897987321,
    "arrivals": 83017,
    "finished_requests": 81643,
    "scheduler_time": 62.999366517931946
}
#Debug simulation 
Total elapsed time: 18.703632526099682. Arrivals time: 0.2008599741384387 Scheduler time: 18.233513221610337 Scheduler overhead time: 0.10594715690240264 Adapter cache time: 0.016788999550044537 Engine time: 0.10065341042354703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55399217 . Total output tokens: 48703791
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 18.6581911589019,
    "estimated_duration": 3600.0047863928758,
    "input_throughput": 5636.467506014468,
    "output_throughput": 4896.455712122018,
    "total_throughput": 10532.923218136486,
    "itl": 47.39786439572113,
    "ttft": 93610.27558573954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0063264266401533,
    "arrivals": 83017,
    "finished_requests": 81644,
    "scheduler_time": 62.999977322089634
}
#Debug simulation 
Total elapsed time: 18.65830305404961. Arrivals time: 0.20245467778295279 Scheduler time: 18.185588038992137 Scheduler overhead time: 0.10658248560503125 Adapter cache time: 0.01676651556044817 Engine time: 0.10106975864619017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54177798 . Total output tokens: 47640682
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 14.305931051261723,
    "estimated_duration": 3599.9967237599367,
    "input_throughput": 5543.238378049904,
    "output_throughput": 4838.447736643422,
    "total_throughput": 10381.686114693326,
    "itl": 46.364588184845545,
    "ttft": 59475.13800041121,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1505591715592878,
    "arrivals": 81259,
    "finished_requests": 80475,
    "scheduler_time": 60.18437266781187
}
#Debug simulation 
Total elapsed time: 14.306009758263826. Arrivals time: 0.19899426959455013 Scheduler time: 13.838730472605675 Scheduler overhead time: 0.10547978477552533 Adapter cache time: 0.016785822808742523 Engine time: 0.10028212005272508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54177798 . Total output tokens: 47640682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 14.432418471667916,
    "estimated_duration": 3600.0226265797883,
    "input_throughput": 5543.198493438057,
    "output_throughput": 4838.412923128874,
    "total_throughput": 10381.611416566931,
    "itl": 46.36688701244653,
    "ttft": 59475.415295664716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2593418878037488,
    "arrivals": 81259,
    "finished_requests": 80475,
    "scheduler_time": 60.18540090804614
}
#Debug simulation 
Total elapsed time: 14.432518559973687. Arrivals time: 0.1995410262607038 Scheduler time: 13.962869197595865 Scheduler overhead time: 0.10669007990509272 Adapter cache time: 0.0169688961468637 Engine time: 0.10038245981559157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54177798 . Total output tokens: 47640682
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 14.316244713962078,
    "estimated_duration": 3600.046140713549,
    "input_throughput": 5542.745626044943,
    "output_throughput": 4830.515865708652,
    "total_throughput": 10373.261491753594,
    "itl": 46.44390018234531,
    "ttft": 60081.888783988565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 179,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3277094926591977,
    "arrivals": 81259,
    "finished_requests": 80460,
    "scheduler_time": 60.186559135677705
}
#Debug simulation 
Total elapsed time: 14.316339823417366. Arrivals time: 0.19843557151034474 Scheduler time: 13.848714958876371 Scheduler overhead time: 0.10557741997763515 Adapter cache time: 0.016928954049944878 Engine time: 0.10085810394957662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54177798 . Total output tokens: 47640682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 14.31507684988901,
    "estimated_duration": 3600.0471664886995,
    "input_throughput": 5542.744046729321,
    "output_throughput": 4830.514489331368,
    "total_throughput": 10373.25853606069,
    "itl": 46.44038390321272,
    "ttft": 60081.012520172786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 179,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2065800131345152,
    "arrivals": 81259,
    "finished_requests": 80460,
    "scheduler_time": 60.18581708156176
}
#Debug simulation 
Total elapsed time: 14.315181049052626. Arrivals time: 0.19753569643944502 Scheduler time: 13.848533124662936 Scheduler overhead time: 0.10583767620846629 Adapter cache time: 0.016846858896315098 Engine time: 0.10062514524906874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54177798 . Total output tokens: 47640682
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 14.351090932264924,
    "estimated_duration": 3600.0021842263504,
    "input_throughput": 5542.754414824932,
    "output_throughput": 4830.419847019358,
    "total_throughput": 10373.17426184429,
    "itl": 46.44246973469482,
    "ttft": 60169.77907202201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 179,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3144539933558568,
    "arrivals": 81259,
    "finished_requests": 80458,
    "scheduler_time": 60.18528057023235
}
#Debug simulation 
Total elapsed time: 14.351181406993419. Arrivals time: 0.19838039064779878 Scheduler time: 13.885231215972453 Scheduler overhead time: 0.10488516604527831 Adapter cache time: 0.016952079720795155 Engine time: 0.09998896112665534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54177798 . Total output tokens: 47640682
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 14.37403636192903,
    "estimated_duration": 3600.010093104031,
    "input_throughput": 5543.217792146154,
    "output_throughput": 4838.429768118057,
    "total_throughput": 10381.647560264211,
    "itl": 46.36331874298133,
    "ttft": 59474.440278576694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1108022436592702,
    "arrivals": 81259,
    "finished_requests": 80475,
    "scheduler_time": 60.18419688707008
}
#Debug simulation 
Total elapsed time: 14.374111068900675. Arrivals time: 0.1977231903001666 Scheduler time: 13.906041416339576 Scheduler overhead time: 0.10630521876737475 Adapter cache time: 0.01685592159628868 Engine time: 0.10124560445547104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54177798 . Total output tokens: 47640682
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 14.309487133286893,
    "estimated_duration": 3600.048120622245,
    "input_throughput": 5542.742577716172,
    "output_throughput": 4830.513209082949,
    "total_throughput": 10373.25578679912,
    "itl": 46.44281943044157,
    "ttft": 60081.34168861143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 179,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3049266032315807,
    "arrivals": 81259,
    "finished_requests": 80460,
    "scheduler_time": 60.186361106757154
}
#Debug simulation 
Total elapsed time: 14.309581852983683. Arrivals time: 0.1996993669308722 Scheduler time: 13.84019991895184 Scheduler overhead time: 0.10656729200854897 Adapter cache time: 0.01674184389412403 Engine time: 0.10033053159713745 
