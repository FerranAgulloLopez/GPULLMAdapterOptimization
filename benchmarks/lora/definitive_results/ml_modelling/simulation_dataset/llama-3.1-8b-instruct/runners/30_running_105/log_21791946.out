INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972636 . Total output tokens: 21965048
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.088339420966804,
    "estimated_duration": 3600.0221489805017,
    "input_throughput": 2592.0662745485074,
    "output_throughput": 2220.0713410230987,
    "total_throughput": 4812.137615571606,
    "itl": 29.253536977244707,
    "ttft": 43444.0436647393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.700911514200644,
    "arrivals": 37601,
    "finished_requests": 37349,
    "scheduler_time": 13.760047385270168
}
#Debug simulation 
Total elapsed time: 4.088451614137739. Arrivals time: 0.10892714746296406 Scheduler time: 3.6510480199940503 Scheduler overhead time: 0.12190120108425617 Adapter cache time: 0.029460011050105095 Engine time: 0.12002641102299094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972636 . Total output tokens: 21965048
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.1533473818562925,
    "estimated_duration": 3600.015267781761,
    "input_throughput": 2592.314283642017,
    "output_throughput": 2220.291694741933,
    "total_throughput": 4812.60597838395,
    "itl": 29.269458981338108,
    "ttft": 43624.05991773769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2081,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.245107491644738,
    "arrivals": 37601,
    "finished_requests": 37346,
    "scheduler_time": 13.733399411372114
}
#Debug simulation 
Total elapsed time: 4.153450993821025. Arrivals time: 0.10639393050223589 Scheduler time: 3.719228907953948 Scheduler overhead time: 0.12362393597140908 Adapter cache time: 0.029220780823379755 Engine time: 0.11835660832002759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972636 . Total output tokens: 21965048
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.079410313162953,
    "estimated_duration": 3600.0144533622943,
    "input_throughput": 2592.0551489132904,
    "output_throughput": 2219.955253939566,
    "total_throughput": 4812.010402852857,
    "itl": 29.260432109571116,
    "ttft": 44161.99970771045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2076,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.617610426563434,
    "arrivals": 37601,
    "finished_requests": 37342,
    "scheduler_time": 13.762675965032134
}
#Debug simulation 
Total elapsed time: 4.079507467802614. Arrivals time: 0.10809803893789649 Scheduler time: 3.643143785651773 Scheduler overhead time: 0.12349705584347248 Adapter cache time: 0.029314622282981873 Engine time: 0.1190457260236144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972636 . Total output tokens: 21965048
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.076289384625852,
    "estimated_duration": 3600.022565028737,
    "input_throughput": 2589.794322560191,
    "output_throughput": 2217.7947098329555,
    "total_throughput": 4807.589032393147,
    "itl": 29.249706905577916,
    "ttft": 45737.291972888735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.189521323368194,
    "arrivals": 37601,
    "finished_requests": 37325,
    "scheduler_time": 13.747775227288104
}
#Debug simulation 
Total elapsed time: 4.076377756893635. Arrivals time: 0.10881390236318111 Scheduler time: 3.640397497918457 Scheduler overhead time: 0.12204153556376696 Adapter cache time: 0.029216391034424305 Engine time: 0.11930911429226398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972636 . Total output tokens: 21965048
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.047062654048204,
    "estimated_duration": 3600.020999824032,
    "input_throughput": 2593.4707048809905,
    "output_throughput": 2220.1362159805935,
    "total_throughput": 4813.606920861584,
    "itl": 29.285500170252778,
    "ttft": 42358.48848518856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2074,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.457201345679021,
    "arrivals": 37601,
    "finished_requests": 37359,
    "scheduler_time": 13.743660788310786
}
#Debug simulation 
Total elapsed time: 4.047152942046523. Arrivals time: 0.10843538399785757 Scheduler time: 3.612343532964587 Scheduler overhead time: 0.12325865076854825 Adapter cache time: 0.02911674790084362 Engine time: 0.11722970800474286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972636 . Total output tokens: 21965048
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.080627094954252,
    "estimated_duration": 3600.00973848214,
    "input_throughput": 2592.756597357273,
    "output_throughput": 2220.2978826857566,
    "total_throughput": 4813.05448004303,
    "itl": 29.25911353273577,
    "ttft": 43468.3540158469,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.227484188862801,
    "arrivals": 37601,
    "finished_requests": 37351,
    "scheduler_time": 13.786073267424838
}
#Debug simulation 
Total elapsed time: 4.08072072872892. Arrivals time: 0.1087286090478301 Scheduler time: 3.6420662687160075 Scheduler overhead time: 0.12484389543533325 Adapter cache time: 0.029256283305585384 Engine time: 0.11902901018038392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972636 . Total output tokens: 21965048
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.07752381823957,
    "estimated_duration": 3600.021648112305,
    "input_throughput": 2592.453021746067,
    "output_throughput": 2219.5724862348748,
    "total_throughput": 4812.025507980941,
    "itl": 29.291037905013944,
    "ttft": 43782.547889747955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2070,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.28861430872199,
    "arrivals": 37601,
    "finished_requests": 37345,
    "scheduler_time": 13.752220606001156
}
#Debug simulation 
Total elapsed time: 4.077642211224884. Arrivals time: 0.10682676453143358 Scheduler time: 3.6430488247424364 Scheduler overhead time: 0.12358468491584063 Adapter cache time: 0.029333011247217655 Engine time: 0.11840054020285606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24344640 . Total output tokens: 21401087
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.862930496223271,
    "estimated_duration": 3599.8653655574894,
    "input_throughput": 2496.911713976836,
    "output_throughput": 2193.1459091602287,
    "total_throughput": 4690.057623137065,
    "itl": 29.13503243403323,
    "ttft": 40247.761214561506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2019,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.350453835507286,
    "arrivals": 36626,
    "finished_requests": 36382,
    "scheduler_time": 12.645637926897855
}
#Debug simulation 
Total elapsed time: 3.8630185262300074. Arrivals time: 0.10189820500090718 Scheduler time: 3.433933772146702 Scheduler overhead time: 0.12292206613346934 Adapter cache time: 0.028790476731956005 Engine time: 0.11867566406726837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24344640 . Total output tokens: 21401087
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.8880103048868477,
    "estimated_duration": 3599.8470453665077,
    "input_throughput": 2496.4852358289627,
    "output_throughput": 2193.434304427812,
    "total_throughput": 4689.919540256775,
    "itl": 29.132134726500933,
    "ttft": 39893.208746123826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.87176134897371,
    "arrivals": 36626,
    "finished_requests": 36386,
    "scheduler_time": 12.67254033284515
}
#Debug simulation 
Total elapsed time: 3.8881026566959918. Arrivals time: 0.10501811979338527 Scheduler time: 3.454902936704457 Scheduler overhead time: 0.12283949414268136 Adapter cache time: 0.02912827394902706 Engine time: 0.11950591765344143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24344640 . Total output tokens: 21401087
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.8721065293066204,
    "estimated_duration": 3599.8477408715826,
    "input_throughput": 2496.4847534979654,
    "output_throughput": 2193.433880647475,
    "total_throughput": 4689.91863414544,
    "itl": 29.153605253684944,
    "ttft": 39898.24368296672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2026,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.203553919512478,
    "arrivals": 36626,
    "finished_requests": 36386,
    "scheduler_time": 12.65955294826272
}
#Debug simulation 
Total elapsed time: 3.8722757822833955. Arrivals time: 0.10287479218095541 Scheduler time: 3.441371717955917 Scheduler overhead time: 0.12330067018046975 Adapter cache time: 0.02908524964004755 Engine time: 0.11872192239388824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24344640 . Total output tokens: 21401087
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.8719378779642284,
    "estimated_duration": 3599.841958251682,
    "input_throughput": 2496.636825791351,
    "output_throughput": 2193.436848498434,
    "total_throughput": 4690.073674289784,
    "itl": 29.071854349218956,
    "ttft": 39257.72665434324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2021,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.770930550187163,
    "arrivals": 36626,
    "finished_requests": 36392,
    "scheduler_time": 12.633929301239428
}
#Debug simulation 
Total elapsed time: 3.8720279866829515. Arrivals time: 0.10692100413143635 Scheduler time: 3.439941597171128 Scheduler overhead time: 0.12234583217650652 Adapter cache time: 0.028888090513646603 Engine time: 0.11723635625094175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24344640 . Total output tokens: 21401087
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.894557448104024,
    "estimated_duration": 3599.864707430058,
    "input_throughput": 2496.655494149462,
    "output_throughput": 2193.1163089837846,
    "total_throughput": 4689.771803133247,
    "itl": 29.12095847220638,
    "ttft": 40745.62558022679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2035,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.113857995909342,
    "arrivals": 36626,
    "finished_requests": 36377,
    "scheduler_time": 12.643957317721467
}
#Debug simulation 
Total elapsed time: 3.894658599048853. Arrivals time: 0.10574052995070815 Scheduler time: 3.4637928185984492 Scheduler overhead time: 0.11984875658527017 Adapter cache time: 0.02910619368776679 Engine time: 0.11962568992748857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24344640 . Total output tokens: 21401087
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.8991813166067004,
    "estimated_duration": 3599.835270791092,
    "input_throughput": 2497.598729850816,
    "output_throughput": 2193.960669279285,
    "total_throughput": 4691.559399130101,
    "itl": 29.108199666946796,
    "ttft": 39277.4851233514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2016,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.869984616190804,
    "arrivals": 36626,
    "finished_requests": 36394,
    "scheduler_time": 12.681014227774437
}
#Debug simulation 
Total elapsed time: 3.899272510781884. Arrivals time: 0.10619484400376678 Scheduler time: 3.466133953537792 Scheduler overhead time: 0.12245635548606515 Adapter cache time: 0.02896426897495985 Engine time: 0.11884601693600416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24344640 . Total output tokens: 21401087
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.9056163681671023,
    "estimated_duration": 3599.836524330702,
    "input_throughput": 2496.602814948929,
    "output_throughput": 2193.348766432666,
    "total_throughput": 4689.951581381595,
    "itl": 29.16922795091408,
    "ttft": 40653.861414832885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.929225543196951,
    "arrivals": 36626,
    "finished_requests": 36379,
    "scheduler_time": 12.674796895295437
}
#Debug simulation 
Total elapsed time: 3.9057099581696093. Arrivals time: 0.10514387069270015 Scheduler time: 3.471675230190158 Scheduler overhead time: 0.1246313713490963 Adapter cache time: 0.02919443789869547 Engine time: 0.117900884244591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24033613 . Total output tokens: 21116913
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.6858503301627934,
    "estimated_duration": 3599.9233725736676,
    "input_throughput": 2457.302304653146,
    "output_throughput": 2156.3764548827617,
    "total_throughput": 4613.678759535907,
    "itl": 28.896061606449113,
    "ttft": 36621.84302530949,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2007,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.271104927123885,
    "arrivals": 36150,
    "finished_requests": 35923,
    "scheduler_time": 11.568229608198298
}
#Debug simulation 
Total elapsed time: 3.6859363322146237. Arrivals time: 0.10085516003891826 Scheduler time: 3.259565125219524 Scheduler overhead time: 0.12172925192862749 Adapter cache time: 0.02875090530142188 Engine time: 0.11816163454204798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24033613 . Total output tokens: 21116913
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.7022231151349843,
    "estimated_duration": 3599.923285801723,
    "input_throughput": 2456.783186153463,
    "output_throughput": 2154.8442519858895,
    "total_throughput": 4611.627438139352,
    "itl": 28.9105797219343,
    "ttft": 36906.23876504861,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2014,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.72853864633454,
    "arrivals": 36150,
    "finished_requests": 35919,
    "scheduler_time": 11.543955112969488
}
#Debug simulation 
Total elapsed time: 3.702320468146354. Arrivals time: 0.10743996035307646 Scheduler time: 3.2672210102900863 Scheduler overhead time: 0.12232135282829404 Adapter cache time: 0.029103136621415615 Engine time: 0.11940151965245605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24033613 . Total output tokens: 21116913
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.7016214323230088,
    "estimated_duration": 3599.923402918944,
    "input_throughput": 2457.642291173829,
    "output_throughput": 2155.9592056061183,
    "total_throughput": 4613.601496779947,
    "itl": 28.916365329492795,
    "ttft": 35473.16422312236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2025,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.205730684506413,
    "arrivals": 36150,
    "finished_requests": 35933,
    "scheduler_time": 11.525497789444477
}
#Debug simulation 
Total elapsed time: 3.701711144298315. Arrivals time: 0.10359820071607828 Scheduler time: 3.272312422748655 Scheduler overhead time: 0.12153197173029184 Adapter cache time: 0.029132443945854902 Engine time: 0.11815877538174391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24033613 . Total output tokens: 21116913
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.7114504841156304,
    "estimated_duration": 3599.93535645398,
    "input_throughput": 2456.7807819504274,
    "output_throughput": 2155.3881477591444,
    "total_throughput": 4612.168929709572,
    "itl": 28.926726392997267,
    "ttft": 37643.684555921216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2000,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.589668697342553,
    "arrivals": 36150,
    "finished_requests": 35913,
    "scheduler_time": 11.558301019234907
}
#Debug simulation 
Total elapsed time: 3.711533115245402. Arrivals time: 0.10210029920563102 Scheduler time: 3.2827763371169567 Scheduler overhead time: 0.12075343448668718 Adapter cache time: 0.028984001372009516 Engine time: 0.12002426572144032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24033613 . Total output tokens: 21116913
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.6897607669234276,
    "estimated_duration": 3599.9175340393285,
    "input_throughput": 2457.115730113657,
    "output_throughput": 2155.8616069995824,
    "total_throughput": 4612.977337113239,
    "itl": 28.929645129896677,
    "ttft": 36550.98496368974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2031,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.094862146950035,
    "arrivals": 36150,
    "finished_requests": 35922,
    "scheduler_time": 11.512201230460077
}
#Debug simulation 
Total elapsed time: 3.6898495303466916. Arrivals time: 0.1051120413467288 Scheduler time: 3.2602498456835747 Scheduler overhead time: 0.12013870570808649 Adapter cache time: 0.029175815172493458 Engine time: 0.11840198887512088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24033613 . Total output tokens: 21116913
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.682262114714831,
    "estimated_duration": 3599.9086515318268,
    "input_throughput": 2457.5195807358905,
    "output_throughput": 2156.233880183883,
    "total_throughput": 4613.753460919774,
    "itl": 28.907995638107025,
    "ttft": 35308.7774668187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2022,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.908288141834232,
    "arrivals": 36150,
    "finished_requests": 35935,
    "scheduler_time": 11.54124430525942
}
#Debug simulation 
Total elapsed time: 3.6823530308902264. Arrivals time: 0.10069857351481915 Scheduler time: 3.258029735647142 Scheduler overhead time: 0.11940690455958247 Adapter cache time: 0.029109463095664978 Engine time: 0.11833063047379255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24033613 . Total output tokens: 21116913
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.676160953938961,
    "estimated_duration": 3599.917631656796,
    "input_throughput": 2457.4667826298232,
    "output_throughput": 2155.044863187475,
    "total_throughput": 4612.511645817299,
    "itl": 28.904617628473865,
    "ttft": 36073.260222100915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.003049527406402,
    "arrivals": 36150,
    "finished_requests": 35927,
    "scheduler_time": 11.503870174814484
}
#Debug simulation 
Total elapsed time: 3.676248357631266. Arrivals time: 0.10114156594499946 Scheduler time: 3.249924624338746 Scheduler overhead time: 0.12018970539793372 Adapter cache time: 0.02920137159526348 Engine time: 0.11867831088602543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23864987 . Total output tokens: 20980197
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.6661949888803065,
    "estimated_duration": 3599.9248965827796,
    "input_throughput": 2451.0522451109427,
    "output_throughput": 2132.9317195724548,
    "total_throughput": 4583.983964683398,
    "itl": 28.77066945186725,
    "ttft": 33209.792246992816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1906,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.60325161489692,
    "arrivals": 35929,
    "finished_requests": 35730,
    "scheduler_time": 10.997278639460891
}
#Debug simulation 
Total elapsed time: 3.666313609108329. Arrivals time: 0.10158041538670659 Scheduler time: 3.2363741104491055 Scheduler overhead time: 0.12295720307156444 Adapter cache time: 0.028665808495134115 Engine time: 0.11890728026628494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23864987 . Total output tokens: 20980197
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.642470838036388,
    "estimated_duration": 3599.941315675802,
    "input_throughput": 2451.446072626689,
    "output_throughput": 2132.8492124485138,
    "total_throughput": 4584.295285075203,
    "itl": 28.79276110258665,
    "ttft": 32524.36498317115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1905,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.907751376214238,
    "arrivals": 35929,
    "finished_requests": 35735,
    "scheduler_time": 10.987207939798054
}
#Debug simulation 
Total elapsed time: 3.6426370800472796. Arrivals time: 0.10173322819173336 Scheduler time: 3.2124645090661943 Scheduler overhead time: 0.12298233015462756 Adapter cache time: 0.028430071659386158 Engine time: 0.11949057644233108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23864987 . Total output tokens: 20980197
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.6522917728871107,
    "estimated_duration": 3599.9369683583122,
    "input_throughput": 2451.1401387185974,
    "output_throughput": 2132.790120350739,
    "total_throughput": 4583.930259069337,
    "itl": 28.79079826294502,
    "ttft": 32823.96220799716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1890,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.163307358110075,
    "arrivals": 35929,
    "finished_requests": 35733,
    "scheduler_time": 10.998241039356557
}
#Debug simulation 
Total elapsed time: 3.6524164020083845. Arrivals time: 0.10256601544097066 Scheduler time: 3.225101644638926 Scheduler overhead time: 0.12069922685623169 Adapter cache time: 0.028422724921256304 Engine time: 0.11859399592503905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23864987 . Total output tokens: 20980197
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.6373404380865395,
    "estimated_duration": 3599.927375213735,
    "input_throughput": 2449.998314056641,
    "output_throughput": 2130.764929540997,
    "total_throughput": 4580.7632435976375,
    "itl": 28.76286234971344,
    "ttft": 35769.6970586962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1893,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.826072340249329,
    "arrivals": 35929,
    "finished_requests": 35704,
    "scheduler_time": 10.981319660516256
}
#Debug simulation 
Total elapsed time: 3.637427448295057. Arrivals time: 0.10128370625898242 Scheduler time: 3.2126806993037462 Scheduler overhead time: 0.12011749763041735 Adapter cache time: 0.028604678809642792 Engine time: 0.11781894415616989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23864987 . Total output tokens: 20980197
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.658915552776307,
    "estimated_duration": 3599.949150431533,
    "input_throughput": 2451.522405237887,
    "output_throughput": 2132.814292412886,
    "total_throughput": 4584.336697650773,
    "itl": 28.75267420545923,
    "ttft": 32444.41993832186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1898,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.07578819950087,
    "arrivals": 35929,
    "finished_requests": 35737,
    "scheduler_time": 10.979825802832226
}
#Debug simulation 
Total elapsed time: 3.6590061588212848. Arrivals time: 0.10299131134524941 Scheduler time: 3.229598843958229 Scheduler overhead time: 0.12045982060953975 Adapter cache time: 0.028494276572018862 Engine time: 0.12075748015195131 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23864987 . Total output tokens: 20980197
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.6357797319069505,
    "estimated_duration": 3599.933088958609,
    "input_throughput": 2451.1427801433383,
    "output_throughput": 2132.792418711613,
    "total_throughput": 4583.9351988549515,
    "itl": 28.741096821728696,
    "ttft": 32774.99506674542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1902,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.142217628965666,
    "arrivals": 35929,
    "finished_requests": 35733,
    "scheduler_time": 10.944125355291169
}
#Debug simulation 
Total elapsed time: 3.6358974878676236. Arrivals time: 0.1000623912550509 Scheduler time: 3.210787541233003 Scheduler overhead time: 0.12064435100182891 Adapter cache time: 0.028394787572324276 Engine time: 0.11891297716647387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23864987 . Total output tokens: 20980197
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.624248498119414,
    "estimated_duration": 3599.9384254612055,
    "input_throughput": 2451.0430338456595,
    "output_throughput": 2132.9237038314855,
    "total_throughput": 4583.966737677145,
    "itl": 28.769682926106896,
    "ttft": 33072.39827678739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.04423769926628,
    "arrivals": 35929,
    "finished_requests": 35730,
    "scheduler_time": 10.981218685252774
}
#Debug simulation 
Total elapsed time: 3.624371897894889. Arrivals time: 0.10254928935319185 Scheduler time: 3.1971118659712374 Scheduler overhead time: 0.12032282119616866 Adapter cache time: 0.028431616723537445 Engine time: 0.11889414582401514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23105715 . Total output tokens: 20279491
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.4293003929778934,
    "estimated_duration": 3599.883369982182,
    "input_throughput": 2371.6848915697674,
    "output_throughput": 2050.547265378916,
    "total_throughput": 4422.232156948683,
    "itl": 28.434456178380554,
    "ttft": 29384.41889842844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.725834914152918,
    "arrivals": 34705,
    "finished_requests": 34531,
    "scheduler_time": 9.230492784591814
}
#Debug simulation 
Total elapsed time: 3.4294216628186405. Arrivals time: 0.10003735776990652 Scheduler time: 3.00195941189304 Scheduler overhead time: 0.12113339174538851 Adapter cache time: 0.030302115716040134 Engine time: 0.11857907706871629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23105715 . Total output tokens: 20279491
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.4298490448854864,
    "estimated_duration": 3599.909196673517,
    "input_throughput": 2371.6678764812496,
    "output_throughput": 2050.5325542158294,
    "total_throughput": 4422.200430697078,
    "itl": 28.434269176823367,
    "ttft": 29349.512821944747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.258791133272165,
    "arrivals": 34705,
    "finished_requests": 34531,
    "scheduler_time": 9.225293341658416
}
#Debug simulation 
Total elapsed time: 3.429937716573477. Arrivals time: 0.09919520234689116 Scheduler time: 3.0030640666373074 Scheduler overhead time: 0.12093555275350809 Adapter cache time: 0.029999967198818922 Engine time: 0.11932457331568003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23105715 . Total output tokens: 20279491
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.416899976786226,
    "estimated_duration": 3599.9008351285866,
    "input_throughput": 2371.5672711565257,
    "output_throughput": 2050.532872452396,
    "total_throughput": 4422.100143608922,
    "itl": 28.439220769789056,
    "ttft": 29217.59497540379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2233,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.759102273029033,
    "arrivals": 34705,
    "finished_requests": 34532,
    "scheduler_time": 9.219289211914871
}
#Debug simulation 
Total elapsed time: 3.4169894526712596. Arrivals time: 0.09836941864341497 Scheduler time: 2.990436030551791 Scheduler overhead time: 0.12097300915047526 Adapter cache time: 0.029864720068871975 Engine time: 0.11994799971580505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23105715 . Total output tokens: 20279491
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.436346447095275,
    "estimated_duration": 3599.9008043547788,
    "input_throughput": 2371.673405464919,
    "output_throughput": 2050.5373345483194,
    "total_throughput": 4422.210740013239,
    "itl": 28.422673896748897,
    "ttft": 29401.301802506256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.10298867947917,
    "arrivals": 34705,
    "finished_requests": 34531,
    "scheduler_time": 9.231429270758538
}
#Debug simulation 
Total elapsed time: 3.436446655075997. Arrivals time: 0.10199397802352905 Scheduler time: 3.003442368004471 Scheduler overhead time: 0.12116622971370816 Adapter cache time: 0.03017116105183959 Engine time: 0.12027868954464793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23105715 . Total output tokens: 20279491
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.438081785105169,
    "estimated_duration": 3599.8816303198746,
    "input_throughput": 2371.6860376993445,
    "output_throughput": 2050.548256316995,
    "total_throughput": 4422.23429401634,
    "itl": 28.439498379741796,
    "ttft": 29315.730676686482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.609769292175507,
    "arrivals": 34705,
    "finished_requests": 34531,
    "scheduler_time": 9.217500562668432
}
#Debug simulation 
Total elapsed time: 3.4381850389763713. Arrivals time: 0.10073114605620503 Scheduler time: 3.0091181197203696 Scheduler overhead time: 0.1214152374304831 Adapter cache time: 0.029904196970164776 Engine time: 0.11942601297050714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23105715 . Total output tokens: 20279491
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.4320592400617898,
    "estimated_duration": 3599.899307083781,
    "input_throughput": 2371.6743918919005,
    "output_throughput": 2050.5381874083077,
    "total_throughput": 4422.212579300209,
    "itl": 28.41879703012646,
    "ttft": 29338.99528510726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.178688409007938,
    "arrivals": 34705,
    "finished_requests": 34531,
    "scheduler_time": 9.229128768930797
}
#Debug simulation 
Total elapsed time: 3.4321849080733955. Arrivals time: 0.09654312347993255 Scheduler time: 3.0044363318011165 Scheduler overhead time: 0.12115926435217261 Adapter cache time: 0.030332080088555813 Engine time: 0.1221232176758349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23105715 . Total output tokens: 20279491
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.418346491176635,
    "estimated_duration": 3599.902232490554,
    "input_throughput": 2371.6724645861345,
    "output_throughput": 2050.5365210690816,
    "total_throughput": 4422.208985655216,
    "itl": 28.42598766340608,
    "ttft": 29327.50668277711,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.41663982817875,
    "arrivals": 34705,
    "finished_requests": 34531,
    "scheduler_time": 9.208530592697203
}
#Debug simulation 
Total elapsed time: 3.4184654019773006. Arrivals time: 0.09870601492002606 Scheduler time: 2.9879057807847857 Scheduler overhead time: 0.12274058721959591 Adapter cache time: 0.030208042357116938 Engine time: 0.1209982018917799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22777251 . Total output tokens: 19994543
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.369402359239757,
    "estimated_duration": 3599.7303720019863,
    "input_throughput": 2340.7903173908467,
    "output_throughput": 2057.7702312410615,
    "total_throughput": 4398.560548631908,
    "itl": 28.40607390091972,
    "ttft": 26766.77446364216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2023,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.376903471635087,
    "arrivals": 34232,
    "finished_requests": 34072,
    "scheduler_time": 8.980392751534717
}
#Debug simulation 
Total elapsed time: 3.369559151120484. Arrivals time: 0.09818416833877563 Scheduler time: 2.9419903717935085 Scheduler overhead time: 0.12249298207461834 Adapter cache time: 0.02905781241133809 Engine time: 0.12000835221260786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22777251 . Total output tokens: 19994543
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.3758368138223886,
    "estimated_duration": 3599.754390742477,
    "input_throughput": 2340.2860544222826,
    "output_throughput": 2057.478148800138,
    "total_throughput": 4397.764203222421,
    "itl": 28.41691975685413,
    "ttft": 26979.768264124614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2026,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.830133675141001,
    "arrivals": 34232,
    "finished_requests": 34070,
    "scheduler_time": 8.986561371654604
}
#Debug simulation 
Total elapsed time: 3.37592853885144. Arrivals time: 0.09861611109226942 Scheduler time: 2.9469146514311433 Scheduler overhead time: 0.12335626455023885 Adapter cache time: 0.029430866241455078 Engine time: 0.11900548031553626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22777251 . Total output tokens: 19994543
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.394309218041599,
    "estimated_duration": 3599.7471378072555,
    "input_throughput": 2340.8224737509827,
    "output_throughput": 2057.761202780522,
    "total_throughput": 4398.583676531505,
    "itl": 28.42239041388906,
    "ttft": 26660.586241859015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2023,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.210084214494259,
    "arrivals": 34232,
    "finished_requests": 34073,
    "scheduler_time": 8.988374551200819
}
#Debug simulation 
Total elapsed time: 3.3943984392099082. Arrivals time: 0.09503314225003123 Scheduler time: 2.971018085256219 Scheduler overhead time: 0.12127860216423869 Adapter cache time: 0.029323378577828407 Engine time: 0.11997215310111642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22777251 . Total output tokens: 19994543
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.3700003707781434,
    "estimated_duration": 3599.7395288709877,
    "input_throughput": 2340.8274216559284,
    "output_throughput": 2057.765552365741,
    "total_throughput": 4398.592974021669,
    "itl": 28.407711628231304,
    "ttft": 26657.84040145666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2024,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.799799859822057,
    "arrivals": 34232,
    "finished_requests": 34073,
    "scheduler_time": 8.978089502813907
}
#Debug simulation 
Total elapsed time: 3.370101112872362. Arrivals time: 0.09565551299601793 Scheduler time: 2.947503955103457 Scheduler overhead time: 0.1216395627707243 Adapter cache time: 0.029158491175621748 Engine time: 0.11894381605088711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22777251 . Total output tokens: 19994543
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.3689664811827242,
    "estimated_duration": 3599.7454853347945,
    "input_throughput": 2340.8235483115845,
    "output_throughput": 2057.762147401116,
    "total_throughput": 4398.585695712701,
    "itl": 28.419909049844012,
    "ttft": 26677.48174900413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2023,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.05888867556553,
    "arrivals": 34232,
    "finished_requests": 34073,
    "scheduler_time": 8.990964355183324
}
#Debug simulation 
Total elapsed time: 3.369090747088194. Arrivals time: 0.09871188690885901 Scheduler time: 2.943582645151764 Scheduler overhead time: 0.12107151001691818 Adapter cache time: 0.0292798625305295 Engine time: 0.11927526909857988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22777251 . Total output tokens: 19994543
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.3755019470117986,
    "estimated_duration": 3599.7520021979635,
    "input_throughput": 2340.7406940409055,
    "output_throughput": 2057.533128803767,
    "total_throughput": 4398.273822844672,
    "itl": 28.405426111389215,
    "ttft": 26660.365037647898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2026,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.933823825596518,
    "arrivals": 34232,
    "finished_requests": 34073,
    "scheduler_time": 8.987839445465088
}
#Debug simulation 
Total elapsed time: 3.3756184922531247. Arrivals time: 0.09762944094836712 Scheduler time: 2.950844005215913 Scheduler overhead time: 0.1207293588668108 Adapter cache time: 0.029070598538964987 Engine time: 0.11941597750410438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22777251 . Total output tokens: 19994543
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.3715544901788235,
    "estimated_duration": 3599.7526287839737,
    "input_throughput": 2340.818903116267,
    "output_throughput": 2057.7580639207113,
    "total_throughput": 4398.576967036978,
    "itl": 28.41846981165713,
    "ttft": 26662.706115767276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2022,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.919914546571375,
    "arrivals": 34232,
    "finished_requests": 34073,
    "scheduler_time": 8.988707761373224
}
#Debug simulation 
Total elapsed time: 3.3716546869836748. Arrivals time: 0.09800561843439937 Scheduler time: 2.9433503416366875 Scheduler overhead time: 0.12074548844248056 Adapter cache time: 0.031287917867302895 Engine time: 0.12071203906089067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22610988 . Total output tokens: 19863471
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.2482084673829377,
    "estimated_duration": 3600.0248955092075,
    "input_throughput": 2339.121601771285,
    "output_throughput": 2015.2893967622965,
    "total_throughput": 4354.410998533582,
    "itl": 28.1820153876973,
    "ttft": 27704.768325376128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1982,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.10579470132513,
    "arrivals": 33997,
    "finished_requests": 33820,
    "scheduler_time": 8.130129364345398
}
#Debug simulation 
Total elapsed time: 3.2482969244010746. Arrivals time: 0.09563552821055055 Scheduler time: 2.826096076518297 Scheduler overhead time: 0.12158379564061761 Adapter cache time: 0.028906827326864004 Engine time: 0.11858776118606329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22610988 . Total output tokens: 19863471
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.2709677102975547,
    "estimated_duration": 3600.0163835900107,
    "input_throughput": 2339.2451874349763,
    "output_throughput": 2015.2947172882225,
    "total_throughput": 4354.539904723199,
    "itl": 28.196297239927038,
    "ttft": 27588.35395409645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1983,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.457061385591288,
    "arrivals": 33997,
    "finished_requests": 33821,
    "scheduler_time": 8.13538551995259
}
#Debug simulation 
Total elapsed time: 3.271062069106847. Arrivals time: 0.09783949563279748 Scheduler time: 2.843221735674888 Scheduler overhead time: 0.12230474501848221 Adapter cache time: 0.02906642761081457 Engine time: 0.12102123675867915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22610988 . Total output tokens: 19863471
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.257598554715514,
    "estimated_duration": 3600.018193014692,
    "input_throughput": 2339.2440116942576,
    "output_throughput": 2015.2937043700078,
    "total_throughput": 4354.537716064266,
    "itl": 28.199869378075523,
    "ttft": 27592.5041082947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1984,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.847270773872452,
    "arrivals": 33997,
    "finished_requests": 33821,
    "scheduler_time": 8.136290983589271
}
#Debug simulation 
Total elapsed time: 3.2577021028846502. Arrivals time: 0.10097466083243489 Scheduler time: 2.828623020555824 Scheduler overhead time: 0.12160435365512967 Adapter cache time: 0.029019581153988838 Engine time: 0.11999551998451352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22610988 . Total output tokens: 19863471
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.2581596402451396,
    "estimated_duration": 3600.0187855896133,
    "input_throughput": 2339.2436266470067,
    "output_throughput": 2015.293372646042,
    "total_throughput": 4354.536999293048,
    "itl": 28.183552987100562,
    "ttft": 27584.699349757506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1983,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.445048296046727,
    "arrivals": 33997,
    "finished_requests": 33821,
    "scheduler_time": 8.127862564525719
}
#Debug simulation 
Total elapsed time: 3.2582879243418574. Arrivals time: 0.09637501370161772 Scheduler time: 2.8337220535613596 Scheduler overhead time: 0.12253559334203601 Adapter cache time: 0.029038858134299517 Engine time: 0.11887013539671898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22610988 . Total output tokens: 19863471
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.2680287626571953,
    "estimated_duration": 3600.0006207263937,
    "input_throughput": 2339.1534855626924,
    "output_throughput": 2015.2877080715914,
    "total_throughput": 4354.441193634284,
    "itl": 28.201217089626724,
    "ttft": 27456.21203327411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.762958400347,
    "arrivals": 33997,
    "finished_requests": 33820,
    "scheduler_time": 8.133144595585899
}
#Debug simulation 
Total elapsed time: 3.2681506369262934. Arrivals time: 0.09818906057626009 Scheduler time: 2.8379402412101626 Scheduler overhead time: 0.12224022764712572 Adapter cache time: 0.029501312412321568 Engine time: 0.1221724022179842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22610988 . Total output tokens: 19863471
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.2556607890874147,
    "estimated_duration": 3600.0090854461528,
    "input_throughput": 2338.7882641847673,
    "output_throughput": 2015.0638034017554,
    "total_throughput": 4353.852067586523,
    "itl": 28.178702169025005,
    "ttft": 27974.405959583528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1984,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.66569914609252,
    "arrivals": 33997,
    "finished_requests": 33817,
    "scheduler_time": 8.112945744922005
}
#Debug simulation 
Total elapsed time: 3.255747094284743. Arrivals time: 0.09686704678460956 Scheduler time: 2.829249958973378 Scheduler overhead time: 0.12210648879408836 Adapter cache time: 0.028944183606654406 Engine time: 0.12073432235047221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22610988 . Total output tokens: 19863471
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.26135438028723,
    "estimated_duration": 3600.008882694718,
    "input_throughput": 2339.0300619750064,
    "output_throughput": 2015.2825274612605,
    "total_throughput": 4354.3125894362665,
    "itl": 28.19821578341173,
    "ttft": 27801.689509654032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1983,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.570977956782755,
    "arrivals": 33997,
    "finished_requests": 33819,
    "scheduler_time": 8.137045159782726
}
#Debug simulation 
Total elapsed time: 3.2615060601383448. Arrivals time: 0.10338395461440086 Scheduler time: 2.8195769474841654 Scheduler overhead time: 0.13009890774264932 Adapter cache time: 0.030121944844722748 Engine time: 0.1194430966861546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22131967 . Total output tokens: 19445509
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.1610219478607178,
    "estimated_duration": 3599.9080086353583,
    "input_throughput": 2271.2635935103967,
    "output_throughput": 2000.0013841268365,
    "total_throughput": 4271.264977637233,
    "itl": 28.104006559299595,
    "ttft": 19819.10633241231,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.457778616194016,
    "arrivals": 33294,
    "finished_requests": 33181,
    "scheduler_time": 7.542540438380887
}
#Debug simulation 
Total elapsed time: 3.1611164058558643. Arrivals time: 0.09919257462024689 Scheduler time: 2.7310171225108206 Scheduler overhead time: 0.12232814403250813 Adapter cache time: 0.028594381641596556 Engine time: 0.12150378711521626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22131967 . Total output tokens: 19445509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.1751483720727265,
    "estimated_duration": 3599.9164111876707,
    "input_throughput": 2271.2569032408433,
    "output_throughput": 1999.94838147498,
    "total_throughput": 4271.205284715823,
    "itl": 28.115060844539084,
    "ttft": 19931.883067191353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1882,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.727603891221616,
    "arrivals": 33294,
    "finished_requests": 33180,
    "scheduler_time": 7.5551534828113605
}
#Debug simulation 
Total elapsed time: 3.175246479921043. Arrivals time: 0.10040473518893123 Scheduler time: 2.7468497292138636 Scheduler overhead time: 0.12177992518991232 Adapter cache time: 0.028501372784376144 Engine time: 0.11992731364443898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22131967 . Total output tokens: 19445509
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.1602237317711115,
    "estimated_duration": 3599.9357705799,
    "input_throughput": 2271.2446890914684,
    "output_throughput": 1999.9376263427712,
    "total_throughput": 4271.182315434239,
    "itl": 28.112860894971583,
    "ttft": 19957.294590302172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.10972449868428,
    "arrivals": 33294,
    "finished_requests": 33180,
    "scheduler_time": 7.553127422862344
}
#Debug simulation 
Total elapsed time: 3.160321165807545. Arrivals time: 0.09945729561150074 Scheduler time: 2.7309035575017333 Scheduler overhead time: 0.12277245474979281 Adapter cache time: 0.02862431015819311 Engine time: 0.12066166568547487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22131967 . Total output tokens: 19445509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.144419187679887,
    "estimated_duration": 3599.91621231978,
    "input_throughput": 2271.25702871045,
    "output_throughput": 1999.9484919568613,
    "total_throughput": 4271.205520667311,
    "itl": 28.10201133750612,
    "ttft": 19942.28165728426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1885,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.888835092536365,
    "arrivals": 33294,
    "finished_requests": 33180,
    "scheduler_time": 7.541603175222939
}
#Debug simulation 
Total elapsed time: 3.144551896955818. Arrivals time: 0.09808176336809993 Scheduler time: 2.71810160856694 Scheduler overhead time: 0.12194122467190027 Adapter cache time: 0.028586937580257654 Engine time: 0.11970701953396201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22131967 . Total output tokens: 19445509
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.162921388167888,
    "estimated_duration": 3599.915585247337,
    "input_throughput": 2271.2574243426975,
    "output_throughput": 1999.9488403296377,
    "total_throughput": 4271.206264672335,
    "itl": 28.113953771028015,
    "ttft": 19963.087239332355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1885,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.988973688203608,
    "arrivals": 33294,
    "finished_requests": 33180,
    "scheduler_time": 7.560376095147281
}
#Debug simulation 
Total elapsed time: 3.1630162741057575. Arrivals time: 0.10107202595099807 Scheduler time: 2.7335102120414376 Scheduler overhead time: 0.12283454416319728 Adapter cache time: 0.028610255103558302 Engine time: 0.11904216138646007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22131967 . Total output tokens: 19445509
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.158910325728357,
    "estimated_duration": 3599.911368924194,
    "input_throughput": 2271.261473429952,
    "output_throughput": 1999.9995172524516,
    "total_throughput": 4271.260990682404,
    "itl": 28.101019227279625,
    "ttft": 19799.118517616065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.052842735797666,
    "arrivals": 33294,
    "finished_requests": 33181,
    "scheduler_time": 7.537451070608727
}
#Debug simulation 
Total elapsed time: 3.159011567942798. Arrivals time: 0.10026516672223806 Scheduler time: 2.7286701491102576 Scheduler overhead time: 0.12205144902691245 Adapter cache time: 0.028640898410230875 Engine time: 0.1212200615555048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22131967 . Total output tokens: 19445509
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.1494987891055644,
    "estimated_duration": 3599.923599906199,
    "input_throughput": 2271.253756666682,
    "output_throughput": 1999.992722119881,
    "total_throughput": 4271.246478786563,
    "itl": 28.111905384526636,
    "ttft": 19845.217842106085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.875625730585073,
    "arrivals": 33294,
    "finished_requests": 33181,
    "scheduler_time": 7.550181300927674
}
#Debug simulation 
Total elapsed time: 3.149600510019809. Arrivals time: 0.10119590349495411 Scheduler time: 2.719313705805689 Scheduler overhead time: 0.12253061169758439 Adapter cache time: 0.028740301728248596 Engine time: 0.11986291967332363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21971033 . Total output tokens: 19315384
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.052043795119971,
    "estimated_duration": 3599.6912422281152,
    "input_throughput": 2254.4369652595133,
    "output_throughput": 1975.9880837994513,
    "total_throughput": 4230.425049058965,
    "itl": 27.963022234026734,
    "ttft": 17248.914691810158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1767,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.684126759455848,
    "arrivals": 33045,
    "finished_requests": 32947,
    "scheduler_time": 6.961024354065149
}
#Debug simulation 
Total elapsed time: 3.05214471090585. Arrivals time: 0.09871332440525293 Scheduler time: 2.6253425064496696 Scheduler overhead time: 0.12293606530874968 Adapter cache time: 0.028034203220158815 Engine time: 0.119182497728616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21971033 . Total output tokens: 19315384
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.1997365881688893,
    "estimated_duration": 3599.6838408391104,
    "input_throughput": 2252.8886864990836,
    "output_throughput": 1974.4208975706163,
    "total_throughput": 4227.3095840697,
    "itl": 28.073004419729475,
    "ttft": 22598.95962614122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1608,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.718812231495871,
    "arrivals": 33045,
    "finished_requests": 32922,
    "scheduler_time": 7.492315356326819
}
#Debug simulation 
Total elapsed time: 3.1998365819454193. Arrivals time: 0.09980609081685543 Scheduler time: 2.7709525898098946 Scheduler overhead time: 0.12317261286079884 Adapter cache time: 0.027573236729949713 Engine time: 0.12047661561518908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21971033 . Total output tokens: 19315384
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.222372260876,
    "estimated_duration": 3599.6847166119214,
    "input_throughput": 2252.8881383903426,
    "output_throughput": 1974.4204172107304,
    "total_throughput": 4227.308555601073,
    "itl": 28.081361953204866,
    "ttft": 22600.381356193462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.051913817608584,
    "arrivals": 33045,
    "finished_requests": 32922,
    "scheduler_time": 7.501067449739298
}
#Debug simulation 
Total elapsed time: 3.2224687822163105. Arrivals time: 0.09972674725577235 Scheduler time: 2.792159728705883 Scheduler overhead time: 0.12314557051286101 Adapter cache time: 0.02764723263680935 Engine time: 0.12139922427013516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21971033 . Total output tokens: 19315384
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.0894382800906897,
    "estimated_duration": 3599.68618182168,
    "input_throughput": 2254.440134526708,
    "output_throughput": 1975.9908616257146,
    "total_throughput": 4230.430996152422,
    "itl": 27.967086837022475,
    "ttft": 17250.85776422436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1767,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.089721129429707,
    "arrivals": 33045,
    "finished_requests": 32947,
    "scheduler_time": 6.96462484167246
}
#Debug simulation 
Total elapsed time: 3.089557956904173. Arrivals time: 0.09863193286582828 Scheduler time: 2.6618090025149286 Scheduler overhead time: 0.12319094873964787 Adapter cache time: 0.028168552555143833 Engine time: 0.11974884010851383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21971033 . Total output tokens: 19315384
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.1914026960730553,
    "estimated_duration": 3599.6782281792534,
    "input_throughput": 2252.8921992291366,
    "output_throughput": 1974.4239761104775,
    "total_throughput": 4227.316175339614,
    "itl": 28.08014707106841,
    "ttft": 22616.431470558342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.950942518119563,
    "arrivals": 33045,
    "finished_requests": 32922,
    "scheduler_time": 7.500109755577448
}
#Debug simulation 
Total elapsed time: 3.191501683089882. Arrivals time: 0.09975863667204976 Scheduler time: 2.7643863139674067 Scheduler overhead time: 0.12237299885600805 Adapter cache time: 0.0274224947206676 Engine time: 0.11944631999358535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21971033 . Total output tokens: 19315384
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.063439149875194,
    "estimated_duration": 3599.6966668373666,
    "input_throughput": 2254.4335679066944,
    "output_throughput": 1975.9851060587603,
    "total_throughput": 4230.418673965455,
    "itl": 27.95768272720901,
    "ttft": 17251.226291391467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1767,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.280388301988529,
    "arrivals": 33045,
    "finished_requests": 32947,
    "scheduler_time": 6.956622446741367
}
#Debug simulation 
Total elapsed time: 3.0635828520171344. Arrivals time: 0.0995308542624116 Scheduler time: 2.634586520958692 Scheduler overhead time: 0.12284060474485159 Adapter cache time: 0.028239639941602945 Engine time: 0.11996879056096077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21971033 . Total output tokens: 19315384
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.210177083965391,
    "estimated_duration": 3599.6904285798882,
    "input_throughput": 2252.7426068688765,
    "output_throughput": 1973.5530432272938,
    "total_throughput": 4226.29565009617,
    "itl": 28.062829869274168,
    "ttft": 23368.219137040815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1605,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.781220288108901,
    "arrivals": 33045,
    "finished_requests": 32916,
    "scheduler_time": 7.470094238428187
}
#Debug simulation 
Total elapsed time: 3.2102955989539623. Arrivals time: 0.10039757238700986 Scheduler time: 2.7814700552262366 Scheduler overhead time: 0.12322382582351565 Adapter cache time: 0.027364693582057953 Engine time: 0.11990168085321784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21650533 . Total output tokens: 19030301
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.940945027861744,
    "estimated_duration": 3599.942432826582,
    "input_throughput": 2244.6247824178076,
    "output_throughput": 1952.9076176031922,
    "total_throughput": 4197.532400021,
    "itl": 27.8004949902642,
    "ttft": 13613.65532657465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.46083108854507,
    "arrivals": 32548,
    "finished_requests": 32470,
    "scheduler_time": 6.2640557854255094
}
#Debug simulation 
Total elapsed time: 2.941046195104718. Arrivals time: 0.09706193022429943 Scheduler time: 2.5153916655108333 Scheduler overhead time: 0.12320801336318254 Adapter cache time: 0.02724132826551795 Engine time: 0.12003116915002465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21650533 . Total output tokens: 19030301
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.959061331115663,
    "estimated_duration": 3599.9272088426205,
    "input_throughput": 2244.600940861206,
    "output_throughput": 1952.7692067585153,
    "total_throughput": 4197.370147619721,
    "itl": 27.83187192291195,
    "ttft": 14060.143576352455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.012123456625154,
    "arrivals": 32548,
    "finished_requests": 32469,
    "scheduler_time": 6.3665026403007365
}
#Debug simulation 
Total elapsed time: 2.9591706241481006. Arrivals time: 0.09969467762857676 Scheduler time: 2.5318366740830243 Scheduler overhead time: 0.12257374357432127 Adapter cache time: 0.02702459366992116 Engine time: 0.11958899861201644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21650533 . Total output tokens: 19030301
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.959930542856455,
    "estimated_duration": 3599.9437761664312,
    "input_throughput": 2244.5906109691505,
    "output_throughput": 1952.760219907112,
    "total_throughput": 4197.350830876262,
    "itl": 27.835598111467633,
    "ttft": 14051.940121106758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.332391523565029,
    "arrivals": 32548,
    "finished_requests": 32469,
    "scheduler_time": 6.375570582095628
}
#Debug simulation 
Total elapsed time: 2.9600498070940375. Arrivals time: 0.09736862871795893 Scheduler time: 2.531501393765211 Scheduler overhead time: 0.12416996620595455 Adapter cache time: 0.027193702291697264 Engine time: 0.12126224720850587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21650533 . Total output tokens: 19030301
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.9599416442215443,
    "estimated_duration": 3599.933559312251,
    "input_throughput": 2244.596981268654,
    "output_throughput": 1952.7657619722884,
    "total_throughput": 4197.362743240942,
    "itl": 27.834409350757337,
    "ttft": 14046.115920819939,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.396301050717085,
    "arrivals": 32548,
    "finished_requests": 32469,
    "scheduler_time": 6.376832469009313
}
#Debug simulation 
Total elapsed time: 2.9600336709991097. Arrivals time: 0.09464450599625707 Scheduler time: 2.5289871892891824 Scheduler overhead time: 0.12865164875984192 Adapter cache time: 0.027427701745182276 Engine time: 0.12064048694446683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21650533 . Total output tokens: 19030301
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.966043022926897,
    "estimated_duration": 3599.9298694638233,
    "input_throughput": 2244.5690035632515,
    "output_throughput": 1952.7963751824543,
    "total_throughput": 4197.365378745706,
    "itl": 27.834916787805682,
    "ttft": 13939.799588027607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.236496270792426,
    "arrivals": 32548,
    "finished_requests": 32470,
    "scheduler_time": 6.374052055246873
}
#Debug simulation 
Total elapsed time: 2.9661584957502782. Arrivals time: 0.09789538150653243 Scheduler time: 2.538737343158573 Scheduler overhead time: 0.12264731666073203 Adapter cache time: 0.02704567462205887 Engine time: 0.12154702330008149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21650533 . Total output tokens: 19030301
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.9476447817869484,
    "estimated_duration": 3599.9305335717204,
    "input_throughput": 2245.2280466591874,
    "output_throughput": 1953.7424220855112,
    "total_throughput": 4198.970468744698,
    "itl": 27.806848996292892,
    "ttft": 13030.935939626967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.735479434370253,
    "arrivals": 32548,
    "finished_requests": 32478,
    "scheduler_time": 6.319839541944457
}
#Debug simulation 
Total elapsed time: 2.9477409687824547. Arrivals time: 0.09678821917623281 Scheduler time: 2.5236835489049554 Scheduler overhead time: 0.1231340579688549 Adapter cache time: 0.027034161612391472 Engine time: 0.11858084797859192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21650533 . Total output tokens: 19030301
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.9528535697609186,
    "estimated_duration": 3599.935919637863,
    "input_throughput": 2244.595509581418,
    "output_throughput": 1952.7644816264308,
    "total_throughput": 4197.359991207849,
    "itl": 27.83365304155802,
    "ttft": 14051.234773991842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.131279248557851,
    "arrivals": 32548,
    "finished_requests": 32469,
    "scheduler_time": 6.37571862856933
}
#Debug simulation 
Total elapsed time: 2.9529458256438375. Arrivals time: 0.09694098541513085 Scheduler time: 2.5264721075072885 Scheduler overhead time: 0.12308799056336284 Adapter cache time: 0.027067014947533607 Engine time: 0.12126507610082626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9042678 . Total output tokens: 8015864
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.4959163679741323,
    "estimated_duration": 3599.6259087214585,
    "input_throughput": 939.1973182015469,
    "output_throughput": 834.5592225907216,
    "total_throughput": 1773.7565407922684,
    "itl": 24.451885400327782,
    "ttft": 11659.55214377638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.012194516659065,
    "arrivals": 13796,
    "finished_requests": 13767,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4960131938569248. Arrivals time: 0.04832565365359187 Scheduler time: 1.076360265724361 Scheduler overhead time: 0.12663457775488496 Adapter cache time: 0.05029874388128519 Engine time: 0.13192651886492968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9042678 . Total output tokens: 8015864
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4758745431900024,
    "estimated_duration": 3599.608286340062,
    "input_throughput": 939.2019161722235,
    "output_throughput": 834.5633082910946,
    "total_throughput": 1773.7652244633182,
    "itl": 24.486966891561462,
    "ttft": 11681.578467580674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.38609475234374,
    "arrivals": 13796,
    "finished_requests": 13767,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4759665941819549. Arrivals time: 0.047037215903401375 Scheduler time: 1.0658377464860678 Scheduler overhead time: 0.12630169512704015 Adapter cache time: 0.05032593430951238 Engine time: 0.12442181585356593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9042678 . Total output tokens: 8015864
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4552468340843916,
    "estimated_duration": 3599.6087770834683,
    "input_throughput": 939.2017881285454,
    "output_throughput": 834.563194513052,
    "total_throughput": 1773.7649826415975,
    "itl": 24.49246798948628,
    "ttft": 11694.440053021039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.651095639325455,
    "arrivals": 13796,
    "finished_requests": 13767,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4553413321264088. Arrivals time: 0.04842044459655881 Scheduler time: 1.0447737807407975 Scheduler overhead time: 0.1267101946286857 Adapter cache time: 0.04953133361414075 Engine time: 0.12400978989899158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9042678 . Total output tokens: 8015864
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4852465139701962,
    "estimated_duration": 3599.624525775845,
    "input_throughput": 939.1976790332953,
    "output_throughput": 834.5595432213895,
    "total_throughput": 1773.7572222546848,
    "itl": 24.46643999198697,
    "ttft": 11666.957875633909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.58434358666336,
    "arrivals": 13796,
    "finished_requests": 13767,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4853535378351808. Arrivals time: 0.048797468189150095 Scheduler time: 1.0686943740583956 Scheduler overhead time: 0.12924845470115542 Adapter cache time: 0.04961962439119816 Engine time: 0.1261115837842226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9042678 . Total output tokens: 8015864
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.481416393071413,
    "estimated_duration": 3599.6209325568593,
    "input_throughput": 939.1986165606058,
    "output_throughput": 834.5603762966637,
    "total_throughput": 1773.7589928572695,
    "itl": 24.488285097204752,
    "ttft": 11692.483444917936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.229918191761556,
    "arrivals": 13796,
    "finished_requests": 13767,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4815681301988661. Arrivals time: 0.04910001717507839 Scheduler time: 1.0657992879860103 Scheduler overhead time: 0.1267647948116064 Adapter cache time: 0.04996155668050051 Engine time: 0.1278948145918548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9042678 . Total output tokens: 8015864
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.4737795949913561,
    "estimated_duration": 3599.620232485504,
    "input_throughput": 939.1987992204438,
    "output_throughput": 834.5605386059564,
    "total_throughput": 1773.7593378264,
    "itl": 24.443371559779564,
    "ttft": 11652.017601312398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.52968130608546,
    "arrivals": 13796,
    "finished_requests": 13767,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.473888659849763. Arrivals time: 0.05100554786622524 Scheduler time: 1.0567789250053465 Scheduler overhead time: 0.12682787608355284 Adapter cache time: 0.0496973842382431 Engine time: 0.1273376219905913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9042678 . Total output tokens: 8015864
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4721227600239217,
    "estimated_duration": 3599.6191520091384,
    "input_throughput": 939.1990811341858,
    "output_throughput": 834.5607891110513,
    "total_throughput": 1773.7598702452372,
    "itl": 24.48946615154666,
    "ttft": 11688.240482378378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.7327910849619,
    "arrivals": 13796,
    "finished_requests": 13767,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4722174811176956. Arrivals time: 0.047828841023147106 Scheduler time: 1.060255414340645 Scheduler overhead time: 0.1272139702923596 Adapter cache time: 0.049745914060622454 Engine time: 0.12449588580057025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8403910 . Total output tokens: 7439174
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.3712241547182202,
    "estimated_duration": 3599.5343979440136,
    "input_throughput": 870.0569723097591,
    "output_throughput": 759.7174238873696,
    "total_throughput": 1629.7743961971287,
    "itl": 24.202018282454638,
    "ttft": 6052.222281866832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.10680194361257,
    "arrivals": 12790,
    "finished_requests": 12774,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3713236600160599. Arrivals time: 0.04660314740613103 Scheduler time: 0.9570041787810624 Scheduler overhead time: 0.1267170631326735 Adapter cache time: 0.051865133456885815 Engine time: 0.12677382910624146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8403910 . Total output tokens: 7439174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3735287049785256,
    "estimated_duration": 3599.5408427654584,
    "input_throughput": 870.0554145105624,
    "output_throughput": 759.7160636463391,
    "total_throughput": 1629.7714781569016,
    "itl": 24.23757811184508,
    "ttft": 6066.06642716586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7116,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.9179144633359,
    "arrivals": 12790,
    "finished_requests": 12774,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3736235038377345. Arrivals time: 0.046070076525211334 Scheduler time: 0.9562568552792072 Scheduler overhead time: 0.12793272081762552 Adapter cache time: 0.052375555504113436 Engine time: 0.12821411294862628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8403910 . Total output tokens: 7439174
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3582523446530104,
    "estimated_duration": 3599.5274192971815,
    "input_throughput": 870.0586591479538,
    "output_throughput": 759.7188968028321,
    "total_throughput": 1629.7775559507859,
    "itl": 24.24897358402339,
    "ttft": 6070.505378923122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7112,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.269255037095455,
    "arrivals": 12790,
    "finished_requests": 12774,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3583474815823138. Arrivals time: 0.04615637939423323 Scheduler time: 0.9465129794552922 Scheduler overhead time: 0.1268115653656423 Adapter cache time: 0.05122715374454856 Engine time: 0.1252265782095492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8403910 . Total output tokens: 7439174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.357714963145554,
    "estimated_duration": 3599.535748543512,
    "input_throughput": 870.0566458514065,
    "output_throughput": 759.7171388300613,
    "total_throughput": 1629.7737846814678,
    "itl": 24.211730168205737,
    "ttft": 6057.52055675891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.57951687564324,
    "arrivals": 12790,
    "finished_requests": 12774,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3578159371390939. Arrivals time: 0.0464315926656127 Scheduler time: 0.9450467745773494 Scheduler overhead time: 0.1270417650230229 Adapter cache time: 0.05155890854075551 Engine time: 0.12532632565125823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8403910 . Total output tokens: 7439174
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3756246878765523,
    "estimated_duration": 3599.5461643958856,
    "input_throughput": 870.0541282058018,
    "output_throughput": 759.7149404691562,
    "total_throughput": 1629.7690686749581,
    "itl": 24.248687074571087,
    "ttft": 6067.26094604803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7115,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.789256311372995,
    "arrivals": 12790,
    "finished_requests": 12774,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3757214401848614. Arrivals time: 0.046736523043364286 Scheduler time: 0.9616473591886461 Scheduler overhead time: 0.12588912108913064 Adapter cache time: 0.05213621770963073 Engine time: 0.1268889051862061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8403910 . Total output tokens: 7439174
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.346210913732648,
    "estimated_duration": 3599.5382677630323,
    "input_throughput": 870.056036922282,
    "output_throughput": 759.7166071245748,
    "total_throughput": 1629.7726440468568,
    "itl": 24.18940790508168,
    "ttft": 6047.284698906754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.50458846439172,
    "arrivals": 12790,
    "finished_requests": 12774,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.346306508872658. Arrivals time: 0.046423081774264574 Scheduler time: 0.9340550852939487 Scheduler overhead time: 0.12767727114260197 Adapter cache time: 0.051370993722230196 Engine time: 0.124529835768044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8403910 . Total output tokens: 7439174
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3574366788379848,
    "estimated_duration": 3599.527785656572,
    "input_throughput": 870.0585705935157,
    "output_throughput": 759.7188194787583,
    "total_throughput": 1629.777390072274,
    "itl": 24.23949987117293,
    "ttft": 6068.055969746026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7115,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.32650502858424,
    "arrivals": 12790,
    "finished_requests": 12774,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.357532967813313. Arrivals time: 0.04511118680238724 Scheduler time: 0.9484225776977837 Scheduler overhead time: 0.12661522068083286 Adapter cache time: 0.051288212183862925 Engine time: 0.12407455453649163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8090413 . Total output tokens: 7145923
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.3177476366981864,
    "estimated_duration": 3599.557561732682,
    "input_throughput": 842.002648386897,
    "output_throughput": 730.3639280418984,
    "total_throughput": 1572.3665764287955,
    "itl": 24.087382748041694,
    "ttft": 6217.159655736266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.99896969859516,
    "arrivals": 12326,
    "finished_requests": 12310,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3180479109287262. Arrivals time: 0.044746152590960264 Scheduler time: 0.9109952342696488 Scheduler overhead time: 0.12689969735220075 Adapter cache time: 0.049209351651370525 Engine time: 0.12343962537124753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8090413 . Total output tokens: 7145923
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3207799359224737,
    "estimated_duration": 3599.554841870935,
    "input_throughput": 842.0032846130125,
    "output_throughput": 730.3644799126148,
    "total_throughput": 1572.3677645256273,
    "itl": 24.11760422785746,
    "ttft": 6232.253635287712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.3880022465098,
    "arrivals": 12326,
    "finished_requests": 12310,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.320882633794099. Arrivals time: 0.045022517908364534 Scheduler time: 0.9105067970231175 Scheduler overhead time: 0.12690072041004896 Adapter cache time: 0.049579139333218336 Engine time: 0.12655550008639693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8090413 . Total output tokens: 7145923
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3137363656423986,
    "estimated_duration": 3599.5508122899582,
    "input_throughput": 842.0042272085182,
    "output_throughput": 730.3652975320812,
    "total_throughput": 1572.3695247405994,
    "itl": 24.126624714356925,
    "ttft": 6236.792454975053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.62169874920315,
    "arrivals": 12326,
    "finished_requests": 12310,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3138413038104773. Arrivals time: 0.04459916101768613 Scheduler time: 0.9056017841212451 Scheduler overhead time: 0.12689818441867828 Adapter cache time: 0.04989305650815368 Engine time: 0.12462284602224827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8090413 . Total output tokens: 7145923
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.324949727859348,
    "estimated_duration": 3599.55569912223,
    "input_throughput": 842.003084085929,
    "output_throughput": 730.3643059728432,
    "total_throughput": 1572.3673900587721,
    "itl": 24.091424656089856,
    "ttft": 6221.042608097317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.39803864543498,
    "arrivals": 12326,
    "finished_requests": 12310,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.325050637125969. Arrivals time: 0.04604700533673167 Scheduler time: 0.9141671690158546 Scheduler overhead time: 0.1265919767320156 Adapter cache time: 0.04955269768834114 Engine time: 0.12624122016131878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8090413 . Total output tokens: 7145923
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3275209330022335,
    "estimated_duration": 3599.5467250165093,
    "input_throughput": 842.0051833015444,
    "output_throughput": 730.3661268594707,
    "total_throughput": 1572.3713101610151,
    "itl": 24.12153104070518,
    "ttft": 6235.52806312206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.19104578049665,
    "arrivals": 12326,
    "finished_requests": 12310,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3276213873177767. Arrivals time: 0.045555675867944956 Scheduler time: 0.9148063762113452 Scheduler overhead time: 0.12719767028465867 Adapter cache time: 0.049783249851316214 Engine time: 0.12773258332163095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8090413 . Total output tokens: 7145923
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.3329449989832938,
    "estimated_duration": 3599.5471304468965,
    "input_throughput": 842.0050884633675,
    "output_throughput": 730.3660445956161,
    "total_throughput": 1572.3711330589838,
    "itl": 24.076767032709874,
    "ttft": 6212.614836525327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.50414562232317,
    "arrivals": 12326,
    "finished_requests": 12310,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3330542230978608. Arrivals time: 0.04512304300442338 Scheduler time: 0.9221874331124127 Scheduler overhead time: 0.12687916541472077 Adapter cache time: 0.04956787545233965 Engine time: 0.12654284480959177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8090413 . Total output tokens: 7145923
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3229756448417902,
    "estimated_duration": 3599.5497216720755,
    "input_throughput": 842.0044823251128,
    "output_throughput": 730.365518823497,
    "total_throughput": 1572.3700011486098,
    "itl": 24.11859991974943,
    "ttft": 6232.772912025265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.7639686658029,
    "arrivals": 12326,
    "finished_requests": 12310,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3230799278244376. Arrivals time: 0.046726773492991924 Scheduler time: 0.911030032671988 Scheduler overhead time: 0.12819205643609166 Adapter cache time: 0.04973341478034854 Engine time: 0.1245210925117135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7932571 . Total output tokens: 7011702
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2974575678817928,
    "estimated_duration": 3599.6293554132008,
    "input_throughput": 830.0135111152402,
    "output_throughput": 718.3500701569252,
    "total_throughput": 1548.3635812721654,
    "itl": 23.86418862861041,
    "ttft": 7096.059103358407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.23701642374543,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2975516496226192. Arrivals time: 0.044376788660883904 Scheduler time: 0.8876518686302006 Scheduler overhead time: 0.12707364419475198 Adapter cache time: 0.04996262863278389 Engine time: 0.1256690858863294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7932571 . Total output tokens: 7011702
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3080811309628189,
    "estimated_duration": 3599.612464247631,
    "input_throughput": 830.0174059499706,
    "output_throughput": 718.3534410114526,
    "total_throughput": 1548.370846961423,
    "itl": 23.902639621090316,
    "ttft": 7103.662342787392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.737200926391836,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.308177751954645. Arrivals time: 0.0442414996214211 Scheduler time: 0.8946227272972465 Scheduler overhead time: 0.12920451303943992 Adapter cache time: 0.050197817385196686 Engine time: 0.1269707470200956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7932571 . Total output tokens: 7011702
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3034289688803256,
    "estimated_duration": 3599.6286054179027,
    "input_throughput": 830.0136840514787,
    "output_throughput": 718.3502198276923,
    "total_throughput": 1548.363903879171,
    "itl": 23.908543683517447,
    "ttft": 7107.18788295834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 50.01634852472025,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3035187567584217. Arrivals time: 0.04322526417672634 Scheduler time: 0.8916465635411441 Scheduler overhead time: 0.12864447105675936 Adapter cache time: 0.05021719355136156 Engine time: 0.12696014810353518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7932571 . Total output tokens: 7011702
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3002984789200127,
    "estimated_duration": 3599.6159403294528,
    "input_throughput": 830.0166044176782,
    "output_throughput": 718.3527473109637,
    "total_throughput": 1548.3693517286417,
    "itl": 23.876254330522382,
    "ttft": 7098.807311113263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.62341180557095,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3004456358030438. Arrivals time: 0.043624423909932375 Scheduler time: 0.8879743311554193 Scheduler overhead time: 0.12863128306344151 Adapter cache time: 0.05037256609648466 Engine time: 0.1265762448310852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7932571 . Total output tokens: 7011702
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2899081190116704,
    "estimated_duration": 3599.6110662036153,
    "input_throughput": 830.0177283183726,
    "output_throughput": 718.3537200109641,
    "total_throughput": 1548.3714483293368,
    "itl": 23.907776793518753,
    "ttft": 7106.754900866923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.55359538666711,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2900010189041495. Arrivals time: 0.04436320345848799 Scheduler time: 0.8806456224992871 Scheduler overhead time: 0.12789265485480428 Adapter cache time: 0.04969797609373927 Engine time: 0.12441894551739097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7932571 . Total output tokens: 7011702
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.3038966809399426,
    "estimated_duration": 3599.6120124714325,
    "input_throughput": 830.0175101228946,
    "output_throughput": 718.3535311697767,
    "total_throughput": 1548.3710412926712,
    "itl": 23.856134698984963,
    "ttft": 7093.518334529076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.72758285524317,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3039950942620635. Arrivals time: 0.0444779796525836 Scheduler time: 0.89153998112306 Scheduler overhead time: 0.12770665111020207 Adapter cache time: 0.04982073325663805 Engine time: 0.1269775670953095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7932571 . Total output tokens: 7011702
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3224515770561993,
    "estimated_duration": 3599.6134522942166,
    "input_throughput": 830.017178121101,
    "output_throughput": 718.3532438328738,
    "total_throughput": 1548.3704219539748,
    "itl": 23.904937058029933,
    "ttft": 7106.313522144399,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.15110885746589,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3225462199188769. Arrivals time: 0.04479436296969652 Scheduler time: 0.903832433745265 Scheduler overhead time: 0.13196682883426547 Adapter cache time: 0.05051558883860707 Engine time: 0.12751386035233736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7152847 . Total output tokens: 6336847
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2094188760966063,
    "estimated_duration": 3599.3539800226176,
    "input_throughput": 745.5674031769271,
    "output_throughput": 651.8358608300196,
    "total_throughput": 1397.4032640069465,
    "itl": 23.5930130567185,
    "ttft": 7608.7396185314865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.24159513227121,
    "arrivals": 10900,
    "finished_requests": 10878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.209514887072146. Arrivals time: 0.039979427587240934 Scheduler time: 0.8027218850329518 Scheduler overhead time: 0.13002844853326678 Adapter cache time: 0.04818154685199261 Engine time: 0.12468196079134941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7152847 . Total output tokens: 6336847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2110418588854373,
    "estimated_duration": 3599.3586729526837,
    "input_throughput": 745.5664310882855,
    "output_throughput": 651.8350109508085,
    "total_throughput": 1397.401442039094,
    "itl": 23.62269982346718,
    "ttft": 7612.798306701862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6235,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.44686532097272,
    "arrivals": 10900,
    "finished_requests": 10878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2111362051218748. Arrivals time: 0.04052476165816188 Scheduler time: 0.8047635671682656 Scheduler overhead time: 0.12811373407021165 Adapter cache time: 0.04839627956971526 Engine time: 0.1258083670400083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7152847 . Total output tokens: 6336847
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.233101427089423,
    "estimated_duration": 3599.3587340759946,
    "input_throughput": 745.5664184272833,
    "output_throughput": 651.8349998815272,
    "total_throughput": 1397.4014183088107,
    "itl": 23.635364353852385,
    "ttft": 7614.133608694373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6233,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.6300554617899,
    "arrivals": 10900,
    "finished_requests": 10878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.233204266987741. Arrivals time: 0.04143488174304366 Scheduler time: 0.8196822428144515 Scheduler overhead time: 0.12829310400411487 Adapter cache time: 0.049041185062378645 Engine time: 0.13061509327962995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7152847 . Total output tokens: 6336847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.207593115977943,
    "estimated_duration": 3599.36128697449,
    "input_throughput": 745.5658896236329,
    "output_throughput": 651.8345375582265,
    "total_throughput": 1397.4004271818594,
    "itl": 23.599670569335938,
    "ttft": 7610.121803753535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.73040020700683,
    "arrivals": 10900,
    "finished_requests": 10878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2076860750094056. Arrivals time: 0.04035393614321947 Scheduler time: 0.8021294022910297 Scheduler overhead time: 0.12784599792212248 Adapter cache time: 0.04799008695408702 Engine time: 0.1258613313548267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7152847 . Total output tokens: 6336847
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2168861511163414,
    "estimated_duration": 3599.33877507336,
    "input_throughput": 745.5705527316763,
    "output_throughput": 651.8386144277795,
    "total_throughput": 1397.4091671594558,
    "itl": 23.62970584227908,
    "ttft": 7613.600149547012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6233,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.22612509840961,
    "arrivals": 10900,
    "finished_requests": 10878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2169809751212597. Arrivals time: 0.04045500000938773 Scheduler time: 0.8087183102034032 Scheduler overhead time: 0.1288569658063352 Adapter cache time: 0.04875727277249098 Engine time: 0.12622737418860197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7152847 . Total output tokens: 6336847
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2071253880858421,
    "estimated_duration": 3599.3364772619625,
    "input_throughput": 745.5710287028795,
    "output_throughput": 651.8390305606437,
    "total_throughput": 1397.4100592635232,
    "itl": 23.579254218162088,
    "ttft": 7607.303732799866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.83566666916433,
    "arrivals": 10900,
    "finished_requests": 10878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.207219717092812. Arrivals time: 0.041108408477157354 Scheduler time: 0.7988132904283702 Scheduler overhead time: 0.1276139090768993 Adapter cache time: 0.04809522023424506 Engine time: 0.12523213727399707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_64_slots_16_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7152847 . Total output tokens: 6336847
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2025277339853346,
    "estimated_duration": 3599.341535802868,
    "input_throughput": 745.5699808719057,
    "output_throughput": 651.8381144613053,
    "total_throughput": 1397.408095333211,
    "itl": 23.626536489083527,
    "ttft": 7613.375315040963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6235,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.804276285598604,
    "arrivals": 10900,
    "finished_requests": 10878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.20268794009462. Arrivals time: 0.03991322498768568 Scheduler time: 0.7970685223117471 Scheduler overhead time: 0.12850582972168922 Adapter cache time: 0.04811226576566696 Engine time: 0.12566383369266987 
