INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125477304 . Total output tokens: 110439748
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.972543021198362,
    "estimated_duration": 3600.1004455553557,
    "input_throughput": 6566.347622101789,
    "output_throughput": 5736.367446496142,
    "total_throughput": 12302.71506859793,
    "itl": 95.66798524011392,
    "ttft": 1450961.6332957165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6281788580352434,
    "arrivals": 186986,
    "finished_requests": 95635,
    "scheduler_time": 46.90534197004146
}
#Debug simulation 
Total elapsed time: 6.972670299001038. Arrivals time: 0.29525271942839026 Scheduler time: 6.516940085217357 Scheduler overhead time: 0.05485909711569548 Adapter cache time: 0.022189670242369175 Engine time: 0.05710822343826294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125477304 . Total output tokens: 110439748
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.582850383128971,
    "estimated_duration": 3600.0439530093595,
    "input_throughput": 6371.108325171153,
    "output_throughput": 5570.593376571439,
    "total_throughput": 11941.701701742593,
    "itl": 86.56941440415052,
    "ttft": 1485921.269728329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6939304106729111,
    "arrivals": 186986,
    "finished_requests": 92813,
    "scheduler_time": 40.342669541080284
}
#Debug simulation 
Total elapsed time: 6.582966831047088. Arrivals time: 0.3098028968088329 Scheduler time: 6.100844433531165 Scheduler overhead time: 0.05899645900353789 Adapter cache time: 0.023466807324439287 Engine time: 0.061382141429930925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125477304 . Total output tokens: 110439748
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.074167730286717,
    "estimated_duration": 3600.0463288304063,
    "input_throughput": 5791.867408210308,
    "output_throughput": 5061.370142400291,
    "total_throughput": 10853.2375506106,
    "itl": 68.0838820626116,
    "ttft": 1595249.9601136176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.71254516587127,
    "arrivals": 186986,
    "finished_requests": 84322,
    "scheduler_time": 20.991196952634283
}
#Debug simulation 
Total elapsed time: 6.074269752949476. Arrivals time: 0.2701772218570113 Scheduler time: 5.597474025562406 Scheduler overhead time: 0.07174187013879418 Adapter cache time: 0.02577590150758624 Engine time: 0.0745924822986126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125477304 . Total output tokens: 110439748
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.548929307144135,
    "estimated_duration": 3600.007504271341,
    "input_throughput": 6371.172830275089,
    "output_throughput": 5570.649776759036,
    "total_throughput": 11941.822607034124,
    "itl": 86.57085296853634,
    "ttft": 1485960.7174693958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.649507339526899,
    "arrivals": 186986,
    "finished_requests": 92813,
    "scheduler_time": 40.34235057821557
}
#Debug simulation 
Total elapsed time: 6.549029984977096. Arrivals time: 0.3061730107292533 Scheduler time: 6.071025599259883 Scheduler overhead time: 0.05899285478517413 Adapter cache time: 0.023145252838730812 Engine time: 0.06123529048636556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125477304 . Total output tokens: 110439748
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.130414943210781,
    "estimated_duration": 3600.056436049043,
    "input_throughput": 5792.713078377949,
    "output_throughput": 5061.631483754818,
    "total_throughput": 10854.344562132766,
    "itl": 68.08144015743838,
    "ttft": 1595329.3824882603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7059174162195997,
    "arrivals": 186986,
    "finished_requests": 84330,
    "scheduler_time": 20.99027740796569
}
#Debug simulation 
Total elapsed time: 6.130520381964743. Arrivals time: 0.29079930391162634 Scheduler time: 5.632092415355146 Scheduler overhead time: 0.07232232019305229 Adapter cache time: 0.025621248874813318 Engine time: 0.07487589539960027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125477304 . Total output tokens: 110439748
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.603385372087359,
    "estimated_duration": 3600.0682955100665,
    "input_throughput": 6371.166632756971,
    "output_throughput": 5570.657096981155,
    "total_throughput": 11941.823729738126,
    "itl": 86.56927904439657,
    "ttft": 1485945.466061026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6064724893542007,
    "arrivals": 186986,
    "finished_requests": 92816,
    "scheduler_time": 40.345038906422765
}
#Debug simulation 
Total elapsed time: 6.603485846891999. Arrivals time: 0.2932781260460615 Scheduler time: 6.136560540180653 Scheduler overhead time: 0.059257537592202425 Adapter cache time: 0.023154161870479584 Engine time: 0.06260087387636304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125477304 . Total output tokens: 110439748
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.106662644073367,
    "estimated_duration": 3600.0322266283033,
    "input_throughput": 5792.293981637453,
    "output_throughput": 5061.370246972874,
    "total_throughput": 10853.664228610327,
    "itl": 68.0820454131289,
    "ttft": 1595424.6228765568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6994967837445439,
    "arrivals": 186986,
    "finished_requests": 84323,
    "scheduler_time": 20.990968330521753
}
#Debug simulation 
Total elapsed time: 6.106764710973948. Arrivals time: 0.2729845722205937 Scheduler time: 5.626051881816238 Scheduler overhead time: 0.07215542579069734 Adapter cache time: 0.025876617059111595 Engine time: 0.07504359446465969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124740686 . Total output tokens: 109789483
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.856753962114453,
    "estimated_duration": 3600.0379916793745,
    "input_throughput": 6657.965847971172,
    "output_throughput": 5831.39568207915,
    "total_throughput": 12489.361530050322,
    "itl": 94.11251752520151,
    "ttft": 1429653.9879345605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 186004,
    "finished_requests": 96935,
    "scheduler_time": 47.85302555467589
}
#Debug simulation 
Total elapsed time: 6.856885417830199. Arrivals time: 0.3207126106135547 Scheduler time: 6.37509028846398 Scheduler overhead time: 0.05582309793680906 Adapter cache time: 0.020486959721893072 Engine time: 0.05796801298856735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124740686 . Total output tokens: 109789483
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.716772209387273,
    "estimated_duration": 3600.0522144711304,
    "input_throughput": 6452.178917469496,
    "output_throughput": 5655.198810218052,
    "total_throughput": 12107.377727687548,
    "itl": 85.28290306224727,
    "ttft": 1467504.0667527614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867943,
    "arrivals": 186004,
    "finished_requests": 93973,
    "scheduler_time": 41.11086198069289
}
#Debug simulation 
Total elapsed time: 6.716873844154179. Arrivals time: 0.3050300036557019 Scheduler time: 6.2386267660185695 Scheduler overhead time: 0.06024279771372676 Adapter cache time: 0.021577535662800074 Engine time: 0.06242314027622342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124740686 . Total output tokens: 109789483
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.445764367934316,
    "estimated_duration": 3600.0153685367923,
    "input_throughput": 5838.798685057663,
    "output_throughput": 5121.185359687328,
    "total_throughput": 10959.98404474499,
    "itl": 67.27703283750515,
    "ttft": 1581310.399314772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 186004,
    "finished_requests": 84941,
    "scheduler_time": 21.299964085684408
}
#Debug simulation 
Total elapsed time: 6.445833756122738. Arrivals time: 0.28057807916775346 Scheduler time: 5.9566027275286615 Scheduler overhead time: 0.07315349439159036 Adapter cache time: 0.023232384584844112 Engine time: 0.07695375196635723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124740686 . Total output tokens: 109789483
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.6971259312704206,
    "estimated_duration": 3600.0671048823897,
    "input_throughput": 6452.1522303009515,
    "output_throughput": 5655.175419477384,
    "total_throughput": 12107.327649778335,
    "itl": 85.28140513817651,
    "ttft": 1467467.3260637976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 186004,
    "finished_requests": 93973,
    "scheduler_time": 41.111143226368384
}
#Debug simulation 
Total elapsed time: 6.6972301178611815. Arrivals time: 0.2950277393683791 Scheduler time: 6.228920048568398 Scheduler overhead time: 0.06045042397454381 Adapter cache time: 0.021538912784308195 Engine time: 0.06238756747916341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124740686 . Total output tokens: 109789483
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.224028918892145,
    "estimated_duration": 3600.0285026490155,
    "input_throughput": 5838.52544071072,
    "output_throughput": 5121.2205643465895,
    "total_throughput": 10959.74600505731,
    "itl": 67.27644268468136,
    "ttft": 1581336.0850467363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 186004,
    "finished_requests": 84938,
    "scheduler_time": 21.29909659674278
}
#Debug simulation 
Total elapsed time: 6.224157746881247. Arrivals time: 0.29192859726026654 Scheduler time: 5.725744095630944 Scheduler overhead time: 0.07278361544013023 Adapter cache time: 0.022901872638612986 Engine time: 0.07573133427649736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124740686 . Total output tokens: 109789483
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.934664661996067,
    "estimated_duration": 3600.0565637788104,
    "input_throughput": 6452.394730047692,
    "output_throughput": 5655.371141899344,
    "total_throughput": 12107.765871947036,
    "itl": 85.28071346469737,
    "ttft": 1467483.623700092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 186004,
    "finished_requests": 93975,
    "scheduler_time": 41.1135120586018
}
#Debug simulation 
Total elapsed time: 6.934734178241342. Arrivals time: 0.5395969497039914 Scheduler time: 6.222536440007389 Scheduler overhead time: 0.0601152628660202 Adapter cache time: 0.021192758809775114 Engine time: 0.06223964923992753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124740686 . Total output tokens: 109789483
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.171792340930551,
    "estimated_duration": 3600.07318905584,
    "input_throughput": 5838.576300031431,
    "output_throughput": 5121.23532822822,
    "total_throughput": 10959.811628259651,
    "itl": 67.27796823808525,
    "ttft": 1581366.5034871313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 186004,
    "finished_requests": 84940,
    "scheduler_time": 21.300632798727964
}
#Debug simulation 
Total elapsed time: 6.171924950089306. Arrivals time: 0.2941852752119303 Scheduler time: 5.67093967879191 Scheduler overhead time: 0.07274661492556334 Adapter cache time: 0.022778845392167568 Engine time: 0.07624976616352797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124498388 . Total output tokens: 109587810
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.896284318994731,
    "estimated_duration": 3600.0681959371836,
    "input_throughput": 6714.751966999071,
    "output_throughput": 5874.480384529086,
    "total_throughput": 12589.232351528157,
    "itl": 93.47633961921905,
    "ttft": 1417953.8417007753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 185665,
    "finished_requests": 98076,
    "scheduler_time": 48.24635338548114
}
#Debug simulation 
Total elapsed time: 6.89638263033703. Arrivals time: 0.310310366563499 Scheduler time: 6.427800675854087 Scheduler overhead time: 0.05561673175543547 Adapter cache time: 0.018696392886340618 Engine time: 0.05725831678137183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124498388 . Total output tokens: 109587810
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.721924290060997,
    "estimated_duration": 3600.0685272367487,
    "input_throughput": 6495.151362562461,
    "output_throughput": 5688.661992142467,
    "total_throughput": 12183.813354704927,
    "itl": 84.79014212870842,
    "ttft": 1455445.0376674738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867946,
    "arrivals": 185665,
    "finished_requests": 94865,
    "scheduler_time": 41.41478625935831
}
#Debug simulation 
Total elapsed time: 6.722024604212493. Arrivals time: 0.2979505085386336 Scheduler time: 6.251451195217669 Scheduler overhead time: 0.06046145875006914 Adapter cache time: 0.01945078605785966 Engine time: 0.0636294512078166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124498388 . Total output tokens: 109587810
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.199187781661749,
    "estimated_duration": 3600.0052470249766,
    "input_throughput": 5875.387547692997,
    "output_throughput": 5142.551393584554,
    "total_throughput": 11017.93894127755,
    "itl": 66.96906613108324,
    "ttft": 1572132.5302948542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 185665,
    "finished_requests": 85717,
    "scheduler_time": 21.447566980333246
}
#Debug simulation 
Total elapsed time: 6.199320429936051. Arrivals time: 0.30406463146209717 Scheduler time: 5.688049187418073 Scheduler overhead time: 0.0737305604852736 Adapter cache time: 0.021421208046376705 Engine time: 0.07639162382110953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124498388 . Total output tokens: 109587810
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.817536145914346,
    "estimated_duration": 3600.092615328819,
    "input_throughput": 6494.979295932454,
    "output_throughput": 5688.365325048605,
    "total_throughput": 12183.344620981059,
    "itl": 84.78912703184284,
    "ttft": 1455429.4087526512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 185665,
    "finished_requests": 94862,
    "scheduler_time": 41.415942772794814
}
#Debug simulation 
Total elapsed time: 6.817662112880498. Arrivals time: 0.2985002654604614 Scheduler time: 6.346412213984877 Scheduler overhead time: 0.06058518495410681 Adapter cache time: 0.019417838659137487 Engine time: 0.06355918245390058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124498388 . Total output tokens: 109587810
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.234945299103856,
    "estimated_duration": 3600.0167458169676,
    "input_throughput": 5874.810728193007,
    "output_throughput": 5142.181913878571,
    "total_throughput": 11016.992642071578,
    "itl": 66.96980760796333,
    "ttft": 1572126.0976566758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 185665,
    "finished_requests": 85712,
    "scheduler_time": 21.45112082462156
}
#Debug simulation 
Total elapsed time: 6.23505398305133. Arrivals time: 0.3008489669300616 Scheduler time: 5.72811560286209 Scheduler overhead time: 0.07339131971821189 Adapter cache time: 0.02110083634033799 Engine time: 0.07621227204799652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124498388 . Total output tokens: 109587810
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.751316100824624,
    "estimated_duration": 3600.0331036209836,
    "input_throughput": 6494.95666483785,
    "output_throughput": 5688.342693127628,
    "total_throughput": 12183.29935796548,
    "itl": 84.78910562503091,
    "ttft": 1455419.9658603002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 185665,
    "finished_requests": 94861,
    "scheduler_time": 41.41668342691684
}
#Debug simulation 
Total elapsed time: 6.7514206282794476. Arrivals time: 0.29832915496081114 Scheduler time: 6.281982305459678 Scheduler overhead time: 0.06014857580885291 Adapter cache time: 0.019335868768393993 Engine time: 0.06261289725080132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124498388 . Total output tokens: 109587810
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.184961843304336,
    "estimated_duration": 3600.0203894482997,
    "input_throughput": 5874.990058942759,
    "output_throughput": 5142.328375211515,
    "total_throughput": 11017.318434154273,
    "itl": 66.96869538422635,
    "ttft": 1572175.0352829827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 185665,
    "finished_requests": 85715,
    "scheduler_time": 21.448337741501394
}
#Debug simulation 
Total elapsed time: 6.185062650125474. Arrivals time: 0.2831202717497945 Scheduler time: 5.6961273099295795 Scheduler overhead time: 0.07334498828276992 Adapter cache time: 0.0212822244502604 Engine time: 0.07610450871288776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 124006175 . Total output tokens: 109143041
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.969490315765142,
    "estimated_duration": 3600.0556599297224,
    "input_throughput": 6852.527385779802,
    "output_throughput": 5965.615265075999,
    "total_throughput": 12818.1426508558,
    "itl": 92.16996837531158,
    "ttft": 1387228.459666008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 184921,
    "finished_requests": 99897,
    "scheduler_time": 49.322353269287774
}
#Debug simulation 
Total elapsed time: 6.969588878098875. Arrivals time: 0.3264225162565708 Scheduler time: 6.485500785056502 Scheduler overhead time: 0.05604594433680177 Adapter cache time: 0.01593612041324377 Engine time: 0.05855274200439453 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 124006175 . Total output tokens: 109143041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.831618098076433,
    "estimated_duration": 3600.079579361421,
    "input_throughput": 6631.526185383589,
    "output_throughput": 5778.011441538666,
    "total_throughput": 12409.537626922254,
    "itl": 83.72004099827093,
    "ttft": 1428310.7876778683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867941,
    "arrivals": 184921,
    "finished_requests": 96704,
    "scheduler_time": 42.39263276009236
}
#Debug simulation 
Total elapsed time: 6.831723337993026. Arrivals time: 0.3023744020611048 Scheduler time: 6.358885919675231 Scheduler overhead time: 0.061007408425211906 Adapter cache time: 0.016831540502607822 Engine time: 0.06323646893724799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 124006175 . Total output tokens: 109143041
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.27710605179891,
    "estimated_duration": 3600.0150503074933,
    "input_throughput": 5973.02002894775,
    "output_throughput": 5208.27294830295,
    "total_throughput": 11181.2929772507,
    "itl": 66.45443319823387,
    "ttft": 1550384.7880383823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.71254516587127,
    "arrivals": 184921,
    "finished_requests": 87148,
    "scheduler_time": 22.21075131627983
}
#Debug simulation 
Total elapsed time: 6.2772096721455455. Arrivals time: 0.2852158057503402 Scheduler time: 5.787699417676777 Scheduler overhead time: 0.07363273808732629 Adapter cache time: 0.018507246859371662 Engine time: 0.07676660921424627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 124006175 . Total output tokens: 109143041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.838488186709583,
    "estimated_duration": 3600.0308477850217,
    "input_throughput": 6631.51900897979,
    "output_throughput": 5778.074933107396,
    "total_throughput": 12409.593942087185,
    "itl": 83.71894186123123,
    "ttft": 1428290.1273939563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407826,
    "arrivals": 184921,
    "finished_requests": 96703,
    "scheduler_time": 42.39371785811213
}
#Debug simulation 
Total elapsed time: 6.8385952319949865. Arrivals time: 0.31583473226055503 Scheduler time: 6.351371762342751 Scheduler overhead time: 0.06110997684299946 Adapter cache time: 0.017337961588054895 Engine time: 0.0635397988371551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 124006175 . Total output tokens: 109143041
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.518515064846724,
    "estimated_duration": 3600.0696694980657,
    "input_throughput": 5973.401065596116,
    "output_throughput": 5208.694198024902,
    "total_throughput": 11182.095263621017,
    "itl": 66.45248791055805,
    "ttft": 1550361.2231638862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7061245333962144,
    "arrivals": 184921,
    "finished_requests": 87157,
    "scheduler_time": 22.209923399878917
}
#Debug simulation 
Total elapsed time: 6.518597586080432. Arrivals time: 0.2839671359397471 Scheduler time: 6.030796248931438 Scheduler overhead time: 0.07363819843158126 Adapter cache time: 0.018459446728229523 Engine time: 0.0762594910338521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 124006175 . Total output tokens: 109143041
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.800977170001715,
    "estimated_duration": 3600.034046614781,
    "input_throughput": 6631.680614923543,
    "output_throughput": 5778.143409382554,
    "total_throughput": 12409.824024306095,
    "itl": 83.71811579707826,
    "ttft": 1428234.699306898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 184921,
    "finished_requests": 96705,
    "scheduler_time": 42.3940447028523
}
#Debug simulation 
Total elapsed time: 6.801108140964061. Arrivals time: 0.30260543106123805 Scheduler time: 6.3280316879972816 Scheduler overhead time: 0.06098589859902859 Adapter cache time: 0.01687291217967868 Engine time: 0.06325880717486143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 124006175 . Total output tokens: 109143041
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.271201805677265,
    "estimated_duration": 3600.054223034383,
    "input_throughput": 5973.156421481662,
    "output_throughput": 5208.549326847435,
    "total_throughput": 11181.705748329096,
    "itl": 66.45314750653536,
    "ttft": 1550340.7218926298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6994967837445439,
    "arrivals": 184921,
    "finished_requests": 87153,
    "scheduler_time": 22.211172874526806
}
#Debug simulation 
Total elapsed time: 6.271305163856596. Arrivals time: 0.2930608429014683 Scheduler time: 5.773689850233495 Scheduler overhead time: 0.07375013781711459 Adapter cache time: 0.018565104342997074 Engine time: 0.07681689923629165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_96_slots_96_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_96_slots_96_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100196291 . Total output tokens: 88073645
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.213871669024229,
    "estimated_duration": 3600.130281627482,
    "input_throughput": 4908.8220751863955,
    "output_throughput": 4330.038298767605,
    "total_throughput": 9238.860373954001,
    "itl": 126.73656550604967,
    "ttft": 1630432.4780930665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 149510,
    "finished_requests": 72002,
    "scheduler_time": 36.14414301147705
}
#Debug simulation 
Total elapsed time: 5.213976790197194. Arrivals time: 0.2603943385183811 Scheduler time: 4.822249279357493 Scheduler overhead time: 0.041714916471391916 Adapter cache time: 0.02608800632879138 Engine time: 0.043345989659428596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_96_slots_96_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_96_slots_96_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100196291 . Total output tokens: 88073645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.109714090358466,
    "estimated_duration": 3600.1152721438475,
    "input_throughput": 4766.225163057609,
    "output_throughput": 4209.370493566377,
    "total_throughput": 8975.595656623987,
    "itl": 114.61276466944064,
    "ttft": 1664082.416336037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867943,
    "arrivals": 149510,
    "finished_requests": 69915,
    "scheduler_time": 31.2685788253548
}
#Debug simulation 
Total elapsed time: 5.109814275056124. Arrivals time: 0.24502156861126423 Scheduler time: 4.720454259775579 Scheduler overhead time: 0.04529127571731806 Adapter cache time: 0.03008612059056759 Engine time: 0.046929558739066124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_96_slots_96_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_96_slots_96_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100196291 . Total output tokens: 88073645
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.809701969847083,
    "estimated_duration": 3600.0630416103445,
    "input_throughput": 4353.368210182669,
    "output_throughput": 3855.6019268460236,
    "total_throughput": 8208.970137028693,
    "itl": 89.53774880603396,
    "ttft": 1763236.6700748692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 149510,
    "finished_requests": 63910,
    "scheduler_time": 17.0037642953046
}
#Debug simulation 
Total elapsed time: 4.809801487252116. Arrivals time: 0.2331924196332693 Scheduler time: 4.39119072817266 Scheduler overhead time: 0.05578999826684594 Adapter cache time: 0.04496890911832452 Engine time: 0.05779794789850712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_96_slots_96_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_96_slots_96_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100196291 . Total output tokens: 88073645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.090631008148193,
    "estimated_duration": 3600.037334376325,
    "input_throughput": 4766.378625062974,
    "output_throughput": 4209.465233955786,
    "total_throughput": 8975.84385901876,
    "itl": 114.61018656107768,
    "ttft": 1663999.0619052278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407827,
    "arrivals": 149510,
    "finished_requests": 69915,
    "scheduler_time": 31.26700226632292
}
#Debug simulation 
Total elapsed time: 5.090735803358257. Arrivals time: 0.24418768053874373 Scheduler time: 4.702322004362941 Scheduler overhead time: 0.04521042434498668 Adapter cache time: 0.03013781551271677 Engine time: 0.04701688652858138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_96_slots_96_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_96_slots_96_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100196291 . Total output tokens: 88073645
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.786231883335859,
    "estimated_duration": 3600.0922517173913,
    "input_throughput": 4353.26344554747,
    "output_throughput": 3855.5609216342978,
    "total_throughput": 8208.824367181767,
    "itl": 89.53570814020179,
    "ttft": 1763120.414204592,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 149510,
    "finished_requests": 63910,
    "scheduler_time": 17.00328618565194
}
#Debug simulation 
Total elapsed time: 4.786368730012327. Arrivals time: 0.2286637886427343 Scheduler time: 4.373000979423523 Scheduler overhead time: 0.05563054885715246 Adapter cache time: 0.04444956732913852 Engine time: 0.0576800387352705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_96_slots_96_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_96_slots_96_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100196291 . Total output tokens: 88073645
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.14361134916544,
    "estimated_duration": 3600.098074408393,
    "input_throughput": 4756.888741930789,
    "output_throughput": 4201.556093019957,
    "total_throughput": 8958.444834950747,
    "itl": 114.54399647721362,
    "ttft": 1664644.1048719177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 149510,
    "finished_requests": 69792,
    "scheduler_time": 31.14994440462575
}
#Debug simulation 
Total elapsed time: 5.143739655148238. Arrivals time: 0.2635015086270869 Scheduler time: 4.736202699597925 Scheduler overhead time: 0.04546215385198593 Adapter cache time: 0.029135876335203648 Engine time: 0.04727396834641695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_96_slots_96_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_96_slots_96_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100196291 . Total output tokens: 88073645
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.824719450902194,
    "estimated_duration": 3600.0955858616535,
    "input_throughput": 4353.576072133297,
    "output_throughput": 3855.7117912405965,
    "total_throughput": 8209.287863373895,
    "itl": 89.53333172611484,
    "ttft": 1763069.241717799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 149510,
    "finished_requests": 63915,
    "scheduler_time": 17.002702441808516
}
#Debug simulation 
Total elapsed time: 4.82481865119189. Arrivals time: 0.2329459534958005 Scheduler time: 4.406319413334131 Scheduler overhead time: 0.05575176142156124 Adapter cache time: 0.045053218491375446 Engine time: 0.05772103741765022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_96_slots_96_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_96_slots_96_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96400063 . Total output tokens: 84684380
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.441133342217654,
    "estimated_duration": 3600.098133163822,
    "input_throughput": 5193.527317425818,
    "output_throughput": 4515.554131774067,
    "total_throughput": 9709.081449199884,
    "itl": 121.0851848324144,
    "ttft": 1543127.688000293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 143761,
    "finished_requests": 75580,
    "scheduler_time": 38.276186060103996
}
#Debug simulation 
Total elapsed time: 5.441242374014109. Arrivals time: 0.2552887871861458 Scheduler time: 5.048792478162795 Scheduler overhead time: 0.043764648493379354 Adapter cache time: 0.026422612834721804 Engine time: 0.04575706459581852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_96_slots_96_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_96_slots_96_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96400063 . Total output tokens: 84684380
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.298981351777911,
    "estimated_duration": 3600.0171784274235,
    "input_throughput": 5044.281207550382,
    "output_throughput": 4387.189343051744,
    "total_throughput": 9431.470550602126,
    "itl": 109.51768609764737,
    "ttft": 1578225.2760796433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867943,
    "arrivals": 143761,
    "finished_requests": 73413,
    "scheduler_time": 33.21033773265593
}
#Debug simulation 
Total elapsed time: 5.299115216825157. Arrivals time: 0.2495939778164029 Scheduler time: 4.900475133676082 Scheduler overhead time: 0.04724459396675229 Adapter cache time: 0.029699149075895548 Engine time: 0.04917880613356829 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_96_slots_96_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_96_slots_96_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96400063 . Total output tokens: 84684380
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.963967453222722,
    "estimated_duration": 3600.0916708217446,
    "input_throughput": 4607.325734073309,
    "output_throughput": 4008.468205673791,
    "total_throughput": 8615.7939397471,
    "itl": 85.73168238843515,
    "ttft": 1686797.927383412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 143761,
    "finished_requests": 67035,
    "scheduler_time": 18.227886680845874
}
#Debug simulation 
Total elapsed time: 4.964088695123792. Arrivals time: 0.24222063831984997 Scheduler time: 4.537309308536351 Scheduler overhead time: 0.05780403409153223 Adapter cache time: 0.038492449559271336 Engine time: 0.06019869772717357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_96_slots_96_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_96_slots_96_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96400063 . Total output tokens: 84684380
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.313696130178869,
    "estimated_duration": 3600.080705907547,
    "input_throughput": 5044.25469412417,
    "output_throughput": 4387.1124816960155,
    "total_throughput": 9431.367175820185,
    "itl": 109.51678974503055,
    "ttft": 1578350.6922529568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407826,
    "arrivals": 143761,
    "finished_requests": 73414,
    "scheduler_time": 33.21180576391838
}
#Debug simulation 
Total elapsed time: 5.313824439421296. Arrivals time: 0.24918728787451982 Scheduler time: 4.91501427302137 Scheduler overhead time: 0.047705241944640875 Adapter cache time: 0.029646176379173994 Engine time: 0.0492295459844172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_96_slots_96_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_96_slots_96_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96400063 . Total output tokens: 84684380
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.959468121174723,
    "estimated_duration": 3600.005832599637,
    "input_throughput": 4607.311146499634,
    "output_throughput": 4008.4865611396494,
    "total_throughput": 8615.797707639284,
    "itl": 85.7304087370972,
    "ttft": 1686787.5428555685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 143761,
    "finished_requests": 67032,
    "scheduler_time": 18.227414252123005
}
#Debug simulation 
Total elapsed time: 4.959568321239203. Arrivals time: 0.23699938505887985 Scheduler time: 4.53767509944737 Scheduler overhead time: 0.05776945734396577 Adapter cache time: 0.03877125680446625 Engine time: 0.060368772596120834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_96_slots_96_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_96_slots_96_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96400063 . Total output tokens: 84684380
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.305001421831548,
    "estimated_duration": 3600.091138264651,
    "input_throughput": 5044.161189972924,
    "output_throughput": 4387.031714872927,
    "total_throughput": 9431.192904845851,
    "itl": 109.51388520772642,
    "ttft": 1578232.1973801367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 143761,
    "finished_requests": 73412,
    "scheduler_time": 33.212038986688135
}
#Debug simulation 
Total elapsed time: 5.305104549974203. Arrivals time: 0.24843638762831688 Scheduler time: 4.907700098585337 Scheduler overhead time: 0.0475072325207293 Adapter cache time: 0.02932118298485875 Engine time: 0.04920427780598402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_96_slots_96_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_96_slots_96_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96400063 . Total output tokens: 84684380
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.950321416836232,
    "estimated_duration": 3600.033816187907,
    "input_throughput": 4607.221167039802,
    "output_throughput": 4008.348181373528,
    "total_throughput": 8615.56934841333,
    "itl": 85.73299457988708,
    "ttft": 1686762.718705926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 143761,
    "finished_requests": 67031,
    "scheduler_time": 18.229037105025803
}
#Debug simulation 
Total elapsed time: 4.950425229035318. Arrivals time: 0.24303252389654517 Scheduler time: 4.522855068556964 Scheduler overhead time: 0.05770081887021661 Adapter cache time: 0.03855741769075394 Engine time: 0.06022958271205425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_96_slots_96_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_96_slots_96_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94478793 . Total output tokens: 83015150
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.569875305052847,
    "estimated_duration": 3600.0339270704812,
    "input_throughput": 5458.4116144679,
    "output_throughput": 4674.958997871273,
    "total_throughput": 10133.370612339173,
    "itl": 116.55556825897175,
    "ttft": 1482014.7545739172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 140843,
    "finished_requests": 78605,
    "scheduler_time": 40.07565360569201
}
#Debug simulation 
Total elapsed time: 5.569981484673917. Arrivals time: 0.2593401097692549 Scheduler time: 5.1743369698524475 Scheduler overhead time: 0.04513967223465443 Adapter cache time: 0.02249804139137268 Engine time: 0.046634284779429436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_96_slots_96_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_96_slots_96_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94478793 . Total output tokens: 83015150
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.451523791067302,
    "estimated_duration": 3600.0492385302855,
    "input_throughput": 5294.4131419106025,
    "output_throughput": 4533.626325250801,
    "total_throughput": 9828.039467161403,
    "itl": 105.68374041888943,
    "ttft": 1520225.6826536416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867946,
    "arrivals": 140843,
    "finished_requests": 76235,
    "scheduler_time": 34.76475613116817
}
#Debug simulation 
Total elapsed time: 5.451625380199403. Arrivals time: 0.2558753425255418 Scheduler time: 5.048372144810855 Scheduler overhead time: 0.04882624698802829 Adapter cache time: 0.024374472443014383 Engine time: 0.0504543068818748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_96_slots_96_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_96_slots_96_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94478793 . Total output tokens: 83015150
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.06241991603747,
    "estimated_duration": 3600.071741702843,
    "input_throughput": 4771.299638566432,
    "output_throughput": 4089.7379431210493,
    "total_throughput": 8861.037581687482,
    "itl": 83.18693979981519,
    "ttft": 1644596.2328408023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 140843,
    "finished_requests": 68733,
    "scheduler_time": 18.715336920155206
}
#Debug simulation 
Total elapsed time: 5.062543531879783. Arrivals time: 0.2533179959282279 Scheduler time: 4.6288594412617385 Scheduler overhead time: 0.059089713264256716 Adapter cache time: 0.031033244915306568 Engine time: 0.061546290293335915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_96_slots_96_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_96_slots_96_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94478793 . Total output tokens: 83015150
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.4517271113581955,
    "estimated_duration": 3600.0674007041744,
    "input_throughput": 5294.293655799859,
    "output_throughput": 4533.568453970494,
    "total_throughput": 9827.862109770354,
    "itl": 105.68300477020783,
    "ttft": 1520248.6503553493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 140843,
    "finished_requests": 76234,
    "scheduler_time": 34.76650345925207
}
#Debug simulation 
Total elapsed time: 5.451828359160572. Arrivals time: 0.2573258373886347 Scheduler time: 5.046731134410948 Scheduler overhead time: 0.04882820323109627 Adapter cache time: 0.02470000134781003 Engine time: 0.050621919333934784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_96_slots_96_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_96_slots_96_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94478793 . Total output tokens: 83015150
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.043497716076672,
    "estimated_duration": 3600.0020949615823,
    "input_throughput": 4776.1816650230285,
    "output_throughput": 4093.4278956738385,
    "total_throughput": 8869.609560696867,
    "itl": 83.3403254944112,
    "ttft": 1644180.3105400545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 140843,
    "finished_requests": 68796,
    "scheduler_time": 18.854226467455916
}
#Debug simulation 
Total elapsed time: 5.0436252797953784. Arrivals time: 0.24263549037277699 Scheduler time: 4.6214197794906795 Scheduler overhead time: 0.0589133738540113 Adapter cache time: 0.03052924247458577 Engine time: 0.061432268004864454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_96_slots_96_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_96_slots_96_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94478793 . Total output tokens: 83015150
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.468133476097137,
    "estimated_duration": 3600.1081014107103,
    "input_throughput": 5294.569624876235,
    "output_throughput": 4533.968853214125,
    "total_throughput": 9828.53847809036,
    "itl": 105.68074887752014,
    "ttft": 1520093.6728921053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 140843,
    "finished_requests": 76239,
    "scheduler_time": 34.76662930748467
}
#Debug simulation 
Total elapsed time: 5.468264155089855. Arrivals time: 0.27226509153842926 Scheduler time: 5.048478953540325 Scheduler overhead time: 0.04875319031998515 Adapter cache time: 0.024709546472877264 Engine time: 0.0505277318879962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_96_slots_96_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_96_slots_96_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94478793 . Total output tokens: 83015150
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.037254705093801,
    "estimated_duration": 3600.0113395562576,
    "input_throughput": 4771.124971544437,
    "output_throughput": 4089.524618501534,
    "total_throughput": 8860.64959004597,
    "itl": 83.18794009832088,
    "ttft": 1644708.1447539313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 140843,
    "finished_requests": 68730,
    "scheduler_time": 18.714581761815907
}
#Debug simulation 
Total elapsed time: 5.03735326975584. Arrivals time: 0.24250220088288188 Scheduler time: 4.614228035323322 Scheduler overhead time: 0.059425851330161095 Adapter cache time: 0.03085234621539712 Engine time: 0.061715525574982166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93499750 . Total output tokens: 82168737
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.698381124064326,
    "estimated_duration": 3600.120027651655,
    "input_throughput": 5515.555550227704,
    "output_throughput": 4796.4295266187755,
    "total_throughput": 10311.985076846478,
    "itl": 113.86675025141759,
    "ttft": 1446209.404140092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 139377,
    "finished_requests": 80011,
    "scheduler_time": 41.52951784297213
}
#Debug simulation 
Total elapsed time: 5.698482433333993. Arrivals time: 0.2786529567092657 Scheduler time: 5.286656324751675 Scheduler overhead time: 0.045821056701242924 Adapter cache time: 0.017535141203552485 Engine time: 0.04758177092298865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93499750 . Total output tokens: 82168737
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.622724890243262,
    "estimated_duration": 3600.0871180190998,
    "input_throughput": 5338.846913953495,
    "output_throughput": 4641.0232453467415,
    "total_throughput": 9979.870159300235,
    "itl": 103.39177035393051,
    "ttft": 1489350.1333319321,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867945,
    "arrivals": 139377,
    "finished_requests": 77377,
    "scheduler_time": 35.9728248841265
}
#Debug simulation 
Total elapsed time: 5.622867010999471. Arrivals time: 0.29000493232160807 Scheduler time: 5.187371970620006 Scheduler overhead time: 0.049784410279244184 Adapter cache time: 0.019330648239701986 Engine time: 0.05197818065062165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93499750 . Total output tokens: 82168737
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.130175278056413,
    "estimated_duration": 3600.057284787544,
    "input_throughput": 4816.451691830032,
    "output_throughput": 4195.985176077958,
    "total_throughput": 9012.43686790799,
    "itl": 81.83608473913871,
    "ttft": 1616319.3534119404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 139377,
    "finished_requests": 69953,
    "scheduler_time": 19.889760855749707
}
#Debug simulation 
Total elapsed time: 5.130309073720127. Arrivals time: 0.25956803653389215 Scheduler time: 4.693404519464821 Scheduler overhead time: 0.06012552045285702 Adapter cache time: 0.025456732138991356 Engine time: 0.06261929264292121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93499750 . Total output tokens: 82168737
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.56112457299605,
    "estimated_duration": 3600.0524010895497,
    "input_throughput": 5338.898676636763,
    "output_throughput": 4641.089389405361,
    "total_throughput": 9979.988066042124,
    "itl": 103.39056891668493,
    "ttft": 1489368.4139126553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407829,
    "arrivals": 139377,
    "finished_requests": 77378,
    "scheduler_time": 35.97260278572488
}
#Debug simulation 
Total elapsed time: 5.5612309188582. Arrivals time: 0.2731266636401415 Scheduler time: 5.143962847534567 Scheduler overhead time: 0.04960689693689346 Adapter cache time: 0.01896790135651827 Engine time: 0.05155863519757986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93499750 . Total output tokens: 82168737
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.140344910789281,
    "estimated_duration": 3600.069638983064,
    "input_throughput": 4816.283221926188,
    "output_throughput": 4195.880500874683,
    "total_throughput": 9012.163722800871,
    "itl": 81.83809565043116,
    "ttft": 1616403.2208517555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 139377,
    "finished_requests": 69949,
    "scheduler_time": 19.89063766620457
}
#Debug simulation 
Total elapsed time: 5.140472579747438. Arrivals time: 0.26319669652730227 Scheduler time: 4.700284654740244 Scheduler overhead time: 0.059909401927143335 Adapter cache time: 0.025439494755119085 Engine time: 0.06249456759542227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93499750 . Total output tokens: 82168737
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.587449250277132,
    "estimated_duration": 3600.005580305857,
    "input_throughput": 5338.916446448135,
    "output_throughput": 4641.052528196498,
    "total_throughput": 9979.968974644633,
    "itl": 103.39178876539779,
    "ttft": 1489306.5994134548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 139377,
    "finished_requests": 77377,
    "scheduler_time": 35.97354533481959
}
#Debug simulation 
Total elapsed time: 5.5875769960694015. Arrivals time: 0.25908490270376205 Scheduler time: 5.182667084503919 Scheduler overhead time: 0.05007345462217927 Adapter cache time: 0.01931905187666416 Engine time: 0.05202735913917422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93499750 . Total output tokens: 82168737
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.136013729032129,
    "estimated_duration": 3600.017916418257,
    "input_throughput": 4816.52936251261,
    "output_throughput": 4196.127172341811,
    "total_throughput": 9012.65653485442,
    "itl": 81.83769650090723,
    "ttft": 1616284.4039456034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 139377,
    "finished_requests": 69955,
    "scheduler_time": 19.891169945478886
}
#Debug simulation 
Total elapsed time: 5.136118204332888. Arrivals time: 0.24523749388754368 Scheduler time: 4.712623508647084 Scheduler overhead time: 0.060514372773468494 Adapter cache time: 0.02521701669320464 Engine time: 0.06321581825613976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92995973 . Total output tokens: 81735433
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.814565374050289,
    "estimated_duration": 3600.0002589897686,
    "input_throughput": 5581.3709873561165,
    "output_throughput": 4861.249094718395,
    "total_throughput": 10442.62008207451,
    "itl": 112.79760062795089,
    "ttft": 1427093.4739552478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 138774,
    "finished_requests": 81217,
    "scheduler_time": 42.35256563182674
}
#Debug simulation 
Total elapsed time: 5.8146821479313076. Arrivals time: 0.2728263447061181 Scheduler time: 5.410220674239099 Scheduler overhead time: 0.046381344087421894 Adapter cache time: 0.014389937743544579 Engine time: 0.048275388311594725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92995973 . Total output tokens: 81735433
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.634080905932933,
    "estimated_duration": 3600.026096195833,
    "input_throughput": 5395.2886676362095,
    "output_throughput": 4701.523974474902,
    "total_throughput": 10096.812642111112,
    "itl": 102.49563703616954,
    "ttft": 1472435.8896050307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867946,
    "arrivals": 138774,
    "finished_requests": 78480,
    "scheduler_time": 36.67638516690864
}
#Debug simulation 
Total elapsed time: 5.634185473900288. Arrivals time: 0.2599305547773838 Scheduler time: 5.231301210355014 Scheduler overhead time: 0.050317867659032345 Adapter cache time: 0.015701696276664734 Engine time: 0.052454888354986906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92995973 . Total output tokens: 81735433
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.170414797030389,
    "estimated_duration": 3600.021780181562,
    "input_throughput": 4852.868417679102,
    "output_throughput": 4236.732700886818,
    "total_throughput": 9089.601118565919,
    "itl": 81.38988969626524,
    "ttft": 1603867.3067039603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 138774,
    "finished_requests": 70634,
    "scheduler_time": 20.308655516397348
}
#Debug simulation 
Total elapsed time: 5.170532703399658. Arrivals time: 0.24903273303061724 Scheduler time: 4.74763395357877 Scheduler overhead time: 0.06023107562214136 Adapter cache time: 0.021722405217587948 Engine time: 0.06269787065684795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92995973 . Total output tokens: 81735433
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.6559511120431125,
    "estimated_duration": 3600.0336602288357,
    "input_throughput": 5395.277331591774,
    "output_throughput": 4701.514096099903,
    "total_throughput": 10096.791427691676,
    "itl": 102.4954501526203,
    "ttft": 1472447.1445914432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 138774,
    "finished_requests": 78480,
    "scheduler_time": 36.677678288075064
}
#Debug simulation 
Total elapsed time: 5.656055266968906. Arrivals time: 0.2592158722691238 Scheduler time: 5.253687251824886 Scheduler overhead time: 0.050267324317246675 Adapter cache time: 0.01573329232633114 Engine time: 0.05273018591105938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92995973 . Total output tokens: 81735433
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.163385902997106,
    "estimated_duration": 3600.0837350939255,
    "input_throughput": 4853.134895081591,
    "output_throughput": 4237.0478362226295,
    "total_throughput": 9090.182731304221,
    "itl": 81.38809837452074,
    "ttft": 1603780.9597302328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 138774,
    "finished_requests": 70640,
    "scheduler_time": 20.309228933418343
}
#Debug simulation 
Total elapsed time: 5.163497455883771. Arrivals time: 0.2453801203519106 Scheduler time: 4.744150069542229 Scheduler overhead time: 0.06023894529789686 Adapter cache time: 0.021855090744793415 Engine time: 0.06252536177635193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92995973 . Total output tokens: 81735433
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.626440920401365,
    "estimated_duration": 3600.042322363464,
    "input_throughput": 5395.069352198323,
    "output_throughput": 4701.51695019189,
    "total_throughput": 10096.586302390213,
    "itl": 102.49543334231775,
    "ttft": 1472457.8312908174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 138774,
    "finished_requests": 78480,
    "scheduler_time": 36.678411624640844
}
#Debug simulation 
Total elapsed time: 5.62654435634613. Arrivals time: 0.2606521132402122 Scheduler time: 5.222836982924491 Scheduler overhead time: 0.04997995821759105 Adapter cache time: 0.015984753146767616 Engine time: 0.05267540505155921 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92995973 . Total output tokens: 81735433
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.183770935051143,
    "estimated_duration": 3600.0218821753797,
    "input_throughput": 4853.341610646583,
    "output_throughput": 4237.187855864506,
    "total_throughput": 9090.529466511089,
    "itl": 81.38673540605954,
    "ttft": 1603879.1361805832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 138774,
    "finished_requests": 70641,
    "scheduler_time": 20.308215829112978
}
#Debug simulation 
Total elapsed time: 5.183870643377304. Arrivals time: 0.2447419068776071 Scheduler time: 4.7644012132659554 Scheduler overhead time: 0.06032292963936925 Adapter cache time: 0.02193355280905962 Engine time: 0.06318817613646388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92753965 . Total output tokens: 81534472
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.821544342674315,
    "estimated_duration": 3600.1154419969457,
    "input_throughput": 5657.086648505667,
    "output_throughput": 4911.111958730073,
    "total_throughput": 10568.19860723574,
    "itl": 111.37949113775726,
    "ttft": 1404587.8994111205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 138381,
    "finished_requests": 82007,
    "scheduler_time": 42.98492877322199
}
#Debug simulation 
Total elapsed time: 5.821648584678769. Arrivals time: 0.26517066452652216 Scheduler time: 5.426899105776101 Scheduler overhead time: 0.046894682105630636 Adapter cache time: 0.011598523240536451 Engine time: 0.04841054370626807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92753965 . Total output tokens: 81534472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.680895181372762,
    "estimated_duration": 3600.039640427844,
    "input_throughput": 5462.767348212529,
    "output_throughput": 4742.009729084861,
    "total_throughput": 10204.777077297389,
    "itl": 101.40626036975263,
    "ttft": 1450300.6311094114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867945,
    "arrivals": 138381,
    "finished_requests": 79200,
    "scheduler_time": 37.197568308931785
}
#Debug simulation 
Total elapsed time: 5.680997243151069. Arrivals time: 0.2642058921046555 Scheduler time: 5.276091423351318 Scheduler overhead time: 0.05064169364050031 Adapter cache time: 0.012868016492575407 Engine time: 0.052568250335752964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92753965 . Total output tokens: 81534472
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.21786333527416,
    "estimated_duration": 3600.0472855467597,
    "input_throughput": 4910.243560124593,
    "output_throughput": 4265.997855544146,
    "total_throughput": 9176.24141566874,
    "itl": 80.70432793531012,
    "ttft": 1586458.8714958034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 138381,
    "finished_requests": 71274,
    "scheduler_time": 20.608889384616564
}
#Debug simulation 
Total elapsed time: 5.217966835014522. Arrivals time: 0.24526166170835495 Scheduler time: 4.799695570487529 Scheduler overhead time: 0.06097234599292278 Adapter cache time: 0.018760988023132086 Engine time: 0.06387140369042754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92753965 . Total output tokens: 81534472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.681718525011092,
    "estimated_duration": 3600.0063105190616,
    "input_throughput": 5462.844868503702,
    "output_throughput": 4742.0766875096315,
    "total_throughput": 10204.921556013333,
    "itl": 101.40535217362161,
    "ttft": 1450227.6352659212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 138381,
    "finished_requests": 79201,
    "scheduler_time": 37.197725963099096
}
#Debug simulation 
Total elapsed time: 5.681814779061824. Arrivals time: 0.2744707311503589 Scheduler time: 5.266333481762558 Scheduler overhead time: 0.050649978686124086 Adapter cache time: 0.012826750986278057 Engine time: 0.05285945162177086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92753965 . Total output tokens: 81534472
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.209078467916697,
    "estimated_duration": 3600.028716839367,
    "input_throughput": 4910.2749978949,
    "output_throughput": 4265.947082078582,
    "total_throughput": 9176.222079973482,
    "itl": 80.7032344409115,
    "ttft": 1586428.4271362019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 138381,
    "finished_requests": 71273,
    "scheduler_time": 20.608685399958357
}
#Debug simulation 
Total elapsed time: 5.2091813599690795. Arrivals time: 0.24538593087345362 Scheduler time: 4.790343459695578 Scheduler overhead time: 0.06088469782844186 Adapter cache time: 0.01916527096182108 Engine time: 0.06396726286038756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92753965 . Total output tokens: 81534472
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.681701820343733,
    "estimated_duration": 3600.020738975212,
    "input_throughput": 5462.965473248462,
    "output_throughput": 4742.154347938479,
    "total_throughput": 10205.119821186941,
    "itl": 101.40492217720136,
    "ttft": 1450255.1177277046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 138381,
    "finished_requests": 79202,
    "scheduler_time": 37.19856689094355
}
#Debug simulation 
Total elapsed time: 5.68180524604395. Arrivals time: 0.2638702099211514 Scheduler time: 5.277100731153041 Scheduler overhead time: 0.0505367387086153 Adapter cache time: 0.012750012334436178 Engine time: 0.05292937718331814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92753965 . Total output tokens: 81534472
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.216050611808896,
    "estimated_duration": 3600.027405061417,
    "input_throughput": 4910.484007745606,
    "output_throughput": 4266.147801654856,
    "total_throughput": 9176.631809400462,
    "itl": 80.70192598814512,
    "ttft": 1586305.08842751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 138381,
    "finished_requests": 71276,
    "scheduler_time": 20.608824469237828
}
#Debug simulation 
Total elapsed time: 5.216154585126787. Arrivals time: 0.24953649612143636 Scheduler time: 4.793377610389143 Scheduler overhead time: 0.060954525135457516 Adapter cache time: 0.019248452503234148 Engine time: 0.06349568627774715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_96_slots_96_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_96_slots_96_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73237179 . Total output tokens: 64409037
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.439214572776109,
    "estimated_duration": 3600.0603800149115,
    "input_throughput": 5176.712619448568,
    "output_throughput": 4520.875563740569,
    "total_throughput": 9697.588183189137,
    "itl": 120.95126086867693,
    "ttft": 1332429.9529812098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 109384,
    "finished_requests": 75385,
    "scheduler_time": 43.595556567646675
}
#Debug simulation 
Total elapsed time: 5.4393216096796095. Arrivals time: 0.24524474702775478 Scheduler time: 5.044432160444558 Scheduler overhead time: 0.04410069528967142 Adapter cache time: 0.03824606817215681 Engine time: 0.04600192653015256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_96_slots_96_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_96_slots_96_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73237179 . Total output tokens: 64409037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.35386916436255,
    "estimated_duration": 3600.013575563967,
    "input_throughput": 5062.394520872043,
    "output_throughput": 4425.895254437739,
    "total_throughput": 9488.289775309782,
    "itl": 108.66963415456422,
    "ttft": 1363967.1648995443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867943,
    "arrivals": 109384,
    "finished_requests": 73755,
    "scheduler_time": 38.98996256972153
}
#Debug simulation 
Total elapsed time: 5.353965434245765. Arrivals time: 0.24324270943179727 Scheduler time: 4.945753158070147 Scheduler overhead time: 0.04796216869726777 Adapter cache time: 0.04382281005382538 Engine time: 0.050058428663760424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_96_slots_96_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_96_slots_96_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73237179 . Total output tokens: 64409037
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.09306870913133,
    "estimated_duration": 3600.0825620274986,
    "input_throughput": 4714.598820322931,
    "output_throughput": 4126.386199219209,
    "total_throughput": 8840.985019542139,
    "itl": 83.42178382510203,
    "ttft": 1468940.084854433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 109384,
    "finished_requests": 68744,
    "scheduler_time": 24.68752291622807
}
#Debug simulation 
Total elapsed time: 5.093166041187942. Arrivals time: 0.2529894602485001 Scheduler time: 4.630249887239188 Scheduler overhead time: 0.05946460319682956 Adapter cache time: 0.059390483889728785 Engine time: 0.062256915494799614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_96_slots_96_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_96_slots_96_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73237179 . Total output tokens: 64409037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.379996822681278,
    "estimated_duration": 3600.008248910775,
    "input_throughput": 5057.119245631823,
    "output_throughput": 4421.4915354196755,
    "total_throughput": 9478.610781051499,
    "itl": 108.7836687832793,
    "ttft": 1365957.0647059605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407827,
    "arrivals": 109384,
    "finished_requests": 73681,
    "scheduler_time": 38.92571478443133
}
#Debug simulation 
Total elapsed time: 5.380126612726599. Arrivals time: 0.24752877047285438 Scheduler time: 4.967956063337624 Scheduler overhead time: 0.04802568769082427 Adapter cache time: 0.04326159926131368 Engine time: 0.05000428622588515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_96_slots_96_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_96_slots_96_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73237179 . Total output tokens: 64409037
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.094758675899357,
    "estimated_duration": 3600.054473548625,
    "input_throughput": 4714.428107880896,
    "output_throughput": 4126.068955106151,
    "total_throughput": 8840.497062987048,
    "itl": 83.42013502494639,
    "ttft": 1468914.5545539341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 109384,
    "finished_requests": 68742,
    "scheduler_time": 24.687517507802806
}
#Debug simulation 
Total elapsed time: 5.0948833199217916. Arrivals time: 0.2378520085476339 Scheduler time: 4.647254568058997 Scheduler overhead time: 0.05961299920454621 Adapter cache time: 0.058616152964532375 Engine time: 0.06264716247096658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_96_slots_96_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_96_slots_96_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73237179 . Total output tokens: 64409037
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.378535873256624,
    "estimated_duration": 3600.057950335213,
    "input_throughput": 5056.979985087417,
    "output_throughput": 4421.369938924983,
    "total_throughput": 9478.3499240124,
    "itl": 108.7824998633815,
    "ttft": 1365905.885965622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 109384,
    "finished_requests": 73681,
    "scheduler_time": 38.92429202676895
}
#Debug simulation 
Total elapsed time: 5.378635271918029. Arrivals time: 0.24798205122351646 Scheduler time: 4.965230129659176 Scheduler overhead time: 0.04814012534916401 Adapter cache time: 0.043756731785833836 Engine time: 0.05037334468215704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_96_slots_96_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_96_slots_96_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73237179 . Total output tokens: 64409037
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.113329055719078,
    "estimated_duration": 3600.047958541664,
    "input_throughput": 4714.273863972356,
    "output_throughput": 4126.010311822932,
    "total_throughput": 8840.284175795288,
    "itl": 83.4195038403847,
    "ttft": 1469094.62565429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 109384,
    "finished_requests": 68739,
    "scheduler_time": 24.685705216280603
}
#Debug simulation 
Total elapsed time: 5.113460371736437. Arrivals time: 0.23826419841498137 Scheduler time: 4.66276658186689 Scheduler overhead time: 0.059602858033031225 Adapter cache time: 0.06057474948465824 Engine time: 0.06338584562763572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_96_slots_96_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_96_slots_96_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71345069 . Total output tokens: 62690597
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.6505522090010345,
    "estimated_duration": 3600.06210313421,
    "input_throughput": 5353.93069558985,
    "output_throughput": 4678.678455389989,
    "total_throughput": 10032.609150979839,
    "itl": 116.29580381719438,
    "ttft": 1253022.992895174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 106465,
    "finished_requests": 77774,
    "scheduler_time": 47.45208325207105
}
#Debug simulation 
Total elapsed time: 5.65065921517089. Arrivals time: 0.2518128943629563 Scheduler time: 5.248311392497271 Scheduler overhead time: 0.045694354455918074 Adapter cache time: 0.03500852268189192 Engine time: 0.047632713336497545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_96_slots_96_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_96_slots_96_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71345069 . Total output tokens: 62690597
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.490676618181169,
    "estimated_duration": 3600.0743146875975,
    "input_throughput": 5227.982634473265,
    "output_throughput": 4570.728979917712,
    "total_throughput": 9798.711614390977,
    "itl": 104.64670179806967,
    "ttft": 1289769.474210713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867944,
    "arrivals": 106465,
    "finished_requests": 75957,
    "scheduler_time": 42.517005886262396
}
#Debug simulation 
Total elapsed time: 5.490805394016206. Arrivals time: 0.24777893675491214 Scheduler time: 5.077641318086535 Scheduler overhead time: 0.04986429354175925 Adapter cache time: 0.03947887383401394 Engine time: 0.052010464016348124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_96_slots_96_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_96_slots_96_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71345069 . Total output tokens: 62690597
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.228196030948311,
    "estimated_duration": 3600.079553518374,
    "input_throughput": 4850.803639306542,
    "output_throughput": 4247.460305441264,
    "total_throughput": 9098.263944747807,
    "itl": 80.69035469618666,
    "ttft": 1404209.666082094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 106465,
    "finished_requests": 70504,
    "scheduler_time": 27.36218950619282
}
#Debug simulation 
Total elapsed time: 5.228297468740493. Arrivals time: 0.2434938563965261 Scheduler time: 4.7756332363933325 Scheduler overhead time: 0.06166052259504795 Adapter cache time: 0.05308204423636198 Engine time: 0.06473358208313584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_96_slots_96_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_96_slots_96_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71345069 . Total output tokens: 62690597
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.510607721284032,
    "estimated_duration": 3600.117212840899,
    "input_throughput": 5228.085055916149,
    "output_throughput": 4571.068670015346,
    "total_throughput": 9799.153725931494,
    "itl": 104.64667309078402,
    "ttft": 1289685.9796259052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407827,
    "arrivals": 106465,
    "finished_requests": 75960,
    "scheduler_time": 42.517991221426804
}
#Debug simulation 
Total elapsed time: 5.510732937138528. Arrivals time: 0.2496669627726078 Scheduler time: 5.095839063171297 Scheduler overhead time: 0.0497641172260046 Adapter cache time: 0.03920126846060157 Engine time: 0.05216058623045683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_96_slots_96_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_96_slots_96_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71345069 . Total output tokens: 62690597
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.187294407282025,
    "estimated_duration": 3600.0032366711266,
    "input_throughput": 4850.656472227847,
    "output_throughput": 4247.332014661973,
    "total_throughput": 9097.98848688982,
    "itl": 80.6931576507523,
    "ttft": 1404340.8022845122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 106465,
    "finished_requests": 70499,
    "scheduler_time": 27.36277531352475
}
#Debug simulation 
Total elapsed time: 5.187427771277726. Arrivals time: 0.23906286899000406 Scheduler time: 4.739314540289342 Scheduler overhead time: 0.06167366914451122 Adapter cache time: 0.05305000627413392 Engine time: 0.06478910753503442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_96_slots_96_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_96_slots_96_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71345069 . Total output tokens: 62690597
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.5529272998683155,
    "estimated_duration": 3600.099547558712,
    "input_throughput": 5227.969324560199,
    "output_throughput": 4570.909993630289,
    "total_throughput": 9798.87931819049,
    "itl": 104.64604205646802,
    "ttft": 1289783.9526692485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 106465,
    "finished_requests": 75958,
    "scheduler_time": 42.519197452350184
}
#Debug simulation 
Total elapsed time: 5.553068818058819. Arrivals time: 0.2713644807226956 Scheduler time: 5.1157616400159895 Scheduler overhead time: 0.05008441908285022 Adapter cache time: 0.03939676471054554 Engine time: 0.05222894577309489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_96_slots_96_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_96_slots_96_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71345069 . Total output tokens: 62690597
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.251523179002106,
    "estimated_duration": 3600.0762253574935,
    "input_throughput": 4850.6681266911,
    "output_throughput": 4247.439510390247,
    "total_throughput": 9098.107637081346,
    "itl": 80.69386705557406,
    "ttft": 1404353.0713741074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 106465,
    "finished_requests": 70502,
    "scheduler_time": 27.36358466391927
}
#Debug simulation 
Total elapsed time: 5.251662182155997. Arrivals time: 0.263205383438617 Scheduler time: 4.77838185057044 Scheduler overhead time: 0.06172602158039808 Adapter cache time: 0.053952503483742476 Engine time: 0.06465552188456059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70365562 . Total output tokens: 61863821
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.7847832958213985,
    "estimated_duration": 3600.028599700071,
    "input_throughput": 5484.711427471721,
    "output_throughput": 4835.1343657242605,
    "total_throughput": 10319.845793195982,
    "itl": 112.93179362383019,
    "ttft": 1165611.8483369022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 105012,
    "finished_requests": 80140,
    "scheduler_time": 51.03677928052039
}
#Debug simulation 
Total elapsed time: 5.784915993921459. Arrivals time: 0.2754355198703706 Scheduler time: 5.359648837707937 Scheduler overhead time: 0.04702077433466911 Adapter cache time: 0.031232076231390238 Engine time: 0.04879888240247965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70365562 . Total output tokens: 61863821
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.719532492570579,
    "estimated_duration": 3600.1165800659223,
    "input_throughput": 5352.743882434811,
    "output_throughput": 4717.8374983870635,
    "total_throughput": 10070.581380821874,
    "itl": 101.76816675111591,
    "ttft": 1235308.2036857032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867943,
    "arrivals": 105012,
    "finished_requests": 78144,
    "scheduler_time": 45.7158203702291
}
#Debug simulation 
Total elapsed time: 5.71963517088443. Arrivals time: 0.274510798510164 Scheduler time: 5.278724038507789 Scheduler overhead time: 0.05135017493739724 Adapter cache time: 0.03677362250164151 Engine time: 0.05343643808737397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70365562 . Total output tokens: 61863821
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.388388060964644,
    "estimated_duration": 3600.018064855115,
    "input_throughput": 4948.1907254587395,
    "output_throughput": 4359.647567666205,
    "total_throughput": 9307.838293124945,
    "itl": 78.7697883836028,
    "ttft": 1359767.0660945417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 105012,
    "finished_requests": 72212,
    "scheduler_time": 29.3701586093035
}
#Debug simulation 
Total elapsed time: 5.388494205661118. Arrivals time: 0.2686649989336729 Scheduler time: 4.912722888868302 Scheduler overhead time: 0.06352716172114015 Adapter cache time: 0.046952067874372005 Engine time: 0.06617693789303303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70365562 . Total output tokens: 61863821
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.741321953944862,
    "estimated_duration": 3600.09124503112,
    "input_throughput": 5352.762385285994,
    "output_throughput": 4717.672093295288,
    "total_throughput": 10070.434478581281,
    "itl": 101.76285149986722,
    "ttft": 1235357.417674782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 105012,
    "finished_requests": 78142,
    "scheduler_time": 45.714946837552745
}
#Debug simulation 
Total elapsed time: 5.741456368938088. Arrivals time: 0.27622511703521013 Scheduler time: 5.298622582107782 Scheduler overhead time: 0.05139754060655832 Adapter cache time: 0.03671815479174256 Engine time: 0.05356917344033718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70365562 . Total output tokens: 61863821
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.4048456978052855,
    "estimated_duration": 3600.04318354249,
    "input_throughput": 4948.465918808815,
    "output_throughput": 4359.726314325961,
    "total_throughput": 9308.192233134776,
    "itl": 78.76925705860931,
    "ttft": 1359792.662591003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 105012,
    "finished_requests": 72215,
    "scheduler_time": 29.368678357925297
}
#Debug simulation 
Total elapsed time: 5.404978823848069. Arrivals time: 0.2631103005260229 Scheduler time: 4.9341483833268285 Scheduler overhead time: 0.0636302069760859 Adapter cache time: 0.047230401542037725 Engine time: 0.06620508432388306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70365562 . Total output tokens: 61863821
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.747090358752757,
    "estimated_duration": 3600.0740567534854,
    "input_throughput": 5352.690721417433,
    "output_throughput": 4717.5835086336265,
    "total_throughput": 10070.27423005106,
    "itl": 101.76490759153302,
    "ttft": 1235180.710315458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 105012,
    "finished_requests": 78141,
    "scheduler_time": 45.71339305483624
}
#Debug simulation 
Total elapsed time: 5.747194965835661. Arrivals time: 0.27222952572628856 Scheduler time: 5.308719654101878 Scheduler overhead time: 0.05124550964683294 Adapter cache time: 0.036478398367762566 Engine time: 0.05368343507871032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70365562 . Total output tokens: 61863821
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.385558784008026,
    "estimated_duration": 3600.0473275848553,
    "input_throughput": 4948.173004145075,
    "output_throughput": 4359.7271290678755,
    "total_throughput": 9307.90013321295,
    "itl": 78.77035851822463,
    "ttft": 1359756.4406622702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 105012,
    "finished_requests": 72213,
    "scheduler_time": 29.369900534119175
}
#Debug simulation 
Total elapsed time: 5.385661487001926. Arrivals time: 0.26761375181376934 Scheduler time: 4.912282350938767 Scheduler overhead time: 0.06310545699670911 Adapter cache time: 0.04633979359641671 Engine time: 0.06580335926264524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69872105 . Total output tokens: 61434027
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.891119224950671,
    "estimated_duration": 3600.1077541147297,
    "input_throughput": 5727.276906207544,
    "output_throughput": 4935.931425855233,
    "total_throughput": 10663.208332062777,
    "itl": 110.63535011261989,
    "ttft": 1016027.584728739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 104295,
    "finished_requests": 82988,
    "scheduler_time": 54.24472831910456
}
#Debug simulation 
Total elapsed time: 5.891222700942308. Arrivals time: 0.2715191291645169 Scheduler time: 5.4716051309369504 Scheduler overhead time: 0.047716664616018534 Adapter cache time: 0.027777152601629496 Engine time: 0.04955377150326967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69872105 . Total output tokens: 61434027
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.8378108269535005,
    "estimated_duration": 3600.007255473274,
    "input_throughput": 5570.477939873939,
    "output_throughput": 4805.425592878622,
    "total_throughput": 10375.903532752562,
    "itl": 99.94022119338686,
    "ttft": 1118144.9116194667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867944,
    "arrivals": 104295,
    "finished_requests": 80702,
    "scheduler_time": 48.808875681317716
}
#Debug simulation 
Total elapsed time: 5.837915951851755. Arrivals time: 0.2759089977480471 Scheduler time: 5.3976228274405 Scheduler overhead time: 0.052379936911165714 Adapter cache time: 0.03176059387624264 Engine time: 0.05494446726515889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69872105 . Total output tokens: 61434027
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.460417286027223,
    "estimated_duration": 3600.0677555253787,
    "input_throughput": 5121.807769228807,
    "output_throughput": 4420.711797874886,
    "total_throughput": 9542.519567103693,
    "itl": 77.73495894306204,
    "ttft": 1309755.7949515241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 104295,
    "finished_requests": 74181,
    "scheduler_time": 31.58008813201431
}
#Debug simulation 
Total elapsed time: 5.460525617934763. Arrivals time: 0.27179565094411373 Scheduler time: 4.983775347471237 Scheduler overhead time: 0.06398483039811254 Adapter cache time: 0.04289873782545328 Engine time: 0.06709627900272608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69872105 . Total output tokens: 61434027
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.823032225947827,
    "estimated_duration": 3600.0547451342286,
    "input_throughput": 5570.353625067526,
    "output_throughput": 4805.4549790894835,
    "total_throughput": 10375.80860415701,
    "itl": 99.93889693027813,
    "ttft": 1118203.6774258502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407829,
    "arrivals": 104295,
    "finished_requests": 80701,
    "scheduler_time": 48.81076354691872
}
#Debug simulation 
Total elapsed time: 5.8231442789547145. Arrivals time: 0.27682121144607663 Scheduler time: 5.382035583257675 Scheduler overhead time: 0.05240217316895723 Adapter cache time: 0.03209461411461234 Engine time: 0.0545759666711092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69872105 . Total output tokens: 61434027
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.453570732846856,
    "estimated_duration": 3600.0443541813306,
    "input_throughput": 5121.5482883107015,
    "output_throughput": 4420.560813790023,
    "total_throughput": 9542.109102100725,
    "itl": 77.73647182401265,
    "ttft": 1309684.220481376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 104295,
    "finished_requests": 74178,
    "scheduler_time": 31.578663268003154
}
#Debug simulation 
Total elapsed time: 5.453673771116883. Arrivals time: 0.2727200551889837 Scheduler time: 4.976152086630464 Scheduler overhead time: 0.06413820525631309 Adapter cache time: 0.043017271906137466 Engine time: 0.06692496687173843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69872105 . Total output tokens: 61434027
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.7990270890295506,
    "estimated_duration": 3600.099028616188,
    "input_throughput": 5570.398436430895,
    "output_throughput": 4805.504477094874,
    "total_throughput": 10375.90291352577,
    "itl": 99.93933622603748,
    "ttft": 1118169.4414697976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 104295,
    "finished_requests": 80705,
    "scheduler_time": 48.811858662671675
}
#Debug simulation 
Total elapsed time: 5.799131256062537. Arrivals time: 0.2740524495020509 Scheduler time: 5.361447730101645 Scheduler overhead time: 0.05220801942050457 Adapter cache time: 0.03178587229922414 Engine time: 0.054555537179112434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69872105 . Total output tokens: 61434027
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.462324866093695,
    "estimated_duration": 3600.0351746534957,
    "input_throughput": 5121.561347459513,
    "output_throughput": 4420.572085530177,
    "total_throughput": 9542.13343298969,
    "itl": 77.73924505993908,
    "ttft": 1309789.590812845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 104295,
    "finished_requests": 74178,
    "scheduler_time": 31.57953616575407
}
#Debug simulation 
Total elapsed time: 5.462434754241258. Arrivals time: 0.2746196324005723 Scheduler time: 4.982252290006727 Scheduler overhead time: 0.06417418271303177 Adapter cache time: 0.04352819314226508 Engine time: 0.06698342273011804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69643671 . Total output tokens: 61225545
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.957859478890896,
    "estimated_duration": 3600.03246982956,
    "input_throughput": 5757.391682909263,
    "output_throughput": 4984.425876817035,
    "total_throughput": 10741.817559726298,
    "itl": 109.15357661124875,
    "ttft": 984104.7971260619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 103971,
    "finished_requests": 83299,
    "scheduler_time": 55.33397109771912
}
#Debug simulation 
Total elapsed time: 5.9579570395872. Arrivals time: 0.27298245253041387 Scheduler time: 5.537982471752912 Scheduler overhead time: 0.04837593762204051 Adapter cache time: 0.02490855287760496 Engine time: 0.050310335122048855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69643671 . Total output tokens: 61225545
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.883030707016587,
    "estimated_duration": 3600.00085738078,
    "input_throughput": 5604.360331924769,
    "output_throughput": 4848.270511996124,
    "total_throughput": 10452.630843920893,
    "itl": 98.70681551963743,
    "ttft": 1088701.0555485212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867945,
    "arrivals": 103971,
    "finished_requests": 81030,
    "scheduler_time": 49.73194918162692
}
#Debug simulation 
Total elapsed time: 5.883147826883942. Arrivals time: 0.2752330363728106 Scheduler time: 5.44491751678288 Scheduler overhead time: 0.053107833955436945 Adapter cache time: 0.02891321526840329 Engine time: 0.05539559619501233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69643671 . Total output tokens: 61225545
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.47830627579242,
    "estimated_duration": 3600.016938363816,
    "input_throughput": 5138.396101104836,
    "output_throughput": 4444.553810147379,
    "total_throughput": 9582.949911252215,
    "itl": 77.06254976776299,
    "ttft": 1301449.757857053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7125451658712701,
    "arrivals": 103971,
    "finished_requests": 74270,
    "scheduler_time": 32.07168696890029
}
#Debug simulation 
Total elapsed time: 5.478445258922875. Arrivals time: 0.2726498576812446 Scheduler time: 5.002690042369068 Scheduler overhead time: 0.06445127865299582 Adapter cache time: 0.03974854061380029 Engine time: 0.06779413996264338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69643671 . Total output tokens: 61225545
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.832822284195572,
    "estimated_duration": 3600.042083511573,
    "input_throughput": 5604.580872098891,
    "output_throughput": 4848.501377232273,
    "total_throughput": 10453.082249331163,
    "itl": 98.70492868455743,
    "ttft": 1088683.8051679672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.657279481440783,
    "arrivals": 103971,
    "finished_requests": 81032,
    "scheduler_time": 49.732164071147324
}
#Debug simulation 
Total elapsed time: 5.832950084004551. Arrivals time: 0.27512392587959766 Scheduler time: 5.3962089996784925 Scheduler overhead time: 0.05249124113470316 Adapter cache time: 0.028932849876582623 Engine time: 0.054853704292327166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69643671 . Total output tokens: 61225545
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.4699220596812665,
    "estimated_duration": 3600.0611629467867,
    "input_throughput": 5138.613529792811,
    "output_throughput": 4444.652819982246,
    "total_throughput": 9583.266349775056,
    "itl": 77.0615677275263,
    "ttft": 1301246.9333707436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7059174162195997,
    "arrivals": 103971,
    "finished_requests": 74274,
    "scheduler_time": 32.07147176270808
}
#Debug simulation 
Total elapsed time: 5.4700530199334025. Arrivals time: 0.27050019009038806 Scheduler time: 4.9967107200063765 Scheduler overhead time: 0.06426285207271576 Adapter cache time: 0.04021809762343764 Engine time: 0.06732601672410965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69643671 . Total output tokens: 61225545
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.860020564869046,
    "estimated_duration": 3600.0530999787097,
    "input_throughput": 5604.562610512418,
    "output_throughput": 4848.284321168268,
    "total_throughput": 10452.846931680686,
    "itl": 98.70425362791437,
    "ttft": 1088761.7023813406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 103971,
    "finished_requests": 81031,
    "scheduler_time": 49.73234025993883
}
#Debug simulation 
Total elapsed time: 5.860160492826253. Arrivals time: 0.27326586842536926 Scheduler time: 5.424846034031361 Scheduler overhead time: 0.05263548670336604 Adapter cache time: 0.02905796654522419 Engine time: 0.0547027881257236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69643671 . Total output tokens: 61225545
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.458467567805201,
    "estimated_duration": 3600.084809922217,
    "input_throughput": 5138.447557961748,
    "output_throughput": 4444.591404041315,
    "total_throughput": 9583.038962003064,
    "itl": 77.06029290030126,
    "ttft": 1301294.5812521,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6994967837445439,
    "arrivals": 103971,
    "finished_requests": 74274,
    "scheduler_time": 32.07061133593038
}
#Debug simulation 
Total elapsed time: 5.4585738787427545. Arrivals time: 0.2718022861517966 Scheduler time: 4.984029490035027 Scheduler overhead time: 0.06453001638874412 Adapter cache time: 0.03967896429821849 Engine time: 0.06757654016837478 
