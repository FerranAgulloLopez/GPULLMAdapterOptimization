INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_128_slots_128_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_128_slots_128_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.533305923920125,
    "estimated_duration": 3600.0808314852043,
    "input_throughput": 5244.454189716322,
    "output_throughput": 4587.638381771117,
    "total_throughput": 9832.09257148744,
    "itl": 94.69999201015153,
    "ttft": 1848942.380035146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454803,
    "arrivals": 263940,
    "finished_requests": 76671,
    "scheduler_time": 27.172701584296405
}
#Debug simulation 
Total elapsed time: 5.533419583924115. Arrivals time: 0.24066775618121028 Scheduler time: 5.113812139257789 Scheduler overhead time: 0.05257405433803797 Adapter cache time: 0.04658982763066888 Engine time: 0.0541421202942729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_128_slots_128_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_128_slots_128_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.554218235891312,
    "estimated_duration": 3600.071971032482,
    "input_throughput": 5244.0351614930705,
    "output_throughput": 4587.254958478995,
    "total_throughput": 9831.290119972065,
    "itl": 94.70102436930196,
    "ttft": 1848933.7980530332,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 263940,
    "finished_requests": 76664,
    "scheduler_time": 27.17403897348887
}
#Debug simulation 
Total elapsed time: 5.554353845771402. Arrivals time: 0.25583904050290585 Scheduler time: 5.119740955065936 Scheduler overhead time: 0.05265395063906908 Adapter cache time: 0.046392615884542465 Engine time: 0.054159173276275396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_128_slots_128_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_128_slots_128_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.729213386774063,
    "estimated_duration": 3600.090334257752,
    "input_throughput": 5500.217539425305,
    "output_throughput": 4786.201567231659,
    "total_throughput": 10286.419106656964,
    "itl": 108.30429581344049,
    "ttft": 1819704.163436802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 263449,
    "finished_requests": 80081,
    "scheduler_time": 35.14319466511568
}
#Debug simulation 
Total elapsed time: 5.729362447746098. Arrivals time: 0.2548145893961191 Scheduler time: 5.315849272534251 Scheduler overhead time: 0.04736578976735473 Adapter cache time: 0.039747883565723896 Engine time: 0.04869205690920353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_128_slots_128_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_128_slots_128_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.546445911750197,
    "estimated_duration": 3600.0396862434063,
    "input_throughput": 5299.968795596759,
    "output_throughput": 4614.723294157804,
    "total_throughput": 9914.692089754562,
    "itl": 94.08810204789192,
    "ttft": 1851389.54365951,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979342,
    "arrivals": 263449,
    "finished_requests": 77139,
    "scheduler_time": 27.226169903611716
}
#Debug simulation 
Total elapsed time: 5.546544227749109. Arrivals time: 0.2487712255679071 Scheduler time: 5.119009807705879 Scheduler overhead time: 0.053436222951859236 Adapter cache time: 0.04448337713256478 Engine time: 0.05492192506790161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_128_slots_128_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_128_slots_128_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.542954077012837,
    "estimated_duration": 3600.032109483871,
    "input_throughput": 5300.0566160882145,
    "output_throughput": 4615.006059593713,
    "total_throughput": 9915.062675681927,
    "itl": 94.08493312734595,
    "ttft": 1851285.2303740792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454802,
    "arrivals": 263449,
    "finished_requests": 77143,
    "scheduler_time": 27.226943196114156
}
#Debug simulation 
Total elapsed time: 5.543053738772869. Arrivals time: 0.24777238257229328 Scheduler time: 5.117666481528431 Scheduler overhead time: 0.0532638025470078 Adapter cache time: 0.0435952921397984 Engine time: 0.05498921172693372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_128_slots_128_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_128_slots_128_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.5595415136776865,
    "estimated_duration": 3600.014998886037,
    "input_throughput": 5299.9606962481985,
    "output_throughput": 4614.728828946723,
    "total_throughput": 9914.68952519492,
    "itl": 94.08191957817725,
    "ttft": 1851312.8077332673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 263449,
    "finished_requests": 77140,
    "scheduler_time": 27.22696822610874
}
#Debug simulation 
Total elapsed time: 5.559637635946274. Arrivals time: 0.24747202638536692 Scheduler time: 5.133753242902458 Scheduler overhead time: 0.05343030486255884 Adapter cache time: 0.043287530075758696 Engine time: 0.05608060956001282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_128_slots_128_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_128_slots_128_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.8159327218309045,
    "estimated_duration": 3600.028854707595,
    "input_throughput": 5631.689860898832,
    "output_throughput": 4880.116440463078,
    "total_throughput": 10511.80630136191,
    "itl": 106.15603074272101,
    "ttft": 1787505.039788975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 259027,
    "finished_requests": 81893,
    "scheduler_time": 35.98770747183636
}
#Debug simulation 
Total elapsed time: 5.816031861118972. Arrivals time: 0.26254526851698756 Scheduler time: 5.389534360729158 Scheduler overhead time: 0.048246546648442745 Adapter cache time: 0.04306165361776948 Engine time: 0.04942568019032478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_128_slots_128_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_128_slots_128_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.717396866064519,
    "estimated_duration": 3600.0131217188004,
    "input_throughput": 5430.288540355769,
    "output_throughput": 4713.892818228885,
    "total_throughput": 10144.181358584654,
    "itl": 92.07321733642802,
    "ttft": 1819327.7388637715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979342,
    "arrivals": 259027,
    "finished_requests": 79035,
    "scheduler_time": 27.958272813664035
}
#Debug simulation 
Total elapsed time: 5.717512082774192. Arrivals time: 0.25598825654014945 Scheduler time: 5.279187329579145 Scheduler overhead time: 0.05434017442166805 Adapter cache time: 0.04559530317783356 Engine time: 0.05606966931372881 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_128_slots_128_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_128_slots_128_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.702919234056026,
    "estimated_duration": 3600.0595031375256,
    "input_throughput": 5430.414131478087,
    "output_throughput": 4713.928751791444,
    "total_throughput": 10144.34288326953,
    "itl": 92.06839403098603,
    "ttft": 1819242.3556549572,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454803,
    "arrivals": 259027,
    "finished_requests": 79038,
    "scheduler_time": 27.96029351037117
}
#Debug simulation 
Total elapsed time: 5.7030175612308085. Arrivals time: 0.2541348454542458 Scheduler time: 5.267418814823031 Scheduler overhead time: 0.05447018751874566 Adapter cache time: 0.044740752317011356 Engine time: 0.05601497087627649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_128_slots_128_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_128_slots_128_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.683141873218119,
    "estimated_duration": 3600.100624333696,
    "input_throughput": 5430.3521040105,
    "output_throughput": 4713.874908188399,
    "total_throughput": 10144.227012198899,
    "itl": 92.06779439795919,
    "ttft": 1819219.5516387417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 259027,
    "finished_requests": 79038,
    "scheduler_time": 27.960295775664196
}
#Debug simulation 
Total elapsed time: 5.683268005028367. Arrivals time: 0.25222201040014625 Scheduler time: 5.24906155327335 Scheduler overhead time: 0.05428589740768075 Adapter cache time: 0.04524350352585316 Engine time: 0.055835665203630924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_128_slots_128_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_128_slots_128_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.873178333044052,
    "estimated_duration": 3600.1067611538797,
    "input_throughput": 5678.654650076965,
    "output_throughput": 4958.13768430548,
    "total_throughput": 10636.792334382446,
    "itl": 104.40906321121724,
    "ttft": 1778316.1190185202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 257078,
    "finished_requests": 82600,
    "scheduler_time": 36.49610334399472
}
#Debug simulation 
Total elapsed time: 5.873315030243248. Arrivals time: 0.26438397681340575 Scheduler time: 5.446755411569029 Scheduler overhead time: 0.048924933187663555 Adapter cache time: 0.03942626714706421 Engine time: 0.050276737194508314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_128_slots_128_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_128_slots_128_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.731718688737601,
    "estimated_duration": 3600.066956396342,
    "input_throughput": 5465.649733275053,
    "output_throughput": 4774.491199243037,
    "total_throughput": 10240.14093251809,
    "itl": 90.82165912565532,
    "ttft": 1812900.8708707036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979342,
    "arrivals": 257078,
    "finished_requests": 79531,
    "scheduler_time": 28.26183891528995
}
#Debug simulation 
Total elapsed time: 5.731817374937236. Arrivals time: 0.2598210982978344 Scheduler time: 5.290922946762294 Scheduler overhead time: 0.055464988108724356 Adapter cache time: 0.041913528461009264 Engine time: 0.0569095965474844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_128_slots_128_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_128_slots_128_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.737838865723461,
    "estimated_duration": 3600.075957198504,
    "input_throughput": 5465.636068221171,
    "output_throughput": 4774.479262203035,
    "total_throughput": 10240.115330424207,
    "itl": 90.8200256409636,
    "ttft": 1812930.8123224587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454805,
    "arrivals": 257078,
    "finished_requests": 79531,
    "scheduler_time": 28.261508203766155
}
#Debug simulation 
Total elapsed time: 5.737935690674931. Arrivals time: 0.25656912894919515 Scheduler time: 5.299402148928493 Scheduler overhead time: 0.05568309035152197 Adapter cache time: 0.0428074412047863 Engine time: 0.05674207862466574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_128_slots_128_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_128_slots_128_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.74000729015097,
    "estimated_duration": 3600.075304920099,
    "input_throughput": 5465.984551241696,
    "output_throughput": 4774.646790445818,
    "total_throughput": 10240.631341687515,
    "itl": 90.8185216188561,
    "ttft": 1812825.8472833182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 257078,
    "finished_requests": 79534,
    "scheduler_time": 28.261611978106494
}
#Debug simulation 
Total elapsed time: 5.7401045630685985. Arrivals time: 0.2589684505946934 Scheduler time: 5.301487603690475 Scheduler overhead time: 0.05505384551361203 Adapter cache time: 0.041338722221553326 Engine time: 0.056355062406510115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_128_slots_128_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_128_slots_128_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.00862227473408,
    "estimated_duration": 3600.034515148061,
    "input_throughput": 5779.2907019238155,
    "output_throughput": 5025.139599045197,
    "total_throughput": 10804.430300969014,
    "itl": 102.9959663834667,
    "ttft": 1760932.2450878553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 256097,
    "finished_requests": 83496,
    "scheduler_time": 36.993075830191295
}
#Debug simulation 
Total elapsed time: 6.00873453496024. Arrivals time: 0.29683723114430904 Scheduler time: 5.550687135197222 Scheduler overhead time: 0.049666989129036665 Adapter cache time: 0.036458808463066816 Engine time: 0.0510801337659359 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_128_slots_128_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_128_slots_128_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.050374038051814,
    "estimated_duration": 3600.006997570222,
    "input_throughput": 5553.237261342307,
    "output_throughput": 4834.6247692704665,
    "total_throughput": 10387.862030612772,
    "itl": 89.65723060386888,
    "ttft": 1795389.4076673659,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979341,
    "arrivals": 256097,
    "finished_requests": 80225,
    "scheduler_time": 28.600455372162063
}
#Debug simulation 
Total elapsed time: 6.0504413321614265. Arrivals time: 0.2598271747119725 Scheduler time: 5.613174026366323 Scheduler overhead time: 0.05544410785660148 Adapter cache time: 0.03829988557845354 Engine time: 0.056807100772857666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_128_slots_128_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_128_slots_128_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.784072710201144,
    "estimated_duration": 3600.0244916115817,
    "input_throughput": 5552.931944374355,
    "output_throughput": 4834.445165735219,
    "total_throughput": 10387.377110109574,
    "itl": 89.65400953601753,
    "ttft": 1795384.8595498358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454804,
    "arrivals": 256097,
    "finished_requests": 80223,
    "scheduler_time": 28.600264440246445
}
#Debug simulation 
Total elapsed time: 5.784170133061707. Arrivals time: 0.25702257780358195 Scheduler time: 5.34947449946776 Scheduler overhead time: 0.05545459408313036 Adapter cache time: 0.03830441413447261 Engine time: 0.05710178753361106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_128_slots_128_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_128_slots_128_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.873845650814474,
    "estimated_duration": 3600.0179198923893,
    "input_throughput": 5552.941803300122,
    "output_throughput": 4834.402046676543,
    "total_throughput": 10387.343849976665,
    "itl": 89.65555997728457,
    "ttft": 1795385.6769421601,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 256097,
    "finished_requests": 80222,
    "scheduler_time": 28.601327768837074
}
#Debug simulation 
Total elapsed time: 5.873941208701581. Arrivals time: 0.2873740908689797 Scheduler time: 5.406670016236603 Scheduler overhead time: 0.0560293891467154 Adapter cache time: 0.03890225384384394 Engine time: 0.05771450372412801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_128_slots_128_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_128_slots_128_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.051426827907562,
    "estimated_duration": 3600.0349384793453,
    "input_throughput": 5787.5238313106,
    "output_throughput": 5066.758604210878,
    "total_throughput": 10854.282435521478,
    "itl": 102.58723209212496,
    "ttft": 1749589.5173792345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8397759470576411,
    "arrivals": 255593,
    "finished_requests": 84461,
    "scheduler_time": 37.47009974728192
}
#Debug simulation 
Total elapsed time: 6.051547709852457. Arrivals time: 0.26485425932332873 Scheduler time: 5.628049654420465 Scheduler overhead time: 0.050224512815475464 Adapter cache time: 0.03282765205949545 Engine time: 0.05134581122547388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_128_slots_128_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_128_slots_128_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.828483768273145,
    "estimated_duration": 3600.0253275584787,
    "input_throughput": 5556.28563134743,
    "output_throughput": 4869.29879793054,
    "total_throughput": 10425.584429277971,
    "itl": 89.56790388544518,
    "ttft": 1785809.7926855958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.928756742184051,
    "arrivals": 255593,
    "finished_requests": 81143,
    "scheduler_time": 29.06462298526942
}
#Debug simulation 
Total elapsed time: 5.82860947214067. Arrivals time: 0.2691389820538461 Scheduler time: 5.385049555450678 Scheduler overhead time: 0.05553685128688812 Adapter cache time: 0.03453129855915904 Engine time: 0.05735627142712474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_128_slots_128_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_128_slots_128_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.78185259224847,
    "estimated_duration": 3600.010081805662,
    "input_throughput": 5556.110828991774,
    "output_throughput": 4869.281919123882,
    "total_throughput": 10425.392748115657,
    "itl": 89.56697889674977,
    "ttft": 1785742.8244862694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8690632403315969,
    "arrivals": 255593,
    "finished_requests": 81139,
    "scheduler_time": 29.065248095295647
}
#Debug simulation 
Total elapsed time: 5.781948151998222. Arrivals time: 0.2535490244626999 Scheduler time: 5.353934116661549 Scheduler overhead time: 0.055410911329090595 Adapter cache time: 0.034811883233487606 Engine time: 0.05739977164193988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_128_slots_128_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_128_slots_128_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.812340220902115,
    "estimated_duration": 3600.0020965553954,
    "input_throughput": 5494.689300022084,
    "output_throughput": 4819.6577487001505,
    "total_throughput": 10314.347048722235,
    "itl": 89.76728505392582,
    "ttft": 1793803.5911242398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8107579594524567,
    "arrivals": 255593,
    "finished_requests": 80286,
    "scheduler_time": 28.412367759559114
}
#Debug simulation 
Total elapsed time: 5.812440651934594. Arrivals time: 0.2707445933483541 Scheduler time: 5.367957229260355 Scheduler overhead time: 0.0555648235604167 Adapter cache time: 0.033491517417132854 Engine time: 0.05763615109026432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_128_slots_128_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_128_slots_128_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.1194365858100355,
    "estimated_duration": 3600.0136263873646,
    "input_throughput": 5939.567240321113,
    "output_throughput": 5171.61653598605,
    "total_throughput": 11111.183776307162,
    "itl": 100.22614077830201,
    "ttft": 1721895.775032829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 253064,
    "finished_requests": 86623,
    "scheduler_time": 38.27895494923645
}
#Debug simulation 
Total elapsed time: 6.119536085985601. Arrivals time: 0.26971898367628455 Scheduler time: 5.691013240255415 Scheduler overhead time: 0.05085043516010046 Adapter cache time: 0.03131011547520757 Engine time: 0.05217233905568719 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_128_slots_128_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_128_slots_128_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.967211042996496,
    "estimated_duration": 3600.093531236688,
    "input_throughput": 5684.013990872801,
    "output_throughput": 4962.928558653976,
    "total_throughput": 10646.942549526777,
    "itl": 87.60083291313423,
    "ttft": 1760317.3173214842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979343,
    "arrivals": 253064,
    "finished_requests": 83067,
    "scheduler_time": 29.65556123651773
}
#Debug simulation 
Total elapsed time: 5.967326377052814. Arrivals time: 0.2715206705033779 Scheduler time: 5.518065980635583 Scheduler overhead time: 0.056990735698491335 Adapter cache time: 0.03293520212173462 Engine time: 0.058484983164817095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_128_slots_128_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_128_slots_128_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.958533153869212,
    "estimated_duration": 3600.0171412921804,
    "input_throughput": 5684.465433588087,
    "output_throughput": 4963.20331230052,
    "total_throughput": 10647.668745888608,
    "itl": 87.59427532699837,
    "ttft": 1760136.2883365978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454804,
    "arrivals": 253064,
    "finished_requests": 83070,
    "scheduler_time": 29.655117782139573
}
#Debug simulation 
Total elapsed time: 5.958634315989912. Arrivals time: 0.29078018106520176 Scheduler time: 5.4928905656561255 Scheduler overhead time: 0.056708762887865305 Adapter cache time: 0.03224658826366067 Engine time: 0.05854916386306286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_128_slots_128_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_128_slots_128_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.982259302865714,
    "estimated_duration": 3600.0184233658706,
    "input_throughput": 5684.154799649017,
    "output_throughput": 4962.97654590758,
    "total_throughput": 10647.131345556596,
    "itl": 87.59630623864031,
    "ttft": 1760085.0427326185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 253064,
    "finished_requests": 83067,
    "scheduler_time": 29.65734097266814
}
#Debug simulation 
Total elapsed time: 5.982356773689389. Arrivals time: 0.26420170394703746 Scheduler time: 5.541298594325781 Scheduler overhead time: 0.05719220032915473 Adapter cache time: 0.03311900934204459 Engine time: 0.058839119505137205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_128_slots_128_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_128_slots_128_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.393656162545085,
    "estimated_duration": 3600.110364911614,
    "input_throughput": 5968.446748028384,
    "output_throughput": 5224.607885170149,
    "total_throughput": 11193.054633198533,
    "itl": 98.99346568144024,
    "ttft": 1727517.1769618078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 252140,
    "finished_requests": 87161,
    "scheduler_time": 38.51781818020204
}
#Debug simulation 
Total elapsed time: 6.393721259664744. Arrivals time: 0.2627591206692159 Scheduler time: 5.973237230908126 Scheduler overhead time: 0.05145050911232829 Adapter cache time: 0.028761487919837236 Engine time: 0.052767927292734385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_128_slots_128_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_128_slots_128_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.985061764717102,
    "estimated_duration": 3600.085500827433,
    "input_throughput": 5705.3492188669425,
    "output_throughput": 5005.3064006003315,
    "total_throughput": 10710.655619467274,
    "itl": 86.60225862201321,
    "ttft": 1767104.5070924847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979339,
    "arrivals": 252140,
    "finished_requests": 83377,
    "scheduler_time": 29.68603572179085
}
#Debug simulation 
Total elapsed time: 5.985189886763692. Arrivals time: 0.2600769866257906 Scheduler time: 5.550683686044067 Scheduler overhead time: 0.05743110040202737 Adapter cache time: 0.030241483356803656 Engine time: 0.0589497834444046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_128_slots_128_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_128_slots_128_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.987967269029468,
    "estimated_duration": 3600.057690266032,
    "input_throughput": 5705.562734602217,
    "output_throughput": 5005.625340039577,
    "total_throughput": 10711.188074641794,
    "itl": 86.60045651026388,
    "ttft": 1767086.2700027074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.87683538224548,
    "arrivals": 252140,
    "finished_requests": 83382,
    "scheduler_time": 29.68670109273642
}
#Debug simulation 
Total elapsed time: 5.988067799713463. Arrivals time: 0.2515679025091231 Scheduler time: 5.5610387129709125 Scheduler overhead time: 0.057493372820317745 Adapter cache time: 0.030326521955430508 Engine time: 0.05961464298889041 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_128_slots_128_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_128_slots_128_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.990813762880862,
    "estimated_duration": 3600.0117881642136,
    "input_throughput": 5705.407428811201,
    "output_throughput": 5005.52805389259,
    "total_throughput": 10710.935482703791,
    "itl": 86.59725189835937,
    "ttft": 1766991.9144494256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 252140,
    "finished_requests": 83378,
    "scheduler_time": 29.68541083649248
}
#Debug simulation 
Total elapsed time: 5.990945661906153. Arrivals time: 0.2663481435738504 Scheduler time: 5.549909200519323 Scheduler overhead time: 0.057760769966989756 Adapter cache time: 0.029586398508399725 Engine time: 0.05941677466034889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_128_slots_128_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_128_slots_128_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.248921912163496,
    "estimated_duration": 3600.0669625884393,
    "input_throughput": 6010.451256840598,
    "output_throughput": 5255.648074500279,
    "total_throughput": 11266.099331340878,
    "itl": 98.64419112011132,
    "ttft": 1720404.9574051993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 251722,
    "finished_requests": 87757,
    "scheduler_time": 38.81343983912977
}
#Debug simulation 
Total elapsed time: 6.249042759183794. Arrivals time: 0.28136365162208676 Scheduler time: 5.811662129126489 Scheduler overhead time: 0.05200886679813266 Adapter cache time: 0.025998864322900772 Engine time: 0.05301617830991745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_128_slots_128_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_128_slots_128_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.123262374196202,
    "estimated_duration": 3600.0746973181576,
    "input_throughput": 5750.414016526297,
    "output_throughput": 5030.6233960899035,
    "total_throughput": 10781.0374126162,
    "itl": 86.23335838725532,
    "ttft": 1761603.5685315526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9287567421840514,
    "arrivals": 251722,
    "finished_requests": 83906,
    "scheduler_time": 29.8786659052097
}
#Debug simulation 
Total elapsed time: 6.123375091236085. Arrivals time: 0.2659685821272433 Scheduler time: 5.682860463857651 Scheduler overhead time: 0.05833358038216829 Adapter cache time: 0.027855865191668272 Engine time: 0.06006735051050782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_128_slots_128_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_128_slots_128_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.833087230101228,
    "estimated_duration": 3600.069339815659,
    "input_throughput": 5491.25089935414,
    "output_throughput": 4812.172034688388,
    "total_throughput": 10303.422934042526,
    "itl": 78.83545986595772,
    "ttft": 1790401.268007669,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8576836194237691,
    "arrivals": 251722,
    "finished_requests": 80221,
    "scheduler_time": 22.118768337974473
}
#Debug simulation 
Total elapsed time: 5.83318808209151. Arrivals time: 0.2559573887847364 Scheduler time: 5.392322805710137 Scheduler overhead time: 0.062323799822479486 Adapter cache time: 0.0281084724701941 Engine time: 0.06430863216519356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_128_slots_128_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_128_slots_128_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.00673062261194,
    "estimated_duration": 3600.074214234503,
    "input_throughput": 5750.632561446262,
    "output_throughput": 5030.968508478704,
    "total_throughput": 10781.601069924967,
    "itl": 86.23137293343395,
    "ttft": 1761591.134844105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8107579594524567,
    "arrivals": 251722,
    "finished_requests": 83911,
    "scheduler_time": 29.880635504606158
}
#Debug simulation 
Total elapsed time: 6.006830958649516. Arrivals time: 0.2739449995569885 Scheduler time: 5.560303645674139 Scheduler overhead time: 0.05768041266128421 Adapter cache time: 0.027483316604048014 Engine time: 0.05940035777166486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_128_slots_128_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_128_slots_128_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.32097176508978,
    "estimated_duration": 3600.0533324533367,
    "input_throughput": 6117.43937276392,
    "output_throughput": 5354.598729475868,
    "total_throughput": 11472.038102239787,
    "itl": 96.91971648472104,
    "ttft": 1695613.546406131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 250208,
    "finished_requests": 89371,
    "scheduler_time": 39.68184531740534
}
#Debug simulation 
Total elapsed time: 6.32109338697046. Arrivals time: 0.2752201617695391 Scheduler time: 5.890836603473872 Scheduler overhead time: 0.052513036876916885 Adapter cache time: 0.02295295661315322 Engine time: 0.05409353552386165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_128_slots_128_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_128_slots_128_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.091211575083435,
    "estimated_duration": 3600.031495075163,
    "input_throughput": 5839.43835734723,
    "output_throughput": 5114.662475922469,
    "total_throughput": 10954.100833269698,
    "itl": 84.91222715064676,
    "ttft": 1738217.7959901418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979342,
    "arrivals": 250208,
    "finished_requests": 85278,
    "scheduler_time": 30.50733915865552
}
#Debug simulation 
Total elapsed time: 6.091338807251304. Arrivals time: 0.26573613099753857 Scheduler time: 5.6551170400343835 Scheduler overhead time: 0.05857124738395214 Adapter cache time: 0.023547174874693155 Engine time: 0.06008943310007453 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_128_slots_128_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_128_slots_128_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.1636050823144615,
    "estimated_duration": 3600.043573629316,
    "input_throughput": 5839.607374198034,
    "output_throughput": 5114.83198005758,
    "total_throughput": 10954.439354255614,
    "itl": 84.90998601760187,
    "ttft": 1738110.4011578104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454804,
    "arrivals": 250208,
    "finished_requests": 85280,
    "scheduler_time": 30.50924343483811
}
#Debug simulation 
Total elapsed time: 6.163724809419364. Arrivals time: 0.2700938219204545 Scheduler time: 5.722536770161241 Scheduler overhead time: 0.05901339277625084 Adapter cache time: 0.023026918526738882 Engine time: 0.060602784622460604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_128_slots_128_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_128_slots_128_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.0951848472468555,
    "estimated_duration": 3600.0453252905845,
    "input_throughput": 5839.58008870433,
    "output_throughput": 5115.042544225092,
    "total_throughput": 10954.622632929422,
    "itl": 84.91036248273275,
    "ttft": 1738092.9353778535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 250208,
    "finished_requests": 85281,
    "scheduler_time": 30.510354241061776
}
#Debug simulation 
Total elapsed time: 6.095282157883048. Arrivals time: 0.2555973706766963 Scheduler time: 5.669182897079736 Scheduler overhead time: 0.05873832758516073 Adapter cache time: 0.02304218988865614 Engine time: 0.06034923205152154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_128_slots_128_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_128_slots_128_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.354828851297498,
    "estimated_duration": 3600.0617233277226,
    "input_throughput": 6192.151333281652,
    "output_throughput": 5384.924895698861,
    "total_throughput": 11577.076228980513,
    "itl": 96.35235805851396,
    "ttft": 1688253.510953646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8331635380256912,
    "arrivals": 249718,
    "finished_requests": 90043,
    "scheduler_time": 39.89413519550586
}
#Debug simulation 
Total elapsed time: 6.354951325338334. Arrivals time: 0.27623465238139033 Scheduler time: 5.9249552371911705 Scheduler overhead time: 0.052956012543290854 Adapter cache time: 0.021037861239165068 Engine time: 0.05426762206479907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_128_slots_128_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_128_slots_128_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.31599034788087,
    "estimated_duration": 3600.04363512166,
    "input_throughput": 5903.497333382122,
    "output_throughput": 5138.722158675952,
    "total_throughput": 11042.219492058075,
    "itl": 84.53517564898567,
    "ttft": 1732767.000661892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9223728212434802,
    "arrivals": 249718,
    "finished_requests": 85848,
    "scheduler_time": 30.658585717850084
}
#Debug simulation 
Total elapsed time: 6.316095977090299. Arrivals time: 0.26452966686338186 Scheduler time: 5.882492929697037 Scheduler overhead time: 0.058480588253587484 Adapter cache time: 0.021960241720080376 Engine time: 0.06022895872592926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_128_slots_128_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_128_slots_128_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.137145250104368,
    "estimated_duration": 3600.025799439314,
    "input_throughput": 5903.362137935214,
    "output_throughput": 5138.62095179461,
    "total_throughput": 11041.983089729825,
    "itl": 84.53438498352115,
    "ttft": 1732746.170982516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8640675403643389,
    "arrivals": 249718,
    "finished_requests": 85845,
    "scheduler_time": 30.657628892226874
}
#Debug simulation 
Total elapsed time: 6.137257629074156. Arrivals time: 0.2801908045075834 Scheduler time: 5.686980267520994 Scheduler overhead time: 0.05884980130940676 Adapter cache time: 0.022230512462556362 Engine time: 0.060483360197395086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_128_slots_128_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_128_slots_128_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.12627968378365,
    "estimated_duration": 3600.0917021477185,
    "input_throughput": 5903.676005619681,
    "output_throughput": 5138.865487499434,
    "total_throughput": 11042.541493119114,
    "itl": 84.53086837026311,
    "ttft": 1732704.2148767712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8043740385118862,
    "arrivals": 249718,
    "finished_requests": 85853,
    "scheduler_time": 30.656988482814526
}
#Debug simulation 
Total elapsed time: 6.126377764623612. Arrivals time: 0.2691718265414238 Scheduler time: 5.68659273115918 Scheduler overhead time: 0.05923558631911874 Adapter cache time: 0.02222834760323167 Engine time: 0.06059285718947649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_128_slots_128_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_128_slots_128_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.445020338986069,
    "estimated_duration": 3600.055975128686,
    "input_throughput": 6282.125099233097,
    "output_throughput": 5481.947540911375,
    "total_throughput": 11764.072640144472,
    "itl": 94.90856527021602,
    "ttft": 1667727.1945177391,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 248697,
    "finished_requests": 91604,
    "scheduler_time": 40.789067997862425
}
#Debug simulation 
Total elapsed time: 6.445121334865689. Arrivals time: 0.28222339041531086 Scheduler time: 6.010971409268677 Scheduler overhead time: 0.05387148633599281 Adapter cache time: 0.01703951833769679 Engine time: 0.05514344247058034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_128_slots_128_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_128_slots_128_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.21793755935505,
    "estimated_duration": 3600.024113847975,
    "input_throughput": 5966.486979177788,
    "output_throughput": 5215.063956872379,
    "total_throughput": 11181.550936050167,
    "itl": 83.49544081671748,
    "ttft": 1714304.5061248455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9301449631573638,
    "arrivals": 248697,
    "finished_requests": 87021,
    "scheduler_time": 31.3187145895011
}
#Debug simulation 
Total elapsed time: 6.218063350301236. Arrivals time: 0.27111907582730055 Scheduler time: 5.779215866699815 Scheduler overhead time: 0.05962137412279844 Adapter cache time: 0.0178259308449924 Engine time: 0.06129239592701197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_128_slots_128_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_128_slots_128_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.207403740845621,
    "estimated_duration": 3600.035790658973,
    "input_throughput": 5966.551514774858,
    "output_throughput": 5215.110096603618,
    "total_throughput": 11181.661611378477,
    "itl": 83.49420501498993,
    "ttft": 1714361.9711088797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8704514613049099,
    "arrivals": 248697,
    "finished_requests": 87022,
    "scheduler_time": 31.31892853367499
}
#Debug simulation 
Total elapsed time: 6.207519138697535. Arrivals time: 0.26233069971203804 Scheduler time: 5.777163679711521 Scheduler overhead time: 0.05966716771945357 Adapter cache time: 0.01801858050748706 Engine time: 0.06144070392474532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_128_slots_128_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_128_slots_128_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.22850586194545,
    "estimated_duration": 3600.0319745274846,
    "input_throughput": 5966.410896341892,
    "output_throughput": 5215.0397921018985,
    "total_throughput": 11181.45068844379,
    "itl": 83.49311119372531,
    "ttft": 1714305.2344076813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8107579594524567,
    "arrivals": 248697,
    "finished_requests": 87021,
    "scheduler_time": 31.320652254357878
}
#Debug simulation 
Total elapsed time: 6.228602620307356. Arrivals time: 0.2722021150402725 Scheduler time: 5.787559389602393 Scheduler overhead time: 0.0595608907751739 Adapter cache time: 0.017880015540868044 Engine time: 0.06239390606060624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_128_slots_128_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_128_slots_128_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.665313395205885,
    "estimated_duration": 3600.055679785199,
    "input_throughput": 4319.9256854071555,
    "output_throughput": 3787.528642005216,
    "total_throughput": 8107.454327412372,
    "itl": 136.64981676220103,
    "ttft": 1906566.4528326553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 200319,
    "finished_requests": 63066,
    "scheduler_time": 28.478624641214573
}
#Debug simulation 
Total elapsed time: 4.665440596174449. Arrivals time: 0.21904988959431648 Scheduler time: 4.306678319815546 Scheduler overhead time: 0.038337272591888905 Adapter cache time: 0.0438701007515192 Engine time: 0.03909761132672429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_128_slots_128_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_128_slots_128_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.529307004995644,
    "estimated_duration": 3600.0633168325085,
    "input_throughput": 4159.568230365292,
    "output_throughput": 3653.4496319837704,
    "total_throughput": 7813.017862349062,
    "itl": 118.7188099982397,
    "ttft": 1939542.1085983186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979342,
    "arrivals": 200319,
    "finished_requests": 60712,
    "scheduler_time": 22.247540035399002
}
#Debug simulation 
Total elapsed time: 4.529405220877379. Arrivals time: 0.2391960546374321 Scheduler time: 4.127820742316544 Scheduler overhead time: 0.043025491293519735 Adapter cache time: 0.05459946300834417 Engine time: 0.04405786516144872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_128_slots_128_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_128_slots_128_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 4.524925136007369,
    "estimated_duration": 3600.0048226881395,
    "input_throughput": 4159.138872713969,
    "output_throughput": 3652.9823285570696,
    "total_throughput": 7812.121201271038,
    "itl": 118.64672381793761,
    "ttft": 1939784.684911799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.87683538224548,
    "arrivals": 200319,
    "finished_requests": 60702,
    "scheduler_time": 22.219997637956084
}
#Debug simulation 
Total elapsed time: 4.5250250729732215. Arrivals time: 0.20509163942188025 Scheduler time: 4.15731660136953 Scheduler overhead time: 0.04275447968393564 Adapter cache time: 0.055294057819992304 Engine time: 0.04385958705097437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_128_slots_128_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_128_slots_128_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.535464631393552,
    "estimated_duration": 3600.060424856198,
    "input_throughput": 4161.356541841492,
    "output_throughput": 3655.0542066319913,
    "total_throughput": 7816.410748473483,
    "itl": 118.8337096171687,
    "ttft": 1938890.5498312947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 200319,
    "finished_requests": 60740,
    "scheduler_time": 22.30918568459147
}
#Debug simulation 
Total elapsed time: 4.5355629893019795. Arrivals time: 0.23063935805112123 Scheduler time: 4.143192428629845 Scheduler overhead time: 0.04274602606892586 Adapter cache time: 0.05450578359887004 Engine time: 0.04385403636842966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_128_slots_128_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_128_slots_128_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.7645839671604335,
    "estimated_duration": 3600.0986444213954,
    "input_throughput": 4527.562883660836,
    "output_throughput": 3958.7201373173857,
    "total_throughput": 8486.283020978222,
    "itl": 130.71582201620654,
    "ttft": 1851328.2635385715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 192932,
    "finished_requests": 66052,
    "scheduler_time": 29.906119031987554
}
#Debug simulation 
Total elapsed time: 4.764682495966554. Arrivals time: 0.2151011717505753 Scheduler time: 4.413168835453689 Scheduler overhead time: 0.039407826494425535 Adapter cache time: 0.037802623119205236 Engine time: 0.04037504456937313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_128_slots_128_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_128_slots_128_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.651964507065713,
    "estimated_duration": 3600.111652162563,
    "input_throughput": 4348.210142481754,
    "output_throughput": 3805.7255784747335,
    "total_throughput": 8153.935720956488,
    "itl": 113.87013909468003,
    "ttft": 1889092.0444272023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979338,
    "arrivals": 192932,
    "finished_requests": 63442,
    "scheduler_time": 23.347748277196445
}
#Debug simulation 
Total elapsed time: 4.652062435168773. Arrivals time: 0.21813845774158835 Scheduler time: 4.27784410957247 Scheduler overhead time: 0.04431755421683192 Adapter cache time: 0.04527898598462343 Engine time: 0.04518364369869232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_128_slots_128_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_128_slots_128_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 4.661401405930519,
    "estimated_duration": 3600.1105708799,
    "input_throughput": 4347.9942329032965,
    "output_throughput": 3805.3897874174563,
    "total_throughput": 8153.384020320753,
    "itl": 113.86420001048015,
    "ttft": 1889077.5843983586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454803,
    "arrivals": 192932,
    "finished_requests": 63439,
    "scheduler_time": 23.34786125616314
}
#Debug simulation 
Total elapsed time: 4.661514330655336. Arrivals time: 0.21496556093916297 Scheduler time: 4.287928623147309 Scheduler overhead time: 0.044341704808175564 Adapter cache time: 0.04719323758035898 Engine time: 0.04569339891895652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_128_slots_128_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_128_slots_128_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.695274023804814,
    "estimated_duration": 3600.1239390058217,
    "input_throughput": 4348.105027829345,
    "output_throughput": 3805.452321117394,
    "total_throughput": 8153.557348946739,
    "itl": 113.86467307871993,
    "ttft": 1889077.558730618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 192932,
    "finished_requests": 63440,
    "scheduler_time": 23.34820470814128
}
#Debug simulation 
Total elapsed time: 4.695367814041674. Arrivals time: 0.21964536467567086 Scheduler time: 4.3177947122603655 Scheduler overhead time: 0.04480451298877597 Adapter cache time: 0.04572879383340478 Engine time: 0.04573098570108414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_128_slots_128_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_128_slots_128_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.972610998898745,
    "estimated_duration": 3600.0131389360017,
    "input_throughput": 4661.578264394866,
    "output_throughput": 4110.067777245143,
    "total_throughput": 8771.646041640008,
    "itl": 126.3496941586827,
    "ttft": 1811910.5292392008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 188974,
    "finished_requests": 68398,
    "scheduler_time": 31.268910309593807
}
#Debug simulation 
Total elapsed time: 4.972708354704082. Arrivals time: 0.22953384462743998 Scheduler time: 4.609172781929374 Scheduler overhead time: 0.04101624945178628 Adapter cache time: 0.031236184295266867 Engine time: 0.04194228444248438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_128_slots_128_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_128_slots_128_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.812467532232404,
    "estimated_duration": 3600.0254277719996,
    "input_throughput": 4464.342633809272,
    "output_throughput": 3938.1338505639847,
    "total_throughput": 8402.476484373257,
    "itl": 110.51092786650278,
    "ttft": 1854696.3040711368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979343,
    "arrivals": 188974,
    "finished_requests": 65521,
    "scheduler_time": 24.427835389638144
}
#Debug simulation 
Total elapsed time: 4.812567108310759. Arrivals time: 0.2147526815533638 Scheduler time: 4.445520498324186 Scheduler overhead time: 0.046001780312508345 Adapter cache time: 0.03719747066497803 Engine time: 0.04695651913061738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_128_slots_128_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_128_slots_128_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.03282668441534,
    "estimated_duration": 3600.084964507791,
    "input_throughput": 4464.873512283244,
    "output_throughput": 3938.30038451286,
    "total_throughput": 8403.173896796105,
    "itl": 110.50414808026939,
    "ttft": 1854624.6308394328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454805,
    "arrivals": 188974,
    "finished_requests": 65527,
    "scheduler_time": 24.4285660326047
}
#Debug simulation 
Total elapsed time: 5.032925089355558. Arrivals time: 0.23245983384549618 Scheduler time: 4.648851442616433 Scheduler overhead time: 0.04552815202623606 Adapter cache time: 0.037359737791121006 Engine time: 0.04672198975458741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_128_slots_128_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_128_slots_128_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.833042751997709,
    "estimated_duration": 3600.0609215088757,
    "input_throughput": 4464.813888000303,
    "output_throughput": 3938.3402973240613,
    "total_throughput": 8403.154185324365,
    "itl": 110.50438630867981,
    "ttft": 1854625.2832014437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 188974,
    "finished_requests": 65526,
    "scheduler_time": 24.42987766866967
}
#Debug simulation 
Total elapsed time: 4.83313852082938. Arrivals time: 0.2177673215046525 Scheduler time: 4.463289831299335 Scheduler overhead time: 0.04581829300150275 Adapter cache time: 0.037123095244169235 Engine time: 0.04692135006189346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_128_slots_128_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_128_slots_128_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.097559520043433,
    "estimated_duration": 3600.0492826828745,
    "input_throughput": 4780.7823306168075,
    "output_throughput": 4155.6869990543055,
    "total_throughput": 8936.469329671114,
    "itl": 120.22962401147588,
    "ttft": 1783415.2109268024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 187135,
    "finished_requests": 69475,
    "scheduler_time": 30.562770793311834
}
#Debug simulation 
Total elapsed time: 5.09765763534233. Arrivals time: 0.2353712748736143 Scheduler time: 4.7302279863506556 Scheduler overhead time: 0.043162244372069836 Adapter cache time: 0.023868697229772806 Engine time: 0.04423204530030489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_128_slots_128_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_128_slots_128_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.833763129077852,
    "estimated_duration": 3600.074307771233,
    "input_throughput": 4551.496607897581,
    "output_throughput": 3961.2615687448765,
    "total_throughput": 8512.758176642457,
    "itl": 104.20261571954006,
    "ttft": 1831557.4092096118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979343,
    "arrivals": 187135,
    "finished_requests": 66157,
    "scheduler_time": 22.771453188328397
}
#Debug simulation 
Total elapsed time: 4.833891327958554. Arrivals time: 0.21938090305775404 Scheduler time: 4.463926703669131 Scheduler overhead time: 0.04794417880475521 Adapter cache time: 0.030314805451780558 Engine time: 0.049219909124076366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_128_slots_128_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_128_slots_128_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 4.91970402887091,
    "estimated_duration": 3600.1173409716257,
    "input_throughput": 4621.065211032831,
    "output_throughput": 4019.613704061779,
    "total_throughput": 8640.67891509461,
    "itl": 107.60525867197306,
    "ttft": 1820075.967080557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454803,
    "arrivals": 187135,
    "finished_requests": 67136,
    "scheduler_time": 24.879169079846175
}
#Debug simulation 
Total elapsed time: 4.919801393058151. Arrivals time: 0.23817293718457222 Scheduler time: 4.533951721619815 Scheduler overhead time: 0.04659070819616318 Adapter cache time: 0.029858781024813652 Engine time: 0.0486319032497704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_128_slots_128_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_128_slots_128_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.90133160399273,
    "estimated_duration": 3600.055502698371,
    "input_throughput": 4620.438209225481,
    "output_throughput": 4019.5891394323385,
    "total_throughput": 8640.027348657819,
    "itl": 107.63784548815852,
    "ttft": 1819923.742750296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 187135,
    "finished_requests": 67131,
    "scheduler_time": 24.88604108838178
}
#Debug simulation 
Total elapsed time: 4.901429645717144. Arrivals time: 0.2150481604039669 Scheduler time: 4.539842326659709 Scheduler overhead time: 0.04666899098083377 Adapter cache time: 0.029389782808721066 Engine time: 0.04793380247429013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_128_slots_128_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_128_slots_128_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.138099713250995,
    "estimated_duration": 3600.0824006738644,
    "input_throughput": 4895.785162223205,
    "output_throughput": 4274.058004094535,
    "total_throughput": 9169.84316631774,
    "itl": 121.13106156294774,
    "ttft": 1761700.0066734836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 186179,
    "finished_requests": 71379,
    "scheduler_time": 32.649677108487076
}
#Debug simulation 
Total elapsed time: 5.138216915074736. Arrivals time: 0.23807459138333797 Scheduler time: 4.772365795914084 Scheduler overhead time: 0.04339962126687169 Adapter cache time: 0.019979122560471296 Engine time: 0.04369991039857268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_128_slots_128_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_128_slots_128_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.927677291911095,
    "estimated_duration": 3600.103592052551,
    "input_throughput": 4660.05757085312,
    "output_throughput": 4076.2935356627336,
    "total_throughput": 8736.351106515853,
    "itl": 106.53954067535659,
    "ttft": 1809598.8226894613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979344,
    "arrivals": 186179,
    "finished_requests": 67925,
    "scheduler_time": 25.44235447618895
}
#Debug simulation 
Total elapsed time: 4.927795487921685. Arrivals time: 0.22484201146289706 Scheduler time: 4.560013980604708 Scheduler overhead time: 0.046818575356155634 Adapter cache time: 0.02521525416523218 Engine time: 0.04819753998890519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_128_slots_128_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_128_slots_128_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 4.967337915673852,
    "estimated_duration": 3600.017910436048,
    "input_throughput": 4659.954871715634,
    "output_throughput": 4076.1780538537905,
    "total_throughput": 8736.132925569425,
    "itl": 106.53662890203913,
    "ttft": 1809564.6796162203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454804,
    "arrivals": 186179,
    "finished_requests": 67922,
    "scheduler_time": 25.441549700014686
}
#Debug simulation 
Total elapsed time: 4.967436894774437. Arrivals time: 0.23283649468794465 Scheduler time: 4.591054039541632 Scheduler overhead time: 0.04730143491178751 Adapter cache time: 0.02519958559423685 Engine time: 0.04825293831527233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_128_slots_128_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_128_slots_128_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.9322295831516385,
    "estimated_duration": 3600.0440439800113,
    "input_throughput": 4660.447982033954,
    "output_throughput": 4076.681512978036,
    "total_throughput": 8737.12949501199,
    "itl": 106.53439365248467,
    "ttft": 1809486.8652325275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 186179,
    "finished_requests": 67929,
    "scheduler_time": 25.442066717979536
}
#Debug simulation 
Total elapsed time: 4.93232535617426. Arrivals time: 0.21782982908189297 Scheduler time: 4.571106608491391 Scheduler overhead time: 0.04728081310167909 Adapter cache time: 0.025374218821525574 Engine time: 0.04793701367452741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.174249846953899,
    "estimated_duration": 3600.051916914408,
    "input_throughput": 4923.22900031705,
    "output_throughput": 4302.569617739284,
    "total_throughput": 9225.798618056333,
    "itl": 120.29684943137185,
    "ttft": 1757494.063687047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8397759470576411,
    "arrivals": 185762,
    "finished_requests": 71743,
    "scheduler_time": 32.79235833343315
}
#Debug simulation 
Total elapsed time: 5.1743415500968695. Arrivals time: 0.23663146747276187 Scheduler time: 4.814133523963392 Scheduler overhead time: 0.04281253553926945 Adapter cache time: 0.01637892611324787 Engine time: 0.043800591956824064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.214475139044225,
    "estimated_duration": 3600.089745549535,
    "input_throughput": 4677.311453364798,
    "output_throughput": 4093.5504505736844,
    "total_throughput": 8770.861903938481,
    "itl": 105.8144059571959,
    "ttft": 1807619.5640084194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9287567421840507,
    "arrivals": 185762,
    "finished_requests": 68152,
    "scheduler_time": 25.410094227331307
}
#Debug simulation 
Total elapsed time: 5.214565098751336. Arrivals time: 0.2338655204512179 Scheduler time: 4.839548819232732 Scheduler overhead time: 0.04757483722642064 Adapter cache time: 0.021599356550723314 Engine time: 0.04896372323855758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 4.924050997942686,
    "estimated_duration": 3600.0695237610594,
    "input_throughput": 4681.290149750605,
    "output_throughput": 4097.249484390513,
    "total_throughput": 8778.539634141118,
    "itl": 105.99708198661547,
    "ttft": 1806639.5407114755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8704514613049097,
    "arrivals": 185762,
    "finished_requests": 68215,
    "scheduler_time": 25.524295255401363
}
#Debug simulation 
Total elapsed time: 4.9241459858603776. Arrivals time: 0.21891528367996216 Scheduler time: 4.565005900338292 Scheduler overhead time: 0.04730767011642456 Adapter cache time: 0.02176095824688673 Engine time: 0.04836885444819927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.062995361164212,
    "estimated_duration": 3600.070327139621,
    "input_throughput": 4677.98583628804,
    "output_throughput": 4094.125019971693,
    "total_throughput": 8772.110856259733,
    "itl": 105.81310409456275,
    "ttft": 1807563.8116899244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8107579594524567,
    "arrivals": 185762,
    "finished_requests": 68160,
    "scheduler_time": 25.414636043255353
}
#Debug simulation 
Total elapsed time: 5.063120834995061. Arrivals time: 0.2333080335520208 Scheduler time: 4.687480087392032 Scheduler overhead time: 0.048126999754458666 Adapter cache time: 0.02166901808232069 Engine time: 0.04931412311270833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_128_slots_128_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_128_slots_128_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.9857208472676575,
    "estimated_duration": 3600.0965544146648,
    "input_throughput": 4683.906596705614,
    "output_throughput": 4084.365732349288,
    "total_throughput": 8768.272329054902,
    "itl": 126.97988009038342,
    "ttft": 1674427.2244016402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 146610,
    "finished_requests": 68411,
    "scheduler_time": 32.62511080997341
}
#Debug simulation 
Total elapsed time: 4.9858595579862595. Arrivals time: 0.22099706018343568 Scheduler time: 4.59889872930944 Scheduler overhead time: 0.041174760553985834 Adapter cache time: 0.06280816858634353 Engine time: 0.042152449022978544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_128_slots_128_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_128_slots_128_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.951563159935176,
    "estimated_duration": 3600.040846420378,
    "input_throughput": 4572.757838669732,
    "output_throughput": 3991.283602875586,
    "total_throughput": 8564.041441545318,
    "itl": 108.91678139090496,
    "ttft": 1702319.041759624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.936528884097934,
    "arrivals": 146610,
    "finished_requests": 66798,
    "scheduler_time": 26.519839721535565
}
#Debug simulation 
Total elapsed time: 4.951660198159516. Arrivals time: 0.23726180288940668 Scheduler time: 4.523083760403097 Scheduler overhead time: 0.046923890709877014 Adapter cache time: 0.07330626808106899 Engine time: 0.04847181960940361 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_128_slots_128_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_128_slots_128_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 4.915688713081181,
    "estimated_duration": 3600.0066008522117,
    "input_throughput": 4572.95300405918,
    "output_throughput": 3991.436570310302,
    "total_throughput": 8564.389574369483,
    "itl": 108.91420339289661,
    "ttft": 1702238.7483798473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454803,
    "arrivals": 146610,
    "finished_requests": 66801,
    "scheduler_time": 26.519587535499166
}
#Debug simulation 
Total elapsed time: 4.915791143197566. Arrivals time: 0.22766811167821288 Scheduler time: 4.49787683878094 Scheduler overhead time: 0.04671132331714034 Adapter cache time: 0.07287579635158181 Engine time: 0.04814406996592879 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_128_slots_128_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_128_slots_128_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.923333371989429,
    "estimated_duration": 3600.0898716254783,
    "input_throughput": 4558.52314392091,
    "output_throughput": 3978.905669244411,
    "total_throughput": 8537.428813165321,
    "itl": 109.22840837621116,
    "ttft": 1706184.311297369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 146610,
    "finished_requests": 66593,
    "scheduler_time": 26.413611630479178
}
#Debug simulation 
Total elapsed time: 4.923430196940899. Arrivals time: 0.2425065105780959 Scheduler time: 4.4914550837129354 Scheduler overhead time: 0.04663796629756689 Adapter cache time: 0.07252041902393103 Engine time: 0.04777631722390652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_128_slots_128_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_128_slots_128_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.19300416810438,
    "estimated_duration": 3600.1014825344887,
    "input_throughput": 4885.682274605574,
    "output_throughput": 4257.828584656614,
    "total_throughput": 9143.510859262187,
    "itl": 120.85622299468558,
    "ttft": 1611739.9626587841,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 142827,
    "finished_requests": 70870,
    "scheduler_time": 34.320222510017764
}
#Debug simulation 
Total elapsed time: 5.193131142295897. Arrivals time: 0.21837520645931363 Scheduler time: 4.811842364259064 Scheduler overhead time: 0.04293623426929116 Adapter cache time: 0.05514532467350364 Engine time: 0.044118826277554035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_128_slots_128_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_128_slots_128_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.092246698215604,
    "estimated_duration": 3600.0318196339344,
    "input_throughput": 4734.83398314331,
    "output_throughput": 4133.32291088279,
    "total_throughput": 8868.1568940261,
    "itl": 104.36656258330382,
    "ttft": 1647947.401232026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979342,
    "arrivals": 142827,
    "finished_requests": 68730,
    "scheduler_time": 27.775419197790256
}
#Debug simulation 
Total elapsed time: 5.092347824014723. Arrivals time: 0.22623437130823731 Scheduler time: 4.679609430488199 Scheduler overhead time: 0.04884869419038296 Adapter cache time: 0.06421376764774323 Engine time: 0.049992495216429234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_128_slots_128_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_128_slots_128_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.08108034171164,
    "estimated_duration": 3600.057929415705,
    "input_throughput": 4734.799365510909,
    "output_throughput": 4133.4395978497905,
    "total_throughput": 8868.2389633607,
    "itl": 104.36755499453655,
    "ttft": 1647734.4868080886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454805,
    "arrivals": 142827,
    "finished_requests": 68731,
    "scheduler_time": 27.775887608153454
}
#Debug simulation 
Total elapsed time: 5.081181970890611. Arrivals time: 0.2209484102204442 Scheduler time: 4.674729136284441 Scheduler overhead time: 0.048510704189538956 Adapter cache time: 0.06365971500054002 Engine time: 0.04982429509982467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_128_slots_128_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_128_slots_128_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.0528068179264665,
    "estimated_duration": 3600.029509936424,
    "input_throughput": 4734.887576046849,
    "output_throughput": 4133.601393801574,
    "total_throughput": 8868.488969848424,
    "itl": 104.36175747556354,
    "ttft": 1647694.5419849707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 142827,
    "finished_requests": 68732,
    "scheduler_time": 27.775923703962846
}
#Debug simulation 
Total elapsed time: 5.052904061973095. Arrivals time: 0.22387180337682366 Scheduler time: 4.644038506783545 Scheduler overhead time: 0.04858162999153137 Adapter cache time: 0.06336509063839912 Engine time: 0.049678008537739515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_128_slots_128_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_128_slots_128_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.275551327969879,
    "estimated_duration": 3600.080660262759,
    "input_throughput": 4985.363855344855,
    "output_throughput": 4381.385721187911,
    "total_throughput": 9366.749576532766,
    "itl": 118.33877102924063,
    "ttft": 1571507.4365166207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 140936,
    "finished_requests": 72796,
    "scheduler_time": 35.70614167154418
}
#Debug simulation 
Total elapsed time: 5.275659785140306. Arrivals time: 0.22760059963911772 Scheduler time: 4.889273662120104 Scheduler overhead time: 0.04372612200677395 Adapter cache time: 0.04900747910141945 Engine time: 0.044939563143998384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_128_slots_128_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_128_slots_128_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.1875840201973915,
    "estimated_duration": 3600.027087972396,
    "input_throughput": 4820.353174001745,
    "output_throughput": 4240.990866710131,
    "total_throughput": 9061.344040711876,
    "itl": 102.4368446258365,
    "ttft": 1612768.4035481932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979343,
    "arrivals": 140936,
    "finished_requests": 70438,
    "scheduler_time": 28.920554503310996
}
#Debug simulation 
Total elapsed time: 5.18769062217325. Arrivals time: 0.22842682339251041 Scheduler time: 4.778373910114169 Scheduler overhead time: 0.04946253541857004 Adapter cache time: 0.056660895235836506 Engine time: 0.0508299907669425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_128_slots_128_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_128_slots_128_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.169724804349244,
    "estimated_duration": 3600.0631264599533,
    "input_throughput": 4820.737967743815,
    "output_throughput": 4241.434514792766,
    "total_throughput": 9062.17248253658,
    "itl": 102.43423327859496,
    "ttft": 1612723.1421102402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454802,
    "arrivals": 140936,
    "finished_requests": 70443,
    "scheduler_time": 28.920867890433158
}
#Debug simulation 
Total elapsed time: 5.169824598357081. Arrivals time: 0.2307561570778489 Scheduler time: 4.758290865458548 Scheduler overhead time: 0.049635293893516064 Adapter cache time: 0.05653091752901673 Engine time: 0.05077349580824375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_128_slots_128_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_128_slots_128_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.1762305442243814,
    "estimated_duration": 3600.0948905891137,
    "input_throughput": 4821.0412579319145,
    "output_throughput": 4241.603475485395,
    "total_throughput": 9062.64473341731,
    "itl": 102.43246143263734,
    "ttft": 1612779.4269323547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 140936,
    "finished_requests": 70446,
    "scheduler_time": 28.921964334676566
}
#Debug simulation 
Total elapsed time: 5.17632838524878. Arrivals time: 0.21923310682177544 Scheduler time: 4.776066950056702 Scheduler overhead time: 0.04960333043709397 Adapter cache time: 0.056517242919653654 Engine time: 0.050927088130265474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_128_slots_128_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_128_slots_128_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.36025441205129,
    "estimated_duration": 3600.0165806209848,
    "input_throughput": 5047.818973340779,
    "output_throughput": 4446.710075218226,
    "total_throughput": 9494.529048559005,
    "itl": 116.46100028454906,
    "ttft": 1549658.8188523047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 139992,
    "finished_requests": 73911,
    "scheduler_time": 36.3660880115879
}
#Debug simulation 
Total elapsed time: 5.360354333650321. Arrivals time: 0.23614461114630103 Scheduler time: 4.968397005926818 Scheduler overhead time: 0.04439908964559436 Adapter cache time: 0.0446229437366128 Engine time: 0.045471410267055035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_128_slots_128_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_128_slots_128_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.206306972075254,
    "estimated_duration": 3600.031820646753,
    "input_throughput": 4866.974758254295,
    "output_throughput": 4291.497067163273,
    "total_throughput": 9158.471825417568,
    "itl": 101.09493097787833,
    "ttft": 1593963.0264597936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.936528884097934,
    "arrivals": 139992,
    "finished_requests": 71254,
    "scheduler_time": 29.33637232149959
}
#Debug simulation 
Total elapsed time: 5.20640484476462. Arrivals time: 0.22174543607980013 Scheduler time: 4.806764698587358 Scheduler overhead time: 0.050155391450971365 Adapter cache time: 0.05117379920557141 Engine time: 0.05249993642792106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_128_slots_128_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_128_slots_128_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.238006725907326,
    "estimated_duration": 3600.0672757230036,
    "input_throughput": 4867.222376137674,
    "output_throughput": 4291.515079227851,
    "total_throughput": 9158.737455365525,
    "itl": 101.09075505043522,
    "ttft": 1594016.1332775704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454803,
    "arrivals": 139992,
    "finished_requests": 71256,
    "scheduler_time": 29.33673930971079
}
#Debug simulation 
Total elapsed time: 5.238107230979949. Arrivals time: 0.23270320240408182 Scheduler time: 4.828632901422679 Scheduler overhead time: 0.04999982938170433 Adapter cache time: 0.051420293748378754 Engine time: 0.0511607569642365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_128_slots_128_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_128_slots_128_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.231137031223625,
    "estimated_duration": 3600.0125561435707,
    "input_throughput": 4866.774414467146,
    "output_throughput": 4291.445587775854,
    "total_throughput": 9158.220002243,
    "itl": 101.08992989953506,
    "ttft": 1593925.331413744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 139992,
    "finished_requests": 71253,
    "scheduler_time": 29.33741653751026
}
#Debug simulation 
Total elapsed time: 5.23125390522182. Arrivals time: 0.24013802222907543 Scheduler time: 4.814421969931573 Scheduler overhead time: 0.04996310966089368 Adapter cache time: 0.05103574646636844 Engine time: 0.05154018243774772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.412592328153551,
    "estimated_duration": 3600.0963998127504,
    "input_throughput": 5140.039861422175,
    "output_throughput": 4510.935040751873,
    "total_throughput": 9650.974902174048,
    "itl": 114.81656045309819,
    "ttft": 1529121.8992183465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 139506,
    "finished_requests": 75120,
    "scheduler_time": 37.05527041836544
}
#Debug simulation 
Total elapsed time: 5.412688408046961. Arrivals time: 0.24131795344874263 Scheduler time: 5.019615516066551 Scheduler overhead time: 0.04491293290629983 Adapter cache time: 0.039037051144987345 Engine time: 0.04615312581881881 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.233220414724201,
    "estimated_duration": 3600.021473619388,
    "input_throughput": 4952.186849617904,
    "output_throughput": 4346.494351398507,
    "total_throughput": 9298.68120101641,
    "itl": 99.71224979564388,
    "ttft": 1575038.469271521,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979343,
    "arrivals": 139506,
    "finished_requests": 72300,
    "scheduler_time": 29.832188301498803
}
#Debug simulation 
Total elapsed time: 5.233334573917091. Arrivals time: 0.2376040550880134 Scheduler time: 4.823599782772362 Scheduler overhead time: 0.050328456331044436 Adapter cache time: 0.04607534082606435 Engine time: 0.05150949768722057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.268747651949525,
    "estimated_duration": 3600.031113281458,
    "input_throughput": 4952.189144762585,
    "output_throughput": 4346.575489937056,
    "total_throughput": 9298.76463469964,
    "itl": 99.71356586298589,
    "ttft": 1574971.4494279586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454803,
    "arrivals": 139506,
    "finished_requests": 72301,
    "scheduler_time": 29.836831179574503
}
#Debug simulation 
Total elapsed time: 5.26887365989387. Arrivals time: 0.23614186560735106 Scheduler time: 4.859022989869118 Scheduler overhead time: 0.05048529850319028 Adapter cache time: 0.04660259839147329 Engine time: 0.05215021735057235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.266177971847355,
    "estimated_duration": 3600.036372446802,
    "input_throughput": 4952.250520703163,
    "output_throughput": 4346.747749485756,
    "total_throughput": 9298.998270188918,
    "itl": 99.70714478359145,
    "ttft": 1574993.6092693936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 139506,
    "finished_requests": 72304,
    "scheduler_time": 29.835045211768275
}
#Debug simulation 
Total elapsed time: 5.266275680158287. Arrivals time: 0.2295943247154355 Scheduler time: 4.863627186976373 Scheduler overhead time: 0.0505413506180048 Adapter cache time: 0.04601972782984376 Engine time: 0.051945225801318884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_128_slots_128_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_128_slots_128_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 270, 270, 8640, 270, 540, 540, 540, 270, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 540, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 8640, 270, 540, 540, 270, 540, 270, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 270, 540, 8640, 8640, 540, 270, 270, 270, 8640, 540, 540, 540, 540, 8640, 540, 8640, 270, 270, 540, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 8640, 8640, 540, 540, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 540, 8640, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 540, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270]
Prompts retrieved: 406080 . Total input tokens: 90338405 . Total output tokens: 79955162
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.42197569925338,
    "estimated_duration": 3600.0813313390063,
    "input_throughput": 5116.728291565754,
    "output_throughput": 4465.040792292679,
    "total_throughput": 9581.769083858433,
    "itl": 115.80995165342867,
    "ttft": 1518231.0413810674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 135164,
    "finished_requests": 74457,
    "scheduler_time": 37.02161334603002
}
#Debug simulation 
Total elapsed time: 5.4220733982510865. Arrivals time: 0.23738174885511398 Scheduler time: 5.0134623176418245 Scheduler overhead time: 0.04476278508082032 Adapter cache time: 0.05906830122694373 Engine time: 0.045878627337515354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_128_slots_128_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_128_slots_128_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 270, 270, 8640, 270, 540, 540, 540, 270, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 540, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 8640, 270, 540, 540, 270, 540, 270, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 270, 540, 8640, 8640, 540, 270, 270, 270, 8640, 540, 540, 540, 540, 8640, 540, 8640, 270, 270, 540, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 8640, 8640, 540, 540, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 540, 8640, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 540, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270]
Prompts retrieved: 406080 . Total input tokens: 90338405 . Total output tokens: 79955162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.310352539177984,
    "estimated_duration": 3600.0644800791483,
    "input_throughput": 4966.433267774947,
    "output_throughput": 4340.741974614976,
    "total_throughput": 9307.175242389923,
    "itl": 99.91453520008405,
    "ttft": 1555334.8152225078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979343,
    "arrivals": 135164,
    "finished_requests": 72338,
    "scheduler_time": 30.273421609023096
}
#Debug simulation 
Total elapsed time: 5.310449179261923. Arrivals time: 0.2237485651858151 Scheduler time: 4.895908983424306 Scheduler overhead time: 0.050910140853375196 Adapter cache time: 0.06316168373450637 Engine time: 0.052071626763790846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_128_slots_128_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_128_slots_128_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 270, 270, 8640, 270, 540, 540, 540, 270, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 540, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 8640, 270, 540, 540, 270, 540, 270, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 270, 540, 8640, 8640, 540, 270, 270, 270, 8640, 540, 540, 540, 540, 8640, 540, 8640, 270, 270, 540, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 8640, 8640, 540, 540, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 540, 8640, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 540, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270]
Prompts retrieved: 406080 . Total input tokens: 90338405 . Total output tokens: 79955162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.286995938979089,
    "estimated_duration": 3600.1006144954604,
    "input_throughput": 4966.567303149062,
    "output_throughput": 4340.905900539716,
    "total_throughput": 9307.473203688778,
    "itl": 99.9145195013189,
    "ttft": 1555304.8544198617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454803,
    "arrivals": 135164,
    "finished_requests": 72340,
    "scheduler_time": 30.273714682092283
}
#Debug simulation 
Total elapsed time: 5.287128878757358. Arrivals time: 0.23785803839564323 Scheduler time: 4.859264633618295 Scheduler overhead time: 0.05054868431761861 Adapter cache time: 0.06310799485072494 Engine time: 0.05188316060230136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_128_slots_128_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_128_slots_128_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 270, 270, 8640, 270, 540, 540, 540, 270, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 540, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 8640, 270, 540, 540, 270, 540, 270, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 270, 540, 8640, 8640, 540, 270, 270, 270, 8640, 540, 540, 540, 540, 8640, 540, 8640, 270, 270, 540, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 8640, 8640, 540, 540, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 540, 8640, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 540, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270]
Prompts retrieved: 406080 . Total input tokens: 90338405 . Total output tokens: 79955162
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.295843326952308,
    "estimated_duration": 3600.0239546093553,
    "input_throughput": 4966.48917491443,
    "output_throughput": 4340.790838347549,
    "total_throughput": 9307.280013261978,
    "itl": 99.9128100010392,
    "ttft": 1555269.908457486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 135164,
    "finished_requests": 72338,
    "scheduler_time": 30.273601533279002
}
#Debug simulation 
Total elapsed time: 5.295941283926368. Arrivals time: 0.23573253164067864 Scheduler time: 4.869863418862224 Scheduler overhead time: 0.050580006558448076 Adapter cache time: 0.06316772568970919 Engine time: 0.05211656028404832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_128_slots_128_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_128_slots_128_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 135, 135, 8640, 135, 540, 540, 540, 135, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 540, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 8640, 135, 540, 540, 135, 540, 135, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 135, 540, 8640, 8640, 540, 135, 135, 135, 8640, 540, 540, 540, 540, 8640, 540, 8640, 135, 135, 540, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 8640, 8640, 540, 540, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 540, 8640, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 540, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135]
Prompts retrieved: 400410 . Total input tokens: 89102245 . Total output tokens: 78834433
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.5333524770103395,
    "estimated_duration": 3600.076875600625,
    "input_throughput": 5309.315789766598,
    "output_throughput": 4614.453128095617,
    "total_throughput": 9923.768917862215,
    "itl": 111.73816277035489,
    "ttft": 1465678.4625641073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 133259,
    "finished_requests": 77064,
    "scheduler_time": 38.53387112046645
}
#Debug simulation 
Total elapsed time: 5.5334723251871765. Arrivals time: 0.23083499493077397 Scheduler time: 5.1353446138091385 Scheduler overhead time: 0.04619734128937125 Adapter cache time: 0.05134639050811529 Engine time: 0.047455654479563236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_128_slots_128_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_128_slots_128_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 135, 135, 8640, 135, 540, 540, 540, 135, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 540, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 8640, 135, 540, 540, 135, 540, 135, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 135, 540, 8640, 8640, 540, 135, 135, 135, 8640, 540, 540, 540, 540, 8640, 540, 8640, 135, 135, 540, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 8640, 8640, 540, 540, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 540, 8640, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 540, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135]
Prompts retrieved: 400410 . Total input tokens: 89102245 . Total output tokens: 78834433
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.414444758091122,
    "estimated_duration": 3600.009567822607,
    "input_throughput": 5144.804937616392,
    "output_throughput": 4469.871453628571,
    "total_throughput": 9614.676391244962,
    "itl": 96.63914268022987,
    "ttft": 1508729.2673410028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979342,
    "arrivals": 133259,
    "finished_requests": 74661,
    "scheduler_time": 31.413037806204947
}
#Debug simulation 
Total elapsed time: 5.414543035905808. Arrivals time: 0.23766826931387186 Scheduler time: 4.991695993579924 Scheduler overhead time: 0.052314415108412504 Adapter cache time: 0.05391424987465143 Engine time: 0.05377583531662822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_128_slots_128_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_128_slots_128_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 135, 135, 8640, 135, 540, 540, 540, 135, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 540, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 8640, 135, 540, 540, 135, 540, 135, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 135, 540, 8640, 8640, 540, 135, 135, 135, 8640, 540, 540, 540, 540, 8640, 540, 8640, 135, 135, 540, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 8640, 8640, 540, 540, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 540, 8640, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 540, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135]
Prompts retrieved: 400410 . Total input tokens: 89102245 . Total output tokens: 78834433
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.392616148106754,
    "estimated_duration": 3600.019671344279,
    "input_throughput": 5144.996330834962,
    "output_throughput": 4470.021963516395,
    "total_throughput": 9615.018294351357,
    "itl": 96.6351417651996,
    "ttft": 1508627.8777175823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454803,
    "arrivals": 133259,
    "finished_requests": 74663,
    "scheduler_time": 31.41497662127046
}
#Debug simulation 
Total elapsed time: 5.39271086640656. Arrivals time: 0.2307710093446076 Scheduler time: 4.977351158391684 Scheduler overhead time: 0.05179101414978504 Adapter cache time: 0.05425288714468479 Engine time: 0.053325021639466286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_128_slots_128_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_128_slots_128_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 135, 135, 8640, 135, 540, 540, 540, 135, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 540, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 8640, 135, 540, 540, 135, 540, 135, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 135, 540, 8640, 8640, 540, 135, 135, 135, 8640, 540, 540, 540, 540, 8640, 540, 8640, 135, 135, 540, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 8640, 8640, 540, 540, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 540, 8640, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 540, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135]
Prompts retrieved: 400410 . Total input tokens: 89102245 . Total output tokens: 78834433
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.404153135139495,
    "estimated_duration": 3600.0532556842977,
    "input_throughput": 5144.948333959944,
    "output_throughput": 4469.980263372855,
    "total_throughput": 9614.928597332799,
    "itl": 96.6369943042851,
    "ttft": 1508613.2142996509,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 133259,
    "finished_requests": 74663,
    "scheduler_time": 31.41775285266141
}
#Debug simulation 
Total elapsed time: 5.404275760054588. Arrivals time: 0.2381025142967701 Scheduler time: 4.980869283899665 Scheduler overhead time: 0.05227351328358054 Adapter cache time: 0.05406456207856536 Engine time: 0.05363859189674258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_128_slots_128_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_128_slots_128_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 66, 66, 8640, 66, 540, 540, 540, 66, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 540, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 8640, 66, 540, 540, 66, 540, 66, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 66, 540, 8640, 8640, 540, 66, 66, 66, 8640, 540, 540, 540, 540, 8640, 540, 8640, 66, 66, 540, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 8640, 8640, 540, 540, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 540, 8640, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 540, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66]
Prompts retrieved: 397512 . Total input tokens: 88456960 . Total output tokens: 78246833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.5777883399277925,
    "estimated_duration": 3600.0277140077055,
    "input_throughput": 5379.455253815457,
    "output_throughput": 4701.007143403279,
    "total_throughput": 10080.462397218736,
    "itl": 110.25599543561277,
    "ttft": 1437879.684684187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 132319,
    "finished_requests": 78450,
    "scheduler_time": 39.669803878650555
}
#Debug simulation 
Total elapsed time: 5.577889279928058. Arrivals time: 0.24552617222070694 Scheduler time: 5.171038830652833 Scheduler overhead time: 0.04665648937225342 Adapter cache time: 0.04434715071693063 Engine time: 0.04797313641756773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_128_slots_128_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_128_slots_128_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 66, 66, 8640, 66, 540, 540, 540, 66, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 540, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 8640, 66, 540, 540, 66, 540, 66, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 66, 540, 8640, 8640, 540, 66, 66, 66, 8640, 540, 540, 540, 540, 8640, 540, 8640, 66, 66, 540, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 8640, 8640, 540, 540, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 540, 8640, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 540, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66]
Prompts retrieved: 397512 . Total input tokens: 88456960 . Total output tokens: 78246833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.467427446972579,
    "estimated_duration": 3600.040322248737,
    "input_throughput": 5191.995457518811,
    "output_throughput": 4546.601019672993,
    "total_throughput": 9738.596477191804,
    "itl": 95.63330456435617,
    "ttft": 1483571.0084580935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979343,
    "arrivals": 132319,
    "finished_requests": 75773,
    "scheduler_time": 32.38421173387601
}
#Debug simulation 
Total elapsed time: 5.467525179963559. Arrivals time: 0.22988380445167422 Scheduler time: 5.057484911289066 Scheduler overhead time: 0.052563237491995096 Adapter cache time: 0.04818445676937699 Engine time: 0.054091048426926136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_128_slots_128_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_128_slots_128_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 66, 66, 8640, 66, 540, 540, 540, 66, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 540, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 8640, 66, 540, 540, 66, 540, 66, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 66, 540, 8640, 8640, 540, 66, 66, 66, 8640, 540, 540, 540, 540, 8640, 540, 8640, 66, 66, 540, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 8640, 8640, 540, 540, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 540, 8640, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 540, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66]
Prompts retrieved: 397512 . Total input tokens: 88456960 . Total output tokens: 78246833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.5391807169653475,
    "estimated_duration": 3600.0167489603687,
    "input_throughput": 5192.188898953862,
    "output_throughput": 4546.724124193844,
    "total_throughput": 9738.913023147707,
    "itl": 95.63141532063813,
    "ttft": 1483620.3425925616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454804,
    "arrivals": 132319,
    "finished_requests": 75776,
    "scheduler_time": 32.38628101341872
}
#Debug simulation 
Total elapsed time: 5.539284092839807. Arrivals time: 0.2363402508199215 Scheduler time: 5.121452686842531 Scheduler overhead time: 0.052995546255260706 Adapter cache time: 0.04824328701943159 Engine time: 0.05459017585963011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_128_slots_128_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_128_slots_128_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 66, 66, 8640, 66, 540, 540, 540, 66, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 540, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 8640, 66, 540, 540, 66, 540, 66, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 66, 540, 8640, 8640, 540, 66, 66, 66, 8640, 540, 540, 540, 540, 8640, 540, 8640, 66, 66, 540, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 8640, 8640, 540, 540, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 540, 8640, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 540, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66]
Prompts retrieved: 397512 . Total input tokens: 88456960 . Total output tokens: 78246833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.46022659773007,
    "estimated_duration": 3600.0497500953616,
    "input_throughput": 5192.078248225563,
    "output_throughput": 4546.654945411914,
    "total_throughput": 9738.733193637476,
    "itl": 95.6296808813979,
    "ttft": 1483532.2514077567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8171418803930272,
    "arrivals": 132319,
    "finished_requests": 75774,
    "scheduler_time": 32.38443693459966
}
#Debug simulation 
Total elapsed time: 5.460349014028907. Arrivals time: 0.23881410947069526 Scheduler time: 5.041189403273165 Scheduler overhead time: 0.05253181606531143 Adapter cache time: 0.048477703239768744 Engine time: 0.053954644594341516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 33, 33, 8640, 33, 540, 540, 540, 33, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 540, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 8640, 33, 540, 540, 33, 540, 33, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 33, 540, 8640, 8640, 540, 33, 33, 33, 8640, 540, 540, 540, 540, 8640, 540, 8640, 33, 33, 540, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 8640, 8640, 540, 540, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 540, 8640, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 540, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33]
Prompts retrieved: 396126 . Total input tokens: 88155553 . Total output tokens: 77962584
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.622711256146431,
    "estimated_duration": 3600.012466712274,
    "input_throughput": 5444.91919993305,
    "output_throughput": 4745.003290391455,
    "total_throughput": 10189.922490324505,
    "itl": 109.12342981460407,
    "ttft": 1426453.925276247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8463883560895911,
    "arrivals": 131875,
    "finished_requests": 79153,
    "scheduler_time": 40.10175420251936
}
#Debug simulation 
Total elapsed time: 5.622790044173598. Arrivals time: 0.226490527857095 Scheduler time: 5.23723969142884 Scheduler overhead time: 0.046964011155068874 Adapter cache time: 0.04102785512804985 Engine time: 0.048388831317424774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 33, 33, 8640, 33, 540, 540, 540, 33, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 540, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 8640, 33, 540, 540, 33, 540, 33, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 33, 540, 8640, 8640, 540, 33, 33, 33, 8640, 540, 540, 540, 540, 8640, 540, 8640, 33, 33, 540, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 8640, 8640, 540, 540, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 540, 8640, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 540, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33]
Prompts retrieved: 396126 . Total input tokens: 88155553 . Total output tokens: 77962584
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.508721795864403,
    "estimated_duration": 3600.0662302485707,
    "input_throughput": 5247.169855176722,
    "output_throughput": 4575.386380839636,
    "total_throughput": 9822.556236016359,
    "itl": 94.76912542133806,
    "ttft": 1474979.3131481986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365288840979344,
    "arrivals": 131875,
    "finished_requests": 76332,
    "scheduler_time": 32.64369469490694
}
#Debug simulation 
Total elapsed time: 5.5088178548030555. Arrivals time: 0.23368162475526333 Scheduler time: 5.0963586354628205 Scheduler overhead time: 0.05283580860123038 Adapter cache time: 0.04594263760372996 Engine time: 0.05438136216253042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 33, 33, 8640, 33, 540, 540, 540, 33, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 540, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 8640, 33, 540, 540, 33, 540, 33, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 33, 540, 8640, 8640, 540, 33, 33, 33, 8640, 540, 540, 540, 540, 8640, 540, 8640, 33, 33, 540, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 8640, 8640, 540, 540, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 540, 8640, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 540, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33]
Prompts retrieved: 396126 . Total input tokens: 88155553 . Total output tokens: 77962584
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.493875314947218,
    "estimated_duration": 3600.062430458187,
    "input_throughput": 5247.246503332382,
    "output_throughput": 4575.42232063559,
    "total_throughput": 9822.668823967972,
    "itl": 94.76788542332996,
    "ttft": 1474929.890876244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8768353822454802,
    "arrivals": 131875,
    "finished_requests": 76334,
    "scheduler_time": 32.64529374355794
}
#Debug simulation 
Total elapsed time: 5.49398085474968. Arrivals time: 0.2263008556328714 Scheduler time: 5.090123918838799 Scheduler overhead time: 0.05268199276179075 Adapter cache time: 0.04515507770702243 Engine time: 0.05435868306085467 
