INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:51 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6164867 . Total output tokens: 5513241
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.1204123198986053,
    "estimated_duration": 3599.7754553301734,
    "input_throughput": 640.7733006192282,
    "output_throughput": 568.6204668597188,
    "total_throughput": 1209.393767478947,
    "itl": 23.708317309285626,
    "ttft": 5757.667624675767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.80537279486412,
    "arrivals": 9452,
    "finished_requests": 9437,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1205076188780367. Arrivals time: 0.03641168447211385 Scheduler time: 0.7037809998728335 Scheduler overhead time: 0.1290428377687931 Adapter cache time: 0.061461050529032946 Engine time: 0.12710238434374332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5209427 . Total output tokens: 4648377
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.0110617098398507,
    "estimated_duration": 3598.823938730547,
    "input_throughput": 545.1394770626175,
    "output_throughput": 485.2176793666547,
    "total_throughput": 1030.3571564292722,
    "itl": 22.713773632891584,
    "ttft": 6752.984495190104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.39164683949993,
    "arrivals": 8047,
    "finished_requests": 8032,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0111474809236825. Arrivals time: 0.031228678300976753 Scheduler time: 0.6111553679220378 Scheduler overhead time: 0.12812108313664794 Adapter cache time: 0.051928096916526556 Engine time: 0.12472505820915103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5209427 . Total output tokens: 4648377
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.0140878283418715,
    "estimated_duration": 3598.818706456327,
    "input_throughput": 545.1402696335873,
    "output_throughput": 485.21838481812694,
    "total_throughput": 1030.3586544517143,
    "itl": 22.74531415775925,
    "ttft": 6753.508679084042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5805,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.33390075859956,
    "arrivals": 8047,
    "finished_requests": 8032,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0141579182818532. Arrivals time: 0.030843479558825493 Scheduler time: 0.6123141208663583 Scheduler overhead time: 0.12716809613630176 Adapter cache time: 0.052570133935660124 Engine time: 0.1277997512370348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5209427 . Total output tokens: 4648377
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.0153367049060762,
    "estimated_duration": 3598.808091648801,
    "input_throughput": 545.1418775434535,
    "output_throughput": 485.2198159863448,
    "total_throughput": 1030.3616935297982,
    "itl": 22.75382939924312,
    "ttft": 6753.5308623386145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.463525186343226,
    "arrivals": 8047,
    "finished_requests": 8032,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.015423120930791. Arrivals time: 0.031152368057519197 Scheduler time: 0.6133098043501377 Scheduler overhead time: 0.12754642311483622 Adapter cache time: 0.05259014619514346 Engine time: 0.1274290131404996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5209427 . Total output tokens: 4648377
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.00980639224872,
    "estimated_duration": 3598.8008756983186,
    "input_throughput": 545.1429706066515,
    "output_throughput": 485.220788899903,
    "total_throughput": 1030.3637595065545,
    "itl": 22.72454734993838,
    "ttft": 6753.060300890712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5805,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.789291714519614,
    "arrivals": 8047,
    "finished_requests": 8032,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0098780980333686. Arrivals time: 0.03083755634725094 Scheduler time: 0.6076862378977239 Scheduler overhead time: 0.12751878052949905 Adapter cache time: 0.05263581918552518 Engine time: 0.1280232253484428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5209427 . Total output tokens: 4648377
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.029634043108672,
    "estimated_duration": 3598.806673666205,
    "input_throughput": 545.1420923373462,
    "output_throughput": 485.22000717006676,
    "total_throughput": 1030.362099507413,
    "itl": 22.749429846637,
    "ttft": 6753.5900731461725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5803,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.061359987882156,
    "arrivals": 8047,
    "finished_requests": 8032,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0296874097548425. Arrivals time: 0.03095004567876458 Scheduler time: 0.6199735137633979 Scheduler overhead time: 0.1350396708585322 Adapter cache time: 0.05326749011874199 Engine time: 0.1266175601631403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5209427 . Total output tokens: 4648377
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.0466254148632288,
    "estimated_duration": 3598.810018753867,
    "input_throughput": 545.1415856287182,
    "output_throughput": 485.2195561589128,
    "total_throughput": 1030.361141787631,
    "itl": 22.703568673159936,
    "ttft": 6752.735890232997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5804,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.05227713907521,
    "arrivals": 8047,
    "finished_requests": 8032,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0467011956498027. Arrivals time: 0.03165893070399761 Scheduler time: 0.6415151380933821 Scheduler overhead time: 0.12714176950976253 Adapter cache time: 0.05388951674103737 Engine time: 0.12901525711640716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5209427 . Total output tokens: 4648377
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.0462483442388475,
    "estimated_duration": 3598.8071172956897,
    "input_throughput": 545.1420251369941,
    "output_throughput": 485.2199473563855,
    "total_throughput": 1030.3619724933797,
    "itl": 22.7511372426978,
    "ttft": 6753.533497890943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5807,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.684141754227944,
    "arrivals": 8047,
    "finished_requests": 8032,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.046310278121382. Arrivals time: 0.03153908485546708 Scheduler time: 0.6387363472022116 Scheduler overhead time: 0.1282178768888116 Adapter cache time: 0.05419575050473213 Engine time: 0.13026335090398788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3292385 . Total output tokens: 2986592
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 0.8218188239261508,
    "estimated_duration": 3599.9540374784083,
    "input_throughput": 347.07943129051523,
    "output_throughput": 303.4472075552303,
    "total_throughput": 650.5266388457455,
    "itl": 21.391570898650418,
    "ttft": 7829.5915807453075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.370287219414347,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8218827489763498. Arrivals time: 0.024946844205260277 Scheduler time: 0.4246277716010809 Scheduler overhead time: 0.13040535477921367 Adapter cache time: 0.041896100621670485 Engine time: 0.13431996665894985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3292385 . Total output tokens: 2986592
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 0.8251453228294849,
    "estimated_duration": 3599.957833994927,
    "input_throughput": 347.0790652604518,
    "output_throughput": 303.44688753972207,
    "total_throughput": 650.5259528001739,
    "itl": 21.414331595433453,
    "ttft": 7830.211142908038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.058733694794782,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8251945707015693. Arrivals time: 0.024628715123981237 Scheduler time: 0.4286251263692975 Scheduler overhead time: 0.13206724589690566 Adapter cache time: 0.04201899794861674 Engine time: 0.13172869430854917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3292385 . Total output tokens: 2986592
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 0.8243911033496261,
    "estimated_duration": 3599.9456653064894,
    "input_throughput": 347.0802384717725,
    "output_throughput": 303.4479132637121,
    "total_throughput": 650.5281517354846,
    "itl": 21.419337605412746,
    "ttft": 7830.224139254929,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3987,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.81551962034901,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8244597250595689. Arrivals time: 0.024989933241158724 Scheduler time: 0.4254830847494304 Scheduler overhead time: 0.13090425450354815 Adapter cache time: 0.042176001239567995 Engine time: 0.1342945727519691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3292385 . Total output tokens: 2986592
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 0.8235638071782887,
    "estimated_duration": 3599.9545090491265,
    "input_throughput": 347.07938582535826,
    "output_throughput": 303.447167805612,
    "total_throughput": 650.5265536309703,
    "itl": 21.395587801335232,
    "ttft": 7829.71366746118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3987,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.278203369961957,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8236241298727691. Arrivals time: 0.024720659013837576 Scheduler time: 0.42729297606274486 Scheduler overhead time: 0.1315050208941102 Adapter cache time: 0.04287715023383498 Engine time: 0.13115701312199235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3292385 . Total output tokens: 2986592
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 0.8283243048936129,
    "estimated_duration": 3599.954241825329,
    "input_throughput": 347.07941158898336,
    "output_throughput": 303.44719033042736,
    "total_throughput": 650.5266019194107,
    "itl": 21.41135892309536,
    "ttft": 7830.380349313354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.55889994200907,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.828374404925853. Arrivals time: 0.024706362280994654 Scheduler time: 0.4306971509940922 Scheduler overhead time: 0.1318304962478578 Adapter cache time: 0.04176402650773525 Engine time: 0.13264364516362548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3292385 . Total output tokens: 2986592
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 0.8229669048450887,
    "estimated_duration": 3599.959418620623,
    "input_throughput": 347.078912483617,
    "output_throughput": 303.4467539688454,
    "total_throughput": 650.5256664524624,
    "itl": 21.386704149886246,
    "ttft": 7829.497989110875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3987,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.452692790057004,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8230222756974399. Arrivals time: 0.024378457572311163 Scheduler time: 0.426101665943861 Scheduler overhead time: 0.13012638920918107 Adapter cache time: 0.041588728316128254 Engine time: 0.13459327211603522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3292385 . Total output tokens: 2986592
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 0.8270100778900087,
    "estimated_duration": 3599.9445265013987,
    "input_throughput": 347.0803482670039,
    "output_throughput": 303.4480092563103,
    "total_throughput": 650.5283575233142,
    "itl": 21.41338095166753,
    "ttft": 7830.1557206975385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3987,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.278671898563665,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8271638401784003. Arrivals time: 0.025248979218304157 Scheduler time: 0.4294252973049879 Scheduler overhead time: 0.1317028529010713 Adapter cache time: 0.04185794712975621 Engine time: 0.13210243312641978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 863190198 . Total output tokens: 760505632
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 51.18408634001389,
    "estimated_duration": 3600.07517184917,
    "input_throughput": 5599.7919592454045,
    "output_throughput": 4868.608616024291,
    "total_throughput": 10468.400575269696,
    "itl": 117.83409184001314,
    "ttft": 2123581.567040459,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9491344282497,
    "arrivals": 1289329,
    "finished_requests": 81427,
    "scheduler_time": 161.9782051676461
}
#Debug simulation 
Total elapsed time: 51.1843394623138. Arrivals time: 0.4081981321796775 Scheduler time: 50.613140516448766 Scheduler overhead time: 0.061456411611288786 Adapter cache time: 0.016615326050668955 Engine time: 0.06034053536131978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 863190198 . Total output tokens: 760505632
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 30.645623978227377,
    "estimated_duration": 3600.0832006722953,
    "input_throughput": 5457.903027444109,
    "output_throughput": 4750.329380389424,
    "total_throughput": 10208.232407833533,
    "itl": 110.70135564626877,
    "ttft": 2139803.970569063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.502317322758035,
    "arrivals": 1289329,
    "finished_requests": 79543,
    "scheduler_time": 166.0613305260085
}
#Debug simulation 
Total elapsed time: 30.645748479291797. Arrivals time: 0.37646112591028214 Scheduler time: 30.106054924428463 Scheduler overhead time: 0.05949010653421283 Adapter cache time: 0.01981819001957774 Engine time: 0.059074126183986664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 863190198 . Total output tokens: 760505632
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.934720203280449,
    "estimated_duration": 3600.0959591910837,
    "input_throughput": 5137.752495951806,
    "output_throughput": 4464.112952036727,
    "total_throughput": 9601.865447988532,
    "itl": 98.78046172160337,
    "ttft": 2167397.2323220195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.178432754073297,
    "arrivals": 1289329,
    "finished_requests": 74737,
    "scheduler_time": 173.51187160874383
}
#Debug simulation 
Total elapsed time: 15.934851450379938. Arrivals time: 0.3191108079627156 Scheduler time: 15.446756320539862 Scheduler overhead time: 0.05945664318278432 Adapter cache time: 0.02361454488709569 Engine time: 0.05964803462848067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 863190198 . Total output tokens: 760505632
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 29.035089203622192,
    "estimated_duration": 3600.0565593561887,
    "input_throughput": 5450.1490952989,
    "output_throughput": 4736.00281520274,
    "total_throughput": 10186.15191050164,
    "itl": 110.68850309199273,
    "ttft": 2138450.9566334696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.706432731007219,
    "arrivals": 1289329,
    "finished_requests": 79341,
    "scheduler_time": 165.82899351622106
}
#Debug simulation 
Total elapsed time: 29.035188945010304. Arrivals time: 0.3544238987378776 Scheduler time: 28.516800498589873 Scheduler overhead time: 0.06014495762065053 Adapter cache time: 0.019222342874854803 Engine time: 0.059716178104281425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 863190198 . Total output tokens: 760505632
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 15.946968627627939,
    "estimated_duration": 3600.018717944886,
    "input_throughput": 5137.8627304912725,
    "output_throughput": 4464.208733107493,
    "total_throughput": 9602.071463598766,
    "itl": 98.77841619647339,
    "ttft": 2167368.6180928973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.101385164372633,
    "arrivals": 1289329,
    "finished_requests": 74737,
    "scheduler_time": 173.51167795224657
}
#Debug simulation 
Total elapsed time: 15.947064994834363. Arrivals time: 0.4133521905168891 Scheduler time: 15.363468813244253 Scheduler overhead time: 0.05923931812867522 Adapter cache time: 0.023576400242745876 Engine time: 0.06119666760787368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 863190198 . Total output tokens: 760505632
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 36.53078405093402,
    "estimated_duration": 3600.095905742652,
    "input_throughput": 5469.502623135831,
    "output_throughput": 4756.054963060187,
    "total_throughput": 10225.557586196017,
    "itl": 110.27375488018497,
    "ttft": 2141151.695903444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 521,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.326022810037233,
    "arrivals": 1289329,
    "finished_requests": 79651,
    "scheduler_time": 166.57235145413694
}
#Debug simulation 
Total elapsed time: 36.53096869261935. Arrivals time: 0.7624847795814276 Scheduler time: 35.60435238992795 Scheduler overhead time: 0.06051013711839914 Adapter cache time: 0.017755907028913498 Engine time: 0.060717576183378696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 863190198 . Total output tokens: 760505632
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 16.010029872879386,
    "estimated_duration": 3600.052113145097,
    "input_throughput": 5137.815347856471,
    "output_throughput": 4464.230654138937,
    "total_throughput": 9602.046001995408,
    "itl": 98.77655668676789,
    "ttft": 2167423.310534413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.026822980791344,
    "arrivals": 1289329,
    "finished_requests": 74738,
    "scheduler_time": 173.5167992648808
}
#Debug simulation 
Total elapsed time: 16.010157581884414. Arrivals time: 0.3399965516291559 Scheduler time: 15.50139591563493 Scheduler overhead time: 0.05948098190128803 Adapter cache time: 0.023798692505806684 Engine time: 0.05936827091500163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801481657 . Total output tokens: 706278274
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 38.993102233856916,
    "estimated_duration": 3600.0695243487626,
    "input_throughput": 5617.442347494189,
    "output_throughput": 4857.364804132025,
    "total_throughput": 10474.807151626213,
    "itl": 117.94315552869718,
    "ttft": 2126032.6656914954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.173956335336005,
    "arrivals": 1197398,
    "finished_requests": 81322,
    "scheduler_time": 161.53509528589288
}
#Debug simulation 
Total elapsed time: 38.99327427987009. Arrivals time: 0.40236284770071507 Scheduler time: 38.43007576698437 Scheduler overhead time: 0.060157849453389645 Adapter cache time: 0.01641734829172492 Engine time: 0.06000329414382577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801481657 . Total output tokens: 706278274
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 27.532527367118746,
    "estimated_duration": 3600.0252347184114,
    "input_throughput": 5455.180650014559,
    "output_throughput": 4726.791033544244,
    "total_throughput": 10181.971683558804,
    "itl": 111.02209201957994,
    "ttft": 2137075.9701792346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.3786998488009035,
    "arrivals": 1197398,
    "finished_requests": 79077,
    "scheduler_time": 165.29472575300872
}
#Debug simulation 
Total elapsed time: 27.532623095903546. Arrivals time: 0.4429988255724311 Scheduler time: 26.928956114221364 Scheduler overhead time: 0.05905460938811302 Adapter cache time: 0.017727382481098175 Engine time: 0.05937237711623311 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801481657 . Total output tokens: 706278274
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 16.908125946763903,
    "estimated_duration": 3600.0083320247354,
    "input_throughput": 5151.4741882748995,
    "output_throughput": 4462.96994845111,
    "total_throughput": 9614.44413672601,
    "itl": 98.60485814909785,
    "ttft": 2163698.848671639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.212579659428467,
    "arrivals": 1197398,
    "finished_requests": 74580,
    "scheduler_time": 173.55903580308214
}
#Debug simulation 
Total elapsed time: 16.908236944582313. Arrivals time: 0.3335984153673053 Scheduler time: 16.40492699947208 Scheduler overhead time: 0.06022984068840742 Adapter cache time: 0.022391341160982847 Engine time: 0.060712928883731365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801481657 . Total output tokens: 706278274
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 27.471563655883074,
    "estimated_duration": 3600.001042139104,
    "input_throughput": 5455.279531899966,
    "output_throughput": 4727.091687142473,
    "total_throughput": 10182.37121904244,
    "itl": 111.0149226876873,
    "ttft": 2136946.7738789874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.103832096084947,
    "arrivals": 1197398,
    "finished_requests": 79080,
    "scheduler_time": 165.3052933858757
}
#Debug simulation 
Total elapsed time: 27.471660845912993. Arrivals time: 0.3514499110169709 Scheduler time: 26.959129231516272 Scheduler overhead time: 0.05936571350321174 Adapter cache time: 0.01811449695378542 Engine time: 0.05891795363277197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801481657 . Total output tokens: 706278274
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 17.007505979854614,
    "estimated_duration": 3600.0514148520847,
    "input_throughput": 5151.687257433798,
    "output_throughput": 4463.165424169413,
    "total_throughput": 9614.852681603212,
    "itl": 98.60356191028905,
    "ttft": 2163764.2164034983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.147130631618222,
    "arrivals": 1197398,
    "finished_requests": 74583,
    "scheduler_time": 173.56416474925257
}
#Debug simulation 
Total elapsed time: 17.007640451192856. Arrivals time: 0.3217409127391875 Scheduler time: 16.51626924984157 Scheduler overhead time: 0.06010576616972685 Adapter cache time: 0.02270908933132887 Engine time: 0.06032449286431074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801481657 . Total output tokens: 706278274
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 27.347503513097763,
    "estimated_duration": 3600.102451350657,
    "input_throughput": 5455.231695595733,
    "output_throughput": 4727.1265831935625,
    "total_throughput": 10182.358278789296,
    "itl": 111.0079723419038,
    "ttft": 2136821.681489353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.830352564342302,
    "arrivals": 1197398,
    "finished_requests": 79083,
    "scheduler_time": 165.32150876766843
}
#Debug simulation 
Total elapsed time: 27.34763085609302. Arrivals time: 0.3420103872194886 Scheduler time: 26.846209039911628 Scheduler overhead time: 0.05874744802713394 Adapter cache time: 0.017632987815886736 Engine time: 0.058345391415059566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801481657 . Total output tokens: 706278274
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 16.902535091154277,
    "estimated_duration": 3600.092975331748,
    "input_throughput": 5152.222769549656,
    "output_throughput": 4463.40222602703,
    "total_throughput": 9615.624995576685,
    "itl": 98.59997658045783,
    "ttft": 2163831.8559740623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.080024666395058,
    "arrivals": 1197398,
    "finished_requests": 74591,
    "scheduler_time": 173.5692865756928
}
#Debug simulation 
Total elapsed time: 16.902659823186696. Arrivals time: 0.33471078984439373 Scheduler time: 16.39858761522919 Scheduler overhead time: 0.06024879729375243 Adapter cache time: 0.022479294799268246 Engine time: 0.060385031159967184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755269785 . Total output tokens: 665596261
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 34.273026913870126,
    "estimated_duration": 3600.007151693112,
    "input_throughput": 5539.326217899678,
    "output_throughput": 4849.780087739209,
    "total_throughput": 10389.106305638887,
    "itl": 117.83996929126636,
    "ttft": 2118226.5488636564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0879950179206532,
    "arrivals": 1127741,
    "finished_requests": 81189,
    "scheduler_time": 161.48556255187054
}
#Debug simulation 
Total elapsed time: 34.27315293811262. Arrivals time: 0.4838406038470566 Scheduler time: 33.6335350330919 Scheduler overhead time: 0.058445623610168695 Adapter cache time: 0.0157728036865592 Engine time: 0.057691311463713646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755269785 . Total output tokens: 665596261
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 35.548126702196896,
    "estimated_duration": 3600.102644863996,
    "input_throughput": 5404.75839703039,
    "output_throughput": 4728.792948247489,
    "total_throughput": 10133.55134527788,
    "itl": 111.22636258337533,
    "ttft": 2130578.1752883387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.143967757672079,
    "arrivals": 1127741,
    "finished_requests": 79209,
    "scheduler_time": 165.30240956376883
}
#Debug simulation 
Total elapsed time: 35.54824665328488. Arrivals time: 0.3524100324138999 Scheduler time: 35.03470178321004 Scheduler overhead time: 0.05889733601361513 Adapter cache time: 0.01908393856137991 Engine time: 0.058702489361166954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755269785 . Total output tokens: 665596261
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 17.25156053341925,
    "estimated_duration": 3600.0114321648825,
    "input_throughput": 5097.489367961405,
    "output_throughput": 4463.390270496248,
    "total_throughput": 9560.879638457653,
    "itl": 98.6459667146154,
    "ttft": 2159063.3329266817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 976,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.325176728060487,
    "arrivals": 1127741,
    "finished_requests": 74638,
    "scheduler_time": 173.45078119954348
}
#Debug simulation 
Total elapsed time: 17.251715030055493. Arrivals time: 0.30992311937734485 Scheduler time: 16.772304638754576 Scheduler overhead time: 0.060216625686734915 Adapter cache time: 0.022541461512446404 Engine time: 0.06042615929618478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755269785 . Total output tokens: 665596261
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 35.54365809680894,
    "estimated_duration": 3600.024634884509,
    "input_throughput": 5405.560231846662,
    "output_throughput": 4729.044583481346,
    "total_throughput": 10134.604815328008,
    "itl": 111.21607488817922,
    "ttft": 2130456.744112078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.817735828943544,
    "arrivals": 1127741,
    "finished_requests": 79215,
    "scheduler_time": 165.31279132379183
}
#Debug simulation 
Total elapsed time: 35.54383140197024. Arrivals time: 0.49675402930006385 Scheduler time: 34.8855417445302 Scheduler overhead time: 0.05894986679777503 Adapter cache time: 0.01925530331209302 Engine time: 0.05876998137682676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755269785 . Total output tokens: 665596261
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 17.257131734862924,
    "estimated_duration": 3600.0551251866787,
    "input_throughput": 5097.457778246774,
    "output_throughput": 4463.374154351813,
    "total_throughput": 9560.831932598587,
    "itl": 98.64434521767524,
    "ttft": 2159091.0714446795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 976,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.257449411307481,
    "arrivals": 1127741,
    "finished_requests": 74639,
    "scheduler_time": 173.45596443995018
}
#Debug simulation 
Total elapsed time: 17.257229398936033. Arrivals time: 0.44671850837767124 Scheduler time: 16.641047198325396 Scheduler overhead time: 0.06048751436173916 Adapter cache time: 0.0226639355532825 Engine time: 0.05998954037204385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755269785 . Total output tokens: 665596261
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 35.43297088006511,
    "estimated_duration": 3600.0755818093903,
    "input_throughput": 5406.246218369113,
    "output_throughput": 4729.433205800254,
    "total_throughput": 10135.679424169368,
    "itl": 111.2070027456332,
    "ttft": 2130403.543223517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.494280342161634,
    "arrivals": 1127741,
    "finished_requests": 79223,
    "scheduler_time": 165.3289455023255
}
#Debug simulation 
Total elapsed time: 35.43309825100005. Arrivals time: 0.46707496885210276 Scheduler time: 34.80508750025183 Scheduler overhead time: 0.05869772844016552 Adapter cache time: 0.018728173337876797 Engine time: 0.0588174625299871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755269785 . Total output tokens: 665596261
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 17.199924698099494,
    "estimated_duration": 3600.0995009229155,
    "input_throughput": 5097.753546893691,
    "output_throughput": 4463.810790751833,
    "total_throughput": 9561.564337645525,
    "itl": 98.64329110746867,
    "ttft": 2159050.775825684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 976,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.190550563260933,
    "arrivals": 1127741,
    "finished_requests": 74644,
    "scheduler_time": 173.46114363554886
}
#Debug simulation 
Total elapsed time: 17.20004913210869. Arrivals time: 0.43437929451465607 Scheduler time: 16.59726818371564 Scheduler overhead time: 0.060077738016843796 Adapter cache time: 0.022316162940114737 Engine time: 0.05974599765613675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747459949 . Total output tokens: 658822510
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 37.85862052813172,
    "estimated_duration": 3600.0334024056224,
    "input_throughput": 5633.497174345086,
    "output_throughput": 4856.462439575474,
    "total_throughput": 10489.959613920559,
    "itl": 118.1180343209838,
    "ttft": 2113697.1459512594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7970490205148466,
    "arrivals": 1116016,
    "finished_requests": 81730,
    "scheduler_time": 161.2944304547323
}
#Debug simulation 
Total elapsed time: 37.85879159998149. Arrivals time: 0.3781658965162933 Scheduler time: 37.32199379382655 Scheduler overhead time: 0.05957493372261524 Adapter cache time: 0.015486393589526415 Engine time: 0.059412441682070494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747459949 . Total output tokens: 658822510
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 22.117189231328666,
    "estimated_duration": 3600.1062765481493,
    "input_throughput": 5451.367957619659,
    "output_throughput": 4718.739863504359,
    "total_throughput": 10170.107821124018,
    "itl": 110.55156926148632,
    "ttft": 2129124.742848525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.0529213127261094,
    "arrivals": 1116016,
    "finished_requests": 79204,
    "scheduler_time": 165.5114909739174
}
#Debug simulation 
Total elapsed time: 22.117334878072143. Arrivals time: 0.35354084987193346 Scheduler time: 21.605388798750937 Scheduler overhead time: 0.057704181876033545 Adapter cache time: 0.018539742566645145 Engine time: 0.057501448318362236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747459949 . Total output tokens: 658822510
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.494878234807402,
    "estimated_duration": 3600.005946324282,
    "input_throughput": 5160.843975541154,
    "output_throughput": 4462.40735141078,
    "total_throughput": 9623.251326951935,
    "itl": 98.47066013328099,
    "ttft": 2155690.141582604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1073,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.057291653468287,
    "arrivals": 1116016,
    "finished_requests": 74899,
    "scheduler_time": 173.57943873686287
}
#Debug simulation 
Total elapsed time: 14.494973719120026. Arrivals time: 0.3043169667944312 Scheduler time: 14.024702948052436 Scheduler overhead time: 0.058451729360967875 Adapter cache time: 0.022663474548608065 Engine time: 0.05884080287069082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747459949 . Total output tokens: 658822510
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 21.899979865178466,
    "estimated_duration": 3600.09136922556,
    "input_throughput": 5461.525273518162,
    "output_throughput": 4724.88396972523,
    "total_throughput": 10186.409243243392,
    "itl": 110.99324119107384,
    "ttft": 2128178.917298496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 864,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.919679995886973,
    "arrivals": 1116016,
    "finished_requests": 79386,
    "scheduler_time": 165.19758813669137
}
#Debug simulation 
Total elapsed time: 21.90012852381915. Arrivals time: 0.3517384617589414 Scheduler time: 21.38895886624232 Scheduler overhead time: 0.05737217143177986 Adapter cache time: 0.020543895661830902 Engine time: 0.05712561681866646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747459949 . Total output tokens: 658822510
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.475538901984692,
    "estimated_duration": 3600.043868327534,
    "input_throughput": 5160.851833905944,
    "output_throughput": 4462.503399288683,
    "total_throughput": 9623.355233194627,
    "itl": 98.46908918766411,
    "ttft": 2155658.6740036774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1073,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.984800641653145,
    "arrivals": 1116016,
    "finished_requests": 74901,
    "scheduler_time": 173.58460661999106
}
#Debug simulation 
Total elapsed time: 14.475636148825288. Arrivals time: 0.3082556910812855 Scheduler time: 14.001147254370153 Scheduler overhead time: 0.05857133539393544 Adapter cache time: 0.023024053312838078 Engine time: 0.05866445600986481 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747459949 . Total output tokens: 658822510
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 21.77839688071981,
    "estimated_duration": 3600.046842880821,
    "input_throughput": 5462.176148870454,
    "output_throughput": 4725.791286200554,
    "total_throughput": 10187.967435071008,
    "itl": 110.98115440832723,
    "ttft": 2128110.48674067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 864,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.515707692652914,
    "arrivals": 1116016,
    "finished_requests": 79396,
    "scheduler_time": 165.21338193618962
}
#Debug simulation 
Total elapsed time: 21.778540225699544. Arrivals time: 0.35193354403600097 Scheduler time: 21.268689691089094 Scheduler overhead time: 0.05693212151527405 Adapter cache time: 0.02031361311674118 Engine time: 0.05643397383391857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747459949 . Total output tokens: 658822510
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.559305797796696,
    "estimated_duration": 3600.078417849725,
    "input_throughput": 5160.955080277799,
    "output_throughput": 4462.760844414095,
    "total_throughput": 9623.715924691895,
    "itl": 98.46742164772081,
    "ttft": 2155624.4886154793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1073,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.908788637835549,
    "arrivals": 1116016,
    "finished_requests": 74903,
    "scheduler_time": 173.5897813046034
}
#Debug simulation 
Total elapsed time: 14.55940212868154. Arrivals time: 0.30664235539734364 Scheduler time: 14.085806654766202 Scheduler overhead time: 0.05867984611541033 Adapter cache time: 0.02312636561691761 Engine time: 0.0591030097566545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743590138 . Total output tokens: 655449743
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 38.90541484998539,
    "estimated_duration": 3600.1230315866906,
    "input_throughput": 5593.429675408886,
    "output_throughput": 4863.1843540868185,
    "total_throughput": 10456.614029495706,
    "itl": 118.91839428589694,
    "ttft": 2116435.4303085473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8036614295467968,
    "arrivals": 1110264,
    "finished_requests": 81507,
    "scheduler_time": 160.96188959609628
}
#Debug simulation 
Total elapsed time: 38.905593905132264. Arrivals time: 0.4766688970848918 Scheduler time: 38.27273010695353 Scheduler overhead time: 0.05856734374538064 Adapter cache time: 0.015459508635103703 Engine time: 0.058177489787340164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743590138 . Total output tokens: 655449743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 23.4861074751243,
    "estimated_duration": 3600.0565439388124,
    "input_throughput": 5447.125277244894,
    "output_throughput": 4735.379789715254,
    "total_throughput": 10182.50506696015,
    "itl": 111.18825713016547,
    "ttft": 2128075.018770061,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.891935068238534,
    "arrivals": 1110264,
    "finished_requests": 79393,
    "scheduler_time": 165.3224681434002
}
#Debug simulation 
Total elapsed time: 23.486234019044787. Arrivals time: 0.4510169136337936 Scheduler time: 22.877236496657133 Scheduler overhead time: 0.05759620247408748 Adapter cache time: 0.017951274290680885 Engine time: 0.05799700226634741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743590138 . Total output tokens: 655449743
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.57447775779292,
    "estimated_duration": 3600.0592585958125,
    "input_throughput": 5137.116272695321,
    "output_throughput": 4473.075536617983,
    "total_throughput": 9610.191809313303,
    "itl": 98.88458641278136,
    "ttft": 2155643.067056626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.067373366705166,
    "arrivals": 1110264,
    "finished_requests": 74906,
    "scheduler_time": 173.45643196581977
}
#Debug simulation 
Total elapsed time: 13.574630892835557. Arrivals time: 0.4176090257242322 Scheduler time: 12.995028954930604 Scheduler overhead time: 0.05728587182238698 Adapter cache time: 0.021278533153235912 Engine time: 0.05755913536995649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743590138 . Total output tokens: 655449743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 24.299933813046664,
    "estimated_duration": 3600.083817521048,
    "input_throughput": 5447.038456316539,
    "output_throughput": 4740.507683999283,
    "total_throughput": 10187.546140315822,
    "itl": 111.4997318882894,
    "ttft": 2128681.3182412614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 702,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.8313441855553485,
    "arrivals": 1110264,
    "finished_requests": 79476,
    "scheduler_time": 165.13888060570721
}
#Debug simulation 
Total elapsed time: 24.300038469024003. Arrivals time: 0.46455538971349597 Scheduler time: 23.680133428424597 Scheduler overhead time: 0.056074922904372215 Adapter cache time: 0.0182447861880064 Engine time: 0.057008322328329086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743590138 . Total output tokens: 655449743
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 13.641933592036366,
    "estimated_duration": 3600.102821703047,
    "input_throughput": 5137.309936956445,
    "output_throughput": 4473.219737757906,
    "total_throughput": 9610.529674714351,
    "itl": 98.88317958456837,
    "ttft": 2155653.9967179988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.003995510661067,
    "arrivals": 1110264,
    "finished_requests": 74908,
    "scheduler_time": 173.4615288241443
}
#Debug simulation 
Total elapsed time: 13.642056721262634. Arrivals time: 0.4303620560094714 Scheduler time: 13.048506517428905 Scheduler overhead time: 0.057600931730121374 Adapter cache time: 0.021669224835932255 Engine time: 0.05797151383012533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743590138 . Total output tokens: 655449743
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 24.240716114640236,
    "estimated_duration": 3600.0950355190566,
    "input_throughput": 5448.042567346325,
    "output_throughput": 4741.010121011749,
    "total_throughput": 10189.052688358073,
    "itl": 111.48603150296758,
    "ttft": 2128788.021588054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 702,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.481512500280493,
    "arrivals": 1110264,
    "finished_requests": 79490,
    "scheduler_time": 165.15457761650893
}
#Debug simulation 
Total elapsed time: 24.240864821709692. Arrivals time: 0.47285262029618025 Scheduler time: 23.61226470163092 Scheduler overhead time: 0.056722769513726234 Adapter cache time: 0.018140702042728662 Engine time: 0.05681996373459697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743590138 . Total output tokens: 655449743
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.638620577286929,
    "estimated_duration": 3600.0340777744427,
    "input_throughput": 5137.408035713261,
    "output_throughput": 4473.305155476638,
    "total_throughput": 9610.7131911899,
    "itl": 98.88141701572512,
    "ttft": 2155626.2402626355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.935439725201601,
    "arrivals": 1110264,
    "finished_requests": 74908,
    "scheduler_time": 173.46134068099926
}
#Debug simulation 
Total elapsed time: 13.638745420146734. Arrivals time: 0.4236343689262867 Scheduler time: 13.049090745393187 Scheduler overhead time: 0.06029700580984354 Adapter cache time: 0.02166089601814747 Engine time: 0.058040285017341375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741693916 . Total output tokens: 653727687
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 35.64222448738292,
    "estimated_duration": 3600.006207551345,
    "input_throughput": 5590.535637906383,
    "output_throughput": 4877.127979160459,
    "total_throughput": 10467.663617066843,
    "itl": 119.00829952356312,
    "ttft": 2112302.70902496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 395,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6119015676202424,
    "arrivals": 1107343,
    "finished_requests": 81724,
    "scheduler_time": 161.13107685381547
}
#Debug simulation 
Total elapsed time: 35.64237997215241. Arrivals time: 0.37786742532625794 Scheduler time: 35.11151533946395 Scheduler overhead time: 0.05713116889819503 Adapter cache time: 0.014987228903919458 Engine time: 0.057250448036938906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741693916 . Total output tokens: 653727687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 25.08467390201986,
    "estimated_duration": 3600.0743072194937,
    "input_throughput": 5415.929877030518,
    "output_throughput": 4726.389109768614,
    "total_throughput": 10142.318986799131,
    "itl": 110.72985636304789,
    "ttft": 2127595.159589034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.669782338226219,
    "arrivals": 1107343,
    "finished_requests": 79217,
    "scheduler_time": 165.61824939507792
}
#Debug simulation 
Total elapsed time: 25.084774076007307. Arrivals time: 0.3486901866272092 Scheduler time: 24.57783891633153 Scheduler overhead time: 0.05883547104895115 Adapter cache time: 0.016475161537528038 Engine time: 0.05838934378698468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741693916 . Total output tokens: 653727687
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.172854851000011,
    "estimated_duration": 3600.0595080029893,
    "input_throughput": 5155.79421916172,
    "output_throughput": 4503.308893633583,
    "total_throughput": 9659.103112795303,
    "itl": 98.51841100560405,
    "ttft": 2149825.9876789954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 924,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.915473750997356,
    "arrivals": 1107343,
    "finished_requests": 75417,
    "scheduler_time": 174.35575470625548
}
#Debug simulation 
Total elapsed time: 13.172980752773583. Arrivals time: 0.298800194170326 Scheduler time: 12.712225217372179 Scheduler overhead time: 0.05673397798091173 Adapter cache time: 0.021633211988955736 Engine time: 0.05770282447338104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741693916 . Total output tokens: 653727687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 25.015535440761596,
    "estimated_duration": 3600.0825818394505,
    "input_throughput": 5416.022426362646,
    "output_throughput": 4726.744071327772,
    "total_throughput": 10142.766497690418,
    "itl": 110.72350849086418,
    "ttft": 2127502.737406774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.433784772763024,
    "arrivals": 1107343,
    "finished_requests": 79220,
    "scheduler_time": 165.62864925609279
}
#Debug simulation 
Total elapsed time: 25.015654588118196. Arrivals time: 0.3550558532588184 Scheduler time: 24.503562807571143 Scheduler overhead time: 0.058306398801505566 Adapter cache time: 0.016098089516162872 Engine time: 0.0578924803994596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741693916 . Total output tokens: 653727687
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 13.529077849816531,
    "estimated_duration": 3600.1012932388285,
    "input_throughput": 5155.994092405278,
    "output_throughput": 4503.309123675949,
    "total_throughput": 9659.303216081227,
    "itl": 98.51687354730915,
    "ttft": 2149794.7317548264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 924,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.8500247231871105,
    "arrivals": 1107343,
    "finished_requests": 75419,
    "scheduler_time": 174.36086144603553
}
#Debug simulation 
Total elapsed time: 13.529150076210499. Arrivals time: 0.6779530332423747 Scheduler time: 12.689175787381828 Scheduler overhead time: 0.056743436958640814 Adapter cache time: 0.02181484317407012 Engine time: 0.05776743870228529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741693916 . Total output tokens: 653727687
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 25.131170950829983,
    "estimated_duration": 3600.0975170085444,
    "input_throughput": 5416.06162274235,
    "output_throughput": 4726.938623079418,
    "total_throughput": 10143.000245821768,
    "itl": 110.71699843447088,
    "ttft": 2127437.8359465366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2047283121663934,
    "arrivals": 1107343,
    "finished_requests": 79224,
    "scheduler_time": 165.6389102708374
}
#Debug simulation 
Total elapsed time: 25.131286907941103. Arrivals time: 0.42854447523131967 Scheduler time: 24.54504235414788 Scheduler overhead time: 0.05824508471414447 Adapter cache time: 0.01628867629915476 Engine time: 0.05856024893000722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741693916 . Total output tokens: 653727687
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.268399013206363,
    "estimated_duration": 3600.04145865683,
    "input_throughput": 5156.079787738192,
    "output_throughput": 4503.383971041492,
    "total_throughput": 9659.463758779684,
    "itl": 98.51530224640129,
    "ttft": 2149770.1161999255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 924,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.790374976322076,
    "arrivals": 1107343,
    "finished_requests": 75419,
    "scheduler_time": 174.36067661090186
}
#Debug simulation 
Total elapsed time: 13.26856867596507. Arrivals time: 0.37862788420170546 Scheduler time: 12.727717406582087 Scheduler overhead time: 0.05706948367878795 Adapter cache time: 0.021647050976753235 Engine time: 0.05749398097395897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740725179 . Total output tokens: 652862987
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 28.32042050594464,
    "estimated_duration": 3600.115779769525,
    "input_throughput": 5618.7298513202195,
    "output_throughput": 4893.492620153407,
    "total_throughput": 10512.222471473628,
    "itl": 117.93152199063945,
    "ttft": 2117458.0369439498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5259402502048904,
    "arrivals": 1105914,
    "finished_requests": 82063,
    "scheduler_time": 161.9874022795758
}
#Debug simulation 
Total elapsed time: 28.32053571473807. Arrivals time: 0.36308092111721635 Scheduler time: 27.804469623137265 Scheduler overhead time: 0.057496769819408655 Adapter cache time: 0.014621993992477655 Engine time: 0.05715222004801035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740725179 . Total output tokens: 652862987
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 25.562864784151316,
    "estimated_duration": 3600.097387425573,
    "input_throughput": 5471.499484653102,
    "output_throughput": 4759.887901880895,
    "total_throughput": 10231.387386533996,
    "itl": 110.32785143508923,
    "ttft": 2129525.8026978066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3461288197897416,
    "arrivals": 1105914,
    "finished_requests": 79851,
    "scheduler_time": 166.29295562093506
}
#Debug simulation 
Total elapsed time: 25.563031003344804. Arrivals time: 0.733968825545162 Scheduler time: 24.673010378610343 Scheduler overhead time: 0.057390664704144 Adapter cache time: 0.015850155148655176 Engine time: 0.0582143422216177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740725179 . Total output tokens: 652862987
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.925307677127421,
    "estimated_duration": 3600.0903256540996,
    "input_throughput": 5177.111215011988,
    "output_throughput": 4513.985630915358,
    "total_throughput": 9691.096845927346,
    "itl": 97.78272606149925,
    "ttft": 2158830.9427659158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.369242318649802,
    "arrivals": 1105914,
    "finished_requests": 75645,
    "scheduler_time": 175.11509595190935
}
#Debug simulation 
Total elapsed time: 13.92540573514998. Arrivals time: 0.30253784358501434 Scheduler time: 13.46161278616637 Scheduler overhead time: 0.057893047109246254 Adapter cache time: 0.019193210173398256 Engine time: 0.05813561752438545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740725179 . Total output tokens: 652862987
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 24.47947620274499,
    "estimated_duration": 3600.027869435964,
    "input_throughput": 5475.014559564536,
    "output_throughput": 4761.470916803109,
    "total_throughput": 10236.485476367645,
    "itl": 110.05222733150643,
    "ttft": 2131004.973801215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.119301094897087,
    "arrivals": 1105914,
    "finished_requests": 79882,
    "scheduler_time": 166.53916357684167
}
#Debug simulation 
Total elapsed time: 24.479592247866094. Arrivals time: 0.36523612355813384 Scheduler time: 23.956815253011882 Scheduler overhead time: 0.05847333185374737 Adapter cache time: 0.015939796809107065 Engine time: 0.05846862634643912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740725179 . Total output tokens: 652862987
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 13.93306624609977,
    "estimated_duration": 3600.043355906632,
    "input_throughput": 5177.178760755843,
    "output_throughput": 4514.044524863069,
    "total_throughput": 9691.223285618911,
    "itl": 97.7815055622539,
    "ttft": 2158812.728130071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.322433836734881,
    "arrivals": 1105914,
    "finished_requests": 75645,
    "scheduler_time": 175.1149346863565
}
#Debug simulation 
Total elapsed time: 13.933185955975205. Arrivals time: 0.30892075784504414 Scheduler time: 13.46213144576177 Scheduler overhead time: 0.05772495223209262 Adapter cache time: 0.01959416875615716 Engine time: 0.058616445399820805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740725179 . Total output tokens: 652862987
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 24.419238987844437,
    "estimated_duration": 3600.0578878233196,
    "input_throughput": 5475.355845435613,
    "output_throughput": 4761.787875129111,
    "total_throughput": 10237.143720564723,
    "itl": 110.04593636321762,
    "ttft": 2130985.5998256155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9110679489001505,
    "arrivals": 1105914,
    "finished_requests": 79886,
    "scheduler_time": 166.5495375951103
}
#Debug simulation 
Total elapsed time: 24.41934615885839. Arrivals time: 0.34721706761047244 Scheduler time: 23.915128261316568 Scheduler overhead time: 0.05790022714063525 Adapter cache time: 0.016048033256083727 Engine time: 0.05834202095866203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740725179 . Total output tokens: 652862987
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.032567867077887,
    "estimated_duration": 3600.101903790491,
    "input_throughput": 5177.480387534255,
    "output_throughput": 4514.0022239064165,
    "total_throughput": 9691.482611440671,
    "itl": 97.77912344311878,
    "ttft": 2158844.028261447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.273347065877196,
    "arrivals": 1105914,
    "finished_requests": 75648,
    "scheduler_time": 175.12011226042955
}
#Debug simulation 
Total elapsed time: 14.032701685093343. Arrivals time: 0.4002518090419471 Scheduler time: 13.471151642501354 Scheduler overhead time: 0.05775497108697891 Adapter cache time: 0.019156672526150942 Engine time: 0.058286061976104975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740232898 . Total output tokens: 652452478
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 36.251942455768585,
    "estimated_duration": 3600.1267867041984,
    "input_throughput": 5521.236939045944,
    "output_throughput": 4864.445625825375,
    "total_throughput": 10385.68256487132,
    "itl": 118.03065652451403,
    "ttft": 2119615.4403847414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7258387573389316,
    "arrivals": 1105156,
    "finished_requests": 80962,
    "scheduler_time": 161.59529489011032
}
#Debug simulation 
Total elapsed time: 36.252068504691124. Arrivals time: 0.37105417298153043 Scheduler time: 35.724504879675806 Scheduler overhead time: 0.06117984978482127 Adapter cache time: 0.013209145981818438 Engine time: 0.05806722259148955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740232898 . Total output tokens: 652452478
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 25.841280737891793,
    "estimated_duration": 3600.0042155730757,
    "input_throughput": 5401.270341819492,
    "output_throughput": 4744.527221971885,
    "total_throughput": 10145.797563791377,
    "itl": 110.52312247614668,
    "ttft": 2134784.4263742045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4950934967445235,
    "arrivals": 1105156,
    "finished_requests": 79099,
    "scheduler_time": 165.95231567044831
}
#Debug simulation 
Total elapsed time: 25.84144680481404. Arrivals time: 0.3350690877996385 Scheduler time: 25.350653634406626 Scheduler overhead time: 0.05820438591763377 Adapter cache time: 0.014657927211374044 Engine time: 0.05801715236157179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740232898 . Total output tokens: 652452478
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.913652033079416,
    "estimated_duration": 3600.1027272963984,
    "input_throughput": 5112.442447947036,
    "output_throughput": 4506.985835980601,
    "total_throughput": 9619.428283927637,
    "itl": 97.82358253137957,
    "ttft": 2158180.9608059097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.33164048084061,
    "arrivals": 1105156,
    "finished_requests": 75021,
    "scheduler_time": 175.04693752606934
}
#Debug simulation 
Total elapsed time: 14.913748130202293. Arrivals time: 0.3189232228323817 Scheduler time: 14.434035433921963 Scheduler overhead time: 0.058298691641539335 Adapter cache time: 0.017269004601985216 Engine time: 0.05910525470972061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740232898 . Total output tokens: 652452478
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 25.885859169997275,
    "estimated_duration": 3600.102101938573,
    "input_throughput": 5401.149870035485,
    "output_throughput": 4744.658489213995,
    "total_throughput": 10145.80835924948,
    "itl": 110.51889248898996,
    "ttft": 2134773.8236428094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.341000968706791,
    "arrivals": 1105156,
    "finished_requests": 79103,
    "scheduler_time": 165.96276992886837
}
#Debug simulation 
Total elapsed time: 25.886012656148523. Arrivals time: 0.36445833509787917 Scheduler time: 25.366937074810266 Scheduler overhead time: 0.057533405255526304 Adapter cache time: 0.014354154467582703 Engine time: 0.05803653411567211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740232898 . Total output tokens: 652452478
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 15.370893004816025,
    "estimated_duration": 3600.0636034672243,
    "input_throughput": 5112.498007611261,
    "output_throughput": 4507.034815821892,
    "total_throughput": 9619.532823433154,
    "itl": 97.82257260910788,
    "ttft": 2158164.0519381464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.292702451637047,
    "arrivals": 1105156,
    "finished_requests": 75021,
    "scheduler_time": 175.04675172609902
}
#Debug simulation 
Total elapsed time: 15.370973047800362. Arrivals time: 0.6823478220030665 Scheduler time: 14.52603896241635 Scheduler overhead time: 0.058901085052639246 Adapter cache time: 0.017723501194268465 Engine time: 0.059514764696359634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740232898 . Total output tokens: 652452478
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 25.89326674770564,
    "estimated_duration": 3600.075678819296,
    "input_throughput": 5401.189512320809,
    "output_throughput": 4744.693313114483,
    "total_throughput": 10145.882825435292,
    "itl": 110.51476726960094,
    "ttft": 2134695.2629642147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1896848826156843,
    "arrivals": 1105156,
    "finished_requests": 79103,
    "scheduler_time": 165.96753827068173
}
#Debug simulation 
Total elapsed time: 25.893389390781522. Arrivals time: 0.36581498431041837 Scheduler time: 25.372507330495864 Scheduler overhead time: 0.058197335340082645 Adapter cache time: 0.014329493511468172 Engine time: 0.05799764022231102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740232898 . Total output tokens: 652452478
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.93150911014527,
    "estimated_duration": 3600.0257463241924,
    "input_throughput": 5112.551769606858,
    "output_throughput": 4507.082210888954,
    "total_throughput": 9619.633980495813,
    "itl": 97.82160064284818,
    "ttft": 2158147.4773072274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.255007125493172,
    "arrivals": 1105156,
    "finished_requests": 75021,
    "scheduler_time": 175.0465899092109
}
#Debug simulation 
Total elapsed time: 14.931661228183657. Arrivals time: 0.38108146004378796 Scheduler time: 14.389876195695251 Scheduler overhead time: 0.05798756889998913 Adapter cache time: 0.01741442270576954 Engine time: 0.05925233894959092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_192_slots_64_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_192_slots_64_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678087627 . Total output tokens: 597685331
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 31.679207905195653,
    "estimated_duration": 3600.1017185479504,
    "input_throughput": 5618.200701328491,
    "output_throughput": 4866.716934616701,
    "total_throughput": 10484.917635945192,
    "itl": 117.8519728825468,
    "ttft": 2111980.242204455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.345878970166709,
    "arrivals": 1012546,
    "finished_requests": 81525,
    "scheduler_time": 161.65770205642247
}
#Debug simulation 
Total elapsed time: 31.679322191979736. Arrivals time: 0.38520980440080166 Scheduler time: 31.13321959413588 Scheduler overhead time: 0.06016252376139164 Adapter cache time: 0.016979902517050505 Engine time: 0.05959745589643717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_192_slots_64_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_192_slots_64_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678087627 . Total output tokens: 597685331
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 22.467743361368775,
    "estimated_duration": 3600.0251004991183,
    "input_throughput": 5449.903667971607,
    "output_throughput": 4730.57868336498,
    "total_throughput": 10180.482351336588,
    "itl": 110.9592134338654,
    "ttft": 2124541.6838474646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.339933379613802,
    "arrivals": 1012546,
    "finished_requests": 79267,
    "scheduler_time": 165.19465919768467
}
#Debug simulation 
Total elapsed time: 22.467910698149353. Arrivals time: 0.3552604541182518 Scheduler time: 21.9534148927778 Scheduler overhead time: 0.05788465728983283 Adapter cache time: 0.019147245213389397 Engine time: 0.05763874901458621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_192_slots_64_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_192_slots_64_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678087627 . Total output tokens: 597685331
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 16.464328914880753,
    "estimated_duration": 3600.0427630563972,
    "input_throughput": 5132.916528000286,
    "output_throughput": 4459.395084065701,
    "total_throughput": 9592.311612065987,
    "itl": 98.3107118071432,
    "ttft": 2154077.265440096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 959,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.2015539318649315,
    "arrivals": 1012546,
    "finished_requests": 74586,
    "scheduler_time": 173.5970803354814
}
#Debug simulation 
Total elapsed time: 16.46442575007677. Arrivals time: 0.3150681918486953 Scheduler time: 15.98103354871273 Scheduler overhead time: 0.05979089438915253 Adapter cache time: 0.022324946243315935 Engine time: 0.05984265077859163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_192_slots_64_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_192_slots_64_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678087627 . Total output tokens: 597685331
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 28.989883898291737,
    "estimated_duration": 3600.074527150262,
    "input_throughput": 5451.235759703729,
    "output_throughput": 4732.641191594105,
    "total_throughput": 10183.876951297834,
    "itl": 110.60224148678994,
    "ttft": 2126351.1961357724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 700,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.774153272528193,
    "arrivals": 1012546,
    "finished_requests": 79272,
    "scheduler_time": 165.55049486038382
}
#Debug simulation 
Total elapsed time: 28.990035680122674. Arrivals time: 0.3430260708555579 Scheduler time: 28.481479772366583 Scheduler overhead time: 0.061181999277323484 Adapter cache time: 0.01929844031110406 Engine time: 0.06012882525101304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_192_slots_64_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_192_slots_64_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678087627 . Total output tokens: 597685331
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 16.52616873383522,
    "estimated_duration": 3600.0834473768573,
    "input_throughput": 5132.85879899929,
    "output_throughput": 4459.363021625942,
    "total_throughput": 9592.221820625233,
    "itl": 98.30908729193467,
    "ttft": 2154047.6509581814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 959,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.133619497935309,
    "arrivals": 1012546,
    "finished_requests": 74587,
    "scheduler_time": 173.60215447142477
}
#Debug simulation 
Total elapsed time: 16.526305580046028. Arrivals time: 0.3919524112716317 Scheduler time: 15.965976976789534 Scheduler overhead time: 0.059999576304107904 Adapter cache time: 0.022054778411984444 Engine time: 0.05993103329092264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_192_slots_64_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_192_slots_64_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678087627 . Total output tokens: 597685331
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 29.08222914300859,
    "estimated_duration": 3600.0190669957556,
    "input_throughput": 5451.72057001862,
    "output_throughput": 4732.932710331139,
    "total_throughput": 10184.65328034976,
    "itl": 110.59169102725325,
    "ttft": 2126344.4369748225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 700,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.468744658399352,
    "arrivals": 1012546,
    "finished_requests": 79277,
    "scheduler_time": 165.56076090783435
}
#Debug simulation 
Total elapsed time: 29.08235456701368. Arrivals time: 0.34118216997012496 Scheduler time: 28.57691406365484 Scheduler overhead time: 0.05989770870655775 Adapter cache time: 0.019381582736968994 Engine time: 0.05994698265567422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_192_slots_64_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_192_slots_64_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678087627 . Total output tokens: 597685331
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 16.40374636463821,
    "estimated_duration": 3600.018405506842,
    "input_throughput": 5132.95153484039,
    "output_throughput": 4459.443589355696,
    "total_throughput": 9592.395124196086,
    "itl": 98.30736615617914,
    "ttft": 2154021.716290817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 959,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.068791821654909,
    "arrivals": 1012546,
    "finished_requests": 74587,
    "scheduler_time": 173.60194027769043
}
#Debug simulation 
Total elapsed time: 16.403837334830314. Arrivals time: 0.31048554833978415 Scheduler time: 15.925543742720038 Scheduler overhead time: 0.05981518980115652 Adapter cache time: 0.02213206561282277 Engine time: 0.059639455284923315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_192_slots_64_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_192_slots_64_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 631986954 . Total output tokens: 556995452
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 45.714758813846856,
    "estimated_duration": 3600.0546824197827,
    "input_throughput": 5609.631458827151,
    "output_throughput": 4892.493185176073,
    "total_throughput": 10502.124644003225,
    "itl": 118.19383095272161,
    "ttft": 2103226.459535799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.281281116022735,
    "arrivals": 943308,
    "finished_requests": 81737,
    "scheduler_time": 161.5364249792034
}
#Debug simulation 
Total elapsed time: 45.71493515977636. Arrivals time: 0.3875755532644689 Scheduler time: 45.16067685931921 Scheduler overhead time: 0.06334385927766562 Adapter cache time: 0.016160864382982254 Engine time: 0.06225326284766197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_192_slots_64_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_192_slots_64_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 631986954 . Total output tokens: 556995452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 25.000038695987314,
    "estimated_duration": 3600.032493411831,
    "input_throughput": 5438.868964608566,
    "output_throughput": 4738.616118387487,
    "total_throughput": 10177.485082996054,
    "itl": 110.74612705884773,
    "ttft": 2113684.00852845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 822,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.013880990417683,
    "arrivals": 943308,
    "finished_requests": 79182,
    "scheduler_time": 165.33414035861858
}
#Debug simulation 
Total elapsed time: 25.0001425947994. Arrivals time: 0.3342829109169543 Scheduler time: 24.501636220142245 Scheduler overhead time: 0.05915143387392163 Adapter cache time: 0.0211794744245708 Engine time: 0.05897571844980121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_192_slots_64_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_192_slots_64_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 631986954 . Total output tokens: 556995452
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.428581004031003,
    "estimated_duration": 3600.0669466450518,
    "input_throughput": 5120.850604508949,
    "output_throughput": 4472.577659980814,
    "total_throughput": 9593.428264489763,
    "itl": 98.41442315152864,
    "ttft": 2143510.511644117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1087,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.194279970224034,
    "arrivals": 943308,
    "finished_requests": 74584,
    "scheduler_time": 173.4934803079429
}
#Debug simulation 
Total elapsed time: 14.428685194812715. Arrivals time: 0.3177191228605807 Scheduler time: 13.942248786333948 Scheduler overhead time: 0.05902443826198578 Adapter cache time: 0.02420581318438053 Engine time: 0.05941542563959956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_192_slots_64_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_192_slots_64_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 631986954 . Total output tokens: 556995452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 26.79006213694811,
    "estimated_duration": 3600.049802524218,
    "input_throughput": 5423.513026489209,
    "output_throughput": 4734.464781028634,
    "total_throughput": 10157.977807517842,
    "itl": 110.6500523326753,
    "ttft": 2115872.4115452343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.943950741766015,
    "arrivals": 943308,
    "finished_requests": 79015,
    "scheduler_time": 165.37415833867436
}
#Debug simulation 
Total elapsed time: 26.79021305218339. Arrivals time: 0.3211976056918502 Scheduler time: 26.30929779773578 Scheduler overhead time: 0.05866673681885004 Adapter cache time: 0.018330184742808342 Engine time: 0.058033255860209465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_192_slots_64_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_192_slots_64_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 631986954 . Total output tokens: 556995452
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.373951524030417,
    "estimated_duration": 3600.101593683404,
    "input_throughput": 5120.973261517708,
    "output_throughput": 4472.659890557529,
    "total_throughput": 9593.633152075237,
    "itl": 98.41196471607407,
    "ttft": 2143479.1100501367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1087,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.11681814617014,
    "arrivals": 943308,
    "finished_requests": 74586,
    "scheduler_time": 173.4986435249185
}
#Debug simulation 
Total elapsed time: 14.374047249089926. Arrivals time: 0.29721227334812284 Scheduler time: 13.90894474554807 Scheduler overhead time: 0.05818299436941743 Adapter cache time: 0.024510386399924755 Engine time: 0.0591035527177155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_192_slots_64_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_192_slots_64_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 631986954 . Total output tokens: 556995452
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 26.89947689604014,
    "estimated_duration": 3600.0358435074527,
    "input_throughput": 5423.861552716115,
    "output_throughput": 4734.672303538334,
    "total_throughput": 10158.53385625445,
    "itl": 110.64298384572096,
    "ttft": 2115757.298352704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6899063036497513,
    "arrivals": 943308,
    "finished_requests": 79019,
    "scheduler_time": 165.38448100989353
}
#Debug simulation 
Total elapsed time: 26.89961475599557. Arrivals time: 0.34676822973415256 Scheduler time: 26.39391249557957 Scheduler overhead time: 0.0583584257401526 Adapter cache time: 0.017828613054007292 Engine time: 0.05816904176026583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_192_slots_64_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_192_slots_64_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 631986954 . Total output tokens: 556995452
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.318660947028548,
    "estimated_duration": 3600.0245923588286,
    "input_throughput": 5121.082794581756,
    "output_throughput": 4472.75555677511,
    "total_throughput": 9593.838351356866,
    "itl": 98.40992299954766,
    "ttft": 2143454.48522106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1087,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.039977673646085,
    "arrivals": 943308,
    "finished_requests": 74586,
    "scheduler_time": 173.49848267286703
}
#Debug simulation 
Total elapsed time: 14.318777010776103. Arrivals time: 0.2968252431601286 Scheduler time: 13.852652424946427 Scheduler overhead time: 0.059296959545463324 Adapter cache time: 0.024437131825834513 Engine time: 0.05935818608850241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_192_slots_64_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_192_slots_64_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624241778 . Total output tokens: 550268966
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 27.400910690892488,
    "estimated_duration": 3600.079855650054,
    "input_throughput": 5588.242707568314,
    "output_throughput": 4859.357764674127,
    "total_throughput": 10447.60047224244,
    "itl": 118.47926265222605,
    "ttft": 2099045.1330715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.459816159885389,
    "arrivals": 932003,
    "finished_requests": 81506,
    "scheduler_time": 161.23254604645538
}
#Debug simulation 
Total elapsed time: 27.40102642495185. Arrivals time: 0.3308675209991634 Scheduler time: 26.920460676774383 Scheduler overhead time: 0.056140955071896315 Adapter cache time: 0.013975042849779129 Engine time: 0.0559790157712996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_192_slots_64_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_192_slots_64_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624241778 . Total output tokens: 550268966
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 31.77876543486491,
    "estimated_duration": 3600.0955658090693,
    "input_throughput": 5431.290542868051,
    "output_throughput": 4732.189379025924,
    "total_throughput": 10163.479921893973,
    "itl": 111.27971078269225,
    "ttft": 2111054.048717055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4377324486617047,
    "arrivals": 932003,
    "finished_requests": 79236,
    "scheduler_time": 164.89678230111443
}
#Debug simulation 
Total elapsed time: 31.77892133081332. Arrivals time: 0.45242799259722233 Scheduler time: 31.162089036311954 Scheduler overhead time: 0.06149565801024437 Adapter cache time: 0.016474054660648108 Engine time: 0.06132224760949612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_192_slots_64_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_192_slots_64_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624241778 . Total output tokens: 550268966
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.362909481860697,
    "estimated_duration": 3600.0702133329646,
    "input_throughput": 5124.414777155279,
    "output_throughput": 4458.372767441222,
    "total_throughput": 9582.7875445965,
    "itl": 98.49878576647174,
    "ttft": 2139307.290942766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 991,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.458279473427708,
    "arrivals": 932003,
    "finished_requests": 74741,
    "scheduler_time": 173.29122412336227
}
#Debug simulation 
Total elapsed time: 13.363027900923043. Arrivals time: 0.2878683996386826 Scheduler time: 12.910823218058795 Scheduler overhead time: 0.05816245777532458 Adapter cache time: 0.022093824576586485 Engine time: 0.05807501822710037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_192_slots_64_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_192_slots_64_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624241778 . Total output tokens: 550268966
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 32.265588643960655,
    "estimated_duration": 3600.1015257228564,
    "input_throughput": 5432.517349930311,
    "output_throughput": 4733.863441970042,
    "total_throughput": 10166.380791900352,
    "itl": 111.2772490533336,
    "ttft": 2111113.873824325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2070139139704366,
    "arrivals": 932003,
    "finished_requests": 79271,
    "scheduler_time": 164.9137903776743
}
#Debug simulation 
Total elapsed time: 32.26569283660501. Arrivals time: 0.511892725713551 Scheduler time: 31.590146421454847 Scheduler overhead time: 0.0612901714630425 Adapter cache time: 0.016464853659272194 Engine time: 0.06096708821132779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_192_slots_64_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_192_slots_64_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624241778 . Total output tokens: 550268966
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 13.305477627087384,
    "estimated_duration": 3600.000027302817,
    "input_throughput": 5124.514683357309,
    "output_throughput": 4458.459688408747,
    "total_throughput": 9582.974371766057,
    "itl": 98.49690012953849,
    "ttft": 2139279.811934257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 991,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.38827386773194,
    "arrivals": 932003,
    "finished_requests": 74741,
    "scheduler_time": 173.29104369891039
}
#Debug simulation 
Total elapsed time: 13.305614179931581. Arrivals time: 0.2906789742410183 Scheduler time: 12.850644757505506 Scheduler overhead time: 0.05823987536132336 Adapter cache time: 0.022163773886859417 Engine time: 0.05798605317249894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_192_slots_64_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_192_slots_64_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624241778 . Total output tokens: 550268966
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 32.269663176033646,
    "estimated_duration": 3600.003138208194,
    "input_throughput": 5432.9374861975175,
    "output_throughput": 4734.371984043069,
    "total_throughput": 10167.309470240587,
    "itl": 111.27175660160364,
    "ttft": 2111022.8432774213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9876750001869965,
    "arrivals": 932003,
    "finished_requests": 79276,
    "scheduler_time": 164.9184433071493
}
#Debug simulation 
Total elapsed time: 32.26985950395465. Arrivals time: 0.4439366306178272 Scheduler time: 31.66270349221304 Scheduler overhead time: 0.06112275691702962 Adapter cache time: 0.01644451590254903 Engine time: 0.06084526889026165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_192_slots_64_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_192_slots_64_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624241778 . Total output tokens: 550268966
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.291824327781796,
    "estimated_duration": 3600.0382063384945,
    "input_throughput": 5124.596446648197,
    "output_throughput": 4458.547126455359,
    "total_throughput": 9583.143573103556,
    "itl": 98.49515252290148,
    "ttft": 2139249.1648230264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 991,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.31909673074263,
    "arrivals": 932003,
    "finished_requests": 74742,
    "scheduler_time": 173.29613063825005
}
#Debug simulation 
Total elapsed time: 13.291942351963371. Arrivals time: 0.3899101158604026 Scheduler time: 12.738294845446944 Scheduler overhead time: 0.05780051788315177 Adapter cache time: 0.02173779346048832 Engine time: 0.0583242392167449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_192_slots_64_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_192_slots_64_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620399998 . Total output tokens: 546847589
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 24.761941959615797,
    "estimated_duration": 3600.0643245342935,
    "input_throughput": 5600.44770939146,
    "output_throughput": 4866.91581608519,
    "total_throughput": 10467.36352547665,
    "itl": 119.04521266066845,
    "ttft": 2092321.4697488602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.730924930195345,
    "arrivals": 926191,
    "finished_requests": 81786,
    "scheduler_time": 160.65202056473748
}
#Debug simulation 
Total elapsed time: 24.76204640371725. Arrivals time: 0.35398505069315434 Scheduler time: 24.26071498915553 Scheduler overhead time: 0.05497337132692337 Adapter cache time: 0.0144648184068501 Engine time: 0.054859290830791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_192_slots_64_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_192_slots_64_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620399998 . Total output tokens: 546847589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 21.54229095391929,
    "estimated_duration": 3600.0705318371183,
    "input_throughput": 5435.10823661976,
    "output_throughput": 4732.575334102052,
    "total_throughput": 10167.68357072181,
    "itl": 111.16065368684063,
    "ttft": 2104497.089383313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6506305754045076,
    "arrivals": 926191,
    "finished_requests": 79387,
    "scheduler_time": 164.93862280783478
}
#Debug simulation 
Total elapsed time: 21.542415810283273. Arrivals time: 0.3214654433541 Scheduler time: 21.06785574601963 Scheduler overhead time: 0.05682919966056943 Adapter cache time: 0.015538860578089952 Engine time: 0.056731150951236486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_192_slots_64_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_192_slots_64_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620399998 . Total output tokens: 546847589
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.95161578990519,
    "estimated_duration": 3600.026496125478,
    "input_throughput": 5134.966373135181,
    "output_throughput": 4472.469582467985,
    "total_throughput": 9607.435955603167,
    "itl": 98.65454593676095,
    "ttft": 2134213.029679734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.860946877244884,
    "arrivals": 926191,
    "finished_requests": 75038,
    "scheduler_time": 173.22877645788262
}
#Debug simulation 
Total elapsed time: 13.951710445806384. Arrivals time: 0.29155558068305254 Scheduler time: 13.49881158163771 Scheduler overhead time: 0.057529352605342865 Adapter cache time: 0.019625688903033733 Engine time: 0.05833622254431248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_192_slots_64_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_192_slots_64_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620399998 . Total output tokens: 546847589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 21.54153710277751,
    "estimated_duration": 3600.072448782773,
    "input_throughput": 5435.3595041166645,
    "output_throughput": 4732.809198259581,
    "total_throughput": 10168.168702376246,
    "itl": 111.15307562131487,
    "ttft": 2104471.9475914254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4076919050747474,
    "arrivals": 926191,
    "finished_requests": 79392,
    "scheduler_time": 164.9490392615832
}
#Debug simulation 
Total elapsed time: 21.54170116968453. Arrivals time: 0.32988659478724003 Scheduler time: 21.0576290381141 Scheduler overhead time: 0.05756825767457485 Adapter cache time: 0.01578014623373747 Engine time: 0.056624680291861296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_192_slots_64_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_192_slots_64_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620399998 . Total output tokens: 546847589
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.02249949472025,
    "estimated_duration": 3600.078759956168,
    "input_throughput": 5135.158765311313,
    "output_throughput": 4472.666314721416,
    "total_throughput": 9607.82508003273,
    "itl": 98.6528469890274,
    "ttft": 2134338.1789143197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.805853708265373,
    "arrivals": 926191,
    "finished_requests": 75042,
    "scheduler_time": 173.23386422422516
}
#Debug simulation 
Total elapsed time: 14.022618878632784. Arrivals time: 0.29119919380173087 Scheduler time: 13.569665253628045 Scheduler overhead time: 0.057888747192919254 Adapter cache time: 0.019640116952359676 Engine time: 0.0583304762840271 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_192_slots_64_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_192_slots_64_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620399998 . Total output tokens: 546847589
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 22.289401655085385,
    "estimated_duration": 3600.0004137495444,
    "input_throughput": 5441.873819007552,
    "output_throughput": 4734.977789140305,
    "total_throughput": 10176.851608147857,
    "itl": 111.26623253669594,
    "ttft": 2105104.4993524197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 529,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.377094177561797,
    "arrivals": 926191,
    "finished_requests": 79488,
    "scheduler_time": 164.8451594188141
}
#Debug simulation 
Total elapsed time: 22.289520604070276. Arrivals time: 0.3416725331917405 Scheduler time: 21.795503095258027 Scheduler overhead time: 0.05587354162707925 Adapter cache time: 0.01599745312705636 Engine time: 0.056359687354415655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_192_slots_64_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_192_slots_64_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620399998 . Total output tokens: 546847589
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.061418953817338,
    "estimated_duration": 3600.0267813543314,
    "input_throughput": 5135.232908752193,
    "output_throughput": 4472.73089283587,
    "total_throughput": 9607.963801588063,
    "itl": 98.65150637236046,
    "ttft": 2134317.1240120656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.754074414111701,
    "arrivals": 926191,
    "finished_requests": 75042,
    "scheduler_time": 173.23366491654184
}
#Debug simulation 
Total elapsed time: 14.061539862770587. Arrivals time: 0.2971955989487469 Scheduler time: 13.60103025753051 Scheduler overhead time: 0.05826769256964326 Adapter cache time: 0.019776830915361643 Engine time: 0.058946486096829176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618463244 . Total output tokens: 545160770
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 26.570561638101935,
    "estimated_duration": 3600.0321435890605,
    "input_throughput": 5608.07492676226,
    "output_throughput": 4867.774036742146,
    "total_throughput": 10475.848963504404,
    "itl": 118.64796792287534,
    "ttft": 2094264.5770496314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7375373392272953,
    "arrivals": 923294,
    "finished_requests": 81697,
    "scheduler_time": 160.7806779243263
}
#Debug simulation 
Total elapsed time: 26.570700351148844. Arrivals time: 0.37391972867771983 Scheduler time: 26.042759076692164 Scheduler overhead time: 0.05820697359740734 Adapter cache time: 0.014826111495494843 Engine time: 0.05740204965695739 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618463244 . Total output tokens: 545160770
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 25.235997607931495,
    "estimated_duration": 3600.104972920173,
    "input_throughput": 5453.949023067937,
    "output_throughput": 4741.340357682533,
    "total_throughput": 10195.28938075047,
    "itl": 110.92171177142997,
    "ttft": 2111570.2916941266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.330036829719325,
    "arrivals": 923294,
    "finished_requests": 79574,
    "scheduler_time": 165.14177739718875
}
#Debug simulation 
Total elapsed time: 25.236194704659283. Arrivals time: 0.32913370290771127 Scheduler time: 24.747862592339516 Scheduler overhead time: 0.05959472805261612 Adapter cache time: 0.01566775143146515 Engine time: 0.0591664114035666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618463244 . Total output tokens: 545160770
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.117150332778692,
    "estimated_duration": 3600.092635264799,
    "input_throughput": 5139.299977662691,
    "output_throughput": 4477.080351243371,
    "total_throughput": 9616.380328906062,
    "itl": 98.59995689617807,
    "ttft": 2140870.9356045276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.543498320081298,
    "arrivals": 923294,
    "finished_requests": 75032,
    "scheduler_time": 173.33148229533163
}
#Debug simulation 
Total elapsed time: 14.11725147580728. Arrivals time: 0.3674444309435785 Scheduler time: 13.588677071034908 Scheduler overhead time: 0.058346450328826904 Adapter cache time: 0.018301826901733875 Engine time: 0.058471428230404854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618463244 . Total output tokens: 545160770
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 25.1848997711204,
    "estimated_duration": 3600.0101722716113,
    "input_throughput": 5454.363754647339,
    "output_throughput": 4741.602435314488,
    "total_throughput": 10195.966189961826,
    "itl": 110.91495235878004,
    "ttft": 2111569.374879924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.112086136909198,
    "arrivals": 923294,
    "finished_requests": 79576,
    "scheduler_time": 165.14636162046827
}
#Debug simulation 
Total elapsed time: 25.185052890330553. Arrivals time: 0.3277315222658217 Scheduler time: 24.697431717533618 Scheduler overhead time: 0.06007890170440078 Adapter cache time: 0.015816662926226854 Engine time: 0.05916101951152086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618463244 . Total output tokens: 545160770
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.065817153081298,
    "estimated_duration": 3600.04210510486,
    "input_throughput": 5139.372112832853,
    "output_throughput": 4477.143191504569,
    "total_throughput": 9616.515304337423,
    "itl": 98.59865981905548,
    "ttft": 2140851.3458733857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.493168846163926,
    "arrivals": 923294,
    "finished_requests": 75032,
    "scheduler_time": 173.33128160931025
}
#Debug simulation 
Total elapsed time: 14.065952325705439. Arrivals time: 0.31936717592179775 Scheduler time: 13.584181279409677 Scheduler overhead time: 0.05871394881978631 Adapter cache time: 0.018745949491858482 Engine time: 0.058809070847928524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618463244 . Total output tokens: 545160770
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 25.147017035167664,
    "estimated_duration": 3600.0434250654444,
    "input_throughput": 5454.911977802881,
    "output_throughput": 4741.6428038474805,
    "total_throughput": 10196.55478165036,
    "itl": 110.90744382063265,
    "ttft": 2111601.4944723905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8983001070190095,
    "arrivals": 923294,
    "finished_requests": 79582,
    "scheduler_time": 165.15669393063502
}
#Debug simulation 
Total elapsed time: 25.147113249171525. Arrivals time: 0.3283914066851139 Scheduler time: 24.6604025028646 Scheduler overhead time: 0.059205605648458004 Adapter cache time: 0.01554720290005207 Engine time: 0.059028576128184795 
