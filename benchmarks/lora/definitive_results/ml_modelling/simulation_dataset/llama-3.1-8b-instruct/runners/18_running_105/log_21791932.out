INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85822682 . Total output tokens: 75577275
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.84463201102335,
    "estimated_duration": 3600.0099505512344,
    "input_throughput": 8037.867505218771,
    "output_throughput": 6956.015217726163,
    "total_throughput": 14993.882722944934,
    "itl": 86.01748834132333,
    "ttft": 461615.1076053513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 127929,
    "finished_requests": 116411,
    "scheduler_time": 86.08619079737291
}
#Debug simulation 
Total elapsed time: 7.844756114995107. Arrivals time: 0.2771924934349954 Scheduler time: 7.401392731466331 Scheduler overhead time: 0.06032988952938467 Adapter cache time: 0.015166607219725847 Engine time: 0.06220765644684434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85822682 . Total output tokens: 75577275
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.8298984380671754,
    "estimated_duration": 3600.040833051472,
    "input_throughput": 7973.86761184816,
    "output_throughput": 6900.318955255813,
    "total_throughput": 14874.186567103972,
    "itl": 83.52797729723459,
    "ttft": 498890.28314675123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 127929,
    "finished_requests": 115475,
    "scheduler_time": 84.0475982917388
}
#Debug simulation 
Total elapsed time: 7.83000019704923. Arrivals time: 0.28771717532072216 Scheduler time: 7.371014087460935 Scheduler overhead time: 0.06222474470268935 Adapter cache time: 0.015444751945324242 Engine time: 0.06417101598344743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85822682 . Total output tokens: 75577275
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.666643836069852,
    "estimated_duration": 3600.01820163204,
    "input_throughput": 7807.411081215643,
    "output_throughput": 6762.140255003132,
    "total_throughput": 14569.551336218776,
    "itl": 77.63064967543137,
    "ttft": 593415.1169032748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 127929,
    "finished_requests": 113113,
    "scheduler_time": 78.52122547776881
}
#Debug simulation 
Total elapsed time: 7.666738559026271. Arrivals time: 0.2823825271334499 Scheduler time: 7.203971504815854 Scheduler overhead time: 0.06539366976357996 Adapter cache time: 0.016011615749448538 Engine time: 0.06787989160511643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85822682 . Total output tokens: 75577275
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.774311388027854,
    "estimated_duration": 3599.9998917265452,
    "input_throughput": 7973.540239811875,
    "output_throughput": 6900.299096422006,
    "total_throughput": 14873.839336233881,
    "itl": 83.5281870538029,
    "ttft": 498949.88485304546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 127929,
    "finished_requests": 115472,
    "scheduler_time": 84.0495982309717
}
#Debug simulation 
Total elapsed time: 7.774402488954365. Arrivals time: 0.2805496617220342 Scheduler time: 7.3244836394442245 Scheduler overhead time: 0.061503796139732 Adapter cache time: 0.015219859196804464 Engine time: 0.06367179926019162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85822682 . Total output tokens: 75577275
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.697798599023372,
    "estimated_duration": 3600.0668291018346,
    "input_throughput": 7807.367566843837,
    "output_throughput": 6762.119470452581,
    "total_throughput": 14569.487037296418,
    "itl": 77.63225251583204,
    "ttft": 593384.3364742645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 127929,
    "finished_requests": 113115,
    "scheduler_time": 78.52389883833735
}
#Debug simulation 
Total elapsed time: 7.697893847012892. Arrivals time: 0.2850493713049218 Scheduler time: 7.231343687977642 Scheduler overhead time: 0.0658623892813921 Adapter cache time: 0.016084897448308766 Engine time: 0.0681945780524984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85822682 . Total output tokens: 75577275
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.804744608933106,
    "estimated_duration": 3600.0705997914406,
    "input_throughput": 7973.629462061932,
    "output_throughput": 6900.225790416195,
    "total_throughput": 14873.855252478126,
    "itl": 83.52831557516564,
    "ttft": 498898.09450789023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 127929,
    "finished_requests": 115474,
    "scheduler_time": 84.0511477961726
}
#Debug simulation 
Total elapsed time: 7.804852696950547. Arrivals time: 0.27987682982347906 Scheduler time: 7.352939822827466 Scheduler overhead time: 0.06372633774299175 Adapter cache time: 0.015371755696833134 Engine time: 0.06384049030020833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 135, 135, 270, 135, 34560, 270, 135, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 34560, 34560, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 270, 270, 34560]
Prompts retrieved: 384480 . Total input tokens: 85822682 . Total output tokens: 75577275
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.6591682359576225,
    "estimated_duration": 3600.0708917170036,
    "input_throughput": 7807.570418868717,
    "output_throughput": 6762.152672051789,
    "total_throughput": 14569.723090920505,
    "itl": 77.63035153708731,
    "ttft": 593294.6691522679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 127929,
    "finished_requests": 113117,
    "scheduler_time": 78.52355332348317
}
#Debug simulation 
Total elapsed time: 7.659342564060353. Arrivals time: 0.2827200550818816 Scheduler time: 7.1955406164051965 Scheduler overhead time: 0.06613914435729384 Adapter cache time: 0.016029620775952935 Engine time: 0.06795103882905096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85669836 . Total output tokens: 75449695
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.868887793971226,
    "estimated_duration": 3600.0883649167636,
    "input_throughput": 8010.136995808639,
    "output_throughput": 7017.826352877352,
    "total_throughput": 15027.963348685991,
    "itl": 85.80191814113397,
    "ttft": 435125.898722714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 127708,
    "finished_requests": 116888,
    "scheduler_time": 87.4757152380682
}
#Debug simulation 
Total elapsed time: 7.868982251966372. Arrivals time: 0.27593954757321626 Scheduler time: 7.427952355938032 Scheduler overhead time: 0.06038503791205585 Adapter cache time: 0.014256491558626294 Engine time: 0.06199254444800317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85669836 . Total output tokens: 75449695
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.846995710046031,
    "estimated_duration": 3600.025701573037,
    "input_throughput": 7944.585225461828,
    "output_throughput": 6963.027233124169,
    "total_throughput": 14907.612458585996,
    "itl": 83.3343724156682,
    "ttft": 473139.4558175215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 127708,
    "finished_requests": 115942,
    "scheduler_time": 85.40224812875908
}
#Debug simulation 
Total elapsed time: 7.847086063004099. Arrivals time: 0.2910697776824236 Scheduler time: 7.386163154034875 Scheduler overhead time: 0.06204272876493633 Adapter cache time: 0.014725981396622956 Engine time: 0.06375401059631258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85669836 . Total output tokens: 75449695
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.694867864018306,
    "estimated_duration": 3600.0683093976777,
    "input_throughput": 7783.2084260334495,
    "output_throughput": 6814.890133044381,
    "total_throughput": 14598.098559077831,
    "itl": 77.49518240705763,
    "ttft": 571594.2134886067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 127708,
    "finished_requests": 113488,
    "scheduler_time": 79.72866124991145
}
#Debug simulation 
Total elapsed time: 7.69497739803046. Arrivals time: 0.2850603818660602 Scheduler time: 7.23017527256161 Scheduler overhead time: 0.06551223632413894 Adapter cache time: 0.015333759016357362 Engine time: 0.06797038554213941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85669836 . Total output tokens: 75449695
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.85800992208533,
    "estimated_duration": 3600.0727808976403,
    "input_throughput": 7945.07354178217,
    "output_throughput": 6963.212836422029,
    "total_throughput": 14908.286378204199,
    "itl": 83.33403061552738,
    "ttft": 473040.31100871944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 127708,
    "finished_requests": 115947,
    "scheduler_time": 85.40501599843961
}
#Debug simulation 
Total elapsed time: 7.858140590018593. Arrivals time: 0.28014860744588077 Scheduler time: 7.4081795933889225 Scheduler overhead time: 0.061854838975705206 Adapter cache time: 0.014675756450742483 Engine time: 0.06387820816598833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85669836 . Total output tokens: 75449695
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.706473793019541,
    "estimated_duration": 3600.075193004478,
    "input_throughput": 7783.092434971023,
    "output_throughput": 6814.651829404021,
    "total_throughput": 14597.744264375044,
    "itl": 77.49738892794748,
    "ttft": 571702.1936088977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 127708,
    "finished_requests": 113486,
    "scheduler_time": 79.72689560864087
}
#Debug simulation 
Total elapsed time: 7.706569731933996. Arrivals time: 0.2842205361230299 Scheduler time: 7.242099400376901 Scheduler overhead time: 0.06572809140197933 Adapter cache time: 0.015488612581975758 Engine time: 0.0677874805405736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85669836 . Total output tokens: 75449695
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.87362235202454,
    "estimated_duration": 3600.03820467619,
    "input_throughput": 7944.804297590115,
    "output_throughput": 6963.127771099509,
    "total_throughput": 14907.932068689624,
    "itl": 83.33193121173973,
    "ttft": 473068.55404387944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 127708,
    "finished_requests": 115944,
    "scheduler_time": 85.40278566129365
}
#Debug simulation 
Total elapsed time: 7.873717361013405. Arrivals time: 0.28160232305526733 Scheduler time: 7.421991017181426 Scheduler overhead time: 0.06205736438278109 Adapter cache time: 0.014870830695144832 Engine time: 0.06375677813775837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 66, 66, 270, 66, 34560, 270, 66, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 34560, 34560, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 270, 270, 34560]
Prompts retrieved: 383790 . Total input tokens: 85669836 . Total output tokens: 75449695
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.734918197034858,
    "estimated_duration": 3600.050914220361,
    "input_throughput": 7783.145202008357,
    "output_throughput": 6814.865007350357,
    "total_throughput": 14598.010209358714,
    "itl": 77.49679660549707,
    "ttft": 571667.1113286099,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 127708,
    "finished_requests": 113487,
    "scheduler_time": 79.7253814218112
}
#Debug simulation 
Total elapsed time: 7.735098292003386. Arrivals time: 0.28827168396674097 Scheduler time: 7.26526591531001 Scheduler overhead time: 0.06632187787909061 Adapter cache time: 0.015489826793782413 Engine time: 0.06837567570619285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85595068 . Total output tokens: 75377246
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.908457322977483,
    "estimated_duration": 3600.073535618058,
    "input_throughput": 8033.962560443795,
    "output_throughput": 7052.826490568044,
    "total_throughput": 15086.78905101184,
    "itl": 85.21849775199303,
    "ttft": 412007.385254735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 127594,
    "finished_requests": 117300,
    "scheduler_time": 88.4498497549027
}
#Debug simulation 
Total elapsed time: 7.908578659989871. Arrivals time: 0.27801494125742465 Scheduler time: 7.465492400107905 Scheduler overhead time: 0.06058596563525498 Adapter cache time: 0.013717422378249466 Engine time: 0.06219036178663373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85595068 . Total output tokens: 75377246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.890127111924812,
    "estimated_duration": 3600.085291249672,
    "input_throughput": 7970.338944397534,
    "output_throughput": 6995.748701069693,
    "total_throughput": 14966.087645467227,
    "itl": 82.76516588443394,
    "ttft": 451087.8279175275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 127594,
    "finished_requests": 116338,
    "scheduler_time": 86.34437875062723
}
#Debug simulation 
Total elapsed time: 7.890218882937916. Arrivals time: 0.28217929508537054 Scheduler time: 7.437965615536086 Scheduler overhead time: 0.06233014049939811 Adapter cache time: 0.014127029455266893 Engine time: 0.0641851396067068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85595068 . Total output tokens: 75377246
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.776133156963624,
    "estimated_duration": 3600.0535923566654,
    "input_throughput": 7800.433043447275,
    "output_throughput": 6842.874242845267,
    "total_throughput": 14643.307286292542,
    "itl": 76.9962246738738,
    "ttft": 553380.3076852066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 127594,
    "finished_requests": 113790,
    "scheduler_time": 80.57007444401037
}
#Debug simulation 
Total elapsed time: 7.776227010996081. Arrivals time: 0.28726561286021024 Scheduler time: 7.308282057289034 Scheduler overhead time: 0.06611229665577412 Adapter cache time: 0.014988311915658414 Engine time: 0.06817968934774399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85595068 . Total output tokens: 75377246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.893050109967589,
    "estimated_duration": 3600.04621852643,
    "input_throughput": 7970.392116728138,
    "output_throughput": 6995.72851881571,
    "total_throughput": 14966.120635543848,
    "itl": 82.76490931465372,
    "ttft": 451086.9839646082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 127594,
    "finished_requests": 116337,
    "scheduler_time": 86.34312874118683
}
#Debug simulation 
Total elapsed time: 7.893175245029852. Arrivals time: 0.282733405707404 Scheduler time: 7.440073650912382 Scheduler overhead time: 0.06228526623453945 Adapter cache time: 0.01417957351077348 Engine time: 0.06431964365765452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85595068 . Total output tokens: 75377246
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.723693151958287,
    "estimated_duration": 3600.0715150941246,
    "input_throughput": 7800.283933877853,
    "output_throughput": 6842.709345276974,
    "total_throughput": 14642.993279154827,
    "itl": 76.99670725193243,
    "ttft": 553310.8363427154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 127594,
    "finished_requests": 113789,
    "scheduler_time": 80.5691185165527
}
#Debug simulation 
Total elapsed time: 7.723790196003392. Arrivals time: 0.2813287952449173 Scheduler time: 7.261873654206283 Scheduler overhead time: 0.06614589656237513 Adapter cache time: 0.014927740558050573 Engine time: 0.06832212407607585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85595068 . Total output tokens: 75377246
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.860915275057778,
    "estimated_duration": 3600.0737848449658,
    "input_throughput": 7970.476361010389,
    "output_throughput": 6995.806615414853,
    "total_throughput": 14966.282976425242,
    "itl": 82.76455033033466,
    "ttft": 451121.4056150486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 127594,
    "finished_requests": 116339,
    "scheduler_time": 86.34198127021084
}
#Debug simulation 
Total elapsed time: 7.861015506088734. Arrivals time: 0.28164398251101375 Scheduler time: 7.409251901321113 Scheduler overhead time: 0.06224615150131285 Adapter cache time: 0.014177820761688054 Engine time: 0.06434961489867419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 270, 33, 33, 270, 33, 34560, 270, 33, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 34560, 34560, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 270, 270, 34560]
Prompts retrieved: 383460 . Total input tokens: 85595068 . Total output tokens: 75377246
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.79122019209899,
    "estimated_duration": 3600.0664811794218,
    "input_throughput": 7800.325395879947,
    "output_throughput": 6842.725302097627,
    "total_throughput": 14643.050697977575,
    "itl": 76.9984456490634,
    "ttft": 553376.208715462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 127594,
    "finished_requests": 113790,
    "scheduler_time": 80.5690756542018
}
#Debug simulation 
Total elapsed time: 7.791374041000381. Arrivals time: 0.2825172533048317 Scheduler time: 7.327582965954207 Scheduler overhead time: 0.06622739648446441 Adapter cache time: 0.01504041242878884 Engine time: 0.06837975815869868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85336343 . Total output tokens: 75145456
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.01674839691259,
    "estimated_duration": 3600.0222752995605,
    "input_throughput": 8146.647091943226,
    "output_throughput": 7116.759853345102,
    "total_throughput": 15263.406945288327,
    "itl": 84.51188891887983,
    "ttft": 338292.34346157603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 127174,
    "finished_requests": 118790,
    "scheduler_time": 90.6181290875009
}
#Debug simulation 
Total elapsed time: 8.016858772956766. Arrivals time: 0.28166398871690035 Scheduler time: 7.567585068754852 Scheduler overhead time: 0.0616077627055347 Adapter cache time: 0.013432687730528414 Engine time: 0.06346637872047722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85336343 . Total output tokens: 75145456
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.958444133982994,
    "estimated_duration": 3600.0713381811565,
    "input_throughput": 8078.732688306657,
    "output_throughput": 7058.8598427160505,
    "total_throughput": 15137.592531022708,
    "itl": 82.1079792179167,
    "ttft": 378891.9285689388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 127174,
    "finished_requests": 117800,
    "scheduler_time": 88.51554444553621
}
#Debug simulation 
Total elapsed time: 7.958568219910376. Arrivals time: 0.27944381383713335 Scheduler time: 7.507248617126606 Scheduler overhead time: 0.06305023212917149 Adapter cache time: 0.013792998855933547 Engine time: 0.06516035529784858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85336343 . Total output tokens: 75145456
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.825125235016458,
    "estimated_duration": 3600.000452571623,
    "input_throughput": 7900.4373401350695,
    "output_throughput": 6904.84524307305,
    "total_throughput": 14805.28258320812,
    "itl": 76.44762666569295,
    "ttft": 484086.5721371706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 127174,
    "finished_requests": 115214,
    "scheduler_time": 82.77778145689278
}
#Debug simulation 
Total elapsed time: 7.825217214063741. Arrivals time: 0.2826836366439238 Scheduler time: 7.360247807228006 Scheduler overhead time: 0.0669967628782615 Adapter cache time: 0.01461780397221446 Engine time: 0.0690533306915313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85336343 . Total output tokens: 75145456
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.956753343925811,
    "estimated_duration": 3600.032382874649,
    "input_throughput": 8078.678996986308,
    "output_throughput": 7058.848448387647,
    "total_throughput": 15137.527445373955,
    "itl": 82.10553125286991,
    "ttft": 378890.68944522325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469847,
    "arrivals": 127174,
    "finished_requests": 117799,
    "scheduler_time": 88.51306357862406
}
#Debug simulation 
Total elapsed time: 7.956853426992893. Arrivals time: 0.277142244274728 Scheduler time: 7.507853029877879 Scheduler overhead time: 0.06310519448015839 Adapter cache time: 0.01381522580049932 Engine time: 0.06497714773286134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85336343 . Total output tokens: 75145456
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.835628173081204,
    "estimated_duration": 3600.041608816845,
    "input_throughput": 7900.464797502014,
    "output_throughput": 6904.814916339111,
    "total_throughput": 14805.279713841124,
    "itl": 76.44631485639714,
    "ttft": 484057.00192492694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 127174,
    "finished_requests": 115215,
    "scheduler_time": 82.78034777682083
}
#Debug simulation 
Total elapsed time: 7.8357569630024955. Arrivals time: 0.2894726078957319 Scheduler time: 7.364248825004324 Scheduler overhead time: 0.06692824885249138 Adapter cache time: 0.014404492918401957 Engine time: 0.06889360584318638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85336343 . Total output tokens: 75145456
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.960937823983841,
    "estimated_duration": 3600.0579858320575,
    "input_throughput": 8078.674042045486,
    "output_throughput": 7058.911300876333,
    "total_throughput": 15137.585342921819,
    "itl": 82.10664914134404,
    "ttft": 378868.1622309802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 127174,
    "finished_requests": 117800,
    "scheduler_time": 88.51391057378827
}
#Debug simulation 
Total elapsed time: 7.961042272974737. Arrivals time: 0.28636880533304065 Scheduler time: 7.501925605232827 Scheduler overhead time: 0.06299042119644582 Adapter cache time: 0.013838243787176907 Engine time: 0.06555984693113714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 66, 66, 135, 66, 34560, 135, 66, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 34560, 34560, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 135, 135, 34560]
Prompts retrieved: 382305 . Total input tokens: 85336343 . Total output tokens: 75145456
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.80702425504569,
    "estimated_duration": 3600.0195951619276,
    "input_throughput": 7900.611440622081,
    "output_throughput": 6904.974082198542,
    "total_throughput": 14805.585522820624,
    "itl": 76.44640581756587,
    "ttft": 484009.43353851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 127174,
    "finished_requests": 115217,
    "scheduler_time": 82.78020104623907
}
#Debug simulation 
Total elapsed time: 7.8071636609965935. Arrivals time: 0.2809758719522506 Scheduler time: 7.344457826344296 Scheduler overhead time: 0.06674657459370792 Adapter cache time: 0.014413918368518353 Engine time: 0.06898983393330127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85274519 . Total output tokens: 75076635
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.04596041305922,
    "estimated_duration": 3600.092717152837,
    "input_throughput": 8160.923150678042,
    "output_throughput": 7147.4225864799055,
    "total_throughput": 15308.345737157946,
    "itl": 84.10242389133738,
    "ttft": 321920.08055834257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 127046,
    "finished_requests": 119112,
    "scheduler_time": 91.24911728185232
}
#Debug simulation 
Total elapsed time: 8.046080362983048. Arrivals time: 0.283999924431555 Scheduler time: 7.594390613026917 Scheduler overhead time: 0.06176260800566524 Adapter cache time: 0.013039905577898026 Engine time: 0.06375922414008528 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85274519 . Total output tokens: 75076635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.9967953289160505,
    "estimated_duration": 3600.0623724500597,
    "input_throughput": 8091.3989776725975,
    "output_throughput": 7086.929714119536,
    "total_throughput": 15178.328691792134,
    "itl": 81.73049174408816,
    "ttft": 363199.8497179184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 127046,
    "finished_requests": 118104,
    "scheduler_time": 89.13111409069462
}
#Debug simulation 
Total elapsed time: 7.996896682889201. Arrivals time: 0.289046049118042 Scheduler time: 7.536115246475674 Scheduler overhead time: 0.06323635333683342 Adapter cache time: 0.013247113092802465 Engine time: 0.06537645636126399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85274519 . Total output tokens: 75076635
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.859277600073256,
    "estimated_duration": 3600.0290349916977,
    "input_throughput": 7906.23512292468,
    "output_throughput": 6933.1432489564795,
    "total_throughput": 14839.37837188116,
    "itl": 76.12184123234238,
    "ttft": 470567.7185213989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 127046,
    "finished_requests": 115453,
    "scheduler_time": 83.39032034340188
}
#Debug simulation 
Total elapsed time: 7.859408105025068. Arrivals time: 0.28318642848171294 Scheduler time: 7.394270993070677 Scheduler overhead time: 0.06694092263933271 Adapter cache time: 0.013855633442290127 Engine time: 0.06950268405489624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85274519 . Total output tokens: 75076635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.949135308968835,
    "estimated_duration": 3600.08237349843,
    "input_throughput": 8091.200972074841,
    "output_throughput": 7086.716178443334,
    "total_throughput": 15177.917150518175,
    "itl": 81.73126041127622,
    "ttft": 363219.96219879965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 127046,
    "finished_requests": 118103,
    "scheduler_time": 89.1318578204635
}
#Debug simulation 
Total elapsed time: 7.949267936986871. Arrivals time: 0.28317879675887525 Scheduler time: 7.494983559357934 Scheduler overhead time: 0.06312189146410674 Adapter cache time: 0.013153837178833783 Engine time: 0.06498189561534673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85274519 . Total output tokens: 75076635
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.848001388949342,
    "estimated_duration": 3600.0804409331017,
    "input_throughput": 7905.934177577143,
    "output_throughput": 6932.992306563798,
    "total_throughput": 14838.92648414094,
    "itl": 76.1229763116781,
    "ttft": 470618.15149676567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 127046,
    "finished_requests": 115452,
    "scheduler_time": 83.39121427519672
}
#Debug simulation 
Total elapsed time: 7.848120347014628. Arrivals time: 0.28462887764908373 Scheduler time: 7.3811612374847755 Scheduler overhead time: 0.0673205906059593 Adapter cache time: 0.013923458056524396 Engine time: 0.0693055815063417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85274519 . Total output tokens: 75076635
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.973640926997177,
    "estimated_duration": 3600.087634648981,
    "input_throughput": 8091.410531132873,
    "output_throughput": 7086.992481639317,
    "total_throughput": 15178.40301277219,
    "itl": 81.73301798188974,
    "ttft": 363146.7841014578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 127046,
    "finished_requests": 118106,
    "scheduler_time": 89.13213554815705
}
#Debug simulation 
Total elapsed time: 7.973768061958253. Arrivals time: 0.28087266732472926 Scheduler time: 7.521598210092634 Scheduler overhead time: 0.063057467690669 Adapter cache time: 0.013175244443118572 Engine time: 0.06516773637849838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 135, 33, 33, 135, 33, 34560, 135, 33, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 34560, 34560, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 135, 135, 34560]
Prompts retrieved: 381975 . Total input tokens: 85274519 . Total output tokens: 75076635
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.824164242018014,
    "estimated_duration": 3600.0708407184193,
    "input_throughput": 7905.988037257674,
    "output_throughput": 6933.054127073555,
    "total_throughput": 14839.04216433123,
    "itl": 76.12168588172317,
    "ttft": 470588.9971037387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 127046,
    "finished_requests": 115453,
    "scheduler_time": 83.39001838173374
}
#Debug simulation 
Total elapsed time: 7.824336540070362. Arrivals time: 0.2851246166974306 Scheduler time: 7.357949609751813 Scheduler overhead time: 0.0668568043038249 Adapter cache time: 0.013870632741600275 Engine time: 0.06885687925387174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 85092058 . Total output tokens: 74934019
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.112986798980273,
    "estimated_duration": 3600.0004743016193,
    "input_throughput": 8269.033354995581,
    "output_throughput": 7217.718215729045,
    "total_throughput": 15486.751570724626,
    "itl": 83.08849213157835,
    "ttft": 258175.42565182003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 126799,
    "finished_requests": 120297,
    "scheduler_time": 93.56953897342603
}
#Debug simulation 
Total elapsed time: 8.113078296068124. Arrivals time: 0.27527219359762967 Scheduler time: 7.669983963598497 Scheduler overhead time: 0.062108356156386435 Adapter cache time: 0.012416351586580276 Engine time: 0.06398938049096614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 85092058 . Total output tokens: 74934019
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.031895142048597,
    "estimated_duration": 3600.0009395837124,
    "input_throughput": 8195.436194361566,
    "output_throughput": 7153.835355103561,
    "total_throughput": 15349.271549465127,
    "itl": 80.7743899912446,
    "ttft": 302542.9209365705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 126799,
    "finished_requests": 119211,
    "scheduler_time": 91.4156522519775
}
#Debug simulation 
Total elapsed time: 8.03198929107748. Arrivals time: 0.2894873934565112 Scheduler time: 7.570721211261116 Scheduler overhead time: 0.06356489704921842 Adapter cache time: 0.012577397050336003 Engine time: 0.06558396166656166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 85092058 . Total output tokens: 74934019
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.898671966046095,
    "estimated_duration": 3600.0667219365505,
    "input_throughput": 8006.511886117207,
    "output_throughput": 6989.849339921067,
    "total_throughput": 14996.361226038274,
    "itl": 75.29733038201925,
    "ttft": 415101.50860297657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 126799,
    "finished_requests": 116471,
    "scheduler_time": 85.50922115751503
}
#Debug simulation 
Total elapsed time: 7.898762785014696. Arrivals time: 0.28465589857660234 Scheduler time: 7.431144200032577 Scheduler overhead time: 0.06773453019559383 Adapter cache time: 0.013165221316739917 Engine time: 0.07002121943514794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 85092058 . Total output tokens: 74934019
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.063444250961766,
    "estimated_duration": 3600.0761868885784,
    "input_throughput": 8195.529057816897,
    "output_throughput": 7153.983044525248,
    "total_throughput": 15349.512102342147,
    "itl": 80.77343708428569,
    "ttft": 302468.24911794055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 126799,
    "finished_requests": 119216,
    "scheduler_time": 91.41929272620334
}
#Debug simulation 
Total elapsed time: 8.063548762002029. Arrivals time: 0.2833044425351545 Scheduler time: 7.6076336179394275 Scheduler overhead time: 0.06387461780104786 Adapter cache time: 0.012676055659539998 Engine time: 0.06580738816410303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 85092058 . Total output tokens: 74934019
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.956115646054968,
    "estimated_duration": 3600.0185178174384,
    "input_throughput": 8006.57353770359,
    "output_throughput": 6989.917656105816,
    "total_throughput": 14996.491193809405,
    "itl": 75.29825674404907,
    "ttft": 415017.56591410364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 126799,
    "finished_requests": 116471,
    "scheduler_time": 85.51038623612858
}
#Debug simulation 
Total elapsed time: 7.956236054073088. Arrivals time: 0.2793312855064869 Scheduler time: 7.493999215075746 Scheduler overhead time: 0.06762290571350604 Adapter cache time: 0.013204676215536892 Engine time: 0.06982017692644149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 85092058 . Total output tokens: 74934019
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.057348120957613,
    "estimated_duration": 3600.0532531630397,
    "input_throughput": 8195.687376034428,
    "output_throughput": 7154.016118337017,
    "total_throughput": 15349.703494371446,
    "itl": 80.77155895295893,
    "ttft": 302395.05160615995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 126799,
    "finished_requests": 119215,
    "scheduler_time": 91.41716765925456
}
#Debug simulation 
Total elapsed time: 8.057448186911643. Arrivals time: 0.2809743309626356 Scheduler time: 7.604628205415793 Scheduler overhead time: 0.06367909151595086 Adapter cache time: 0.012586308876052499 Engine time: 0.06548873707652092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 66, 33, 33, 66, 33, 34560, 66, 33, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 34560, 34560, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 66, 66, 34560]
Prompts retrieved: 381216 . Total input tokens: 85092058 . Total output tokens: 74934019
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.926558954990469,
    "estimated_duration": 3600.0793031941453,
    "input_throughput": 8006.484183397329,
    "output_throughput": 6989.896577465184,
    "total_throughput": 14996.380760862512,
    "itl": 75.29960977202036,
    "ttft": 415049.3866574093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 126799,
    "finished_requests": 116472,
    "scheduler_time": 85.51394231076388
}
#Debug simulation 
Total elapsed time: 7.926734482054599. Arrivals time: 0.28388166439253837 Scheduler time: 7.45831778133288 Scheduler overhead time: 0.0682664995547384 Adapter cache time: 0.013369865948334336 Engine time: 0.07059780089184642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73276919 . Total output tokens: 64428052
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.010830838000402,
    "estimated_duration": 3600.019677575749,
    "input_throughput": 7158.206706623695,
    "output_throughput": 6213.721869171454,
    "total_throughput": 13371.92857579515,
    "itl": 96.57829212319557,
    "ttft": 249139.43979688553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 109373,
    "finished_requests": 103951,
    "scheduler_time": 81.30188711652596
}
#Debug simulation 
Total elapsed time: 7.010962539003231. Arrivals time: 0.24719745048787445 Scheduler time: 6.619136705528945 Scheduler overhead time: 0.05421573738567531 Adapter cache time: 0.009049304877407849 Engine time: 0.05575811141170561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73276919 . Total output tokens: 64428052
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.99106013099663,
    "estimated_duration": 3600.0655905467493,
    "input_throughput": 7090.249985174134,
    "output_throughput": 6156.716160450238,
    "total_throughput": 13246.966145624372,
    "itl": 93.91023039881033,
    "ttft": 296700.5101860257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 109373,
    "finished_requests": 102961,
    "scheduler_time": 79.4548110134129
}
#Debug simulation 
Total elapsed time: 6.991157545009628. Arrivals time: 0.24823272600769997 Scheduler time: 6.5939238662831485 Scheduler overhead time: 0.0559054312761873 Adapter cache time: 0.009322054916992784 Engine time: 0.0572969273198396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73276919 . Total output tokens: 64428052
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.857416145969182,
    "estimated_duration": 3600.067621037592,
    "input_throughput": 6914.670672998468,
    "output_throughput": 6004.863318031066,
    "total_throughput": 12919.533991029535,
    "itl": 87.58940746127841,
    "ttft": 419238.9714921016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137886,
    "arrivals": 109373,
    "finished_requests": 100376,
    "scheduler_time": 74.43636103542471
}
#Debug simulation 
Total elapsed time: 6.857511257985607. Arrivals time: 0.24923197156749666 Scheduler time: 6.450994540704414 Scheduler overhead time: 0.05891955946572125 Adapter cache time: 0.009903922909870744 Engine time: 0.060617316979914904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73276919 . Total output tokens: 64428052
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 6.977060285978951,
    "estimated_duration": 3600.0146659210254,
    "input_throughput": 7090.205004337043,
    "output_throughput": 6156.640751998041,
    "total_throughput": 13246.845756335084,
    "itl": 93.91029330950093,
    "ttft": 296738.73488905985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 109373,
    "finished_requests": 102959,
    "scheduler_time": 79.4535988645799
}
#Debug simulation 
Total elapsed time: 6.977153058047406. Arrivals time: 0.2442668708972633 Scheduler time: 6.585566918365657 Scheduler overhead time: 0.05526073114015162 Adapter cache time: 0.009207698749378324 Engine time: 0.05682720220647752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73276919 . Total output tokens: 64428052
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 6.877474253997207,
    "estimated_duration": 3600.0831975512774,
    "input_throughput": 6914.706587040044,
    "output_throughput": 6004.854280785573,
    "total_throughput": 12919.560867825616,
    "itl": 87.59013979402982,
    "ttft": 419220.7053627126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861715,
    "arrivals": 109373,
    "finished_requests": 100377,
    "scheduler_time": 74.43765376459154
}
#Debug simulation 
Total elapsed time: 6.877605573972687. Arrivals time: 0.25601342518348247 Scheduler time: 6.463417660212144 Scheduler overhead time: 0.05902718682773411 Adapter cache time: 0.009905103594064713 Engine time: 0.0611201353603974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73276919 . Total output tokens: 64428052
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.986417977022938,
    "estimated_duration": 3600.0684936435687,
    "input_throughput": 7090.139269591115,
    "output_throughput": 6156.56786506529,
    "total_throughput": 13246.707134656406,
    "itl": 93.90782846969195,
    "ttft": 296796.45253385574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 109373,
    "finished_requests": 102959,
    "scheduler_time": 79.45251601136177
}
#Debug simulation 
Total elapsed time: 6.98651874193456. Arrivals time: 0.24828853749204427 Scheduler time: 6.5896082611288875 Scheduler overhead time: 0.05579774978104979 Adapter cache time: 0.009337459690868855 Engine time: 0.05710755626205355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 328320 . Total input tokens: 73276919 . Total output tokens: 64428052
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.8442150939954445,
    "estimated_duration": 3600.057072401293,
    "input_throughput": 6914.278440423943,
    "output_throughput": 6004.58147336571,
    "total_throughput": 12918.859913789653,
    "itl": 87.58957241837734,
    "ttft": 419264.379062636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585543,
    "arrivals": 109373,
    "finished_requests": 100373,
    "scheduler_time": 74.43526832223414
}
#Debug simulation 
Total elapsed time: 6.844373578089289. Arrivals time: 0.25058343447744846 Scheduler time: 6.436111793387681 Scheduler overhead time: 0.059344214387238026 Adapter cache time: 0.00985635700635612 Engine time: 0.06053650821559131 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66096526 . Total output tokens: 58014848
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.517163643962704,
    "estimated_duration": 3600.0213271926286,
    "input_throughput": 6763.832151791331,
    "output_throughput": 5857.853074566414,
    "total_throughput": 12621.685226357744,
    "itl": 80.1859353408213,
    "ttft": 15282.156763196697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 98647,
    "finished_requests": 98229,
    "scheduler_time": 77.52782017464449
}
#Debug simulation 
Total elapsed time: 6.5172579060308635. Arrivals time: 0.21964531287085265 Scheduler time: 6.1364929005503654 Scheduler overhead time: 0.05982255842536688 Adapter cache time: 0.012619683635421097 Engine time: 0.06082138838246465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66096526 . Total output tokens: 58014848
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.548721477971412,
    "estimated_duration": 3600.0391762985955,
    "input_throughput": 6763.7986165016,
    "output_throughput": 5857.824031149065,
    "total_throughput": 12621.622647650665,
    "itl": 80.18665471545656,
    "ttft": 15318.55368958682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 98647,
    "finished_requests": 98229,
    "scheduler_time": 77.5284170852879
}
#Debug simulation 
Total elapsed time: 6.548851878964342. Arrivals time: 0.21872521133627743 Scheduler time: 6.168456077226438 Scheduler overhead time: 0.05985339020844549 Adapter cache time: 0.012845278019085526 Engine time: 0.06087763630785048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66096526 . Total output tokens: 58014848
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.560014714021236,
    "estimated_duration": 3600.0491562324246,
    "input_throughput": 6762.954599619951,
    "output_throughput": 5856.713640561956,
    "total_throughput": 12619.668240181907,
    "itl": 80.39595243875542,
    "ttft": 15809.46257267637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 98647,
    "finished_requests": 98218,
    "scheduler_time": 77.55625131694404
}
#Debug simulation 
Total elapsed time: 6.560136643005535. Arrivals time: 0.2177003634860739 Scheduler time: 6.178897555335425 Scheduler overhead time: 0.06081684527453035 Adapter cache time: 0.012639478431083262 Engine time: 0.06179759046062827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66096526 . Total output tokens: 58014848
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 6.5817671429831535,
    "estimated_duration": 3600.0523284990118,
    "input_throughput": 6763.773906073289,
    "output_throughput": 5857.802630550233,
    "total_throughput": 12621.576536623521,
    "itl": 80.18633227801723,
    "ttft": 15318.32820320135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 98647,
    "finished_requests": 98229,
    "scheduler_time": 77.52846914960637
}
#Debug simulation 
Total elapsed time: 6.581853047944605. Arrivals time: 0.21530139446258545 Scheduler time: 6.202169565134682 Scheduler overhead time: 0.061690147151239216 Adapter cache time: 0.012837415211834013 Engine time: 0.06149410118814558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66096526 . Total output tokens: 58014848
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 6.553480903035961,
    "estimated_duration": 3600.0492317056946,
    "input_throughput": 6762.954457837918,
    "output_throughput": 5856.7135177788205,
    "total_throughput": 12619.66797561674,
    "itl": 80.39606878959653,
    "ttft": 15809.624907796477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 98647,
    "finished_requests": 98218,
    "scheduler_time": 77.55647957640731
}
#Debug simulation 
Total elapsed time: 6.553573457058519. Arrivals time: 0.2174232016550377 Scheduler time: 6.173436273238622 Scheduler overhead time: 0.06039330910425633 Adapter cache time: 0.01263661403208971 Engine time: 0.06140524661168456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66096526 . Total output tokens: 58014848
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.558431557030417,
    "estimated_duration": 3600.0509089592715,
    "input_throughput": 6763.776573103866,
    "output_throughput": 5857.804940346353,
    "total_throughput": 12621.581513450219,
    "itl": 80.18558772519877,
    "ttft": 15318.338370722999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 98647,
    "finished_requests": 98229,
    "scheduler_time": 77.5282026429995
}
#Debug simulation 
Total elapsed time: 6.558527468936518. Arrivals time: 0.21633626148104668 Scheduler time: 6.179698725230992 Scheduler overhead time: 0.06036432017572224 Adapter cache time: 0.012812523869797587 Engine time: 0.061154112103395164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66096526 . Total output tokens: 58014848
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.5945017950143665,
    "estimated_duration": 3600.0274374935584,
    "input_throughput": 6762.995400099243,
    "output_throughput": 5856.7489737466,
    "total_throughput": 12619.744373845842,
    "itl": 80.39552393970787,
    "ttft": 15773.06201005099,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 98647,
    "finished_requests": 98218,
    "scheduler_time": 77.55594251253757
}
#Debug simulation 
Total elapsed time: 6.594671498984098. Arrivals time: 0.22319260041695088 Scheduler time: 6.208135542343371 Scheduler overhead time: 0.06066482712049037 Adapter cache time: 0.012633823906071484 Engine time: 0.061625906731933355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64870906 . Total output tokens: 56951984
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.480025282944553,
    "estimated_duration": 3600.005389106596,
    "input_throughput": 6641.398113554895,
    "output_throughput": 5765.066647622584,
    "total_throughput": 12406.464761177478,
    "itl": 72.47500011693833,
    "ttft": 17208.609791410603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 96919,
    "finished_requests": 96457,
    "scheduler_time": 75.37095771176281
}
#Debug simulation 
Total elapsed time: 6.480117960018106. Arrivals time: 0.21879763319157064 Scheduler time: 6.08391565119382 Scheduler overhead time: 0.06552241172175854 Adapter cache time: 0.014614661107771099 Engine time: 0.06670360476709902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64870906 . Total output tokens: 56951984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.487247912911698,
    "estimated_duration": 3600.005412323962,
    "input_throughput": 6641.3980707228,
    "output_throughput": 5765.066610442178,
    "total_throughput": 12406.464681164978,
    "itl": 72.47531836635982,
    "ttft": 17208.63964922176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 96919,
    "finished_requests": 96457,
    "scheduler_time": 75.37108639358394
}
#Debug simulation 
Total elapsed time: 6.487340332940221. Arrivals time: 0.21481037058401853 Scheduler time: 6.095598028157838 Scheduler overhead time: 0.0652820784598589 Adapter cache time: 0.01457904267590493 Engine time: 0.06660922279115766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64870906 . Total output tokens: 56951984
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.4842513729818165,
    "estimated_duration": 3600.0054141161827,
    "input_throughput": 6641.398067416458,
    "output_throughput": 5765.066607572107,
    "total_throughput": 12406.464674988565,
    "itl": 72.47484819698222,
    "ttft": 17208.615080631174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 96919,
    "finished_requests": 96457,
    "scheduler_time": 75.37096141428391
}
#Debug simulation 
Total elapsed time: 6.484356509055942. Arrivals time: 0.21754629618953913 Scheduler time: 6.090129384887405 Scheduler overhead time: 0.0652827526209876 Adapter cache time: 0.01458979572635144 Engine time: 0.06626179860904813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64870906 . Total output tokens: 56951984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 6.472915599006228,
    "estimated_duration": 3600.0054429543816,
    "input_throughput": 6641.398014214883,
    "output_throughput": 5765.066561390472,
    "total_throughput": 12406.464575605354,
    "itl": 72.47445530738548,
    "ttft": 17208.679656426462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 96919,
    "finished_requests": 96457,
    "scheduler_time": 75.37082599501908
}
#Debug simulation 
Total elapsed time: 6.473016464035027. Arrivals time: 0.21610876044724137 Scheduler time: 6.079800338018686 Scheduler overhead time: 0.06520269229076803 Adapter cache time: 0.014649456483311951 Engine time: 0.06663029151968658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64870906 . Total output tokens: 56951984
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 6.487150305998512,
    "estimated_duration": 3600.0053933905597,
    "input_throughput": 6641.39810565171,
    "output_throughput": 5765.066640762223,
    "total_throughput": 12406.464746413933,
    "itl": 72.47509406399392,
    "ttft": 17208.686702926552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 96919,
    "finished_requests": 96457,
    "scheduler_time": 75.37094952570925
}
#Debug simulation 
Total elapsed time: 6.487243681913242. Arrivals time: 0.21667416382115334 Scheduler time: 6.09221834409982 Scheduler overhead time: 0.06547332496847957 Adapter cache time: 0.014632869395427406 Engine time: 0.06769587774761021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64870906 . Total output tokens: 56951984
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.498551830998622,
    "estimated_duration": 3600.006594400239,
    "input_throughput": 6641.39588999371,
    "output_throughput": 5765.064717459958,
    "total_throughput": 12406.460607453668,
    "itl": 72.47371236320502,
    "ttft": 17208.64172079821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 96919,
    "finished_requests": 96457,
    "scheduler_time": 75.370703462505
}
#Debug simulation 
Total elapsed time: 6.498644966050051. Arrivals time: 0.21680655039381236 Scheduler time: 6.104304737993516 Scheduler overhead time: 0.06553466210607439 Adapter cache time: 0.01457736804150045 Engine time: 0.06683135777711868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64870906 . Total output tokens: 56951984
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.46426258108113,
    "estimated_duration": 3600.0054277610034,
    "input_throughput": 6641.398042244083,
    "output_throughput": 5765.066585721223,
    "total_throughput": 12406.464627965306,
    "itl": 72.47509794662473,
    "ttft": 17208.63401197031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 96919,
    "finished_requests": 96457,
    "scheduler_time": 75.37105403511967
}
#Debug simulation 
Total elapsed time: 6.464420916046947. Arrivals time: 0.21603546373080462 Scheduler time: 6.072139892377891 Scheduler overhead time: 0.06520844565238804 Adapter cache time: 0.014534827903844416 Engine time: 0.06598550267517567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64282371 . Total output tokens: 56405100
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.441382733057253,
    "estimated_duration": 3600.039363261712,
    "input_throughput": 6558.523565311238,
    "output_throughput": 5751.949329031447,
    "total_throughput": 12310.472894342684,
    "itl": 68.29751421229177,
    "ttft": 15069.120080528963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 96050,
    "finished_requests": 95650,
    "scheduler_time": 74.6075180917132
}
#Debug simulation 
Total elapsed time: 6.441518287057988. Arrivals time: 0.21507911873050034 Scheduler time: 6.0411844530608505 Scheduler overhead time: 0.06896221044007689 Adapter cache time: 0.014171337010338902 Engine time: 0.06997375388164073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64282371 . Total output tokens: 56405100
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.4930878499289975,
    "estimated_duration": 3600.039362577341,
    "input_throughput": 6558.523566558019,
    "output_throughput": 5751.949330124898,
    "total_throughput": 12310.472896682917,
    "itl": 68.29779154701266,
    "ttft": 15069.131064798781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 96050,
    "finished_requests": 95650,
    "scheduler_time": 74.60761912996439
}
#Debug simulation 
Total elapsed time: 6.49321076401975. Arrivals time: 0.21464449993800372 Scheduler time: 6.091808816185221 Scheduler overhead time: 0.0694791388232261 Adapter cache time: 0.014362199348397553 Engine time: 0.07046672108117491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64282371 . Total output tokens: 56405100
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.485167692997493,
    "estimated_duration": 3600.03846511021,
    "input_throughput": 6558.5252015570295,
    "output_throughput": 5751.950764049983,
    "total_throughput": 12310.475965607013,
    "itl": 68.29734085501745,
    "ttft": 15068.996365684368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 96050,
    "finished_requests": 95650,
    "scheduler_time": 74.60743879357427
}
#Debug simulation 
Total elapsed time: 6.485257456079125. Arrivals time: 0.21406233275774866 Scheduler time: 6.085206489544362 Scheduler overhead time: 0.06931917904876173 Adapter cache time: 0.014330909354612231 Engine time: 0.0701325791887939 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64282371 . Total output tokens: 56405100
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 6.700264315935783,
    "estimated_duration": 3600.0393705004826,
    "input_throughput": 6558.523552123702,
    "output_throughput": 5751.949317465728,
    "total_throughput": 12310.47286958943,
    "itl": 68.29692105651901,
    "ttft": 15068.988012748801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 96050,
    "finished_requests": 95650,
    "scheduler_time": 74.60727411822982
}
#Debug simulation 
Total elapsed time: 6.700356711982749. Arrivals time: 0.2161407998064533 Scheduler time: 6.298294560867362 Scheduler overhead time: 0.06903412914834917 Adapter cache time: 0.014260209631174803 Engine time: 0.07031706895213574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64282371 . Total output tokens: 56405100
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 6.475414631073363,
    "estimated_duration": 3600.039550902342,
    "input_throughput": 6558.523223469023,
    "output_throughput": 5751.949029229352,
    "total_throughput": 12310.472252698375,
    "itl": 68.297499329371,
    "ttft": 15069.092268044542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861723,
    "arrivals": 96050,
    "finished_requests": 95650,
    "scheduler_time": 74.60755527350894
}
#Debug simulation 
Total elapsed time: 6.475506142014638. Arrivals time: 0.21895420679356903 Scheduler time: 6.070340287988074 Scheduler overhead time: 0.06905800383538008 Adapter cache time: 0.01425020769238472 Engine time: 0.07070560660213232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64282371 . Total output tokens: 56405100
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.490559134050272,
    "estimated_duration": 3600.0395862447463,
    "input_throughput": 6558.523159082514,
    "output_throughput": 5751.948972761165,
    "total_throughput": 12310.47213184368,
    "itl": 68.29771477586877,
    "ttft": 15069.180455563286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 96050,
    "finished_requests": 95650,
    "scheduler_time": 74.60773985958248
}
#Debug simulation 
Total elapsed time: 6.490678156958893. Arrivals time: 0.2149655323009938 Scheduler time: 6.089715364971198 Scheduler overhead time: 0.06917241145856678 Adapter cache time: 0.014364272472448647 Engine time: 0.07011643226724118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64282371 . Total output tokens: 56405100
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.632856910000555,
    "estimated_duration": 3600.039368808677,
    "input_throughput": 6558.52355520582,
    "output_throughput": 5751.949320168804,
    "total_throughput": 12310.472875374624,
    "itl": 68.29761050092141,
    "ttft": 15069.117589778036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2367897061258555,
    "arrivals": 96050,
    "finished_requests": 95650,
    "scheduler_time": 74.60761569978013
}
#Debug simulation 
Total elapsed time: 6.633018213091418. Arrivals time: 0.2166475160047412 Scheduler time: 6.231137753231451 Scheduler overhead time: 0.06911101378500462 Adapter cache time: 0.014174273470416665 Engine time: 0.06965784216299653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63989941 . Total output tokens: 56147875
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.48083706095349,
    "estimated_duration": 3600.0701448603704,
    "input_throughput": 6517.349122626613,
    "output_throughput": 5752.062089557746,
    "total_throughput": 12269.41121218436,
    "itl": 66.21656308199599,
    "ttft": 16790.406132768298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 95612,
    "finished_requests": 95169,
    "scheduler_time": 74.31911839180961
}
#Debug simulation 
Total elapsed time: 6.480929648038. Arrivals time: 0.21772072813473642 Scheduler time: 6.072643770836294 Scheduler overhead time: 0.0711215257178992 Adapter cache time: 0.013676130678504705 Engine time: 0.07279445545282215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63989941 . Total output tokens: 56147875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.518167512025684,
    "estimated_duration": 3600.0701525318864,
    "input_throughput": 6517.3491087385655,
    "output_throughput": 5752.062077300475,
    "total_throughput": 12269.41118603904,
    "itl": 66.21679395139797,
    "ttft": 16790.41926141294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 95612,
    "finished_requests": 95169,
    "scheduler_time": 74.31931164114751
}
#Debug simulation 
Total elapsed time: 6.518260897952132. Arrivals time: 0.2208849914604798 Scheduler time: 6.106462268857285 Scheduler overhead time: 0.0712234772508964 Adapter cache time: 0.013778102700598538 Engine time: 0.07260857545770705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63989941 . Total output tokens: 56147875
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.510853172047064,
    "estimated_duration": 3600.018315712752,
    "input_throughput": 6517.442952329724,
    "output_throughput": 5752.144901490632,
    "total_throughput": 12269.587853820356,
    "itl": 66.21681542414669,
    "ttft": 16752.961264698315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 95612,
    "finished_requests": 95169,
    "scheduler_time": 74.31818337106574
}
#Debug simulation 
Total elapsed time: 6.510958781000227. Arrivals time: 0.21833751176018268 Scheduler time: 6.1042253454215825 Scheduler overhead time: 0.07045060209929943 Adapter cache time: 0.013518586405552924 Engine time: 0.07137677655555308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63989941 . Total output tokens: 56147875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 6.472215190995485,
    "estimated_duration": 3600.0160271328104,
    "input_throughput": 6517.447095558282,
    "output_throughput": 5752.1485582086425,
    "total_throughput": 12269.595653766924,
    "itl": 66.21637658773993,
    "ttft": 16752.95180133819,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 95612,
    "finished_requests": 95169,
    "scheduler_time": 74.31794131169477
}
#Debug simulation 
Total elapsed time: 6.472337107989006. Arrivals time: 0.21547836705576628 Scheduler time: 6.068324867635965 Scheduler overhead time: 0.07049245201051235 Adapter cache time: 0.013509633135981858 Engine time: 0.07172734348569065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63989941 . Total output tokens: 56147875
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 6.471159955020994,
    "estimated_duration": 3600.0708269865736,
    "input_throughput": 6517.34788774685,
    "output_throughput": 5752.060999681335,
    "total_throughput": 12269.408887428184,
    "itl": 66.21672712892187,
    "ttft": 16790.41096606211,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 95612,
    "finished_requests": 95169,
    "scheduler_time": 74.31917992440378
}
#Debug simulation 
Total elapsed time: 6.471245844033547. Arrivals time: 0.2150098066776991 Scheduler time: 6.066848833928816 Scheduler overhead time: 0.07072966080158949 Adapter cache time: 0.013649165979586542 Engine time: 0.07208589615765959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63989941 . Total output tokens: 56147875
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.498704545083456,
    "estimated_duration": 3600.0614886989174,
    "input_throughput": 6517.364793255137,
    "output_throughput": 5752.075920093222,
    "total_throughput": 12269.440713348358,
    "itl": 66.21648993508768,
    "ttft": 16790.232075589316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 95612,
    "finished_requests": 95169,
    "scheduler_time": 74.31904162240633
}
#Debug simulation 
Total elapsed time: 6.4987964070169255. Arrivals time: 0.2159991676453501 Scheduler time: 6.093546955147758 Scheduler overhead time: 0.07083656184840947 Adapter cache time: 0.013521803775802255 Engine time: 0.07191260601393878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63989941 . Total output tokens: 56147875
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.503911140025593,
    "estimated_duration": 3600.070823292914,
    "input_throughput": 6517.347894433625,
    "output_throughput": 5752.061005582928,
    "total_throughput": 12269.408900016553,
    "itl": 66.21678551236455,
    "ttft": 16790.4083472071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 95612,
    "finished_requests": 95169,
    "scheduler_time": 74.3192648243977
}
#Debug simulation 
Total elapsed time: 6.504053718061186. Arrivals time: 0.21528334426693618 Scheduler time: 6.099125673994422 Scheduler overhead time: 0.07113060064148158 Adapter cache time: 0.013704616925679147 Engine time: 0.07180251961108297 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63828119 . Total output tokens: 56011401
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.438322486006655,
    "estimated_duration": 3600.0077965536043,
    "input_throughput": 6496.383986276116,
    "output_throughput": 5709.56235696973,
    "total_throughput": 12205.946343245845,
    "itl": 64.08643851267826,
    "ttft": 15657.931613540792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 95376,
    "finished_requests": 94964,
    "scheduler_time": 73.3555011039319
}
#Debug simulation 
Total elapsed time: 6.43841332802549. Arrivals time: 0.21527918544597924 Scheduler time: 6.029780994052999 Scheduler overhead time: 0.07232117501553148 Adapter cache time: 0.01322029996663332 Engine time: 0.07401239138562232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63828119 . Total output tokens: 56011401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.413502618088387,
    "estimated_duration": 3600.0078165933874,
    "input_throughput": 6496.383950113382,
    "output_throughput": 5709.562325186912,
    "total_throughput": 12205.946275300294,
    "itl": 64.0865540803877,
    "ttft": 15657.942360153826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 95376,
    "finished_requests": 94964,
    "scheduler_time": 73.35556193995222
}
#Debug simulation 
Total elapsed time: 6.413591709104367. Arrivals time: 0.21385001635644585 Scheduler time: 6.0071854430716485 Scheduler overhead time: 0.07243610208388418 Adapter cache time: 0.013147997437044978 Engine time: 0.07343132595997304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63828119 . Total output tokens: 56011401
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.401271017966792,
    "estimated_duration": 3600.0215576723817,
    "input_throughput": 6496.3591537826915,
    "output_throughput": 5709.540532109933,
    "total_throughput": 12205.899685892624,
    "itl": 64.08670122596153,
    "ttft": 15657.907454280614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 95376,
    "finished_requests": 94964,
    "scheduler_time": 73.35577668355234
}
#Debug simulation 
Total elapsed time: 6.40136329899542. Arrivals time: 0.2138868656475097 Scheduler time: 5.995326105854474 Scheduler overhead time: 0.07200450799427927 Adapter cache time: 0.01303334184922278 Engine time: 0.07322778331581503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63828119 . Total output tokens: 56011401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 6.43440476001706,
    "estimated_duration": 3600.0215614090725,
    "input_throughput": 6496.359147039708,
    "output_throughput": 5709.540526183639,
    "total_throughput": 12205.899673223346,
    "itl": 64.08635465013208,
    "ttft": 15657.888813178657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 95376,
    "finished_requests": 94964,
    "scheduler_time": 73.35559521435204
}
#Debug simulation 
Total elapsed time: 6.434496706002392. Arrivals time: 0.21802155883051455 Scheduler time: 6.0233038938604295 Scheduler overhead time: 0.07251955673564225 Adapter cache time: 0.013244293280877173 Engine time: 0.07341292675118893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63828119 . Total output tokens: 56011401
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 6.416732064099051,
    "estimated_duration": 3600.0184704735116,
    "input_throughput": 6496.364724740953,
    "output_throughput": 5709.545428331223,
    "total_throughput": 12205.910153072176,
    "itl": 64.08664045523012,
    "ttft": 15657.978366725649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 95376,
    "finished_requests": 94964,
    "scheduler_time": 73.35577754402557
}
#Debug simulation 
Total elapsed time: 6.416826331987977. Arrivals time: 0.2149059564108029 Scheduler time: 6.007489809417166 Scheduler overhead time: 0.07298398879356682 Adapter cache time: 0.013221807312220335 Engine time: 0.07414785050787032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63828119 . Total output tokens: 56011401
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.420290186069906,
    "estimated_duration": 3600.041582871432,
    "input_throughput": 6496.323017843102,
    "output_throughput": 5709.5087728418775,
    "total_throughput": 12205.831790684979,
    "itl": 64.08596885408416,
    "ttft": 15657.809363184984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 95376,
    "finished_requests": 94964,
    "scheduler_time": 73.35594780922567
}
#Debug simulation 
Total elapsed time: 6.4204093960579485. Arrivals time: 0.2164998819353059 Scheduler time: 6.011037160642445 Scheduler overhead time: 0.07227958843577653 Adapter cache time: 0.01304089732002467 Engine time: 0.0737945995060727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63828119 . Total output tokens: 56011401
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.433024761965498,
    "estimated_duration": 3600.0187427437363,
    "input_throughput": 6496.364233419432,
    "output_throughput": 5709.544996517022,
    "total_throughput": 12205.909229936455,
    "itl": 64.08671632645476,
    "ttft": 15657.981652120918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 95376,
    "finished_requests": 94964,
    "scheduler_time": 73.35587020583601
}
#Debug simulation 
Total elapsed time: 6.433201418025419. Arrivals time: 0.21574865968432277 Scheduler time: 6.02390021388419 Scheduler overhead time: 0.07255311694461852 Adapter cache time: 0.013256248901598155 Engine time: 0.073849459993653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63748350 . Total output tokens: 55952342
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.3852801859611645,
    "estimated_duration": 3600.060248788054,
    "input_throughput": 6553.794483840331,
    "output_throughput": 5660.363602764719,
    "total_throughput": 12214.15808660505,
    "itl": 62.37451895468837,
    "ttft": 13594.582056015981,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 95267,
    "finished_requests": 94910,
    "scheduler_time": 72.31956126377777
}
#Debug simulation 
Total elapsed time: 6.385400305967778. Arrivals time: 0.21375320048537105 Scheduler time: 5.976028243312612 Scheduler overhead time: 0.07382209750358015 Adapter cache time: 0.012678788276389241 Engine time: 0.07461550086736679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63748350 . Total output tokens: 55952342
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.371826761984266,
    "estimated_duration": 3600.06135777639,
    "input_throughput": 6553.859963812735,
    "output_throughput": 5660.36241465241,
    "total_throughput": 12214.222378465145,
    "itl": 62.37442942454274,
    "ttft": 13556.80168498506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 95267,
    "finished_requests": 94911,
    "scheduler_time": 72.31966217910391
}
#Debug simulation 
Total elapsed time: 6.37192868697457. Arrivals time: 0.2142684719292447 Scheduler time: 5.962370531866327 Scheduler overhead time: 0.0734665528871119 Adapter cache time: 0.012685432797297835 Engine time: 0.07478662650100887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63748350 . Total output tokens: 55952342
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.38814928708598,
    "estimated_duration": 3600.013158287823,
    "input_throughput": 6553.879933933742,
    "output_throughput": 5660.350977631294,
    "total_throughput": 12214.230911565035,
    "itl": 62.37479686826494,
    "ttft": 13594.657526022274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 95267,
    "finished_requests": 94909,
    "scheduler_time": 72.31873888303524
}
#Debug simulation 
Total elapsed time: 6.388272890006192. Arrivals time: 0.2138215326704085 Scheduler time: 5.978378327097744 Scheduler overhead time: 0.07378868910018355 Adapter cache time: 0.012780669960193336 Engine time: 0.07512386690359563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63748350 . Total output tokens: 55952342
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 6.368299194029532,
    "estimated_duration": 3600.019862032244,
    "input_throughput": 6553.8677296855085,
    "output_throughput": 5660.340437259923,
    "total_throughput": 12214.208166945431,
    "itl": 62.374589293772274,
    "ttft": 13594.668880630212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 95267,
    "finished_requests": 94909,
    "scheduler_time": 72.3188399212862
}
#Debug simulation 
Total elapsed time: 6.368426830973476. Arrivals time: 0.21259393368382007 Scheduler time: 5.960025668260641 Scheduler overhead time: 0.07384880085010082 Adapter cache time: 0.01268398982938379 Engine time: 0.07482252537738532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63748350 . Total output tokens: 55952342
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 6.384062733966857,
    "estimated_duration": 3600.063111121458,
    "input_throughput": 6553.856771874793,
    "output_throughput": 5660.359657876149,
    "total_throughput": 12214.21642975094,
    "itl": 62.374152859016206,
    "ttft": 13556.734266342433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861723,
    "arrivals": 95267,
    "finished_requests": 94911,
    "scheduler_time": 72.31954103973692
}
#Debug simulation 
Total elapsed time: 6.384203855064698. Arrivals time: 0.21588870859704912 Scheduler time: 5.9725635522045195 Scheduler overhead time: 0.0737793993903324 Adapter cache time: 0.012728740577585995 Engine time: 0.07466674852184951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63748350 . Total output tokens: 55952342
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 6.389237649971619,
    "estimated_duration": 3600.0387684335196,
    "input_throughput": 6553.833588371731,
    "output_throughput": 5660.397376461282,
    "total_throughput": 12214.230964833014,
    "itl": 62.37415867552742,
    "ttft": 13594.479656881267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 95267,
    "finished_requests": 94910,
    "scheduler_time": 72.31906608795948
}
#Debug simulation 
Total elapsed time: 6.389331777929328. Arrivals time: 0.2180167055921629 Scheduler time: 5.974548894446343 Scheduler overhead time: 0.0740052992478013 Adapter cache time: 0.01289129292126745 Engine time: 0.07551914965733886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63748350 . Total output tokens: 55952342
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 6.380262680002488,
    "estimated_duration": 3600.0627890383103,
    "input_throughput": 6553.857358222015,
    "output_throughput": 5660.360164285777,
    "total_throughput": 12214.217522507792,
    "itl": 62.37430739703458,
    "ttft": 13556.864664180317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2367897061258555,
    "arrivals": 95267,
    "finished_requests": 94911,
    "scheduler_time": 72.31962990258941
}
#Debug simulation 
Total elapsed time: 6.380429693032056. Arrivals time: 0.21914094779640436 Scheduler time: 5.965472379815765 Scheduler overhead time: 0.07383415033109486 Adapter cache time: 0.012675344478338957 Engine time: 0.07506940618623048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55399217 . Total output tokens: 48703791
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.6654816350201145,
    "estimated_duration": 3600.029625512435,
    "input_throughput": 5710.372452024976,
    "output_throughput": 4958.12336473739,
    "total_throughput": 10668.495816762366,
    "itl": 58.24618173551741,
    "ttft": 13019.428111767427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 83017,
    "finished_requests": 82719,
    "scheduler_time": 61.35090366664758
}
#Debug simulation 
Total elapsed time: 5.6655934599693865. Arrivals time: 0.201636623009108 Scheduler time: 5.2570604995125905 Scheduler overhead time: 0.07611327269114554 Adapter cache time: 0.017541671870276332 Engine time: 0.07733725674916059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55399217 . Total output tokens: 48703791
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.678804425988346,
    "estimated_duration": 3600.0296736208734,
    "input_throughput": 5710.372375715299,
    "output_throughput": 4958.123298480277,
    "total_throughput": 10668.495674195576,
    "itl": 58.24645565431326,
    "ttft": 13019.395912608994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2348263315111399,
    "arrivals": 83017,
    "finished_requests": 82719,
    "scheduler_time": 61.35096763153985
}
#Debug simulation 
Total elapsed time: 5.6788957110838965. Arrivals time: 0.19703469378873706 Scheduler time: 5.274857703363523 Scheduler overhead time: 0.076611616066657 Adapter cache time: 0.017633318551816046 Engine time: 0.07704111095517874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55399217 . Total output tokens: 48703791
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.647054070024751,
    "estimated_duration": 3600.0288750610953,
    "input_throughput": 5710.373642392277,
    "output_throughput": 4958.124398293078,
    "total_throughput": 10668.498040685356,
    "itl": 58.24622905008872,
    "ttft": 13019.424346296952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2413462840113789,
    "arrivals": 83017,
    "finished_requests": 82719,
    "scheduler_time": 61.35087167695727
}
#Debug simulation 
Total elapsed time: 5.647152672987431. Arrivals time: 0.19220105127897114 Scheduler time: 5.248169550788589 Scheduler overhead time: 0.07669667177833617 Adapter cache time: 0.017493556952103972 Engine time: 0.07694274536333978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55399217 . Total output tokens: 48703791
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 5.615351947024465,
    "estimated_duration": 3600.0442098995204,
    "input_throughput": 5710.34931834178,
    "output_throughput": 4958.10327854229,
    "total_throughput": 10668.45259688407,
    "itl": 58.24630662097671,
    "ttft": 13019.373292219636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 83017,
    "finished_requests": 82719,
    "scheduler_time": 61.351147174628146
}
#Debug simulation 
Total elapsed time: 5.61543928203173. Arrivals time: 0.1904618120752275 Scheduler time: 5.219550441834144 Scheduler overhead time: 0.07556033122818917 Adapter cache time: 0.01735847524832934 Engine time: 0.07724107895046473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55399217 . Total output tokens: 48703791
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 5.627234425046481,
    "estimated_duration": 3600.0315550639657,
    "input_throughput": 5710.369391369052,
    "output_throughput": 4958.120707273314,
    "total_throughput": 10668.490098642367,
    "itl": 58.246433724980726,
    "ttft": 13019.40433089418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861717,
    "arrivals": 83017,
    "finished_requests": 82719,
    "scheduler_time": 61.350972797158185
}
#Debug simulation 
Total elapsed time: 5.627323623048142. Arrivals time: 0.1911117727868259 Scheduler time: 5.229296478792094 Scheduler overhead time: 0.07646489480976015 Adapter cache time: 0.017647550557740033 Engine time: 0.07702582166530192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55399217 . Total output tokens: 48703791
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.676476606051438,
    "estimated_duration": 3600.0345953212804,
    "input_throughput": 5710.36456891753,
    "output_throughput": 4958.116520101678,
    "total_throughput": 10668.48108901921,
    "itl": 58.24652255391302,
    "ttft": 13019.446607755057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 83017,
    "finished_requests": 82719,
    "scheduler_time": 61.35106954475206
}
#Debug simulation 
Total elapsed time: 5.676568947965279. Arrivals time: 0.1915530376136303 Scheduler time: 5.275827738689259 Scheduler overhead time: 0.07758419041056186 Adapter cache time: 0.017826017341576517 Engine time: 0.07742225751280785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55399217 . Total output tokens: 48703791
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.623299636063166,
    "estimated_duration": 3600.031292974677,
    "input_throughput": 5710.369807095064,
    "output_throughput": 4958.121068234157,
    "total_throughput": 10668.490875329222,
    "itl": 58.24641330921529,
    "ttft": 13019.434594184171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585545,
    "arrivals": 83017,
    "finished_requests": 82719,
    "scheduler_time": 61.351053611369395
}
#Debug simulation 
Total elapsed time: 5.623445500037633. Arrivals time: 0.19159083277918398 Scheduler time: 5.226339309243485 Scheduler overhead time: 0.07574588211718947 Adapter cache time: 0.01732218882534653 Engine time: 0.07712306990288198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54177798 . Total output tokens: 47640682
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.5078264030162245,
    "estimated_duration": 3600.0323105676453,
    "input_throughput": 5572.865538208625,
    "output_throughput": 4860.724429787363,
    "total_throughput": 10433.589967995988,
    "itl": 54.13757297584552,
    "ttft": 15196.997193629228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 81259,
    "finished_requests": 80918,
    "scheduler_time": 59.11775134789745
}
#Debug simulation 
Total elapsed time: 5.507916409056634. Arrivals time: 0.18814793520141393 Scheduler time: 5.105001574847847 Scheduler overhead time: 0.07879290450364351 Adapter cache time: 0.018168922746554017 Engine time: 0.08085165126249194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54177798 . Total output tokens: 47640682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.553029031027108,
    "estimated_duration": 3600.024924918352,
    "input_throughput": 5572.876971249029,
    "output_throughput": 4860.734401831084,
    "total_throughput": 10433.611373080113,
    "itl": 54.137684765171194,
    "ttft": 15196.975260234849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 81259,
    "finished_requests": 80918,
    "scheduler_time": 59.117690880651196
}
#Debug simulation 
Total elapsed time: 5.553117220988497. Arrivals time: 0.1891723551088944 Scheduler time: 5.1457962456624955 Scheduler overhead time: 0.08056867879349738 Adapter cache time: 0.01842575764749199 Engine time: 0.08134781487751752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54177798 . Total output tokens: 47640682
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.537234302028082,
    "estimated_duration": 3600.0325192617693,
    "input_throughput": 5572.86521514924,
    "output_throughput": 4860.724148010845,
    "total_throughput": 10433.589363160085,
    "itl": 54.137499016739355,
    "ttft": 15196.966752930131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2413462840113789,
    "arrivals": 81259,
    "finished_requests": 80918,
    "scheduler_time": 59.11781614677612
}
#Debug simulation 
Total elapsed time: 5.537321242038161. Arrivals time: 0.18240248830989003 Scheduler time: 5.138380230870098 Scheduler overhead time: 0.08026838081423193 Adapter cache time: 0.018276456044986844 Engine time: 0.08045482472516596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54177798 . Total output tokens: 47640682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 5.516948007978499,
    "estimated_duration": 3600.0325166210873,
    "input_throughput": 5572.865219237026,
    "output_throughput": 4860.724151576264,
    "total_throughput": 10433.589370813292,
    "itl": 54.13719258972956,
    "ttft": 15196.95383789012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 81259,
    "finished_requests": 80918,
    "scheduler_time": 59.1176835430716
}
#Debug simulation 
Total elapsed time: 5.517017436912283. Arrivals time: 0.1801506201736629 Scheduler time: 5.121430472005159 Scheduler overhead time: 0.07935035461559892 Adapter cache time: 0.018172046751715243 Engine time: 0.08065709308721125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_32_slots_32_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54177798 . Total output tokens: 47640682
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 5.5280046639963984,
    "estimated_duration": 3600.0325549535764,
    "input_throughput": 5572.865159898175,
    "output_throughput": 4860.724099820161,
    "total_throughput": 10433.589259718337,
    "itl": 54.13767687794704,
    "ttft": 15196.961460244287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861717,
    "arrivals": 81259,
    "finished_requests": 80918,
    "scheduler_time": 59.117824113467435
}
#Debug simulation 
Total elapsed time: 5.52807570900768. Arrivals time: 0.18291931960266083 Scheduler time: 5.12941302836407 Scheduler overhead time: 0.07967489119619131 Adapter cache time: 0.018125183531083167 Engine time: 0.08051258628256619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_32_slots_32_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54177798 . Total output tokens: 47640682
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.5198892609914765,
    "estimated_duration": 3600.0487232717774,
    "input_throughput": 5572.93040794365,
    "output_throughput": 4860.858100858245,
    "total_throughput": 10433.788508801894,
    "itl": 54.13725353950767,
    "ttft": 15108.328603394753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 81259,
    "finished_requests": 80920,
    "scheduler_time": 59.11788231231428
}
#Debug simulation 
Total elapsed time: 5.519986291998066. Arrivals time: 0.17995749809779227 Scheduler time: 5.125170149374753 Scheduler overhead time: 0.07957802014425397 Adapter cache time: 0.018118319450877607 Engine time: 0.07990078150760382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_32_slots_32_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54177798 . Total output tokens: 47640682
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.553844561916776,
    "estimated_duration": 3600.0323484700107,
    "input_throughput": 5572.865479535601,
    "output_throughput": 4860.7243786120025,
    "total_throughput": 10433.589858147603,
    "itl": 54.13768009973663,
    "ttft": 15196.998910592565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585545,
    "arrivals": 81259,
    "finished_requests": 80918,
    "scheduler_time": 59.11784049757403
}
#Debug simulation 
Total elapsed time: 5.553982647950761. Arrivals time: 0.18127838033251464 Scheduler time: 5.15561273181811 Scheduler overhead time: 0.08017007692251354 Adapter cache time: 0.01838162960484624 Engine time: 0.0808361591771245 
