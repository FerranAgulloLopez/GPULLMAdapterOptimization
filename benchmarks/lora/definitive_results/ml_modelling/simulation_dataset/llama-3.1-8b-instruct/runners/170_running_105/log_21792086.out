INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618463244 . Total output tokens: 545160770
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.87182361772284,
    "estimated_duration": 3600.093785007233,
    "input_throughput": 5139.667771172474,
    "output_throughput": 4477.342803436888,
    "total_throughput": 9617.010574609361,
    "itl": 98.59774462011495,
    "ttft": 2140837.743965426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.443460723776399,
    "arrivals": 923294,
    "finished_requests": 75035,
    "scheduler_time": 173.3364551486737
}
#Debug simulation 
Total elapsed time: 13.871969982981682. Arrivals time: 0.3507177750580013 Scheduler time: 13.364868355449289 Scheduler overhead time: 0.055876894388347864 Adapter cache time: 0.018236908596009016 Engine time: 0.056945993565022945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_192_slots_64_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_192_slots_64_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 23.10881458595395,
    "estimated_duration": 3600.0910056411053,
    "input_throughput": 5581.556679682222,
    "output_throughput": 4876.327285196992,
    "total_throughput": 10457.883964879215,
    "itl": 119.05796012913811,
    "ttft": 2097384.4867852232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5656147043965913,
    "arrivals": 921863,
    "finished_requests": 81397,
    "scheduler_time": 160.9526862099104
}
#Debug simulation 
Total elapsed time: 23.108977452851832. Arrivals time: 0.42801135452464223 Scheduler time: 22.540533492341638 Scheduler overhead time: 0.05199617147445679 Adapter cache time: 0.013591391034424305 Engine time: 0.052762210834771395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_192_slots_64_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_192_slots_64_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 17.670516167767346,
    "estimated_duration": 3600.019070855328,
    "input_throughput": 5407.665519775891,
    "output_throughput": 4728.080786515372,
    "total_throughput": 10135.746306291263,
    "itl": 110.84416845630774,
    "ttft": 2115417.1645888076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.869072108357218,
    "arrivals": 921863,
    "finished_requests": 78882,
    "scheduler_time": 165.37428525099074
}
#Debug simulation 
Total elapsed time: 17.670663891825825. Arrivals time: 0.4088500696234405 Scheduler time: 17.113056521397084 Scheduler overhead time: 0.05406591575592756 Adapter cache time: 0.015602803323417902 Engine time: 0.05558448610827327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_192_slots_64_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_192_slots_64_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.857109415810555,
    "estimated_duration": 3600.040213202451,
    "input_throughput": 5110.569579897457,
    "output_throughput": 4481.691049125144,
    "total_throughput": 9592.260629022601,
    "itl": 98.34708185399036,
    "ttft": 2144684.437950005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 818,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.105547746042742,
    "arrivals": 921863,
    "finished_requests": 74662,
    "scheduler_time": 173.99160373378368
}
#Debug simulation 
Total elapsed time: 12.857206935994327. Arrivals time: 0.3872681832872331 Scheduler time: 12.312979843001813 Scheduler overhead time: 0.05597772169858217 Adapter cache time: 0.019410358741879463 Engine time: 0.056236641481518745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_192_slots_64_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_192_slots_64_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 16.001743940170854,
    "estimated_duration": 3600.0087488679237,
    "input_throughput": 5426.203479684008,
    "output_throughput": 4743.17458405334,
    "total_throughput": 10169.378063737347,
    "itl": 111.21600045532651,
    "ttft": 2113662.815681863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 635,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.334210433871479,
    "arrivals": 921863,
    "finished_requests": 79140,
    "scheduler_time": 165.23132869263932
}
#Debug simulation 
Total elapsed time: 16.001835567876697. Arrivals time: 0.3035790426656604 Scheduler time: 15.554010873194784 Scheduler overhead time: 0.05232164077460766 Adapter cache time: 0.016166892368346453 Engine time: 0.05272650672122836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_192_slots_64_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_192_slots_64_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 12.823889745865017,
    "estimated_duration": 3600.0878619632545,
    "input_throughput": 5110.5019392406675,
    "output_throughput": 4481.631731954846,
    "total_throughput": 9592.133671195514,
    "itl": 98.3456619823471,
    "ttft": 2144677.091896721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 818,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.050661694239845,
    "arrivals": 921863,
    "finished_requests": 74662,
    "scheduler_time": 173.99668967075746
}
#Debug simulation 
Total elapsed time: 12.82399837905541. Arrivals time: 0.29733684891834855 Scheduler time: 12.370178429875523 Scheduler overhead time: 0.05570053355768323 Adapter cache time: 0.01935265865176916 Engine time: 0.05618532933294773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_192_slots_64_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_192_slots_64_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 16.028142974246293,
    "estimated_duration": 3600.0208872581234,
    "input_throughput": 5426.946568323946,
    "output_throughput": 4753.243532715392,
    "total_throughput": 10180.190101039338,
    "itl": 111.23253687061754,
    "ttft": 2112125.3549470846,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.80481688058002,
    "arrivals": 921863,
    "finished_requests": 79248,
    "scheduler_time": 165.35891079755206
}
#Debug simulation 
Total elapsed time: 16.028240391984582. Arrivals time: 0.3976828306913376 Scheduler time: 15.486054447479546 Scheduler overhead time: 0.052517494186758995 Adapter cache time: 0.01619850005954504 Engine time: 0.05269634537398815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_192_slots_64_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_192_slots_64_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617493948 . Total output tokens: 544286026
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.764260353054851,
    "estimated_duration": 3600.0338700798497,
    "input_throughput": 5110.578584526462,
    "output_throughput": 4481.698945694124,
    "total_throughput": 9592.277530220586,
    "itl": 98.34423113032881,
    "ttft": 2144655.855462968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 818,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.996811228320024,
    "arrivals": 921863,
    "finished_requests": 74662,
    "scheduler_time": 173.99654825327264
}
#Debug simulation 
Total elapsed time: 12.764431670308113. Arrivals time: 0.38020847272127867 Scheduler time: 12.228288310114294 Scheduler overhead time: 0.055518608540296555 Adapter cache time: 0.019273003563284874 Engine time: 0.05582700343802571 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 27.32916484773159,
    "estimated_duration": 3600.052563686617,
    "input_throughput": 5612.924712217895,
    "output_throughput": 4889.194723861313,
    "total_throughput": 10502.119436079209,
    "itl": 118.09016608762143,
    "ttft": 2096955.6451622848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0829088450642304,
    "arrivals": 921076,
    "finished_requests": 81793,
    "scheduler_time": 161.57911290738525
}
#Debug simulation 
Total elapsed time: 27.329294472001493. Arrivals time: 0.8163738311268389 Scheduler time: 26.369756537489593 Scheduler overhead time: 0.053534464444965124 Adapter cache time: 0.01301978388801217 Engine time: 0.05416845576837659 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 22.196231589186937,
    "estimated_duration": 3600.0964275793776,
    "input_throughput": 5443.668911162212,
    "output_throughput": 4745.8056592911325,
    "total_throughput": 10189.474570453345,
    "itl": 110.34391338345065,
    "ttft": 2109282.7348360927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 395,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.872868677773516,
    "arrivals": 921076,
    "finished_requests": 79343,
    "scheduler_time": 165.8592174268179
}
#Debug simulation 
Total elapsed time: 22.19633085373789. Arrivals time: 0.4250994850881398 Scheduler time: 21.61772718373686 Scheduler overhead time: 0.05801089759916067 Adapter cache time: 0.014279169496148825 Engine time: 0.05739216413348913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.24413590412587,
    "estimated_duration": 3600.065583461615,
    "input_throughput": 5133.353426920158,
    "output_throughput": 4479.591448023949,
    "total_throughput": 9612.944874944107,
    "itl": 98.08235591915209,
    "ttft": 2139224.1289753257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.567897665333024,
    "arrivals": 921076,
    "finished_requests": 74825,
    "scheduler_time": 173.96335177813893
}
#Debug simulation 
Total elapsed time: 11.244247820228338. Arrivals time: 0.3912933371029794 Scheduler time: 10.694820197299123 Scheduler overhead time: 0.054708253126591444 Adapter cache time: 0.022949807345867157 Engine time: 0.05537114478647709 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 17.399330004118383,
    "estimated_duration": 3600.054978871536,
    "input_throughput": 5465.353478064786,
    "output_throughput": 4756.895130909357,
    "total_throughput": 10222.248608974143,
    "itl": 109.99004783978349,
    "ttft": 2111604.002051011,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7732469504652486,
    "arrivals": 921076,
    "finished_requests": 79619,
    "scheduler_time": 166.29469697969517
}
#Debug simulation 
Total elapsed time: 17.399419113993645. Arrivals time: 0.4057257492095232 Scheduler time: 16.84529079310596 Scheduler overhead time: 0.054221884813159704 Adapter cache time: 0.01604971056804061 Engine time: 0.05467084841802716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 11.184865791816264,
    "estimated_duration": 3600.0065739024776,
    "input_throughput": 5133.437570356122,
    "output_throughput": 4479.664875311105,
    "total_throughput": 9613.102445667226,
    "itl": 98.0808104910674,
    "ttft": 2139199.5331045263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.509076387174449,
    "arrivals": 921076,
    "finished_requests": 74825,
    "scheduler_time": 173.96316349716008
}
#Debug simulation 
Total elapsed time: 11.185015401802957. Arrivals time: 0.3782918476499617 Scheduler time: 10.651610037311912 Scheduler overhead time: 0.05449843732640147 Adapter cache time: 0.020153547637164593 Engine time: 0.05544077465310693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 17.420335276052356,
    "estimated_duration": 3600.055887592804,
    "input_throughput": 5465.693482096744,
    "output_throughput": 4757.221425096143,
    "total_throughput": 10222.914907192888,
    "itl": 109.9829786445124,
    "ttft": 2111607.9664281947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.530308280135489,
    "arrivals": 921076,
    "finished_requests": 79623,
    "scheduler_time": 166.30495546580363
}
#Debug simulation 
Total elapsed time: 17.420452103950083. Arrivals time: 0.41595817636698484 Scheduler time: 16.855221062898636 Scheduler overhead time: 0.05437738401815295 Adapter cache time: 0.016084918286651373 Engine time: 0.055253127589821815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617029693 . Total output tokens: 543862399
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.274749029893428,
    "estimated_duration": 3600.0584810135624,
    "input_throughput": 5133.60160604857,
    "output_throughput": 4479.773338420733,
    "total_throughput": 9613.374944469304,
    "itl": 98.07969775162216,
    "ttft": 2139164.2494427166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.449426640309416,
    "arrivals": 921076,
    "finished_requests": 74828,
    "scheduler_time": 173.96834154750985
}
#Debug simulation 
Total elapsed time: 11.274856495670974. Arrivals time: 0.3874281821772456 Scheduler time: 10.731850020121783 Scheduler overhead time: 0.054655271116644144 Adapter cache time: 0.020437325350940228 Engine time: 0.055364574771374464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_192_slots_64_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_192_slots_64_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 28.76492362609133,
    "estimated_duration": 3600.0019133624382,
    "input_throughput": 5601.330911839953,
    "output_throughput": 4874.167687208508,
    "total_throughput": 10475.49859904846,
    "itl": 118.98481538071144,
    "ttft": 2085862.4512041865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.464902332741812,
    "arrivals": 851723,
    "finished_requests": 81623,
    "scheduler_time": 160.58343941238385
}
#Debug simulation 
Total elapsed time: 28.765038328710943. Arrivals time: 0.34094528993591666 Scheduler time: 28.27111611608416 Scheduler overhead time: 0.057314522098749876 Adapter cache time: 0.01612045895308256 Engine time: 0.05655167903751135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_192_slots_64_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_192_slots_64_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 20.448904648888856,
    "estimated_duration": 3600.0163825567056,
    "input_throughput": 5439.941911067546,
    "output_throughput": 4738.495103148687,
    "total_throughput": 10178.437014216233,
    "itl": 111.33273644015614,
    "ttft": 2098426.9659353257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 430,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.146281865732749,
    "arrivals": 851723,
    "finished_requests": 79315,
    "scheduler_time": 164.7049919662192
}
#Debug simulation 
Total elapsed time: 20.449057993944734. Arrivals time: 0.3136812252923846 Scheduler time: 19.98701497586444 Scheduler overhead time: 0.05486157722771168 Adapter cache time: 0.014457185287028551 Engine time: 0.05552939930930734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_192_slots_64_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_192_slots_64_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.49686731910333,
    "estimated_duration": 3600.0770493702753,
    "input_throughput": 5142.1816105958505,
    "output_throughput": 4472.7828819154365,
    "total_throughput": 9614.964492511286,
    "itl": 98.84642777958786,
    "ttft": 2128397.953822955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.434653017371918,
    "arrivals": 851723,
    "finished_requests": 74794,
    "scheduler_time": 172.90132080610857
}
#Debug simulation 
Total elapsed time: 14.496972221881151. Arrivals time: 0.30561236338689923 Scheduler time: 14.031427558977157 Scheduler overhead time: 0.05710627092048526 Adapter cache time: 0.020047055557370186 Engine time: 0.05742717953398824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_192_slots_64_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_192_slots_64_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 20.872350670862943,
    "estimated_duration": 3600.081609373377,
    "input_throughput": 5440.24695134869,
    "output_throughput": 4738.700632669652,
    "total_throughput": 10178.947584018342,
    "itl": 111.32595345290386,
    "ttft": 2098448.7898661685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 430,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9505427084956284,
    "arrivals": 851723,
    "finished_requests": 79322,
    "scheduler_time": 164.71578902809247
}
#Debug simulation 
Total elapsed time: 20.872419998049736. Arrivals time: 0.31773337721824646 Scheduler time: 20.405889025423676 Scheduler overhead time: 0.054681173991411924 Adapter cache time: 0.014528550207614899 Engine time: 0.05616351682692766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_192_slots_64_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_192_slots_64_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.535149022005498,
    "estimated_duration": 3600.0174285214757,
    "input_throughput": 5142.266771636982,
    "output_throughput": 4472.856956865686,
    "total_throughput": 9615.12372850267,
    "itl": 98.84483939100895,
    "ttft": 2128378.705350484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.3752103876835,
    "arrivals": 851723,
    "finished_requests": 74794,
    "scheduler_time": 172.9011425869976
}
#Debug simulation 
Total elapsed time: 14.535291699692607. Arrivals time: 0.28840436413884163 Scheduler time: 14.085688900202513 Scheduler overhead time: 0.057616335805505514 Adapter cache time: 0.020251447334885597 Engine time: 0.057922777719795704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_192_slots_64_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_192_slots_64_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 21.8695338210091,
    "estimated_duration": 3600.0375406806916,
    "input_throughput": 5431.3050291978225,
    "output_throughput": 4728.090695626921,
    "total_throughput": 10159.395724824743,
    "itl": 110.88899535327296,
    "ttft": 2097046.9385909983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4258899574167927,
    "arrivals": 851723,
    "finished_requests": 79167,
    "scheduler_time": 164.95353384937812
}
#Debug simulation 
Total elapsed time: 21.869644781108946. Arrivals time: 0.33537085819989443 Scheduler time: 21.385131125338376 Scheduler overhead time: 0.05533095123246312 Adapter cache time: 0.013801167719066143 Engine time: 0.05608248896896839 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_192_slots_64_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_192_slots_64_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 34560, 4320, 1080, 34560, 1080, 4320, 4320, 1080, 34560, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 1080, 4320, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 4320, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 1080, 4320, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 4320, 1080, 4320, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 4320, 1080, 34560, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 1080]
Prompts retrieved: 2557440 . Total input tokens: 570412107 . Total output tokens: 502600301
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.49662878504023,
    "estimated_duration": 3600.0651847423474,
    "input_throughput": 5142.31327767609,
    "output_throughput": 4472.846510736844,
    "total_throughput": 9615.159788412935,
    "itl": 98.84290310032922,
    "ttft": 2128407.1405172786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.315353523641852,
    "arrivals": 851723,
    "finished_requests": 74797,
    "scheduler_time": 172.90620301966806
}
#Debug simulation 
Total elapsed time: 14.496720603201538. Arrivals time: 0.28425785759463906 Scheduler time: 14.052725173532963 Scheduler overhead time: 0.05682762339711189 Adapter cache time: 0.020328976679593325 Engine time: 0.05738171236589551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_192_slots_64_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_192_slots_64_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 31.134435219224542,
    "estimated_duration": 3600.082679300207,
    "input_throughput": 5597.685329803931,
    "output_throughput": 4888.04690547291,
    "total_throughput": 10485.73223527684,
    "itl": 118.68773897741806,
    "ttft": 2091666.800454102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0035599366808285,
    "arrivals": 839966,
    "finished_requests": 81656,
    "scheduler_time": 160.9860033545335
}
#Debug simulation 
Total elapsed time: 31.13459353800863. Arrivals time: 0.3723874897696078 Scheduler time: 30.605444331187755 Scheduler overhead time: 0.05981978680938482 Adapter cache time: 0.013945673126727343 Engine time: 0.059289305936545134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_192_slots_64_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_192_slots_64_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 27.62319049425423,
    "estimated_duration": 3600.0043389442294,
    "input_throughput": 5424.845128305426,
    "output_throughput": 4744.64733701106,
    "total_throughput": 10169.492465316487,
    "itl": 111.00219488652915,
    "ttft": 2101160.4118456636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4813150050770547,
    "arrivals": 839966,
    "finished_requests": 79192,
    "scheduler_time": 165.17841052549642
}
#Debug simulation 
Total elapsed time: 27.623348230030388. Arrivals time: 0.3470784528180957 Scheduler time: 27.11658614128828 Scheduler overhead time: 0.05957115534693003 Adapter cache time: 0.016148374881595373 Engine time: 0.059711867943406105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_192_slots_64_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_192_slots_64_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.026758606079966,
    "estimated_duration": 3600.105903581364,
    "input_throughput": 5114.291216178907,
    "output_throughput": 4478.268815359484,
    "total_throughput": 9592.56003153839,
    "itl": 98.70726563027728,
    "ttft": 2131339.7667686776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.782830867101464,
    "arrivals": 839966,
    "finished_requests": 74654,
    "scheduler_time": 173.1808589562144
}
#Debug simulation 
Total elapsed time: 15.026852059178054. Arrivals time: 0.6424789321608841 Scheduler time: 14.224345432128757 Scheduler overhead time: 0.05733694415539503 Adapter cache time: 0.01933620171621442 Engine time: 0.05797508638352156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_192_slots_64_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_192_slots_64_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 27.665397125296295,
    "estimated_duration": 3600.0204516603085,
    "input_throughput": 5425.210845952965,
    "output_throughput": 4744.761378264458,
    "total_throughput": 10169.972224217423,
    "itl": 110.99474754301664,
    "ttft": 2101103.6442412757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.253646765453737,
    "arrivals": 839966,
    "finished_requests": 79197,
    "scheduler_time": 165.18860257571046
}
#Debug simulation 
Total elapsed time: 27.66550821112469. Arrivals time: 0.3352629663422704 Scheduler time: 27.169810106046498 Scheduler overhead time: 0.05968451779335737 Adapter cache time: 0.016088755801320076 Engine time: 0.06010108208283782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_192_slots_64_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_192_slots_64_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.701049251947552,
    "estimated_duration": 3600.0506156532165,
    "input_throughput": 5114.369759120515,
    "output_throughput": 4478.337590560425,
    "total_throughput": 9592.707349680939,
    "itl": 98.70585059740652,
    "ttft": 2131319.9928993783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.727737698121953,
    "arrivals": 839966,
    "finished_requests": 74654,
    "scheduler_time": 173.1806641970467
}
#Debug simulation 
Total elapsed time: 14.701195464003831. Arrivals time: 0.3463509501889348 Scheduler time: 14.194961623754352 Scheduler overhead time: 0.05720811616629362 Adapter cache time: 0.019604704808443785 Engine time: 0.05776329291984439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_192_slots_64_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_192_slots_64_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 27.39803477516398,
    "estimated_duration": 3600.0496359790977,
    "input_throughput": 5429.9140224725215,
    "output_throughput": 4748.897301064674,
    "total_throughput": 10178.811323537197,
    "itl": 110.98654832520151,
    "ttft": 2101708.5998949567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.057898130533272,
    "arrivals": 839966,
    "finished_requests": 79271,
    "scheduler_time": 165.2466068746562
}
#Debug simulation 
Total elapsed time: 27.39823597902432. Arrivals time: 0.3439422342926264 Scheduler time: 26.896759435534477 Scheduler overhead time: 0.05839130561798811 Adapter cache time: 0.01581869274377823 Engine time: 0.05883508920669556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_192_slots_64_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_192_slots_64_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 4320, 4320, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 540, 4320, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 34560, 34560, 540, 4320, 34560, 540, 4320, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 4320, 540, 540, 540, 540, 540, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 540, 4320, 4320, 34560, 540, 540, 540, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 4320, 4320, 34560, 4320, 540, 4320, 34560, 34560, 4320, 34560, 4320, 540, 34560, 4320, 540, 4320, 4320, 540, 4320, 34560, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 4320, 540, 34560, 34560, 4320, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 34560, 4320, 540, 540]
Prompts retrieved: 2522880 . Total input tokens: 562749910 . Total output tokens: 495716696
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.726407455746084,
    "estimated_duration": 3600.109299434669,
    "input_throughput": 5114.286392052392,
    "output_throughput": 4478.264591169968,
    "total_throughput": 9592.550983222362,
    "itl": 98.70453581492393,
    "ttft": 2131286.8946541995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.6761655211448945,
    "arrivals": 839966,
    "finished_requests": 74654,
    "scheduler_time": 173.18581673299474
}
#Debug simulation 
Total elapsed time: 14.72649986576289. Arrivals time: 0.29588827304542065 Scheduler time: 14.269939083606005 Scheduler overhead time: 0.05755269946530461 Adapter cache time: 0.019414147362113 Engine time: 0.05824578180909157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_192_slots_64_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_192_slots_64_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 17.983275454025716,
    "estimated_duration": 3600.0161672628556,
    "input_throughput": 5597.56958406144,
    "output_throughput": 4868.911467507913,
    "total_throughput": 10466.481051569352,
    "itl": 118.95117422540729,
    "ttft": 2078498.1931976536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7441497482592454,
    "arrivals": 834363,
    "finished_requests": 81754,
    "scheduler_time": 160.56946509435468
}
#Debug simulation 
Total elapsed time: 17.983414107002318. Arrivals time: 0.41616742266342044 Scheduler time: 17.432080877944827 Scheduler overhead time: 0.05022968305274844 Adapter cache time: 0.01247629476711154 Engine time: 0.0506348037160933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_192_slots_64_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_192_slots_64_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 21.20588489063084,
    "estimated_duration": 3600.116257768504,
    "input_throughput": 5443.170052554473,
    "output_throughput": 4736.789530949794,
    "total_throughput": 10179.959583504267,
    "itl": 111.00459973988004,
    "ttft": 2096129.56342597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.113625464364893,
    "arrivals": 834363,
    "finished_requests": 79522,
    "scheduler_time": 164.9193371587051
}
#Debug simulation 
Total elapsed time: 21.205974557902664. Arrivals time: 0.4560133181512356 Scheduler time: 20.598288928624243 Scheduler overhead time: 0.05581248225644231 Adapter cache time: 0.01588488183915615 Engine time: 0.05649111792445183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_192_slots_64_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_192_slots_64_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.145158348139375,
    "estimated_duration": 3600.035187594506,
    "input_throughput": 5131.828173141991,
    "output_throughput": 4469.604923709539,
    "total_throughput": 9601.43309685153,
    "itl": 98.65032312502314,
    "ttft": 2124862.2074553035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 852,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.397222304693449,
    "arrivals": 834363,
    "finished_requests": 74976,
    "scheduler_time": 172.97040040919794
}
#Debug simulation 
Total elapsed time: 12.145304128993303. Arrivals time: 0.7154928869567811 Scheduler time: 11.273882864043117 Scheduler overhead time: 0.055236898362636566 Adapter cache time: 0.019597461912781 Engine time: 0.05583419371396303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_192_slots_64_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_192_slots_64_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 17.020652316045016,
    "estimated_duration": 3600.022631505582,
    "input_throughput": 5443.816610620553,
    "output_throughput": 4737.124386595278,
    "total_throughput": 10180.94099721583,
    "itl": 110.8387333407079,
    "ttft": 2093845.621463314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.575619254428887,
    "arrivals": 834363,
    "finished_requests": 79554,
    "scheduler_time": 165.07213895041468
}
#Debug simulation 
Total elapsed time: 17.020810305140913. Arrivals time: 0.3187522371299565 Scheduler time: 16.554540519602597 Scheduler overhead time: 0.05440281052142382 Adapter cache time: 0.014995607547461987 Engine time: 0.05450582830235362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_192_slots_64_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_192_slots_64_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 11.77445146907121,
    "estimated_duration": 3600.086781960455,
    "input_throughput": 5132.1007295104,
    "output_throughput": 4469.646420922514,
    "total_throughput": 9601.747150432915,
    "itl": 98.6490624714121,
    "ttft": 2124830.7425028645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 852,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.3379867921816455,
    "arrivals": 834363,
    "finished_requests": 74978,
    "scheduler_time": 172.97556002734697
}
#Debug simulation 
Total elapsed time: 11.774570329114795. Arrivals time: 0.36664551217108965 Scheduler time: 11.252363603096455 Scheduler overhead time: 0.0553603763692081 Adapter cache time: 0.019661976024508476 Engine time: 0.05541989393532276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_192_slots_64_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_192_slots_64_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 16.8816503318958,
    "estimated_duration": 3600.031966244344,
    "input_throughput": 5444.359434521117,
    "output_throughput": 4737.404045273537,
    "total_throughput": 10181.763479794654,
    "itl": 110.83095721839568,
    "ttft": 2093825.9909133886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3451745728589444,
    "arrivals": 834363,
    "finished_requests": 79562,
    "scheduler_time": 165.08187220170143
}
#Debug simulation 
Total elapsed time: 16.88175858790055. Arrivals time: 0.4062824146822095 Scheduler time: 16.33047111518681 Scheduler overhead time: 0.053112097550183535 Adapter cache time: 0.015077707823365927 Engine time: 0.05353992618620396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_192_slots_64_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_192_slots_64_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 4320, 4320, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 270, 4320, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 34560, 34560, 270, 4320, 34560, 270, 4320, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 4320, 270, 270, 270, 270, 270, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 270, 4320, 4320, 34560, 270, 270, 270, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 4320, 4320, 34560, 4320, 270, 4320, 34560, 34560, 4320, 34560, 4320, 270, 34560, 4320, 270, 4320, 4320, 270, 4320, 34560, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 4320, 270, 34560, 34560, 4320, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 34560, 4320, 270, 270]
Prompts retrieved: 2505600 . Total input tokens: 558864513 . Total output tokens: 492296354
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.780867232009768,
    "estimated_duration": 3600.0279150122733,
    "input_throughput": 5132.184648611818,
    "output_throughput": 4469.719507701412,
    "total_throughput": 9601.90415631323,
    "itl": 98.64750781835014,
    "ttft": 2124805.6302156053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 852,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.279372631199686,
    "arrivals": 834363,
    "finished_requests": 74978,
    "scheduler_time": 172.97530724014698
}
#Debug simulation 
Total elapsed time: 11.780983573757112. Arrivals time: 0.3674587355926633 Scheduler time: 11.258049833588302 Scheduler overhead time: 0.05497044883668423 Adapter cache time: 0.019297512713819742 Engine time: 0.05607884330675006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 38.558657018933445,
    "estimated_duration": 3600.070326697864,
    "input_throughput": 5585.341444827706,
    "output_throughput": 4867.44213579654,
    "total_throughput": 10452.783580624247,
    "itl": 118.8962257896993,
    "ttft": 2069506.5389624182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7802642657700918,
    "arrivals": 831492,
    "finished_requests": 81356,
    "scheduler_time": 160.54049430731675
}
#Debug simulation 
Total elapsed time: 38.55883643589914. Arrivals time: 0.3802780299447477 Scheduler time: 38.01748187560588 Scheduler overhead time: 0.06296113412827253 Adapter cache time: 0.011912740301340818 Engine time: 0.062076407484710217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 18.621442739851773,
    "estimated_duration": 3600.080133234714,
    "input_throughput": 5433.525720557808,
    "output_throughput": 4741.872227344395,
    "total_throughput": 10175.397947902204,
    "itl": 111.05178635108238,
    "ttft": 2099052.8635633234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3261460199207113,
    "arrivals": 831492,
    "finished_requests": 79263,
    "scheduler_time": 165.0247632484902
}
#Debug simulation 
Total elapsed time: 18.621652917936444. Arrivals time: 0.3337172158062458 Scheduler time: 18.13782286643982 Scheduler overhead time: 0.055819245520979166 Adapter cache time: 0.01453203335404396 Engine time: 0.056009892374277115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.026815698016435,
    "estimated_duration": 3600.0350593272115,
    "input_throughput": 5130.796699366572,
    "output_throughput": 4480.224423984983,
    "total_throughput": 9611.021123351555,
    "itl": 98.73054233496585,
    "ttft": 2128497.5805809777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 725,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4176987588918095,
    "arrivals": 831492,
    "finished_requests": 74856,
    "scheduler_time": 173.11454318755153
}
#Debug simulation 
Total elapsed time: 12.026907442137599. Arrivals time: 0.281326696742326 Scheduler time: 11.591777567286044 Scheduler overhead time: 0.05502148997038603 Adapter cache time: 0.018133743200451136 Engine time: 0.05547539750114083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 18.90813932288438,
    "estimated_duration": 3600.118743788761,
    "input_throughput": 5436.570678055506,
    "output_throughput": 4744.567947784957,
    "total_throughput": 10181.138625840462,
    "itl": 111.08003219055097,
    "ttft": 2099157.6525891707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1709296463476453,
    "arrivals": 831492,
    "finished_requests": 79305,
    "scheduler_time": 165.04792467962852
}
#Debug simulation 
Total elapsed time: 18.90828796615824. Arrivals time: 0.6664964100345969 Scheduler time: 18.092623262666166 Scheduler overhead time: 0.0551742329262197 Adapter cache time: 0.014775108080357313 Engine time: 0.05537800909951329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 11.993711446877569,
    "estimated_duration": 3600.0953268155317,
    "input_throughput": 5130.988022014259,
    "output_throughput": 4480.469414199627,
    "total_throughput": 9611.457436213885,
    "itl": 98.72967453475496,
    "ttft": 2128465.7234728863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 725,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.369440456740584,
    "arrivals": 831492,
    "finished_requests": 74860,
    "scheduler_time": 173.11966606903448
}
#Debug simulation 
Total elapsed time: 11.993801877833903. Arrivals time: 0.27692457055673003 Scheduler time: 11.563020955305547 Scheduler overhead time: 0.05490548117086291 Adapter cache time: 0.018090813886374235 Engine time: 0.055752940475940704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 18.821704590227455,
    "estimated_duration": 3600.0669011261507,
    "input_throughput": 5427.852186271155,
    "output_throughput": 4741.431053589708,
    "total_throughput": 10169.283239860863,
    "itl": 111.04804871215725,
    "ttft": 2098305.0609576846,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8855322651378685,
    "arrivals": 831492,
    "finished_requests": 79220,
    "scheduler_time": 165.02610305908513
}
#Debug simulation 
Total elapsed time: 18.821850439999253. Arrivals time: 0.3686333457008004 Scheduler time: 18.30347701907158 Scheduler overhead time: 0.05569495400413871 Adapter cache time: 0.014571093488484621 Engine time: 0.05584789393469691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 4320, 4320, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 135, 4320, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 34560, 34560, 135, 4320, 34560, 135, 4320, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 4320, 135, 135, 135, 135, 135, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 135, 4320, 4320, 34560, 135, 135, 135, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 4320, 4320, 34560, 4320, 135, 4320, 34560, 34560, 4320, 34560, 4320, 135, 34560, 4320, 135, 4320, 4320, 135, 4320, 34560, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 4320, 135, 34560, 34560, 4320, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 34560, 4320, 135, 135]
Prompts retrieved: 2496960 . Total input tokens: 556916435 . Total output tokens: 490596253
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.050032916944474,
    "estimated_duration": 3600.0462583295366,
    "input_throughput": 5131.05795717504,
    "output_throughput": 4480.530482817896,
    "total_throughput": 9611.588439992936,
    "itl": 98.72838925988823,
    "ttft": 2128447.9885718366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 725,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.320560803059514,
    "arrivals": 831492,
    "finished_requests": 74860,
    "scheduler_time": 173.11947723672043
}
#Debug simulation 
Total elapsed time: 12.050123704131693. Arrivals time: 0.2869022502563894 Scheduler time: 11.608750342857093 Scheduler overhead time: 0.055419845040887594 Adapter cache time: 0.018012614455074072 Engine time: 0.055768633261322975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_192_slots_64_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_192_slots_64_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 26.308938033413142,
    "estimated_duration": 3600.007439133066,
    "input_throughput": 5609.843129897355,
    "output_throughput": 4888.142954570588,
    "total_throughput": 10497.986084467942,
    "itl": 118.30149731427937,
    "ttft": 2090182.8800799267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.552389886332691,
    "arrivals": 830076,
    "finished_requests": 81738,
    "scheduler_time": 161.20489426658887
}
#Debug simulation 
Total elapsed time: 26.30907058622688. Arrivals time: 0.33670434122905135 Scheduler time: 25.821503250394017 Scheduler overhead time: 0.05690559931099415 Adapter cache time: 0.013841048814356327 Engine time: 0.05694335885345936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_192_slots_64_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_192_slots_64_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 18.482159725856036,
    "estimated_duration": 3600.009863396315,
    "input_throughput": 5445.040914834308,
    "output_throughput": 4736.792855315224,
    "total_throughput": 10181.833770149531,
    "itl": 110.74783789226551,
    "ttft": 2100703.968417821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9300501131173258,
    "arrivals": 830076,
    "finished_requests": 79254,
    "scheduler_time": 165.12330225175117
}
#Debug simulation 
Total elapsed time: 18.482315644156188. Arrivals time: 0.3358086319640279 Scheduler time: 17.99921752838418 Scheduler overhead time: 0.054634487722069025 Adapter cache time: 0.013464211486279964 Engine time: 0.05563075514510274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_192_slots_64_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_192_slots_64_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.551633710972965,
    "estimated_duration": 3600.006969142768,
    "input_throughput": 5148.865865782969,
    "output_throughput": 4485.588816469761,
    "total_throughput": 9634.45468225273,
    "itl": 98.43385846420126,
    "ttft": 2132063.5542265363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.995424275873257,
    "arrivals": 830076,
    "finished_requests": 74971,
    "scheduler_time": 173.42349222474897
}
#Debug simulation 
Total elapsed time: 12.551726661156863. Arrivals time: 0.2843425963073969 Scheduler time: 12.11383913597092 Scheduler overhead time: 0.055187361780554056 Adapter cache time: 0.01737414486706257 Engine time: 0.0559425288811326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_192_slots_64_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_192_slots_64_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 17.61093647684902,
    "estimated_duration": 3600.0210760058562,
    "input_throughput": 5454.446956123336,
    "output_throughput": 4745.101386726496,
    "total_throughput": 10199.548342849832,
    "itl": 110.98707823014604,
    "ttft": 2100832.881298199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9116819989262113,
    "arrivals": 830076,
    "finished_requests": 79368,
    "scheduler_time": 165.06585271909515
}
#Debug simulation 
Total elapsed time: 17.61109035415575. Arrivals time: 0.31112704798579216 Scheduler time: 17.154837508685887 Scheduler overhead time: 0.05317843426018953 Adapter cache time: 0.013983037322759628 Engine time: 0.054547086358070374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_192_slots_64_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_192_slots_64_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 12.63416912406683,
    "estimated_duration": 3600.069743566149,
    "input_throughput": 5149.023580203703,
    "output_throughput": 4485.801428947586,
    "total_throughput": 9634.82500915129,
    "itl": 98.43309706770981,
    "ttft": 2132124.6256094114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.949858497018024,
    "arrivals": 830076,
    "finished_requests": 74974,
    "scheduler_time": 173.428571227454
}
#Debug simulation 
Total elapsed time: 12.634334192145616. Arrivals time: 0.2828746475279331 Scheduler time: 12.197800217196345 Scheduler overhead time: 0.055236262269318104 Adapter cache time: 0.017223200760781765 Engine time: 0.055980841629207134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_192_slots_64_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_192_slots_64_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 17.743182993959635,
    "estimated_duration": 3600.0657954865374,
    "input_throughput": 5454.9555801509905,
    "output_throughput": 4745.252995491783,
    "total_throughput": 10200.208575642773,
    "itl": 110.98163178477792,
    "ttft": 2100843.079300871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.713166399742465,
    "arrivals": 830076,
    "finished_requests": 79372,
    "scheduler_time": 165.07592402184605
}
#Debug simulation 
Total elapsed time: 17.74330343492329. Arrivals time: 0.3102694605477154 Scheduler time: 17.286680308170617 Scheduler overhead time: 0.05418767686933279 Adapter cache time: 0.014030076563358307 Engine time: 0.05459673656150699 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_192_slots_64_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_192_slots_64_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 4320, 4320, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 66, 4320, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 34560, 34560, 66, 4320, 34560, 66, 4320, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 4320, 66, 66, 66, 66, 66, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 66, 4320, 4320, 34560, 66, 66, 66, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 4320, 4320, 34560, 4320, 66, 4320, 34560, 34560, 4320, 34560, 4320, 66, 34560, 4320, 66, 4320, 4320, 66, 4320, 34560, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 4320, 66, 34560, 34560, 4320, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 34560, 4320, 66, 66]
Prompts retrieved: 2492544 . Total input tokens: 555933371 . Total output tokens: 489756818
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.646784452721477,
    "estimated_duration": 3600.024373279397,
    "input_throughput": 5149.088472174452,
    "output_throughput": 4485.857962480707,
    "total_throughput": 9634.94643465516,
    "itl": 98.43190786466882,
    "ttft": 2132108.9316272065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.904706952516019,
    "arrivals": 830076,
    "finished_requests": 74974,
    "scheduler_time": 173.42835248520407
}
#Debug simulation 
Total elapsed time: 12.646892705000937. Arrivals time: 0.34884272748604417 Scheduler time: 12.144196946173906 Scheduler overhead time: 0.05504112644121051 Adapter cache time: 0.017363075632601976 Engine time: 0.05627877591177821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 38.97477344190702,
    "estimated_duration": 3600.124306509652,
    "input_throughput": 5584.02551924386,
    "output_throughput": 4868.602166960483,
    "total_throughput": 10452.627686204343,
    "itl": 118.58353280814178,
    "ttft": 2069956.786723371,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7472022206103421,
    "arrivals": 829350,
    "finished_requests": 81411,
    "scheduler_time": 160.57984587457844
}
#Debug simulation 
Total elapsed time: 38.97490946017206. Arrivals time: 0.3788856086321175 Scheduler time: 38.434528070967644 Scheduler overhead time: 0.06315187364816666 Adapter cache time: 0.011525801382958889 Engine time: 0.06270508095622063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 22.15542289800942,
    "estimated_duration": 3600.109842580036,
    "input_throughput": 5441.762850757925,
    "output_throughput": 4750.032845593607,
    "total_throughput": 10191.795696351532,
    "itl": 110.27308650409915,
    "ttft": 2095636.2836118916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 354,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.581975278770554,
    "arrivals": 829350,
    "finished_requests": 79334,
    "scheduler_time": 165.6336989629387
}
#Debug simulation 
Total elapsed time: 22.15551318321377. Arrivals time: 0.32088272739201784 Scheduler time: 21.67973414901644 Scheduler overhead time: 0.058007045183330774 Adapter cache time: 0.014015682507306337 Engine time: 0.05877549387514591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.339994850102812,
    "estimated_duration": 3600.083983760126,
    "input_throughput": 5131.910000805973,
    "output_throughput": 4480.179649351946,
    "total_throughput": 9612.08965015792,
    "itl": 98.29044598508001,
    "ttft": 2122376.675150853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.348260586187276,
    "arrivals": 829350,
    "finished_requests": 74813,
    "scheduler_time": 173.391920561544
}
#Debug simulation 
Total elapsed time: 11.34017028613016. Arrivals time: 0.2872477867640555 Scheduler time: 10.900595667771995 Scheduler overhead time: 0.054925980512052774 Adapter cache time: 0.016302200965583324 Engine time: 0.05572545202448964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 22.226726991590112,
    "estimated_duration": 3600.070443007187,
    "input_throughput": 5441.902682225068,
    "output_throughput": 4750.142329358265,
    "total_throughput": 10192.045011583334,
    "itl": 110.26887659327126,
    "ttft": 2095596.4040348916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 354,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.420941645866257,
    "arrivals": 829350,
    "finished_requests": 79335,
    "scheduler_time": 165.63818429660412
}
#Debug simulation 
Total elapsed time: 22.226879355031997. Arrivals time: 0.34619774064049125 Scheduler time: 21.726701833773404 Scheduler overhead time: 0.057955869007855654 Adapter cache time: 0.01381961815059185 Engine time: 0.05813256883993745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 11.236336795147508,
    "estimated_duration": 3600.0458724985897,
    "input_throughput": 5131.964328881545,
    "output_throughput": 4480.227077997134,
    "total_throughput": 9612.19140687868,
    "itl": 98.28946981790402,
    "ttft": 2122360.1893021367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.310358142866787,
    "arrivals": 829350,
    "finished_requests": 74813,
    "scheduler_time": 173.3917117433281
}
#Debug simulation 
Total elapsed time: 11.23643487226218. Arrivals time: 0.2720361393876374 Scheduler time: 10.813856925815344 Scheduler overhead time: 0.05451606959104538 Adapter cache time: 0.016118299681693316 Engine time: 0.05491422675549984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 22.179868092760444,
    "estimated_duration": 3600.0309422003925,
    "input_throughput": 5442.283501048144,
    "output_throughput": 4750.570001919728,
    "total_throughput": 10192.853502967871,
    "itl": 110.26458453997685,
    "ttft": 2095565.817454562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 354,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2599080129619598,
    "arrivals": 829350,
    "finished_requests": 79341,
    "scheduler_time": 165.64271010578082
}
#Debug simulation 
Total elapsed time: 22.179959794972092. Arrivals time: 0.32859218725934625 Scheduler time: 21.696657276712358 Scheduler overhead time: 0.057258105371147394 Adapter cache time: 0.013854985125362873 Engine time: 0.059032673481851816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 4320, 4320, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 33, 4320, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 34560, 34560, 33, 4320, 34560, 33, 4320, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 4320, 33, 33, 33, 33, 33, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 33, 4320, 4320, 34560, 33, 33, 33, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 4320, 4320, 34560, 4320, 33, 4320, 34560, 34560, 4320, 34560, 4320, 33, 34560, 4320, 33, 4320, 4320, 33, 4320, 34560, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 4320, 33, 34560, 34560, 4320, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 34560, 4320, 33, 33]
Prompts retrieved: 2490432 . Total input tokens: 555459942 . Total output tokens: 489348034
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.323185513727367,
    "estimated_duration": 3600.0057075701807,
    "input_throughput": 5132.02158572962,
    "output_throughput": 4480.277063473398,
    "total_throughput": 9612.298649203018,
    "itl": 98.28842586345144,
    "ttft": 2122343.0417213896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.270384527780148,
    "arrivals": 829350,
    "finished_requests": 74813,
    "scheduler_time": 173.39152043000553
}
#Debug simulation 
Total elapsed time: 11.323331312742084. Arrivals time: 0.27548572747036815 Scheduler time: 10.896520827431232 Scheduler overhead time: 0.054894824512302876 Adapter cache time: 0.015862793661653996 Engine time: 0.0552504020743072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_192_slots_64_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_192_slots_64_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 18.375999069307,
    "estimated_duration": 3600.0725232751506,
    "input_throughput": 5608.126466750326,
    "output_throughput": 4869.552734468661,
    "total_throughput": 10477.679201218985,
    "itl": 118.72780651429707,
    "ttft": 2066100.65694687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7736518567381419,
    "arrivals": 771049,
    "finished_requests": 81524,
    "scheduler_time": 160.43340385684346
}
#Debug simulation 
Total elapsed time: 18.37617493001744. Arrivals time: 0.31989502534270287 Scheduler time: 17.918155157007277 Scheduler overhead time: 0.0526576335541904 Adapter cache time: 0.009440497029572725 Engine time: 0.05342946574091911 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_192_slots_64_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_192_slots_64_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.822604842949659,
    "estimated_duration": 3600.058385512255,
    "input_throughput": 5442.080905921826,
    "output_throughput": 4734.871820023146,
    "total_throughput": 10176.952725944973,
    "itl": 110.98291128017043,
    "ttft": 2086555.6772201448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.70586660584901,
    "arrivals": 771049,
    "finished_requests": 79215,
    "scheduler_time": 164.67929278336086
}
#Debug simulation 
Total elapsed time: 13.8227194189094. Arrivals time: 0.2932705581188202 Scheduler time: 13.3864490785636 Scheduler overhead time: 0.052036752458661795 Adapter cache time: 0.014674988109618425 Engine time: 0.05283477297052741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_192_slots_64_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_192_slots_64_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.062695409171283,
    "estimated_duration": 3600.0464199103794,
    "input_throughput": 5140.075388378091,
    "output_throughput": 4468.464048416483,
    "total_throughput": 9608.539436794574,
    "itl": 98.56635975295195,
    "ttft": 2116628.2685561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.378893392952181,
    "arrivals": 771049,
    "finished_requests": 74793,
    "scheduler_time": 172.82438490621183
}
#Debug simulation 
Total elapsed time: 10.062788526061922. Arrivals time: 0.2688687299378216 Scheduler time: 9.64065448148176 Scheduler overhead time: 0.054304967634379864 Adapter cache time: 0.019084700383245945 Engine time: 0.05492715537548065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_192_slots_64_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_192_slots_64_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 14.141887478064746,
    "estimated_duration": 3600.0913904821505,
    "input_throughput": 5444.424564281678,
    "output_throughput": 4734.385922829952,
    "total_throughput": 10178.810487111628,
    "itl": 111.03101537653548,
    "ttft": 2086389.0569583313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.81904876490123,
    "arrivals": 771049,
    "finished_requests": 79216,
    "scheduler_time": 164.65410979550379
}
#Debug simulation 
Total elapsed time: 14.141978831961751. Arrivals time: 0.2972828890196979 Scheduler time: 13.701410478446633 Scheduler overhead time: 0.052157717291265726 Adapter cache time: 0.015190692618489265 Engine time: 0.0527031309902668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_192_slots_64_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_192_slots_64_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 10.03871151106432,
    "estimated_duration": 3600.102567674823,
    "input_throughput": 5140.116608386433,
    "output_throughput": 4468.527131545065,
    "total_throughput": 9608.643739931498,
    "itl": 98.56494840503638,
    "ttft": 2116604.0005634767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.32069346632345,
    "arrivals": 771049,
    "finished_requests": 74794,
    "scheduler_time": 172.8296613099881
}
#Debug simulation 
Total elapsed time: 10.038815849926323. Arrivals time: 0.2765493565239012 Scheduler time: 9.60854547470808 Scheduler overhead time: 0.05453540990129113 Adapter cache time: 0.01900304201990366 Engine time: 0.055121279787272215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_192_slots_64_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_192_slots_64_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 14.048843036871403,
    "estimated_duration": 3600.0810432532444,
    "input_throughput": 5445.011866256779,
    "output_throughput": 4734.610358826021,
    "total_throughput": 10179.6222250828,
    "itl": 111.02375229561046,
    "ttft": 2086375.5495339688,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5622278848383413,
    "arrivals": 771049,
    "finished_requests": 79222,
    "scheduler_time": 164.6643020614745
}
#Debug simulation 
Total elapsed time: 14.049022688996047. Arrivals time: 0.3052447778172791 Scheduler time: 13.600542299449444 Scheduler overhead time: 0.05209082458168268 Adapter cache time: 0.014994400553405285 Engine time: 0.05293596675619483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_192_slots_64_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_192_slots_64_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 1080, 1080, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 34560, 34560, 540, 1080, 34560, 540, 1080, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 1080, 540, 540, 540, 540, 540, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 540, 1080, 1080, 34560, 540, 540, 540, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 1080, 1080, 34560, 1080, 540, 1080, 34560, 34560, 1080, 34560, 1080, 540, 34560, 1080, 540, 1080, 1080, 540, 1080, 34560, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 1080, 540, 34560, 34560, 1080, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 2315520 . Total input tokens: 516382939 . Total output tokens: 454893921
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.091463078279048,
    "estimated_duration": 3600.044165270333,
    "input_throughput": 5140.199994910461,
    "output_throughput": 4468.599623080455,
    "total_throughput": 9608.799617990915,
    "itl": 98.56346196900374,
    "ttft": 2116583.9939385667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.262493539694719,
    "arrivals": 771049,
    "finished_requests": 74794,
    "scheduler_time": 172.82945883212727
}
#Debug simulation 
Total elapsed time: 10.09157878300175. Arrivals time: 0.3134738551452756 Scheduler time: 9.624630302656442 Scheduler overhead time: 0.05422234209254384 Adapter cache time: 0.0192602570168674 Engine time: 0.05495120631530881 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_192_slots_64_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_192_slots_64_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 17.88548335665837,
    "estimated_duration": 3600.0906509489337,
    "input_throughput": 5648.894978419383,
    "output_throughput": 4870.6140206158725,
    "total_throughput": 10519.508999035255,
    "itl": 118.9226228892411,
    "ttft": 2064293.466753396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5142416683165338,
    "arrivals": 765271,
    "finished_requests": 81913,
    "scheduler_time": 160.27244159663556
}
#Debug simulation 
Total elapsed time: 17.8856032458134. Arrivals time: 0.39168603951111436 Scheduler time: 17.35437743458897 Scheduler overhead time: 0.05304011097177863 Adapter cache time: 0.011144182179123163 Engine time: 0.053048110101372004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_192_slots_64_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_192_slots_64_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.828029894270003,
    "estimated_duration": 3600.089923074356,
    "input_throughput": 5498.436267696294,
    "output_throughput": 4733.460653518247,
    "total_throughput": 10231.896921214542,
    "itl": 111.11599946600553,
    "ttft": 2082771.1743215928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.145724681806754,
    "arrivals": 765271,
    "finished_requests": 79671,
    "scheduler_time": 164.52089898480352
}
#Debug simulation 
Total elapsed time: 11.828116121236235. Arrivals time: 0.3591807596385479 Scheduler time: 11.331042834091932 Scheduler overhead time: 0.05080067738890648 Adapter cache time: 0.013200675137341022 Engine time: 0.05116755003109574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_192_slots_64_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_192_slots_64_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.02335537597537,
    "estimated_duration": 3600.0277431044406,
    "input_throughput": 5191.358326556599,
    "output_throughput": 4471.079155106677,
    "total_throughput": 9662.437481663277,
    "itl": 98.34185671395959,
    "ttft": 2111605.553691162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.076013884479216,
    "arrivals": 765271,
    "finished_requests": 75208,
    "scheduler_time": 173.0779131152092
}
#Debug simulation 
Total elapsed time: 10.023444657679647. Arrivals time: 0.3883873801678419 Scheduler time: 9.485244990326464 Scheduler overhead time: 0.0542220831848681 Adapter cache time: 0.015772870741784573 Engine time: 0.05484757898375392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_192_slots_64_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_192_slots_64_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 12.23512326227501,
    "estimated_duration": 3600.0743532865154,
    "input_throughput": 5492.036291403353,
    "output_throughput": 4727.33569640403,
    "total_throughput": 10219.371987807384,
    "itl": 110.76273758163715,
    "ttft": 2083530.7665507111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.185359562323424,
    "arrivals": 765271,
    "finished_requests": 79579,
    "scheduler_time": 164.74398850392498
}
#Debug simulation 
Total elapsed time: 12.235279421322048. Arrivals time: 0.3729448071680963 Scheduler time: 11.722965176217258 Scheduler overhead time: 0.05079656792804599 Adapter cache time: 0.013810706790536642 Engine time: 0.05176147539168596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_192_slots_64_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_192_slots_64_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 10.038493299856782,
    "estimated_duration": 3600.0960456996386,
    "input_throughput": 5191.481772361392,
    "output_throughput": 4471.070436919931,
    "total_throughput": 9662.552209281324,
    "itl": 98.34125195913259,
    "ttft": 2111564.7765215407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.036247386569193,
    "arrivals": 765271,
    "finished_requests": 75211,
    "scheduler_time": 173.08300442770144
}
#Debug simulation 
Total elapsed time: 10.038598623592407. Arrivals time: 0.35603426583111286 Scheduler time: 9.530051650945097 Scheduler overhead time: 0.05497885402292013 Adapter cache time: 0.015778018161654472 Engine time: 0.05640435451641679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_192_slots_64_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_192_slots_64_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 13.74021639674902,
    "estimated_duration": 3600.026413507604,
    "input_throughput": 5420.757449661634,
    "output_throughput": 4669.218519322538,
    "total_throughput": 10089.975968984172,
    "itl": 108.03199910581716,
    "ttft": 2073929.2242733345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6301754275150486,
    "arrivals": 765271,
    "finished_requests": 78560,
    "scheduler_time": 166.7513156572188
}
#Debug simulation 
Total elapsed time: 13.740345170721412. Arrivals time: 0.42578494641929865 Scheduler time: 13.171690446790308 Scheduler overhead time: 0.05289549333974719 Adapter cache time: 0.013297699857503176 Engine time: 0.05311834346503019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_192_slots_64_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_192_slots_64_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.140737335197628,
    "estimated_duration": 3600.080655588065,
    "input_throughput": 5198.3863114152955,
    "output_throughput": 4476.374709823716,
    "total_throughput": 9674.761021239012,
    "itl": 98.6059596190729,
    "ttft": 2111798.278565088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.482467026542901,
    "arrivals": 765271,
    "finished_requests": 75308,
    "scheduler_time": 172.83732260185585
}
#Debug simulation 
Total elapsed time: 10.140852747950703. Arrivals time: 0.34655047627165914 Scheduler time: 9.646028438117355 Scheduler overhead time: 0.053652848582714796 Adapter cache time: 0.01464061951264739 Engine time: 0.05500514525920153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 14.873089436907321,
    "estimated_duration": 3600.075082530493,
    "input_throughput": 5567.203888956735,
    "output_throughput": 4869.124281618791,
    "total_throughput": 10436.328170575527,
    "itl": 118.83923877426257,
    "ttft": 2069684.4510608693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 74,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48931826836429493,
    "arrivals": 762397,
    "finished_requests": 80984,
    "scheduler_time": 160.42759821898937
}
#Debug simulation 
Total elapsed time: 14.873239086009562. Arrivals time: 0.29455949971452355 Scheduler time: 14.447573367040604 Scheduler overhead time: 0.04963178653270006 Adapter cache time: 0.008447972126305103 Engine time: 0.05090558994561434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.814092652406543,
    "estimated_duration": 3600.0127501944385,
    "input_throughput": 5407.114182845227,
    "output_throughput": 4736.286836506089,
    "total_throughput": 10143.401019351315,
    "itl": 111.11130833597828,
    "ttft": 2089295.0827759155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 395,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.886750887506645,
    "arrivals": 762397,
    "finished_requests": 78743,
    "scheduler_time": 164.71898346257754
}
#Debug simulation 
Total elapsed time: 13.814248461276293. Arrivals time: 0.28933097468689084 Scheduler time: 13.383095563855022 Scheduler overhead time: 0.052158106584101915 Adapter cache time: 0.013502638787031174 Engine time: 0.05301863560453057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.172455335967243,
    "estimated_duration": 3600.045484581855,
    "input_throughput": 5094.246191761695,
    "output_throughput": 4465.192195166695,
    "total_throughput": 9559.43838692839,
    "itl": 98.65167812597217,
    "ttft": 2120074.468008379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.902396966777772,
    "arrivals": 762397,
    "finished_requests": 74205,
    "scheduler_time": 172.84599219748918
}
#Debug simulation 
Total elapsed time: 8.172542120795697. Arrivals time: 0.2468322622589767 Scheduler time: 7.777660696301609 Scheduler overhead time: 0.05288128415122628 Adapter cache time: 0.016254352405667305 Engine time: 0.05408413475379348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 14.03319105366245,
    "estimated_duration": 3600.077093654413,
    "input_throughput": 5408.257238245971,
    "output_throughput": 4737.516046548647,
    "total_throughput": 10145.773284794619,
    "itl": 111.0982074795954,
    "ttft": 2089220.9562278634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.731260660812255,
    "arrivals": 762397,
    "finished_requests": 78795,
    "scheduler_time": 164.766197419987
}
#Debug simulation 
Total elapsed time: 14.033276685047895. Arrivals time: 0.300197163131088 Scheduler time: 13.591468878090382 Scheduler overhead time: 0.05220888601616025 Adapter cache time: 0.013339489698410034 Engine time: 0.0529726124368608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 8.175979735795408,
    "estimated_duration": 3600.003262402894,
    "input_throughput": 5094.305938978211,
    "output_throughput": 4465.2445646036695,
    "total_throughput": 9559.55050358188,
    "itl": 98.6505651423567,
    "ttft": 2120057.5096254107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.8603521799249885,
    "arrivals": 762397,
    "finished_requests": 74205,
    "scheduler_time": 172.84581480538102
}
#Debug simulation 
Total elapsed time: 8.176076265983284. Arrivals time: 0.25633012037724257 Scheduler time: 7.77209801832214 Scheduler overhead time: 0.05279989168047905 Adapter cache time: 0.016278665512800217 Engine time: 0.05382055463269353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 14.133059931918979,
    "estimated_duration": 3600.0158284972144,
    "input_throughput": 5408.660941395932,
    "output_throughput": 4737.868890737628,
    "total_throughput": 10146.52983213356,
    "itl": 111.09377879352168,
    "ttft": 2089165.103843452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5535683762282027,
    "arrivals": 762397,
    "finished_requests": 78799,
    "scheduler_time": 164.7706823322374
}
#Debug simulation 
Total elapsed time: 14.13316364819184. Arrivals time: 0.3047194695100188 Scheduler time: 13.685689979232848 Scheduler overhead time: 0.05248983250930905 Adapter cache time: 0.013263836968690157 Engine time: 0.05366057809442282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.199800603091717,
    "estimated_duration": 3600.0636293129246,
    "input_throughput": 5094.411623913505,
    "output_throughput": 4465.561627606059,
    "total_throughput": 9559.973251519563,
    "itl": 98.64987165639126,
    "ttft": 2120023.9591131294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.812922346480222,
    "arrivals": 762397,
    "finished_requests": 74209,
    "scheduler_time": 172.85091718715617
}
#Debug simulation 
Total elapsed time: 8.19988976791501. Arrivals time: 0.2523610619828105 Scheduler time: 7.797099446877837 Scheduler overhead time: 0.05402547772973776 Adapter cache time: 0.016362109687179327 Engine time: 0.05492513347417116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_192_slots_64_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_192_slots_64_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 14.909124934114516,
    "estimated_duration": 3600.1254129457575,
    "input_throughput": 5640.739605063855,
    "output_throughput": 4869.76813000935,
    "total_throughput": 10510.507735073204,
    "itl": 118.74806011409342,
    "ttft": 2069217.6821621947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7802642657700918,
    "arrivals": 760968,
    "finished_requests": 81739,
    "scheduler_time": 160.40476587237998
}
#Debug simulation 
Total elapsed time: 14.909220942296088. Arrivals time: 0.30218737944960594 Scheduler time: 14.47479631844908 Scheduler overhead time: 0.04997789300978184 Adapter cache time: 0.009166039060801268 Engine time: 0.05128064285963774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_192_slots_64_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_192_slots_64_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 11.139950186945498,
    "estimated_duration": 3600.0610188858136,
    "input_throughput": 5471.633924165102,
    "output_throughput": 4731.218973969352,
    "total_throughput": 10202.852898134455,
    "itl": 110.89331330647882,
    "ttft": 2087267.1457123093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.762396616884511,
    "arrivals": 760968,
    "finished_requests": 79288,
    "scheduler_time": 164.71159635870202
}
#Debug simulation 
Total elapsed time: 11.140047742985189. Arrivals time: 0.3252616133540869 Scheduler time: 10.677280647214502 Scheduler overhead time: 0.05029650451615453 Adapter cache time: 0.012621690984815359 Engine time: 0.05163736455142498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_192_slots_64_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_192_slots_64_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.627920718397945,
    "estimated_duration": 3600.006159699071,
    "input_throughput": 5169.186433157536,
    "output_throughput": 4467.711522289302,
    "total_throughput": 9636.897955446839,
    "itl": 98.4880059152122,
    "ttft": 2117256.8230437757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 614,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.5981509021716525,
    "arrivals": 760968,
    "finished_requests": 74803,
    "scheduler_time": 172.9145154300916
}
#Debug simulation 
Total elapsed time: 8.628007007297128. Arrivals time: 0.2556878821924329 Scheduler time: 8.22380612976849 Scheduler overhead time: 0.053392868023365736 Adapter cache time: 0.01567342272028327 Engine time: 0.054652600549161434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_192_slots_64_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_192_slots_64_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 10.999208681751043,
    "estimated_duration": 3600.007720490522,
    "input_throughput": 5472.180764466742,
    "output_throughput": 4731.390964261363,
    "total_throughput": 10203.571728728106,
    "itl": 110.88740804971499,
    "ttft": 2087279.828841431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.586092553273771,
    "arrivals": 760968,
    "finished_requests": 79293,
    "scheduler_time": 164.71617791551157
}
#Debug simulation 
Total elapsed time: 10.999304806813598. Arrivals time: 0.2900105626322329 Scheduler time: 10.573676854837686 Scheduler overhead time: 0.050103938207030296 Adapter cache time: 0.012221846729516983 Engine time: 0.0505436765961349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_192_slots_64_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_192_slots_64_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 8.69037485588342,
    "estimated_duration": 3600.075910599318,
    "input_throughput": 5169.199056389343,
    "output_throughput": 4467.8019018,
    "total_throughput": 9637.000958189343,
    "itl": 98.48706788670553,
    "ttft": 2117239.3030424174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 614,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.555898998142253,
    "arrivals": 760968,
    "finished_requests": 74804,
    "scheduler_time": 172.91971429839526
}
#Debug simulation 
Total elapsed time: 8.690544425975531. Arrivals time: 0.2540803849697113 Scheduler time: 8.287565237376839 Scheduler overhead time: 0.053156813606619835 Adapter cache time: 0.01576840505003929 Engine time: 0.05490031372755766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_192_slots_64_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_192_slots_64_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 10.881622964981943,
    "estimated_duration": 3600.0407778583144,
    "input_throughput": 5471.3958022769975,
    "output_throughput": 4731.766957965948,
    "total_throughput": 10203.162760242945,
    "itl": 110.90801705865223,
    "ttft": 2087105.4309067044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.419506036476222,
    "arrivals": 760968,
    "finished_requests": 79292,
    "scheduler_time": 164.7081097711281
}
#Debug simulation 
Total elapsed time: 10.881765459198505. Arrivals time: 0.2782047027722001 Scheduler time: 10.467597806826234 Scheduler overhead time: 0.0499730259180069 Adapter cache time: 0.012376162689179182 Engine time: 0.050698574632406235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_192_slots_64_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_192_slots_64_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.687843603082001,
    "estimated_duration": 3600.0345170268974,
    "input_throughput": 5169.258492379327,
    "output_throughput": 4467.853273052333,
    "total_throughput": 9637.11176543166,
    "itl": 98.48600727156024,
    "ttft": 2117225.8654211843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 614,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.5146826799959285,
    "arrivals": 760968,
    "finished_requests": 74804,
    "scheduler_time": 172.9195370441209
}
#Debug simulation 
Total elapsed time: 8.687960006762296. Arrivals time: 0.25973187666386366 Scheduler time: 8.278804352972656 Scheduler overhead time: 0.05368397431448102 Adapter cache time: 0.015972383320331573 Engine time: 0.05468918615952134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 13.636905550956726,
    "estimated_duration": 3600.105700150639,
    "input_throughput": 5619.190569641755,
    "output_throughput": 4870.633103707564,
    "total_throughput": 10489.82367334932,
    "itl": 118.85892218389657,
    "ttft": 2067942.3649485884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 102,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6744657212588929,
    "arrivals": 760248,
    "finished_requests": 81684,
    "scheduler_time": 160.38528683453833
}
#Debug simulation 
Total elapsed time: 13.637001504655927. Arrivals time: 0.2926316470839083 Scheduler time: 13.214498579502106 Scheduler overhead time: 0.049085181672126055 Adapter cache time: 0.008644514717161655 Engine time: 0.05019568372517824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 12.671283444855362,
    "estimated_duration": 3600.07527177363,
    "input_throughput": 5457.418391788391,
    "output_throughput": 4733.610192434762,
    "total_throughput": 10191.028584223153,
    "itl": 111.09088907573827,
    "ttft": 2083043.341602769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7824742667935791,
    "arrivals": 760248,
    "finished_requests": 79346,
    "scheduler_time": 164.65794822948374
}
#Debug simulation 
Total elapsed time: 12.671371346805245. Arrivals time: 0.2838354744017124 Scheduler time: 12.251920500770211 Scheduler overhead time: 0.051092776004225016 Adapter cache time: 0.009282799903303385 Engine time: 0.05222391989082098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.917804483324289,
    "estimated_duration": 3600.0445672153874,
    "input_throughput": 5150.141242373882,
    "output_throughput": 4472.69657343568,
    "total_throughput": 9622.837815809562,
    "itl": 98.76293705963309,
    "ttft": 2117177.351590291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.159724272405764,
    "arrivals": 760248,
    "finished_requests": 74976,
    "scheduler_time": 172.70944864376227
}
#Debug simulation 
Total elapsed time: 7.917957182042301. Arrivals time: 0.2490757592022419 Scheduler time: 7.522114238701761 Scheduler overhead time: 0.05293099628761411 Adapter cache time: 0.015099771320819855 Engine time: 0.05406551854684949 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 12.645726904738694,
    "estimated_duration": 3600.0368088441546,
    "input_throughput": 5457.476699052974,
    "output_throughput": 4733.660766505157,
    "total_throughput": 10191.137465558131,
    "itl": 111.0902254892148,
    "ttft": 2083018.482864111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7449923005141318,
    "arrivals": 760248,
    "finished_requests": 79346,
    "scheduler_time": 164.6569672662873
}
#Debug simulation 
Total elapsed time: 12.64581738691777. Arrivals time: 0.28879173239693046 Scheduler time: 12.222268106415868 Scheduler overhead time: 0.05078500183299184 Adapter cache time: 0.009030535817146301 Engine time: 0.05179343651980162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 7.910129606258124,
    "estimated_duration": 3600.0060823804706,
    "input_throughput": 5150.196298485171,
    "output_throughput": 4472.74438751858,
    "total_throughput": 9622.94068600375,
    "itl": 98.76194775523466,
    "ttft": 2117162.9016703907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.1214075947320445,
    "arrivals": 760248,
    "finished_requests": 74976,
    "scheduler_time": 172.7092804865191
}
#Debug simulation 
Total elapsed time: 7.910219470970333. Arrivals time: 0.25048071099445224 Scheduler time: 7.513487632386386 Scheduler overhead time: 0.05276379454880953 Adapter cache time: 0.014951806049793959 Engine time: 0.053951578214764595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 12.613982355222106,
    "estimated_duration": 3600.1034672462997,
    "input_throughput": 5457.407871398781,
    "output_throughput": 4733.862833402296,
    "total_throughput": 10191.270704801078,
    "itl": 111.08957364720379,
    "ttft": 2082960.2360864657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6894634615816172,
    "arrivals": 760248,
    "finished_requests": 79349,
    "scheduler_time": 164.6615806526076
}
#Debug simulation 
Total elapsed time: 12.614115823991597. Arrivals time: 0.2982514901086688 Scheduler time: 12.182128493208438 Scheduler overhead time: 0.05046760709956288 Adapter cache time: 0.008922210428863764 Engine time: 0.05128876958042383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.981055626645684,
    "estimated_duration": 3600.073370067599,
    "input_throughput": 5150.453641907813,
    "output_throughput": 4472.836063254355,
    "total_throughput": 9623.289705162168,
    "itl": 98.76119345528963,
    "ttft": 2117136.36624815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.083090917058326,
    "arrivals": 760248,
    "finished_requests": 74979,
    "scheduler_time": 172.71431613148616
}
#Debug simulation 
Total elapsed time: 7.981176097877324. Arrivals time: 0.2504066755063832 Scheduler time: 7.58343257708475 Scheduler overhead time: 0.05309394560754299 Adapter cache time: 0.015064091887325048 Engine time: 0.05431962804868817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_192_slots_64_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_192_slots_64_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 12.291089246049523,
    "estimated_duration": 3600.081051134948,
    "input_throughput": 5583.246242098718,
    "output_throughput": 4870.874780575235,
    "total_throughput": 10454.121022673951,
    "itl": 119.0762058743883,
    "ttft": 2067370.7223441233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 109,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7207525844825424,
    "arrivals": 753816,
    "finished_requests": 81487,
    "scheduler_time": 160.2924939458879
}
#Debug simulation 
Total elapsed time: 12.29126889212057. Arrivals time: 0.28335125697776675 Scheduler time: 11.880037524271756 Scheduler overhead time: 0.04805035283789039 Adapter cache time: 0.008665863890200853 Engine time: 0.049507275223731995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_192_slots_64_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_192_slots_64_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 10.473077189177275,
    "estimated_duration": 3600.081862134384,
    "input_throughput": 5442.054028289392,
    "output_throughput": 4751.246959106373,
    "total_throughput": 10193.300987395764,
    "itl": 111.03585542942714,
    "ttft": 2085870.4699709716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6483170770015603,
    "arrivals": 753816,
    "finished_requests": 79372,
    "scheduler_time": 164.99428628492635
}
#Debug simulation 
Total elapsed time: 10.473166547250003. Arrivals time: 0.27388896560296416 Scheduler time: 10.063178853597492 Scheduler overhead time: 0.04983178060501814 Adapter cache time: 0.012273052707314491 Engine time: 0.0513048991560936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_192_slots_64_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_192_slots_64_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.10647010197863,
    "estimated_duration": 3600.0056429490637,
    "input_throughput": 5115.074482193122,
    "output_throughput": 4472.510211625747,
    "total_throughput": 9587.58469381887,
    "itl": 98.9287386401952,
    "ttft": 2115770.004605048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 748,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.610283672064571,
    "arrivals": 753816,
    "finished_requests": 74596,
    "scheduler_time": 172.62044839444616
}
#Debug simulation 
Total elapsed time: 8.106566426344216. Arrivals time: 0.25703901378437877 Scheduler time: 7.700644668657333 Scheduler overhead time: 0.05277964426204562 Adapter cache time: 0.01745301717892289 Engine time: 0.05394194182008505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_192_slots_64_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_192_slots_64_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 10.500821046996862,
    "estimated_duration": 3600.0312881060217,
    "input_throughput": 5442.341866508521,
    "output_throughput": 4751.398982701355,
    "total_throughput": 10193.740849209875,
    "itl": 111.03132218157418,
    "ttft": 2085807.9618189177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4789541182573855,
    "arrivals": 753816,
    "finished_requests": 79374,
    "scheduler_time": 164.99890238752909
}
#Debug simulation 
Total elapsed time: 10.500908832997084. Arrivals time: 0.27063742419704795 Scheduler time: 10.094183649402112 Scheduler overhead time: 0.0499366819858551 Adapter cache time: 0.012299525551497936 Engine time: 0.05119423707947135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_192_slots_64_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_192_slots_64_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 8.083748794626445,
    "estimated_duration": 3600.0639617130296,
    "input_throughput": 5114.99189898778,
    "output_throughput": 4472.568313019183,
    "total_throughput": 9587.560212006963,
    "itl": 98.92751618688273,
    "ttft": 2115746.979359136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 748,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.5578830263810515,
    "arrivals": 753816,
    "finished_requests": 74597,
    "scheduler_time": 172.62563925324147
}
#Debug simulation 
Total elapsed time: 8.083839166909456. Arrivals time: 0.2508127368055284 Scheduler time: 7.684082205872983 Scheduler overhead time: 0.05282216751947999 Adapter cache time: 0.017394730355590582 Engine time: 0.05410286411643028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_192_slots_64_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_192_slots_64_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 10.474560462404042,
    "estimated_duration": 3600.1021263477737,
    "input_throughput": 5442.4428286641505,
    "output_throughput": 4751.575205271698,
    "total_throughput": 10194.018033935849,
    "itl": 111.02611849387114,
    "ttft": 2085797.0025008654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3109793804865237,
    "arrivals": 753816,
    "finished_requests": 79378,
    "scheduler_time": 165.00908629258578
}
#Debug simulation 
Total elapsed time: 10.474656753242016. Arrivals time: 0.2808676855638623 Scheduler time: 10.057993792928755 Scheduler overhead time: 0.04970181966200471 Adapter cache time: 0.012266382109373808 Engine time: 0.05098097352311015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_192_slots_64_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_192_slots_64_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.121779074892402,
    "estimated_duration": 3600.013452228162,
    "input_throughput": 5115.063664165702,
    "output_throughput": 4472.631064762898,
    "total_throughput": 9587.6947289286,
    "itl": 98.92619094843198,
    "ttft": 2115728.4011832494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 748,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.507553552463679,
    "arrivals": 753816,
    "finished_requests": 74597,
    "scheduler_time": 172.625459242291
}
#Debug simulation 
Total elapsed time: 8.121881953906268. Arrivals time: 0.25856475019827485 Scheduler time: 7.713777398690581 Scheduler overhead time: 0.05315901851281524 Adapter cache time: 0.017403329256922007 Engine time: 0.0542565006762743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 10.656354385893792,
    "estimated_duration": 3600.1321281352502,
    "input_throughput": 5594.341063929797,
    "output_throughput": 4875.048296933131,
    "total_throughput": 10469.389360862928,
    "itl": 119.1135458764877,
    "ttft": 2068105.0704677068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 89,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5885044038435439,
    "arrivals": 750836,
    "finished_requests": 81519,
    "scheduler_time": 160.2153686930966
}
#Debug simulation 
Total elapsed time: 10.656489334069192. Arrivals time: 0.2989946035668254 Scheduler time: 10.233153752982616 Scheduler overhead time: 0.046526331920176744 Adapter cache time: 0.008146652486175299 Engine time: 0.048240961972624063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.651760755106807,
    "estimated_duration": 3600.082109575985,
    "input_throughput": 5424.945711113311,
    "output_throughput": 4738.203874469149,
    "total_throughput": 10163.14958558246,
    "itl": 111.43756586080416,
    "ttft": 2085896.4075696827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9031262083817304,
    "arrivals": 750836,
    "finished_requests": 79132,
    "scheduler_time": 164.367638596475
}
#Debug simulation 
Total elapsed time: 9.651942325290293. Arrivals time: 0.2695469968020916 Scheduler time: 9.248399026226252 Scheduler overhead time: 0.04879866447299719 Adapter cache time: 0.01252756267786026 Engine time: 0.05003004288300872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.576504400931299,
    "estimated_duration": 3600.0953122635474,
    "input_throughput": 5122.566599050631,
    "output_throughput": 4473.182403016641,
    "total_throughput": 9595.749002067272,
    "itl": 98.90361807416208,
    "ttft": 2114616.475553774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 657,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.914663542136581,
    "arrivals": 750836,
    "finished_requests": 74651,
    "scheduler_time": 172.58163878949264
}
#Debug simulation 
Total elapsed time: 7.576620505191386. Arrivals time: 0.24862560303881764 Scheduler time: 7.180653672199696 Scheduler overhead time: 0.05257188202813268 Adapter cache time: 0.01645640144124627 Engine time: 0.053655956871807575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 9.732928375713527,
    "estimated_duration": 3600.0293795886214,
    "input_throughput": 5425.249335668431,
    "output_throughput": 4738.414107595223,
    "total_throughput": 10163.663443263653,
    "itl": 111.43237308727385,
    "ttft": 2085878.676328446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.725433923797678,
    "arrivals": 750836,
    "finished_requests": 79136,
    "scheduler_time": 164.37247626869268
}
#Debug simulation 
Total elapsed time: 9.733042961917818. Arrivals time: 0.2718106540851295 Scheduler time: 9.325774711556733 Scheduler overhead time: 0.04943263530731201 Adapter cache time: 0.012748528271913528 Engine time: 0.05054477322846651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 7.659785101190209,
    "estimated_duration": 3600.0502054679987,
    "input_throughput": 5122.630782201165,
    "output_throughput": 4473.238449713934,
    "total_throughput": 9595.8692319151,
    "itl": 98.9024144848018,
    "ttft": 2114600.7265071236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 657,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.869719114811192,
    "arrivals": 750836,
    "finished_requests": 74651,
    "scheduler_time": 172.58147642126931
}
#Debug simulation 
Total elapsed time: 7.659873347263783. Arrivals time: 0.2942521534860134 Scheduler time: 7.216886268462986 Scheduler overhead time: 0.05295228725299239 Adapter cache time: 0.01669081673026085 Engine time: 0.05422642780467868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 9.654041341040283,
    "estimated_duration": 3600.0571406789313,
    "input_throughput": 5424.931948807025,
    "output_throughput": 4738.340068897626,
    "total_throughput": 10163.272017704652,
    "itl": 111.3967839149323,
    "ttft": 2085848.5814072988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.547184455287632,
    "arrivals": 750836,
    "finished_requests": 79133,
    "scheduler_time": 164.40008035284635
}
#Debug simulation 
Total elapsed time: 9.654128761962056. Arrivals time: 0.2660339721478522 Scheduler time: 9.252989661879838 Scheduler overhead time: 0.04943083692342043 Adapter cache time: 0.012751545291393995 Engine time: 0.05032187467440963 
