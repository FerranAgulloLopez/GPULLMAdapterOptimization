INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:51 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1764322333037853,
    "estimated_duration": 3599.88998303996,
    "input_throughput": 704.055960582356,
    "output_throughput": 615.6682594306377,
    "total_throughput": 1319.7242200129936,
    "itl": 22.95811318589458,
    "ttft": 6623.251270402961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1765382969751954. Arrivals time: 0.037063096184283495 Scheduler time: 0.7562858439050615 Scheduler overhead time: 0.13029467267915606 Adapter cache time: 0.053519914392381907 Engine time: 0.1341922516003251 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1432861289940774,
    "estimated_duration": 3599.889944516014,
    "input_throughput": 704.0559681167567,
    "output_throughput": 615.6682660191643,
    "total_throughput": 1319.724234135921,
    "itl": 22.958441341323752,
    "ttft": 6623.237746234207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1433700588531792. Arrivals time: 0.03551660384982824 Scheduler time: 0.735909366980195 Scheduler overhead time: 0.12929515913128853 Adapter cache time: 0.05325085390359163 Engine time: 0.12458279263228178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1492309351451695,
    "estimated_duration": 3599.878352614845,
    "input_throughput": 704.0582352342536,
    "output_throughput": 615.6702485210695,
    "total_throughput": 1319.7284837553232,
    "itl": 22.958644406102298,
    "ttft": 6623.169503041142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1493063722737134. Arrivals time: 0.03590443218126893 Scheduler time: 0.7422690563835204 Scheduler overhead time: 0.12801169976592064 Adapter cache time: 0.05288916639983654 Engine time: 0.12593539152294397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1508427299559116,
    "estimated_duration": 3599.8786732584567,
    "input_throughput": 704.0581725233136,
    "output_throughput": 615.6701936829069,
    "total_throughput": 1319.7283662062205,
    "itl": 22.958454231160434,
    "ttft": 6623.212081221998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.150915150064975. Arrivals time: 0.03579514427110553 Scheduler time: 0.7401251108385623 Scheduler overhead time: 0.1294794655404985 Adapter cache time: 0.052606231067329645 Engine time: 0.12787214759737253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1519203167408705,
    "estimated_duration": 3599.8756675649474,
    "input_throughput": 704.0587603722493,
    "output_throughput": 615.6707077328564,
    "total_throughput": 1319.7294681051055,
    "itl": 22.958617168781593,
    "ttft": 6623.127338156919,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1519984267652035. Arrivals time: 0.035967514384537935 Scheduler time: 0.7426056312397122 Scheduler overhead time: 0.12899446161463857 Adapter cache time: 0.052952594589442015 Engine time: 0.12670926237478852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.160321619361639,
    "estimated_duration": 3599.8690745643316,
    "input_throughput": 704.0600498246555,
    "output_throughput": 615.6718353064629,
    "total_throughput": 1319.7318851311184,
    "itl": 22.958329536948185,
    "ttft": 6623.140969110296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.160383454989642. Arrivals time: 0.03627327689900994 Scheduler time: 0.7508023586124182 Scheduler overhead time: 0.12825097981840372 Adapter cache time: 0.0531688635237515 Engine time: 0.12674714485183358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1871213880367577,
    "estimated_duration": 3599.86914278942,
    "input_throughput": 704.0600364812375,
    "output_throughput": 615.6718236381872,
    "total_throughput": 1319.7318601194247,
    "itl": 22.9585032284484,
    "ttft": 6623.176934645733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337262,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1871879110112786. Arrivals time: 0.03669453039765358 Scheduler time: 0.772661526221782 Scheduler overhead time: 0.12908265367150307 Adapter cache time: 0.0532777551561594 Engine time: 0.13040705816820264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1743799331597984,
    "estimated_duration": 3599.7765346875935,
    "input_throughput": 679.3171677286415,
    "output_throughput": 609.2486516500761,
    "total_throughput": 1288.5658193787176,
    "itl": 23.08642747516898,
    "ttft": 6432.228429453685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 10134,
    "finished_requests": 10116,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1744568264111876. Arrivals time: 0.03579009836539626 Scheduler time: 0.7589960573241115 Scheduler overhead time: 0.12976036965847015 Adapter cache time: 0.05198858352378011 Engine time: 0.12924664421007037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.180068725720048,
    "estimated_duration": 3599.7835703837195,
    "input_throughput": 679.3158400184968,
    "output_throughput": 609.2474608872722,
    "total_throughput": 1288.563300905769,
    "itl": 23.086666828862317,
    "ttft": 6432.336165424998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489667,
    "arrivals": 10134,
    "finished_requests": 10116,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1801323317922652. Arrivals time: 0.03604698507115245 Scheduler time: 0.7694912799634039 Scheduler overhead time: 0.12888183910399675 Adapter cache time: 0.05209194263443351 Engine time: 0.12843788089230657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1743228370323777,
    "estimated_duration": 3599.7686637311094,
    "input_throughput": 679.3186530673856,
    "output_throughput": 609.2499837827972,
    "total_throughput": 1288.5686368501829,
    "itl": 23.087001199091137,
    "ttft": 6432.279178050674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 10134,
    "finished_requests": 10116,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1744049587287009. Arrivals time: 0.036008769646286964 Scheduler time: 0.7600682680495083 Scheduler overhead time: 0.1303774998523295 Adapter cache time: 0.052311600651592016 Engine time: 0.1303485338576138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.172556865029037,
    "estimated_duration": 3599.7690674845426,
    "input_throughput": 679.3185768743763,
    "output_throughput": 609.2499154487547,
    "total_throughput": 1288.5684923231308,
    "itl": 23.086653527077107,
    "ttft": 6432.242178031756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 10134,
    "finished_requests": 10116,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1726552969776094. Arrivals time: 0.03612754913046956 Scheduler time: 0.7615812532603741 Scheduler overhead time: 0.12846330227330327 Adapter cache time: 0.05235959589481354 Engine time: 0.1288163331337273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1759266559965909,
    "estimated_duration": 3599.7624727419097,
    "input_throughput": 679.3198213818165,
    "output_throughput": 609.2510315908396,
    "total_throughput": 1288.570852972656,
    "itl": 23.086533348427853,
    "ttft": 6432.146337996063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 10134,
    "finished_requests": 10116,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1759891118854284. Arrivals time: 0.035998756531625986 Scheduler time: 0.7646218123845756 Scheduler overhead time: 0.12891012011095881 Adapter cache time: 0.052064808551222086 Engine time: 0.12906103022396564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1803686302155256,
    "estimated_duration": 3599.761450926229,
    "input_throughput": 679.3200142111623,
    "output_throughput": 609.2512045307041,
    "total_throughput": 1288.5712187418665,
    "itl": 23.08645552676059,
    "ttft": 6432.1234230068485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 10134,
    "finished_requests": 10116,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1804381320253015. Arrivals time: 0.03607747284695506 Scheduler time: 0.7668590154498816 Scheduler overhead time: 0.12935028551146388 Adapter cache time: 0.05211373511701822 Engine time: 0.13062511896714568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.191918437834829,
    "estimated_duration": 3599.761892540818,
    "input_throughput": 679.3199308729755,
    "output_throughput": 609.2511297884772,
    "total_throughput": 1288.5710606614527,
    "itl": 23.08664536007139,
    "ttft": 6432.125981884672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 10134,
    "finished_requests": 10116,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1919957278296351. Arrivals time: 0.03646342223510146 Scheduler time: 0.776700337883085 Scheduler overhead time: 0.1296328972093761 Adapter cache time: 0.05213611153885722 Engine time: 0.13179591484367847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.099561960902065,
    "estimated_duration": 3600.009685540552,
    "input_throughput": 641.1960526860083,
    "output_throughput": 557.3404449601442,
    "total_throughput": 1198.5364976461526,
    "itl": 22.522174730299184,
    "ttft": 5362.773840224033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0996270468458533. Arrivals time: 0.03409504750743508 Scheduler time: 0.6917922152206302 Scheduler overhead time: 0.1301302253268659 Adapter cache time: 0.04964066809043288 Engine time: 0.12783117266371846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1007157238200307,
    "estimated_duration": 3600.0131498829214,
    "input_throughput": 641.195435654192,
    "output_throughput": 557.3399086237373,
    "total_throughput": 1198.5353442779294,
    "itl": 22.52239149097818,
    "ttft": 5362.820724173136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489666,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.100807431153953. Arrivals time: 0.0374025609344244 Scheduler time: 0.6874137627892196 Scheduler overhead time: 0.13031587190926075 Adapter cache time: 0.049337859731167555 Engine time: 0.13017725851386786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0996612692251801,
    "estimated_duration": 3600.0218905449015,
    "input_throughput": 641.1938788657234,
    "output_throughput": 557.3385554320353,
    "total_throughput": 1198.5324342977588,
    "itl": 22.52252603168759,
    "ttft": 5362.887094445156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0997658330015838. Arrivals time: 0.03478594310581684 Scheduler time: 0.6890293029136956 Scheduler overhead time: 0.13155807740986347 Adapter cache time: 0.049643410835415125 Engine time: 0.12888589454814792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1065181200392544,
    "estimated_duration": 3600.0219113470666,
    "input_throughput": 641.1938751606846,
    "output_throughput": 557.3385522115414,
    "total_throughput": 1198.5324273722258,
    "itl": 22.522224837265632,
    "ttft": 5362.899302197575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939695,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.106576964724809. Arrivals time: 0.03458430198952556 Scheduler time: 0.694579656701535 Scheduler overhead time: 0.13138439413160086 Adapter cache time: 0.049544306471943855 Engine time: 0.13034179154783487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1013098820112646,
    "estimated_duration": 3600.0198040640907,
    "input_throughput": 641.1942504855468,
    "output_throughput": 557.3388784514252,
    "total_throughput": 1198.5331289369722,
    "itl": 22.522561114539613,
    "ttft": 5362.778231474574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.101372394245118. Arrivals time: 0.03433406678959727 Scheduler time: 0.6929884450510144 Scheduler overhead time: 0.13038234040141106 Adapter cache time: 0.049545399844646454 Engine time: 0.12812215834856033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1072393162176013,
    "estimated_duration": 3600.019679499198,
    "input_throughput": 641.1942726716181,
    "output_throughput": 557.3388977360025,
    "total_throughput": 1198.5331704076207,
    "itl": 22.52217855974629,
    "ttft": 5362.72421955216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1073014130815864. Arrivals time: 0.034485109616070986 Scheduler time: 0.6953989136964083 Scheduler overhead time: 0.1308431513607502 Adapter cache time: 0.04939965484663844 Engine time: 0.13078475836664438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1036852169781923,
    "estimated_duration": 3600.019650505594,
    "input_throughput": 641.1942778356267,
    "output_throughput": 557.3389022246622,
    "total_throughput": 1198.533180060289,
    "itl": 22.522605296519053,
    "ttft": 5362.789559272714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1037573562934995. Arrivals time: 0.034313452895730734 Scheduler time: 0.689911175519228 Scheduler overhead time: 0.13161622220650315 Adapter cache time: 0.04955303017050028 Engine time: 0.13173019420355558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.095764079131186,
    "estimated_duration": 3598.994652803639,
    "input_throughput": 628.6558381623257,
    "output_throughput": 546.6612734385029,
    "total_throughput": 1175.3171116008286,
    "itl": 22.43934475822488,
    "ttft": 7862.449011086615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0958407162688673. Arrivals time: 0.03382999589666724 Scheduler time: 0.685598193667829 Scheduler overhead time: 0.13071480905637145 Adapter cache time: 0.04862926434725523 Engine time: 0.13093796325847507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0802506213076413,
    "estimated_duration": 3598.9922862434396,
    "input_throughput": 628.656251542452,
    "output_throughput": 546.6616329021276,
    "total_throughput": 1175.3178844445795,
    "itl": 22.44006241435195,
    "ttft": 7862.45685171352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489668,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.080360365100205. Arrivals time: 0.033425820991396904 Scheduler time: 0.6727673285640776 Scheduler overhead time: 0.13020751904696226 Adapter cache time: 0.04843978816643357 Engine time: 0.12952090986073017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0988988019526005,
    "estimated_duration": 3599.0080609467227,
    "input_throughput": 628.6534960982665,
    "output_throughput": 546.6592368460729,
    "total_throughput": 1175.3127329443394,
    "itl": 22.439952016914948,
    "ttft": 7862.382018845792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0989697119221091. Arrivals time: 0.03353901207447052 Scheduler time: 0.6884793369099498 Scheduler overhead time: 0.13159809354692698 Adapter cache time: 0.04857424693182111 Engine time: 0.13044907990843058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.082525767851621,
    "estimated_duration": 3599.01218776521,
    "input_throughput": 628.6527752507853,
    "output_throughput": 546.6586100175635,
    "total_throughput": 1175.3113852683489,
    "itl": 22.440003119977494,
    "ttft": 7862.492862882312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4391118016093971,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0825999840162694. Arrivals time: 0.03319289116188884 Scheduler time: 0.6751844948157668 Scheduler overhead time: 0.1312269982881844 Adapter cache time: 0.04851488070562482 Engine time: 0.1284229476004839 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0965109039098024,
    "estimated_duration": 3599.0076833215335,
    "input_throughput": 628.6535620596137,
    "output_throughput": 546.6592942041882,
    "total_throughput": 1175.312856263802,
    "itl": 22.440437744317276,
    "ttft": 7862.328514463986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0965652279555798. Arrivals time: 0.033689429983496666 Scheduler time: 0.6866367519833148 Scheduler overhead time: 0.1312011331319809 Adapter cache time: 0.04857383156195283 Engine time: 0.1301672044210136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0913296528160572,
    "estimated_duration": 3599.0075025430706,
    "input_throughput": 628.6535936369373,
    "output_throughput": 546.6593216629326,
    "total_throughput": 1175.31291529987,
    "itl": 22.43952519540613,
    "ttft": 7862.301188642355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0914234747178853. Arrivals time: 0.034372007474303246 Scheduler time: 0.6828615572303534 Scheduler overhead time: 0.13027553306892514 Adapter cache time: 0.04816650738939643 Engine time: 0.1294137709774077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0845560259185731,
    "estimated_duration": 3599.006926435141,
    "input_throughput": 628.6536942681191,
    "output_throughput": 546.659409168952,
    "total_throughput": 1175.313103437071,
    "itl": 22.44036189796607,
    "ttft": 7862.358050469613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0846119858324528. Arrivals time: 0.0332654039375484 Scheduler time: 0.6752033801749349 Scheduler overhead time: 0.13116397708654404 Adapter cache time: 0.048655901569873095 Engine time: 0.13011394254863262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0593110220506787,
    "estimated_duration": 3599.825114233693,
    "input_throughput": 589.9736605543686,
    "output_throughput": 517.9882191018432,
    "total_throughput": 1107.9618796562117,
    "itl": 22.207256095015843,
    "ttft": 6205.844983345805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0593680879101157. Arrivals time: 0.03328288160264492 Scheduler time: 0.6499865832738578 Scheduler overhead time: 0.13205901952460408 Adapter cache time: 0.04618404619395733 Engine time: 0.13119932264089584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.06229790719226,
    "estimated_duration": 3599.8265047446316,
    "input_throughput": 589.9734326642669,
    "output_throughput": 517.9880190176771,
    "total_throughput": 1107.9614516819438,
    "itl": 22.207518693121337,
    "ttft": 6206.051344509231,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489667,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0623909728601575. Arrivals time: 0.03295120410621166 Scheduler time: 0.6517250197939575 Scheduler overhead time: 0.132009815890342 Adapter cache time: 0.04634074168279767 Engine time: 0.1324262795969844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0439455029554665,
    "estimated_duration": 3599.8136459967777,
    "input_throughput": 589.9755400843605,
    "output_throughput": 517.9898693016036,
    "total_throughput": 1107.9654093859642,
    "itl": 22.207697268150373,
    "ttft": 6206.052469140123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0440374370664358. Arrivals time: 0.03231390751898289 Scheduler time: 0.6386026786640286 Scheduler overhead time: 0.13110006833449006 Adapter cache time: 0.045829853508621454 Engine time: 0.12944912444800138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0545145808719099,
    "estimated_duration": 3599.8211979056664,
    "input_throughput": 589.9743024002423,
    "output_throughput": 517.9887826331045,
    "total_throughput": 1107.9630850333467,
    "itl": 22.207444880053384,
    "ttft": 6206.124792656933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0545874410308897. Arrivals time: 0.03249181108549237 Scheduler time: 0.6463847989216447 Scheduler overhead time: 0.13175641233101487 Adapter cache time: 0.0456369542516768 Engine time: 0.13166005536913872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0512249250896275,
    "estimated_duration": 3599.8136186674083,
    "input_throughput": 589.9755445633867,
    "output_throughput": 517.9898732341229,
    "total_throughput": 1107.9654177975096,
    "itl": 22.20771926951163,
    "ttft": 6206.058023062292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0513266869820654. Arrivals time: 0.03230041265487671 Scheduler time: 0.6435504308901727 Scheduler overhead time: 0.13281411211937666 Adapter cache time: 0.046272539999336004 Engine time: 0.12978509394451976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0497231618501246,
    "estimated_duration": 3599.828692752973,
    "input_throughput": 589.9730740730943,
    "output_throughput": 517.987704179888,
    "total_throughput": 1107.9607782529824,
    "itl": 22.207159240868734,
    "ttft": 6206.054865098442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.049776169937104. Arrivals time: 0.032166707795113325 Scheduler time: 0.6421787394210696 Scheduler overhead time: 0.1320857461541891 Adapter cache time: 0.046068933326750994 Engine time: 0.13048826809972525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.061413642950356,
    "estimated_duration": 3599.8288815989667,
    "input_throughput": 589.9730431232756,
    "output_throughput": 517.9876770064012,
    "total_throughput": 1107.9607201296767,
    "itl": 22.207492663429907,
    "ttft": 6206.0941043078365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0614905320107937. Arrivals time: 0.032842890825122595 Scheduler time: 0.652641189750284 Scheduler overhead time: 0.13188013713806868 Adapter cache time: 0.046061212196946144 Engine time: 0.13131777523085475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9527451382018626,
    "estimated_duration": 3599.7357209655424,
    "input_throughput": 465.6216816801269,
    "output_throughput": 416.8425452070467,
    "total_throughput": 882.4642268871736,
    "itl": 22.009336770798686,
    "ttft": 5797.043921730566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.952853097114712. Arrivals time: 0.02849529590457678 Scheduler time: 0.5444232923910022 Scheduler overhead time: 0.13169865775853395 Adapter cache time: 0.04854758223518729 Engine time: 0.13226462714374065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.949027196969837,
    "estimated_duration": 3599.738310573844,
    "input_throughput": 465.6213467175079,
    "output_throughput": 416.8422453355498,
    "total_throughput": 882.4635920530577,
    "itl": 22.0104870882212,
    "ttft": 5797.024159267517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489668,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9490933720953763. Arrivals time: 0.028690512757748365 Scheduler time: 0.542417086660862 Scheduler overhead time: 0.13165185460820794 Adapter cache time: 0.048363156616687775 Engine time: 0.12947071576490998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9582428000867367,
    "estimated_duration": 3599.730109063345,
    "input_throughput": 465.62240757436325,
    "output_throughput": 416.84319505565327,
    "total_throughput": 882.4656026300165,
    "itl": 22.010340371802197,
    "ttft": 5796.8365928339235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9583038841374218. Arrivals time: 0.02855294616892934 Scheduler time: 0.5444603711366653 Scheduler overhead time: 0.13201618660241365 Adapter cache time: 0.04841172322630882 Engine time: 0.13745309505611658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9391686138696969,
    "estimated_duration": 3599.7337199824783,
    "input_throughput": 465.6219405051323,
    "output_throughput": 416.8427769172059,
    "total_throughput": 882.4647174223381,
    "itl": 22.01007095512862,
    "ttft": 5796.980110362785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4391118016093971,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9392328509129584. Arrivals time: 0.028452251572161913 Scheduler time: 0.5344354836270213 Scheduler overhead time: 0.13095941254869103 Adapter cache time: 0.04859326500445604 Engine time: 0.12959102354943752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9610096197575331,
    "estimated_duration": 3599.7480011211155,
    "input_throughput": 465.62009326152446,
    "output_throughput": 416.84112319325493,
    "total_throughput": 882.4612164547793,
    "itl": 22.010500072419976,
    "ttft": 5796.855964020723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9610714889131486. Arrivals time: 0.028348281513899565 Scheduler time: 0.5404213331639767 Scheduler overhead time: 0.13239499367773533 Adapter cache time: 0.048819201067090034 Engine time: 0.1438064114190638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9516367870382965,
    "estimated_duration": 3599.744782842132,
    "input_throughput": 465.62050953974716,
    "output_throughput": 416.84149586162647,
    "total_throughput": 882.4620054013736,
    "itl": 22.009530739409556,
    "ttft": 5797.044863268647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9517004899680614. Arrivals time: 0.028564912732690573 Scheduler time: 0.5438718730583787 Scheduler overhead time: 0.13361133635044098 Adapter cache time: 0.04878420056775212 Engine time: 0.12913274904713035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.943118398077786,
    "estimated_duration": 3599.744773292268,
    "input_throughput": 465.6205107750049,
    "output_throughput": 416.841496967477,
    "total_throughput": 882.4620077424819,
    "itl": 22.010520177955797,
    "ttft": 5796.984225657676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9431788371875882. Arrivals time: 0.028426382690668106 Scheduler time: 0.5365343326702714 Scheduler overhead time: 0.1322832596488297 Adapter cache time: 0.04851218918338418 Engine time: 0.1303060078062117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9235179978422821,
    "estimated_duration": 3599.6373115236825,
    "input_throughput": 435.4816511601454,
    "output_throughput": 385.6388518798881,
    "total_throughput": 821.1205030400336,
    "itl": 21.581482373705132,
    "ttft": 3408.1556768729974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9235823857598007. Arrivals time: 0.027502448298037052 Scheduler time: 0.5165316248312593 Scheduler overhead time: 0.1324585764668882 Adapter cache time: 0.046249158680438995 Engine time: 0.13333152513951063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9174005673266947,
    "estimated_duration": 3599.6373115236825,
    "input_throughput": 435.4816511601454,
    "output_throughput": 385.6388518798881,
    "total_throughput": 821.1205030400336,
    "itl": 21.58172238123755,
    "ttft": 3408.1492300709747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9174497690983117. Arrivals time: 0.026999822817742825 Scheduler time: 0.5090508256107569 Scheduler overhead time: 0.13311552861705422 Adapter cache time: 0.046428519301116467 Engine time: 0.1337543991394341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.927398125641048,
    "estimated_duration": 3599.6373115236825,
    "input_throughput": 435.4816511601454,
    "output_throughput": 385.6388518798881,
    "total_throughput": 821.1205030400336,
    "itl": 21.581909389560984,
    "ttft": 3408.0922088395864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9274728680029511. Arrivals time: 0.027651614975184202 Scheduler time: 0.5200477987527847 Scheduler overhead time: 0.13299574051052332 Adapter cache time: 0.0465450556948781 Engine time: 0.13227102486416698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.916187406051904,
    "estimated_duration": 3599.6373115236825,
    "input_throughput": 435.4816511601454,
    "output_throughput": 385.6388518798881,
    "total_throughput": 821.1205030400336,
    "itl": 21.581570249925022,
    "ttft": 3408.100104231602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.439111801609397,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9162439918145537. Arrivals time: 0.028302463237196207 Scheduler time: 0.5092520453035831 Scheduler overhead time: 0.13273268844932318 Adapter cache time: 0.04593693418428302 Engine time: 0.132440781686455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9123484189622104,
    "estimated_duration": 3599.6373115236825,
    "input_throughput": 435.4816511601454,
    "output_throughput": 385.6388518798881,
    "total_throughput": 821.1205030400336,
    "itl": 21.58185516151765,
    "ttft": 3408.0948695656743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.912421990185976. Arrivals time: 0.027417150791734457 Scheduler time: 0.5081349983811378 Scheduler overhead time: 0.13225812371820211 Adapter cache time: 0.046094323974102736 Engine time: 0.13114187074825168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9317618012428284,
    "estimated_duration": 3599.6373115236825,
    "input_throughput": 435.4816511601454,
    "output_throughput": 385.6388518798881,
    "total_throughput": 821.1205030400336,
    "itl": 21.5814462748046,
    "ttft": 3408.099717154685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.931813184171915. Arrivals time: 0.027342674788087606 Scheduler time: 0.5131735117174685 Scheduler overhead time: 0.1328864968381822 Adapter cache time: 0.04606115538626909 Engine time: 0.13336289348080754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9157308479771018,
    "estimated_duration": 3599.6373115236825,
    "input_throughput": 435.4816511601454,
    "output_throughput": 385.6388518798881,
    "total_throughput": 821.1205030400336,
    "itl": 21.58180167276448,
    "ttft": 3408.09168681363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9158037891611457. Arrivals time: 0.027032324112951756 Scheduler time: 0.5116753149777651 Scheduler overhead time: 0.1326672756113112 Adapter cache time: 0.045970101840794086 Engine time: 0.1308244653046131 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9139866069890559,
    "estimated_duration": 3597.8429513791693,
    "input_throughput": 409.5634578588659,
    "output_throughput": 373.2283532512877,
    "total_throughput": 782.7918111101535,
    "itl": 21.47668307199742,
    "ttft": 6484.272056989326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.914039365015924. Arrivals time: 0.02701175259426236 Scheduler time: 0.5082970447838306 Scheduler overhead time: 0.133092753123492 Adapter cache time: 0.044583247508853674 Engine time: 0.13325030868873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9012572127394378,
    "estimated_duration": 3597.8429513791693,
    "input_throughput": 409.5634578588659,
    "output_throughput": 373.2283532512877,
    "total_throughput": 782.7918111101535,
    "itl": 21.476911517727814,
    "ttft": 6484.2405949987005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9013197650201619. Arrivals time: 0.02695802878588438 Scheduler time: 0.49798508640378714 Scheduler overhead time: 0.13119821855798364 Adapter cache time: 0.0440636295825243 Engine time: 0.13356594229117036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9117324077524245,
    "estimated_duration": 3597.8429513791693,
    "input_throughput": 409.5634578588659,
    "output_throughput": 373.2283532512877,
    "total_throughput": 782.7918111101535,
    "itl": 21.477126432596435,
    "ttft": 6484.258847991195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9118440309539437. Arrivals time: 0.02674255706369877 Scheduler time: 0.5037675751373172 Scheduler overhead time: 0.13295465568080544 Adapter cache time: 0.04442051891237497 Engine time: 0.135811987798661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8960272101685405,
    "estimated_duration": 3597.8429513791693,
    "input_throughput": 409.5634578588659,
    "output_throughput": 373.2283532512877,
    "total_throughput": 782.7918111101535,
    "itl": 21.476840864783767,
    "ttft": 6484.220860991953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8962463522329926. Arrivals time: 0.026724955532699823 Scheduler time: 0.492965972982347 Scheduler overhead time: 0.1322376886382699 Adapter cache time: 0.04469128372147679 Engine time: 0.13165797479450703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8979154112748802,
    "estimated_duration": 3597.8429513791693,
    "input_throughput": 409.5634578588659,
    "output_throughput": 373.2283532512877,
    "total_throughput": 782.7918111101535,
    "itl": 21.47696685288661,
    "ttft": 6484.186557637437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8979841293767095. Arrivals time: 0.0267368801869452 Scheduler time: 0.4937820225022733 Scheduler overhead time: 0.1329557504504919 Adapter cache time: 0.04429347813129425 Engine time: 0.13241891749203205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9028487950563431,
    "estimated_duration": 3597.8429513791693,
    "input_throughput": 409.5634578588659,
    "output_throughput": 373.2283532512877,
    "total_throughput": 782.7918111101535,
    "itl": 21.476677207823506,
    "ttft": 6484.11310196981,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9029021542519331. Arrivals time: 0.026979409158229828 Scheduler time: 0.49846343183889985 Scheduler overhead time: 0.13277254346758127 Adapter cache time: 0.044592094141989946 Engine time: 0.13245059410110116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.90661550918594,
    "estimated_duration": 3597.8429513791693,
    "input_throughput": 409.5634578588659,
    "output_throughput": 373.2283532512877,
    "total_throughput": 782.7918111101535,
    "itl": 21.47692053882024,
    "ttft": 6484.192554892697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9066908620297909. Arrivals time: 0.02680044947192073 Scheduler time: 0.4999434342607856 Scheduler overhead time: 0.13334879325702786 Adapter cache time: 0.04440467106178403 Engine time: 0.13452018285170197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8560365419834852,
    "estimated_duration": 3599.9127154248035,
    "input_throughput": 358.9903706450004,
    "output_throughput": 328.35268336791177,
    "total_throughput": 687.3430540129121,
    "itl": 21.23248105331888,
    "ttft": 4018.4260553645972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8560855691321194. Arrivals time: 0.02541287336498499 Scheduler time: 0.4530004570260644 Scheduler overhead time: 0.13254105392843485 Adapter cache time: 0.04228166816756129 Engine time: 0.13463365472853184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8718195869587362,
    "estimated_duration": 3599.9127154248035,
    "input_throughput": 358.9903706450004,
    "output_throughput": 328.35268336791177,
    "total_throughput": 687.3430540129121,
    "itl": 21.23269356769109,
    "ttft": 4018.4702823519283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8718826686963439. Arrivals time: 0.02552569005638361 Scheduler time: 0.46333591965958476 Scheduler overhead time: 0.13690551929175854 Adapter cache time: 0.042412697337567806 Engine time: 0.13460591481998563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8573181098327041,
    "estimated_duration": 3599.9127154248035,
    "input_throughput": 358.9903706450004,
    "output_throughput": 328.35268336791177,
    "total_throughput": 687.3430540129121,
    "itl": 21.232908657137227,
    "ttft": 4018.223091494019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8573862048797309. Arrivals time: 0.02545530768111348 Scheduler time: 0.4528965032659471 Scheduler overhead time: 0.13293573772534728 Adapter cache time: 0.042526512406766415 Engine time: 0.13594029005616903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8572320626117289,
    "estimated_duration": 3599.9127154248035,
    "input_throughput": 358.9903706450004,
    "output_throughput": 328.35268336791177,
    "total_throughput": 687.3430540129121,
    "itl": 21.232601338335204,
    "ttft": 4018.169932987094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8572800699621439. Arrivals time: 0.02534898603335023 Scheduler time: 0.4534438750706613 Scheduler overhead time: 0.1330281887203455 Adapter cache time: 0.042416410986334085 Engine time: 0.13453472079709172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8584731728769839,
    "estimated_duration": 3599.9127154248035,
    "input_throughput": 358.9903706450004,
    "output_throughput": 328.35268336791177,
    "total_throughput": 687.3430540129121,
    "itl": 21.23279650439586,
    "ttft": 4018.2771125961317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8586247037164867. Arrivals time: 0.025536034256219864 Scheduler time: 0.4562487262301147 Scheduler overhead time: 0.13327667489647865 Adapter cache time: 0.04227333841845393 Engine time: 0.13321369467303157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8492059693671763,
    "estimated_duration": 3599.9127154248035,
    "input_throughput": 358.9903706450004,
    "output_throughput": 328.35268336791177,
    "total_throughput": 687.3430540129121,
    "itl": 21.23249899361305,
    "ttft": 4018.2332633749934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8492748541757464. Arrivals time: 0.025544514413923025 Scheduler time: 0.44655391620472074 Scheduler overhead time: 0.13351358333602548 Adapter cache time: 0.043619001284241676 Engine time: 0.13169137760996819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8551603360101581,
    "estimated_duration": 3599.9127154248035,
    "input_throughput": 358.9903706450004,
    "output_throughput": 328.35268336791177,
    "total_throughput": 687.3430540129121,
    "itl": 21.232722383781923,
    "ttft": 4018.3004034980722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8552209050394595. Arrivals time: 0.02507963916286826 Scheduler time: 0.4527025409042835 Scheduler overhead time: 0.13248339388519526 Adapter cache time: 0.042597202118486166 Engine time: 0.13344895793125033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8293540207669139,
    "estimated_duration": 3598.503303736297,
    "input_throughput": 342.1736472275953,
    "output_throughput": 308.8089425529214,
    "total_throughput": 650.9825897805167,
    "itl": 21.21094088855572,
    "ttft": 2130.3934218562463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8294209549203515. Arrivals time: 0.02452099695801735 Scheduler time: 0.42670850874856114 Scheduler overhead time: 0.13324191607534885 Adapter cache time: 0.040939063765108585 Engine time: 0.13509188639000058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8302916139364243,
    "estimated_duration": 3598.503303736297,
    "input_throughput": 342.1736472275953,
    "output_throughput": 308.8089425529214,
    "total_throughput": 650.9825897805167,
    "itl": 21.211091310136503,
    "ttft": 2130.4623339085542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8303462220355868. Arrivals time: 0.02500925911590457 Scheduler time: 0.42834141571074724 Scheduler overhead time: 0.1339913671836257 Adapter cache time: 0.04066464863717556 Engine time: 0.13398686284199357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8266253937035799,
    "estimated_duration": 3598.503303736297,
    "input_throughput": 342.1736472275953,
    "output_throughput": 308.8089425529214,
    "total_throughput": 650.9825897805167,
    "itl": 21.21126582217009,
    "ttft": 2130.414252190038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.826819506008178. Arrivals time: 0.024632218293845654 Scheduler time: 0.4256132342852652 Scheduler overhead time: 0.1344996583648026 Adapter cache time: 0.04087159316986799 Engine time: 0.13264509616419673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8332339809276164,
    "estimated_duration": 3598.503303736297,
    "input_throughput": 342.1736472275953,
    "output_throughput": 308.8089425529214,
    "total_throughput": 650.9825897805167,
    "itl": 21.21108658701879,
    "ttft": 2130.384715313195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4391118016093971,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8332854323089123. Arrivals time: 0.02456729719415307 Scheduler time: 0.4303421056829393 Scheduler overhead time: 0.133577024564147 Adapter cache time: 0.04090661182999611 Engine time: 0.1353989806957543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8296352913603187,
    "estimated_duration": 3598.503303736297,
    "input_throughput": 342.1736472275953,
    "output_throughput": 308.8089425529214,
    "total_throughput": 650.9825897805167,
    "itl": 21.211167550525058,
    "ttft": 2130.3532415611066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8296870510093868. Arrivals time: 0.02424008958041668 Scheduler time: 0.4301729998551309 Scheduler overhead time: 0.13272273819893599 Adapter cache time: 0.040909124072641134 Engine time: 0.1329138115979731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8401475599966943,
    "estimated_duration": 3598.503303736297,
    "input_throughput": 342.1736472275953,
    "output_throughput": 308.8089425529214,
    "total_throughput": 650.9825897805167,
    "itl": 21.210669949327468,
    "ttft": 2130.474987666118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8402078640647233. Arrivals time: 0.024862637743353844 Scheduler time: 0.43549378495663404 Scheduler overhead time: 0.13342163991183043 Adapter cache time: 0.041084006894379854 Engine time: 0.13638929510489106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8393283020704985,
    "estimated_duration": 3598.503303736297,
    "input_throughput": 342.1736472275953,
    "output_throughput": 308.8089425529214,
    "total_throughput": 650.9825897805167,
    "itl": 21.21119813809258,
    "ttft": 2130.3409220322924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8393788640387356. Arrivals time: 0.024828089866787195 Scheduler time: 0.4344172650016844 Scheduler overhead time: 0.13431464927271008 Adapter cache time: 0.040987986605614424 Engine time: 0.13604120444506407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.7930252491496503,
    "estimated_duration": 3599.408513770525,
    "input_throughput": 316.847891990264,
    "output_throughput": 274.13559650842876,
    "total_throughput": 590.9834884986927,
    "itl": 20.954739939950347,
    "ttft": 3882.1492512560467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7931812861934304. Arrivals time: 0.023656485602259636 Scheduler time: 0.39425626350566745 Scheduler overhead time: 0.13379095308482647 Adapter cache time: 0.03840533457696438 Engine time: 0.13405984919518232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8001412199810147,
    "estimated_duration": 3599.408513770525,
    "input_throughput": 316.847891990264,
    "output_throughput": 274.13559650842876,
    "total_throughput": 590.9834884986927,
    "itl": 20.954845783873647,
    "ttft": 3882.2736344546906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8002046439796686. Arrivals time: 0.02321953233331442 Scheduler time: 0.3995726518332958 Scheduler overhead time: 0.13403368974104524 Adapter cache time: 0.0385453337803483 Engine time: 0.1356664034537971 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.801515098195523,
    "estimated_duration": 3599.408513770525,
    "input_throughput": 316.847891990264,
    "output_throughput": 274.13559650842876,
    "total_throughput": 590.9834884986927,
    "itl": 20.95483169123772,
    "ttft": 3882.275727043241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48098376162815837,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8016816102899611. Arrivals time: 0.023430679459124804 Scheduler time: 0.40044131595641375 Scheduler overhead time: 0.13566790102049708 Adapter cache time: 0.03852336248382926 Engine time: 0.13413937343284488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7953192400746047,
    "estimated_duration": 3599.408513770525,
    "input_throughput": 316.847891990264,
    "output_throughput": 274.13559650842876,
    "total_throughput": 590.9834884986927,
    "itl": 20.954560864648844,
    "ttft": 3882.2563114367945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4391118016093971,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7953680767677724. Arrivals time: 0.023573054932057858 Scheduler time: 0.3967906846664846 Scheduler overhead time: 0.1339803426526487 Adapter cache time: 0.03836802393198013 Engine time: 0.1337151899933815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.806868027895689,
    "estimated_duration": 3599.408513770525,
    "input_throughput": 316.847891990264,
    "output_throughput": 274.13559650842876,
    "total_throughput": 590.9834884986927,
    "itl": 20.954926926385333,
    "ttft": 3882.3876467491637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924963,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8069543177261949. Arrivals time: 0.024387777782976627 Scheduler time: 0.40311332466080785 Scheduler overhead time: 0.13501402363181114 Adapter cache time: 0.03853586595505476 Engine time: 0.13652744935825467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8017705301754177,
    "estimated_duration": 3599.408513770525,
    "input_throughput": 316.847891990264,
    "output_throughput": 274.13559650842876,
    "total_throughput": 590.9834884986927,
    "itl": 20.954494840954805,
    "ttft": 3882.461779746549,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8018302889540792. Arrivals time: 0.023730875458568335 Scheduler time: 0.4002407449297607 Scheduler overhead time: 0.1347257373854518 Adapter cache time: 0.03837976465001702 Engine time: 0.13572136219590902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8018645839765668,
    "estimated_duration": 3599.408513770525,
    "input_throughput": 316.847891990264,
    "output_throughput": 274.13559650842876,
    "total_throughput": 590.9834884986927,
    "itl": 20.954899380827925,
    "ttft": 3882.408200294629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8019237359985709. Arrivals time: 0.023592684417963028 Scheduler time: 0.40057553350925446 Scheduler overhead time: 0.13425705442205071 Adapter cache time: 0.03858239250257611 Engine time: 0.13589629298076034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.7072457922622561,
    "estimated_duration": 3599.8640415108266,
    "input_throughput": 222.07422024318572,
    "output_throughput": 200.40173508809175,
    "total_throughput": 422.4759553312775,
    "itl": 20.540769051448446,
    "ttft": 4396.108032226936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7073304010555148. Arrivals time: 0.02029968984425068 Scheduler time: 0.3179017920047045 Scheduler overhead time: 0.1323961652815342 Adapter cache time: 0.035097439773380756 Engine time: 0.13299271510913968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7078377059660852,
    "estimated_duration": 3599.8640415108266,
    "input_throughput": 222.07422024318572,
    "output_throughput": 200.40173508809175,
    "total_throughput": 422.4759553312775,
    "itl": 20.54098495909805,
    "ttft": 4396.109605056276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896656,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7078910381533206. Arrivals time: 0.020565844140946865 Scheduler time: 0.31692443741485476 Scheduler overhead time: 0.13269072398543358 Adapter cache time: 0.0352572132833302 Engine time: 0.13383948802947998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7160323923453689,
    "estimated_duration": 3599.8640415108266,
    "input_throughput": 222.07422024318572,
    "output_throughput": 200.40173508809175,
    "total_throughput": 422.4759553312775,
    "itl": 20.54108589124392,
    "ttft": 4396.112842468522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7161304941400886. Arrivals time: 0.020552033558487892 Scheduler time: 0.3221992598846555 Scheduler overhead time: 0.13312473520636559 Adapter cache time: 0.03560821292921901 Engine time: 0.13556815357878804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7114542257040739,
    "estimated_duration": 3599.8640415108266,
    "input_throughput": 222.07422024318572,
    "output_throughput": 200.40173508809175,
    "total_throughput": 422.4759553312775,
    "itl": 20.540809566349004,
    "ttft": 4396.143008274794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939695,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7115034400485456. Arrivals time: 0.02049702638760209 Scheduler time: 0.31924109859392047 Scheduler overhead time: 0.13303507817909122 Adapter cache time: 0.03559826500713825 Engine time: 0.13448799308389425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7124262489378452,
    "estimated_duration": 3599.8640415108266,
    "input_throughput": 222.07422024318572,
    "output_throughput": 200.40173508809175,
    "total_throughput": 422.4759553312775,
    "itl": 20.54107311699759,
    "ttft": 4396.109836101869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7124842377379537. Arrivals time: 0.020791315007954836 Scheduler time: 0.3179831560701132 Scheduler overhead time: 0.13339139008894563 Adapter cache time: 0.03519983682781458 Engine time: 0.1365025951527059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.709496065042913,
    "estimated_duration": 3599.8640415108266,
    "input_throughput": 222.07422024318572,
    "output_throughput": 200.40173508809175,
    "total_throughput": 422.4759553312775,
    "itl": 20.540688923881646,
    "ttft": 4396.1341773024515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.709587958175689. Arrivals time: 0.020298152696341276 Scheduler time: 0.31695403903722763 Scheduler overhead time: 0.1327490950934589 Adapter cache time: 0.03561187395825982 Engine time: 0.1350614633411169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7208472732454538,
    "estimated_duration": 3599.8640415108266,
    "input_throughput": 222.07422024318572,
    "output_throughput": 200.40173508809175,
    "total_throughput": 422.4759553312775,
    "itl": 20.54101126734377,
    "ttft": 4396.126642520967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7208963790908456. Arrivals time: 0.02059935498982668 Scheduler time: 0.32229542965069413 Scheduler overhead time: 0.13778205448761582 Adapter cache time: 0.036076152231544256 Engine time: 0.13423458579927683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.69083197042346,
    "estimated_duration": 3599.372259265802,
    "input_throughput": 200.2843685157057,
    "output_throughput": 182.79492995098198,
    "total_throughput": 383.07929846668765,
    "itl": 20.512138343682953,
    "ttft": 5885.375316206527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6909045092761517. Arrivals time: 0.020048799458891153 Scheduler time: 0.3018188066780567 Scheduler overhead time: 0.13196023413911462 Adapter cache time: 0.03347123507410288 Engine time: 0.13490728801116347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6889550099149346,
    "estimated_duration": 3599.3657523495895,
    "input_throughput": 200.28473058883029,
    "output_throughput": 182.79526040678311,
    "total_throughput": 383.0799909956134,
    "itl": 20.67947869535869,
    "ttft": 5885.571610583018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.689006055239588. Arrivals time: 0.01957970065996051 Scheduler time: 0.3019741359166801 Scheduler overhead time: 0.13152390951290727 Adapter cache time: 0.03330972557887435 Engine time: 0.13429387100040913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6991518922150135,
    "estimated_duration": 3599.3657523495895,
    "input_throughput": 200.28473058883029,
    "output_throughput": 182.79526040678311,
    "total_throughput": 383.0799909956134,
    "itl": 20.679555017904576,
    "ttft": 5885.591609557011,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.699200042989105. Arrivals time: 0.0201359735801816 Scheduler time: 0.30960957147181034 Scheduler overhead time: 0.1328936805948615 Adapter cache time: 0.03362654335796833 Engine time: 0.13456179853528738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.6974396179430187,
    "estimated_duration": 3599.372259265802,
    "input_throughput": 200.2843685157057,
    "output_throughput": 182.79492995098198,
    "total_throughput": 383.07929846668765,
    "itl": 20.512446853272284,
    "ttft": 5885.470801660014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.439111801609397,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6974955769255757. Arrivals time: 0.019888625480234623 Scheduler time: 0.30471757194027305 Scheduler overhead time: 0.13572552846744657 Adapter cache time: 0.03376427851617336 Engine time: 0.1339702708646655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6925117867067456,
    "estimated_duration": 3599.3657523495895,
    "input_throughput": 200.28473058883029,
    "output_throughput": 182.79526040678311,
    "total_throughput": 383.0799909956134,
    "itl": 20.679594122465616,
    "ttft": 5885.582448076001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6925939088687301. Arrivals time: 0.020201533567160368 Scheduler time: 0.30471601989120245 Scheduler overhead time: 0.13142591435462236 Adapter cache time: 0.033398010302335024 Engine time: 0.13437474612146616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.7065625921823084,
    "estimated_duration": 3599.372259265802,
    "input_throughput": 200.2843685157057,
    "output_throughput": 182.79492995098198,
    "total_throughput": 383.07929846668765,
    "itl": 20.512087001255537,
    "ttft": 5885.366959698287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7066165939904749. Arrivals time: 0.02021917002275586 Scheduler time: 0.3143876069225371 Scheduler overhead time: 0.1338083785958588 Adapter cache time: 0.033801254350692034 Engine time: 0.1350665600039065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6894810139201581,
    "estimated_duration": 3599.3657523495895,
    "input_throughput": 200.28473058883029,
    "output_throughput": 182.79526040678311,
    "total_throughput": 383.0799909956134,
    "itl": 20.6795195011983,
    "ttft": 5885.5489419579135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6895288089290261. Arrivals time: 0.020330311730504036 Scheduler time: 0.3025665474124253 Scheduler overhead time: 0.13259139470756054 Adapter cache time: 0.033317025285214186 Engine time: 0.13236743211746216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.657711423933506,
    "estimated_duration": 3599.433494054874,
    "input_throughput": 173.11974260094505,
    "output_throughput": 160.7408501797921,
    "total_throughput": 333.86059278073714,
    "itl": 20.313963886155857,
    "ttft": 16706.166873257982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6577695007435977. Arrivals time: 0.018384787254035473 Scheduler time: 0.27548489859327674 Scheduler overhead time: 0.1317166155204177 Adapter cache time: 0.031483163591474295 Engine time: 0.13219174556434155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.673321588896215,
    "estimated_duration": 3599.433494054874,
    "input_throughput": 173.11974260094505,
    "output_throughput": 160.7408501797921,
    "total_throughput": 333.86059278073714,
    "itl": 20.314263282621997,
    "ttft": 16706.100942459416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896683,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6734044440090656. Arrivals time: 0.01902455138042569 Scheduler time: 0.28501735674217343 Scheduler overhead time: 0.13136191852390766 Adapter cache time: 0.03170230472460389 Engine time: 0.1375747094862163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6596765727736056,
    "estimated_duration": 3599.433494054874,
    "input_throughput": 173.11974260094505,
    "output_throughput": 160.7408501797921,
    "total_throughput": 333.86059278073714,
    "itl": 20.314330781628353,
    "ttft": 16706.135620659385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.659726110752672. Arrivals time: 0.01890175510197878 Scheduler time: 0.27635502722114325 Scheduler overhead time: 0.1311262114904821 Adapter cache time: 0.03157131001353264 Engine time: 0.1330930395051837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.6680902461521327,
    "estimated_duration": 3599.433494054874,
    "input_throughput": 173.11974260094505,
    "output_throughput": 160.7408501797921,
    "total_throughput": 333.86059278073714,
    "itl": 20.314121765486757,
    "ttft": 16706.11118299868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4391118016093971,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6681569083593786. Arrivals time: 0.01913438644260168 Scheduler time: 0.28025388857349753 Scheduler overhead time: 0.13201943039894104 Adapter cache time: 0.03170129796490073 Engine time: 0.1363940923474729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6612429372034967,
    "estimated_duration": 3599.433494054874,
    "input_throughput": 173.11974260094505,
    "output_throughput": 160.7408501797921,
    "total_throughput": 333.86059278073714,
    "itl": 20.314308145937467,
    "ttft": 16706.129390133836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6613067961297929. Arrivals time: 0.018633371219038963 Scheduler time: 0.2772593260742724 Scheduler overhead time: 0.13181638065725565 Adapter cache time: 0.03170016221702099 Engine time: 0.13342489721253514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.6598734511062503,
    "estimated_duration": 3599.433494054874,
    "input_throughput": 173.11974260094505,
    "output_throughput": 160.7408501797921,
    "total_throughput": 333.86059278073714,
    "itl": 20.313878879050723,
    "ttft": 16706.167661740554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6599265150725842. Arrivals time: 0.018725558649748564 Scheduler time: 0.27758449921384454 Scheduler overhead time: 0.1305080666206777 Adapter cache time: 0.031510763335973024 Engine time: 0.13338572392240167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6619266560301185,
    "estimated_duration": 3599.433494054874,
    "input_throughput": 173.11974260094505,
    "output_throughput": 160.7408501797921,
    "total_throughput": 333.86059278073714,
    "itl": 20.314279936126862,
    "ttft": 16706.12108136147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6619882127270103. Arrivals time: 0.019074073061347008 Scheduler time: 0.2781215230934322 Scheduler overhead time: 0.13140428345650434 Adapter cache time: 0.031505195423960686 Engine time: 0.1335933138616383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.539560035802424,
    "estimated_duration": 3599.28417793585,
    "input_throughput": 116.92324895594855,
    "output_throughput": 96.55253178683404,
    "total_throughput": 213.4757807427826,
    "itl": 19.84465185290918,
    "ttft": 8785.534851467297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5396097912453115. Arrivals time: 0.015186784323304892 Scheduler time: 0.19900574255734682 Scheduler overhead time: 0.11872397223487496 Adapter cache time: 0.025680592749267817 Engine time: 0.11977075226604939 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5481853280216455,
    "estimated_duration": 3599.28417793585,
    "input_throughput": 116.92324895594855,
    "output_throughput": 96.55253178683404,
    "total_throughput": 213.4757807427826,
    "itl": 19.844937434658092,
    "ttft": 8785.549725636303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489666,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5482835611328483. Arrivals time: 0.015710287261754274 Scheduler time: 0.2060875939205289 Scheduler overhead time: 0.11872436199337244 Adapter cache time: 0.025809227488934994 Engine time: 0.12076542526483536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5371453710831702,
    "estimated_duration": 3599.28417793585,
    "input_throughput": 116.92324895594855,
    "output_throughput": 96.55253178683404,
    "total_throughput": 213.4757807427826,
    "itl": 19.844986500058642,
    "ttft": 8785.492525231564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5372088230215013. Arrivals time: 0.015261194203048944 Scheduler time: 0.19858004758134484 Scheduler overhead time: 0.11741189612075686 Adapter cache time: 0.025602418463677168 Engine time: 0.11904104193672538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.5516353659331799,
    "estimated_duration": 3599.28417793585,
    "input_throughput": 116.92324895594855,
    "output_throughput": 96.55253178683404,
    "total_throughput": 213.4757807427826,
    "itl": 19.844741333274886,
    "ttft": 8785.54010937583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.439111801609397,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5516916271299124. Arrivals time: 0.015319215599447489 Scheduler time: 0.19915913930162787 Scheduler overhead time: 0.1189218619838357 Adapter cache time: 0.025788072496652603 Engine time: 0.1197091294452548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5442467997781932,
    "estimated_duration": 3599.28417793585,
    "input_throughput": 116.92324895594855,
    "output_throughput": 96.55253178683404,
    "total_throughput": 213.4757807427826,
    "itl": 19.844964681043678,
    "ttft": 8785.530980080635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5442955680191517. Arrivals time: 0.01533515378832817 Scheduler time: 0.20157748647034168 Scheduler overhead time: 0.11803050711750984 Adapter cache time: 0.025789922568947077 Engine time: 0.1222150307148695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.5447383332066238,
    "estimated_duration": 3599.28417793585,
    "input_throughput": 116.92324895594855,
    "output_throughput": 96.55253178683404,
    "total_throughput": 213.4757807427826,
    "itl": 19.844589811330355,
    "ttft": 8785.50634889153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5447875019162893. Arrivals time: 0.015402848366647959 Scheduler time: 0.199794705491513 Scheduler overhead time: 0.1190707003697753 Adapter cache time: 0.025874935556203127 Engine time: 0.12337997788563371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5389906610362232,
    "estimated_duration": 3599.28417793585,
    "input_throughput": 116.92324895594855,
    "output_throughput": 96.55253178683404,
    "total_throughput": 213.4757807427826,
    "itl": 19.844931485713758,
    "ttft": 8785.55493299179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5390534391626716. Arrivals time: 0.015427595470100641 Scheduler time: 0.19977581035345793 Scheduler overhead time: 0.11807932145893574 Adapter cache time: 0.025886270217597485 Engine time: 0.11879439326003194 
