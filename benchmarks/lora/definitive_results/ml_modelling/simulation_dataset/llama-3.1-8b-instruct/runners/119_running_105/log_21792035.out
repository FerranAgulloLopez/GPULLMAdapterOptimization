INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_160_slots_16_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_160_slots_16_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [4320, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 8640, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 4320, 17280, 17280, 17280, 8640, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1620000 . Total input tokens: 361237859 . Total output tokens: 318173948
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 89.01487081311643,
    "estimated_duration": 3600.0046050490614,
    "input_throughput": 7171.523048551255,
    "output_throughput": 6234.716746895416,
    "total_throughput": 13406.23979544667,
    "itl": 85.96550231863563,
    "ttft": 1902503.1404725758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3521067364932944,
    "arrivals": 540089,
    "finished_requests": 104328,
    "scheduler_time": 286.59190378629313
}
#Debug simulation 
Total elapsed time: 89.01507647894323. Arrivals time: 0.5097417095676064 Scheduler time: 88.27619015239179 Scheduler overhead time: 0.08994186716154218 Adapter cache time: 0.01736230030655861 Engine time: 0.08777375845238566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_160_slots_16_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_160_slots_16_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [4320, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 8640, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 4320, 17280, 17280, 17280, 8640, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1620000 . Total input tokens: 361237859 . Total output tokens: 318173948
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 88.32377605838701,
    "estimated_duration": 3600.0164148372455,
    "input_throughput": 7071.6852553993,
    "output_throughput": 6144.115873704976,
    "total_throughput": 13215.801129104277,
    "itl": 83.60934069833439,
    "ttft": 1908657.508507284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5184932488668847,
    "arrivals": 540089,
    "finished_requests": 102819,
    "scheduler_time": 291.02801994480285
}
#Debug simulation 
Total elapsed time: 88.32396981539205. Arrivals time: 0.48710776260122657 Scheduler time: 87.60363925108686 Scheduler overhead time: 0.0918028368614614 Adapter cache time: 0.017963646911084652 Engine time: 0.08851865865290165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_160_slots_16_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_160_slots_16_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [4320, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 8640, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 4320, 17280, 17280, 17280, 8640, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1620000 . Total input tokens: 361237859 . Total output tokens: 318173948
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 88.7791873542592,
    "estimated_duration": 3600.03776998376,
    "input_throughput": 7172.179474138261,
    "output_throughput": 6235.068472656957,
    "total_throughput": 13407.247946795218,
    "itl": 85.96143186891408,
    "ttft": 1902451.10739722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1896848826156843,
    "arrivals": 540089,
    "finished_requests": 104337,
    "scheduler_time": 286.6055333291649
}
#Debug simulation 
Total elapsed time: 88.77934822207317. Arrivals time: 0.5108810281381011 Scheduler time: 88.03917252458632 Scheduler overhead time: 0.08950868202373385 Adapter cache time: 0.017537992913275957 Engine time: 0.08709983341395855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_160_slots_16_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_160_slots_16_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [4320, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 8640, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 4320, 17280, 17280, 17280, 8640, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1620000 . Total input tokens: 361237859 . Total output tokens: 318173948
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 88.45144385006279,
    "estimated_duration": 3600.092752138462,
    "input_throughput": 7071.923628877884,
    "output_throughput": 6144.163643245286,
    "total_throughput": 13216.08727212317,
    "itl": 83.60938328672334,
    "ttft": 1908628.070634893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4948818907328083,
    "arrivals": 540089,
    "finished_requests": 102823,
    "scheduler_time": 291.03546564709274
}
#Debug simulation 
Total elapsed time: 88.45160180516541. Arrivals time: 0.512152960523963 Scheduler time: 87.70501797506586 Scheduler overhead time: 0.09123680088669062 Adapter cache time: 0.0182588966563344 Engine time: 0.08961794106289744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_160_slots_16_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_160_slots_16_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 8640, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 1080, 17280, 17280, 17280, 8640, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1448280 . Total input tokens: 322886139 . Total output tokens: 284546184
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 93.04945886088535,
    "estimated_duration": 3600.030103100298,
    "input_throughput": 7190.525428581063,
    "output_throughput": 6286.276878771282,
    "total_throughput": 13476.802307352345,
    "itl": 85.95724522416053,
    "ttft": 1838186.1570839074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.208544616671283,
    "arrivals": 483089,
    "finished_requests": 104956,
    "scheduler_time": 284.48287776513314
}
#Debug simulation 
Total elapsed time: 93.04962518392131. Arrivals time: 0.5072259232401848 Scheduler time: 92.31279460107908 Scheduler overhead time: 0.08996027382090688 Adapter cache time: 0.017781779170036316 Engine time: 0.08747424464672804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_160_slots_16_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_160_slots_16_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 8640, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 1080, 17280, 17280, 17280, 8640, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1448280 . Total input tokens: 322886139 . Total output tokens: 284546184
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 94.23975668195635,
    "estimated_duration": 3600.0582477491835,
    "input_throughput": 7230.287181123819,
    "output_throughput": 6321.757436627342,
    "total_throughput": 13552.044617751162,
    "itl": 86.1288100969322,
    "ttft": 1851747.7356429554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3016304636281015,
    "arrivals": 483089,
    "finished_requests": 105494,
    "scheduler_time": 282.8744837410582
}
#Debug simulation 
Total elapsed time: 94.23992076097056. Arrivals time: 0.5172310974448919 Scheduler time: 93.49281007796526 Scheduler overhead time: 0.09025746956467628 Adapter cache time: 0.017084050457924604 Engine time: 0.08745160512626171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_160_slots_16_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_160_slots_16_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 8640, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 1080, 17280, 17280, 17280, 8640, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1448280 . Total input tokens: 322886139 . Total output tokens: 284546184
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.06441792333499,
    "estimated_duration": 3600.054954245831,
    "input_throughput": 7146.699516254973,
    "output_throughput": 6237.167844762492,
    "total_throughput": 13383.867361017465,
    "itl": 84.0547218331928,
    "ttft": 1859893.1775830993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.297448158692578,
    "arrivals": 483089,
    "finished_requests": 104353,
    "scheduler_time": 286.3788496368185
}
#Debug simulation 
Total elapsed time: 92.06458747619763. Arrivals time: 0.505131253041327 Scheduler time: 91.32715585036203 Scheduler overhead time: 0.091635060030967 Adapter cache time: 0.017558488063514233 Engine time: 0.08834592532366514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_160_slots_16_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_160_slots_16_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 8640, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 1080, 17280, 17280, 17280, 8640, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1448280 . Total input tokens: 322886139 . Total output tokens: 284546184
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 93.25578037882224,
    "estimated_duration": 3600.0480375934158,
    "input_throughput": 7128.648210248798,
    "output_throughput": 6242.599477929006,
    "total_throughput": 13371.247688177804,
    "itl": 85.0584811373099,
    "ttft": 1850375.5506141752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2841028641676506,
    "arrivals": 483089,
    "finished_requests": 104088,
    "scheduler_time": 287.4016267591653
}
#Debug simulation 
Total elapsed time: 93.25604024389759. Arrivals time: 0.5018790056928992 Scheduler time: 92.5239155809395 Scheduler overhead time: 0.09062426164746284 Adapter cache time: 0.017553491052240133 Engine time: 0.08707124134525657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_160_slots_16_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_160_slots_16_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 8640, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 1080, 17280, 17280, 17280, 8640, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1448280 . Total input tokens: 322886139 . Total output tokens: 284546184
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 92.18461798783392,
    "estimated_duration": 3600.022016265282,
    "input_throughput": 7146.764904146656,
    "output_throughput": 6237.224911000481,
    "total_throughput": 13383.989815147137,
    "itl": 84.05409806833636,
    "ttft": 1859875.8356398726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.276529323854493,
    "arrivals": 483089,
    "finished_requests": 104353,
    "scheduler_time": 286.37803521184156
}
#Debug simulation 
Total elapsed time: 92.18479092977941. Arrivals time: 0.5113323149271309 Scheduler time: 91.44213947746903 Scheduler overhead time: 0.09054789179936051 Adapter cache time: 0.01751552801579237 Engine time: 0.08830140717327595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_160_slots_16_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_160_slots_16_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 8640, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 1080, 17280, 17280, 17280, 8640, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1448280 . Total input tokens: 322886139 . Total output tokens: 284546184
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 94.31690220208839,
    "estimated_duration": 3600.0873476718693,
    "input_throughput": 7230.673171536783,
    "output_throughput": 6322.185769942186,
    "total_throughput": 13552.85894147897,
    "itl": 86.12177808823255,
    "ttft": 1851614.5107178374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.00455117533914,
    "arrivals": 483089,
    "finished_requests": 105502,
    "scheduler_time": 282.9010932654757
}
#Debug simulation 
Total elapsed time: 94.31707702996209. Arrivals time: 0.5183603265322745 Scheduler time: 93.5684492024593 Scheduler overhead time: 0.09012020658701658 Adapter cache time: 0.017691449262201786 Engine time: 0.08771371142938733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_160_slots_16_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_160_slots_16_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 8640, 17280, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 1080, 17280, 17280, 17280, 8640, 8640, 1080, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1448280 . Total input tokens: 322886139 . Total output tokens: 284546184
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.80374315194786,
    "estimated_duration": 3600.0921218434128,
    "input_throughput": 7146.763507492015,
    "output_throughput": 6237.219282183876,
    "total_throughput": 13383.982789675892,
    "itl": 84.05368381572866,
    "ttft": 1859878.5565510408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.25436778595672,
    "arrivals": 483089,
    "finished_requests": 104355,
    "scheduler_time": 286.38497968755485
}
#Debug simulation 
Total elapsed time: 92.80391997192055. Arrivals time: 0.51113585755229 Scheduler time: 92.05920379795134 Scheduler overhead time: 0.09130931086838245 Adapter cache time: 0.017575354781001806 Engine time: 0.08932300424203277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_160_slots_16_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_160_slots_16_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 8640, 540, 540, 540, 17280, 540, 8640, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 540, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 540, 8640, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 540, 540, 8640, 540, 8640, 17280, 540, 540, 8640, 540, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 540, 17280, 17280, 17280, 8640, 8640, 540, 540, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 8640, 540, 540, 8640, 8640, 17280, 17280, 17280, 540, 17280, 8640, 8640, 540, 540, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 17280, 8640, 17280, 540, 540, 540, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1419660 . Total input tokens: 316477910 . Total output tokens: 278919133
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 92.35131178423762,
    "estimated_duration": 3600.1008327116892,
    "input_throughput": 7147.591191388368,
    "output_throughput": 6246.4225434101645,
    "total_throughput": 13394.013734798533,
    "itl": 86.99359305749657,
    "ttft": 1835009.0482997824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.287893525054685,
    "arrivals": 473564,
    "finished_requests": 104621,
    "scheduler_time": 285.57376066911485
}
#Debug simulation 
Total elapsed time: 92.35147909494117. Arrivals time: 0.5090926247648895 Scheduler time: 91.61070079728961 Scheduler overhead time: 0.09076856961473823 Adapter cache time: 0.01791674317792058 Engine time: 0.08804992958903313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_160_slots_16_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_160_slots_16_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 8640, 540, 540, 540, 17280, 540, 8640, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 540, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 540, 8640, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 540, 540, 8640, 540, 8640, 17280, 540, 540, 8640, 540, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 540, 17280, 17280, 17280, 8640, 8640, 540, 540, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 8640, 540, 540, 8640, 8640, 17280, 17280, 17280, 540, 17280, 8640, 8640, 540, 540, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 17280, 8640, 17280, 540, 540, 540, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1419660 . Total input tokens: 316477910 . Total output tokens: 278919133
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.57168822269887,
    "estimated_duration": 3600.001574704239,
    "input_throughput": 7151.658816181263,
    "output_throughput": 6270.095590681637,
    "total_throughput": 13421.754406862901,
    "itl": 85.89621928787102,
    "ttft": 1833933.9141689672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.301073279702107,
    "arrivals": 473564,
    "finished_requests": 104863,
    "scheduler_time": 285.3715397041388
}
#Debug simulation 
Total elapsed time: 92.57185148773715. Arrivals time: 0.5225885109975934 Scheduler time: 91.81802300876006 Scheduler overhead time: 0.0905756913125515 Adapter cache time: 0.017483997158706188 Engine time: 0.08774618338793516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_160_slots_16_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_160_slots_16_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 8640, 540, 540, 540, 17280, 540, 8640, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 540, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 540, 8640, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 540, 540, 8640, 540, 8640, 17280, 540, 540, 8640, 540, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 540, 17280, 17280, 17280, 8640, 8640, 540, 540, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 8640, 540, 540, 8640, 8640, 17280, 17280, 17280, 540, 17280, 8640, 8640, 540, 540, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 17280, 8640, 17280, 540, 540, 540, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1419660 . Total input tokens: 316477910 . Total output tokens: 278919133
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 91.6097695841454,
    "estimated_duration": 3600.0390530509476,
    "input_throughput": 7070.680241212307,
    "output_throughput": 6199.521080496498,
    "total_throughput": 13270.201321708806,
    "itl": 84.15968509017789,
    "ttft": 1837109.5637846629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4754267035098865,
    "arrivals": 473564,
    "finished_requests": 103512,
    "scheduler_time": 289.26630050794773
}
#Debug simulation 
Total elapsed time: 91.60993333207443. Arrivals time: 0.4995288443751633 Scheduler time: 90.87483269209042 Scheduler overhead time: 0.09265764988958836 Adapter cache time: 0.017820801120251417 Engine time: 0.08933078311383724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_160_slots_16_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_160_slots_16_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 8640, 540, 540, 540, 17280, 540, 8640, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 540, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 540, 8640, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 540, 540, 8640, 540, 8640, 17280, 540, 540, 8640, 540, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 540, 17280, 17280, 17280, 8640, 8640, 540, 540, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 8640, 540, 540, 8640, 8640, 17280, 17280, 17280, 540, 17280, 8640, 8640, 540, 540, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 17280, 8640, 17280, 540, 540, 540, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1419660 . Total input tokens: 316477910 . Total output tokens: 278919133
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 93.2496612588875,
    "estimated_duration": 3600.073726391191,
    "input_throughput": 7161.651388135607,
    "output_throughput": 6265.971397928201,
    "total_throughput": 13427.622786063808,
    "itl": 85.92555219518367,
    "ttft": 1844365.736999292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.961289860461836,
    "arrivals": 473564,
    "finished_requests": 104893,
    "scheduler_time": 285.2338491623714
}
#Debug simulation 
Total elapsed time: 93.24983395356685. Arrivals time: 0.5176707608625293 Scheduler time: 92.50148776406422 Scheduler overhead time: 0.08937296038493514 Adapter cache time: 0.017297890037298203 Engine time: 0.08872625976800919 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_160_slots_16_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_160_slots_16_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 8640, 540, 540, 540, 17280, 540, 8640, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 540, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 540, 8640, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 540, 540, 8640, 540, 8640, 17280, 540, 540, 8640, 540, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 540, 17280, 17280, 17280, 8640, 8640, 540, 540, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 8640, 540, 540, 8640, 8640, 17280, 17280, 17280, 540, 17280, 8640, 8640, 540, 540, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 17280, 8640, 17280, 540, 540, 540, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1419660 . Total input tokens: 316477910 . Total output tokens: 278919133
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 91.40843920689076,
    "estimated_duration": 3600.0491076813555,
    "input_throughput": 7051.863805366468,
    "output_throughput": 6178.836825458341,
    "total_throughput": 13230.70063082481,
    "itl": 83.93087200761511,
    "ttft": 1839090.8466852473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4534722827887285,
    "arrivals": 473564,
    "finished_requests": 103279,
    "scheduler_time": 290.11038231727326
}
#Debug simulation 
Total elapsed time: 91.40860549872741. Arrivals time: 0.5132068647071719 Scheduler time: 90.66036867862567 Scheduler overhead time: 0.09147996082901955 Adapter cache time: 0.017933495808392763 Engine time: 0.08970321249216795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_160_slots_16_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_160_slots_16_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 8640, 540, 540, 540, 17280, 540, 8640, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 540, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 540, 8640, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 540, 540, 8640, 540, 8640, 17280, 540, 540, 8640, 540, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 540, 17280, 17280, 17280, 8640, 8640, 540, 540, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 8640, 540, 540, 8640, 8640, 17280, 17280, 17280, 540, 17280, 8640, 8640, 540, 540, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 17280, 8640, 17280, 540, 540, 540, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1419660 . Total input tokens: 316477910 . Total output tokens: 278919133
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 91.78684398205951,
    "estimated_duration": 3600.031290362645,
    "input_throughput": 7154.525870080825,
    "output_throughput": 6270.283833484712,
    "total_throughput": 13424.809703565537,
    "itl": 86.13212353780041,
    "ttft": 1837573.8065358982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0492386219231333,
    "arrivals": 473564,
    "finished_requests": 104742,
    "scheduler_time": 285.858122808713
}
#Debug simulation 
Total elapsed time: 91.787010461092. Arrivals time: 0.5197860607877374 Scheduler time: 91.03478908259422 Scheduler overhead time: 0.09121385961771011 Adapter cache time: 0.01788750197738409 Engine time: 0.08813822688534856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_160_slots_16_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_160_slots_16_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 8640, 540, 540, 540, 17280, 540, 8640, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 540, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 540, 8640, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 540, 540, 8640, 540, 8640, 17280, 540, 540, 8640, 540, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 540, 17280, 17280, 17280, 8640, 8640, 540, 540, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 8640, 540, 540, 8640, 8640, 17280, 17280, 17280, 540, 17280, 8640, 8640, 540, 540, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 17280, 8640, 17280, 540, 540, 540, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 540, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1419660 . Total input tokens: 316477910 . Total output tokens: 278919133
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.71929050097242,
    "estimated_duration": 3600.037128729181,
    "input_throughput": 7128.131205985246,
    "output_throughput": 6229.18297732006,
    "total_throughput": 13357.314183305307,
    "itl": 84.42564146878031,
    "ttft": 1844059.697241289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1048576182127072,
    "arrivals": 473564,
    "finished_requests": 104289,
    "scheduler_time": 287.16476621609945
}
#Debug simulation 
Total elapsed time: 92.71945743821561. Arrivals time: 0.5034202141687274 Scheduler time: 91.98282873816788 Scheduler overhead time: 0.09179221326485276 Adapter cache time: 0.017727687023580074 Engine time: 0.08845652965828776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_160_slots_16_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_160_slots_16_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 8640, 270, 270, 270, 17280, 270, 8640, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 270, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 270, 8640, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 270, 270, 8640, 270, 8640, 17280, 270, 270, 8640, 270, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 270, 17280, 17280, 17280, 8640, 8640, 270, 270, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 8640, 270, 270, 8640, 8640, 17280, 17280, 17280, 270, 17280, 8640, 8640, 270, 270, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 17280, 8640, 17280, 270, 270, 270, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1405350 . Total input tokens: 313318214 . Total output tokens: 276121542
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 97.7840935443528,
    "estimated_duration": 3600.059389063281,
    "input_throughput": 7061.543228211766,
    "output_throughput": 6176.819212359145,
    "total_throughput": 13238.362440570912,
    "itl": 85.85507354206521,
    "ttft": 1860214.04223105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7919628476584308,
    "arrivals": 468761,
    "finished_requests": 102913,
    "scheduler_time": 288.9091570868227
}
#Debug simulation 
Total elapsed time: 97.78426281036809. Arrivals time: 0.5182800842449069 Scheduler time: 97.03237237269059 Scheduler overhead time: 0.09184638550505042 Adapter cache time: 0.017557055223733187 Engine time: 0.0889527415856719 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_160_slots_16_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_160_slots_16_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 8640, 270, 270, 270, 17280, 270, 8640, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 270, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 270, 8640, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 270, 270, 8640, 270, 8640, 17280, 270, 270, 8640, 270, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 270, 17280, 17280, 17280, 8640, 8640, 270, 270, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 8640, 270, 270, 8640, 8640, 17280, 17280, 17280, 270, 17280, 8640, 8640, 270, 270, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 17280, 8640, 17280, 270, 270, 270, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1405350 . Total input tokens: 313318214 . Total output tokens: 276121542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 93.5368409208022,
    "estimated_duration": 3600.051094123842,
    "input_throughput": 7129.888529053476,
    "output_throughput": 6218.1795243236975,
    "total_throughput": 13348.068053377174,
    "itl": 85.5142246895218,
    "ttft": 1853296.7865190057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 288,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.110660541653636,
    "arrivals": 468761,
    "finished_requests": 103847,
    "scheduler_time": 286.89202429759894
}
#Debug simulation 
Total elapsed time: 93.53701635589823. Arrivals time: 0.5137367364950478 Scheduler time: 92.78843632154167 Scheduler overhead time: 0.09229516424238682 Adapter cache time: 0.018127860967069864 Engine time: 0.0886600986123085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_160_slots_16_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_160_slots_16_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 8640, 270, 270, 270, 17280, 270, 8640, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 270, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 270, 8640, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 270, 270, 8640, 270, 8640, 17280, 270, 270, 8640, 270, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 270, 17280, 17280, 17280, 8640, 8640, 270, 270, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 8640, 270, 270, 8640, 8640, 17280, 17280, 17280, 270, 17280, 8640, 8640, 270, 270, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 17280, 8640, 17280, 270, 270, 270, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1405350 . Total input tokens: 313318214 . Total output tokens: 276121542
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 90.57534419093281,
    "estimated_duration": 3600.0533377560505,
    "input_throughput": 7041.647059540818,
    "output_throughput": 6164.811717437921,
    "total_throughput": 13206.45877697874,
    "itl": 84.11375110742522,
    "ttft": 1858317.8063690134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1317361892340787,
    "arrivals": 468761,
    "finished_requests": 102652,
    "scheduler_time": 289.5036285083184
}
#Debug simulation 
Total elapsed time: 90.57550903689116. Arrivals time: 0.5088085113093257 Scheduler time: 89.82940272754058 Scheduler overhead time: 0.09311588201671839 Adapter cache time: 0.017556292936205864 Engine time: 0.09059540741145611 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_160_slots_16_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_160_slots_16_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 8640, 270, 270, 270, 17280, 270, 8640, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 270, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 270, 8640, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 270, 270, 8640, 270, 8640, 17280, 270, 270, 8640, 270, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 270, 17280, 17280, 17280, 8640, 8640, 270, 270, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 8640, 270, 270, 8640, 8640, 17280, 17280, 17280, 270, 17280, 8640, 8640, 270, 270, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 17280, 8640, 17280, 270, 270, 270, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1405350 . Total input tokens: 313318214 . Total output tokens: 276121542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 94.61026313481852,
    "estimated_duration": 3600.0026730004042,
    "input_throughput": 7114.109995550307,
    "output_throughput": 6228.884541719195,
    "total_throughput": 13342.994537269502,
    "itl": 85.66516664534491,
    "ttft": 1846950.4371428778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 279,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9102184929372723,
    "arrivals": 468761,
    "finished_requests": 103663,
    "scheduler_time": 286.96227586768754
}
#Debug simulation 
Total elapsed time: 94.6104278229177. Arrivals time: 0.5600959369912744 Scheduler time: 93.81707953289151 Scheduler overhead time: 0.09101456170901656 Adapter cache time: 0.01789921009913087 Engine time: 0.0892326864413917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_160_slots_16_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_160_slots_16_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 8640, 270, 270, 270, 17280, 270, 8640, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 270, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 270, 8640, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 270, 270, 8640, 270, 8640, 17280, 270, 270, 8640, 270, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 270, 17280, 17280, 17280, 8640, 8640, 270, 270, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 8640, 270, 270, 8640, 8640, 17280, 17280, 17280, 270, 17280, 8640, 8640, 270, 270, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 17280, 8640, 17280, 270, 270, 270, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1405350 . Total input tokens: 313318214 . Total output tokens: 276121542
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 90.56216711830348,
    "estimated_duration": 3600.032667270647,
    "input_throughput": 7041.6874909135895,
    "output_throughput": 6164.847114241895,
    "total_throughput": 13206.534605155484,
    "itl": 84.11334120121359,
    "ttft": 1858308.8524166418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1112315887492232,
    "arrivals": 468761,
    "finished_requests": 102652,
    "scheduler_time": 289.5032603609563
}
#Debug simulation 
Total elapsed time: 90.56234139297158. Arrivals time: 0.49654934508726 Scheduler time: 89.82924337638542 Scheduler overhead time: 0.09323337627574801 Adapter cache time: 0.017814130522310734 Engine time: 0.09003239311277866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_160_slots_16_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_160_slots_16_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 8640, 270, 270, 270, 17280, 270, 8640, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 270, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 270, 8640, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 270, 270, 8640, 270, 8640, 17280, 270, 270, 8640, 270, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 270, 17280, 17280, 17280, 8640, 8640, 270, 270, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 8640, 270, 270, 8640, 8640, 17280, 17280, 17280, 270, 17280, 8640, 8640, 270, 270, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 17280, 8640, 17280, 270, 270, 270, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1405350 . Total input tokens: 313318214 . Total output tokens: 276121542
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 96.59667082829401,
    "estimated_duration": 3600.0438129631107,
    "input_throughput": 7034.47077749759,
    "output_throughput": 6169.313251140586,
    "total_throughput": 13203.784028638176,
    "itl": 84.5434504903781,
    "ttft": 1853757.0666463394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7428104167757494,
    "arrivals": 468761,
    "finished_requests": 102529,
    "scheduler_time": 289.9991799149553
}
#Debug simulation 
Total elapsed time: 96.59684056928381. Arrivals time: 0.5075399782508612 Scheduler time: 95.85415195301175 Scheduler overhead time: 0.0930762947537005 Adapter cache time: 0.017153357155621052 Engine time: 0.0891508786007762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_160_slots_16_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_160_slots_16_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 8640, 270, 270, 270, 17280, 270, 8640, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 270, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 270, 8640, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 270, 270, 8640, 270, 8640, 17280, 270, 270, 8640, 270, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 270, 17280, 17280, 17280, 8640, 8640, 270, 270, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 8640, 270, 270, 8640, 8640, 17280, 17280, 17280, 270, 17280, 8640, 8640, 270, 270, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 17280, 8640, 17280, 270, 270, 270, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 270, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1405350 . Total input tokens: 313318214 . Total output tokens: 276121542
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 91.18697927007452,
    "estimated_duration": 3600.0129929381774,
    "input_throughput": 7041.725974247154,
    "output_throughput": 6164.880805579117,
    "total_throughput": 13206.606779826272,
    "itl": 84.11294402629962,
    "ttft": 1858300.3179258832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0917625741474413,
    "arrivals": 468761,
    "finished_requests": 102652,
    "scheduler_time": 289.5030550430882
}
#Debug simulation 
Total elapsed time: 91.18714659614488. Arrivals time: 0.5037612840533257 Scheduler time: 90.44780756952241 Scheduler overhead time: 0.09201600961387157 Adapter cache time: 0.017655643168836832 Engine time: 0.09007901651784778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 8640, 135, 135, 135, 17280, 135, 8640, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 135, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 135, 8640, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 135, 135, 8640, 135, 8640, 17280, 135, 135, 8640, 135, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 135, 17280, 17280, 17280, 8640, 8640, 135, 135, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 8640, 135, 135, 8640, 8640, 17280, 17280, 17280, 135, 17280, 8640, 8640, 135, 135, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 17280, 8640, 17280, 135, 135, 135, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1398195 . Total input tokens: 311712266 . Total output tokens: 274723048
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 93.364116279874,
    "estimated_duration": 3600.008561342211,
    "input_throughput": 7219.482830982472,
    "output_throughput": 6324.013016100117,
    "total_throughput": 13543.495847082588,
    "itl": 86.83534158933966,
    "ttft": 1830346.4684898546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9175986192654795,
    "arrivals": 466310,
    "finished_requests": 105441,
    "scheduler_time": 282.98150636844343
}
#Debug simulation 
Total elapsed time: 93.36429062765092. Arrivals time: 0.5137979788705707 Scheduler time: 92.62160638533533 Scheduler overhead time: 0.08963476680219173 Adapter cache time: 0.017566034104675055 Engine time: 0.08677154406905174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 8640, 135, 135, 135, 17280, 135, 8640, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 135, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 135, 8640, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 135, 135, 8640, 135, 8640, 17280, 135, 135, 8640, 135, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 135, 17280, 17280, 17280, 8640, 8640, 135, 135, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 8640, 135, 135, 8640, 8640, 17280, 17280, 17280, 135, 17280, 8640, 8640, 135, 135, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 17280, 8640, 17280, 135, 135, 135, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1398195 . Total input tokens: 311712266 . Total output tokens: 274723048
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.9934866912663,
    "estimated_duration": 3600.084888678984,
    "input_throughput": 7233.185551231586,
    "output_throughput": 6319.762089929081,
    "total_throughput": 13552.947641160667,
    "itl": 86.36997677188987,
    "ttft": 1839505.714604049,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2033690606942424,
    "arrivals": 466310,
    "finished_requests": 105592,
    "scheduler_time": 282.4579048695321
}
#Debug simulation 
Total elapsed time: 92.99365665204823. Arrivals time: 0.52053730096668 Scheduler time: 92.24035923043266 Scheduler overhead time: 0.09092128183692694 Adapter cache time: 0.01727413246408105 Engine time: 0.08895789831876755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 8640, 135, 135, 135, 17280, 135, 8640, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 135, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 135, 8640, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 135, 135, 8640, 135, 8640, 17280, 135, 135, 8640, 135, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 135, 17280, 17280, 17280, 8640, 8640, 135, 135, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 8640, 135, 135, 8640, 8640, 17280, 17280, 17280, 135, 17280, 8640, 8640, 135, 135, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 17280, 8640, 17280, 135, 135, 135, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1398195 . Total input tokens: 311712266 . Total output tokens: 274723048
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 91.60732992133126,
    "estimated_duration": 3600.0489375690026,
    "input_throughput": 7154.879682661618,
    "output_throughput": 6259.860460457436,
    "total_throughput": 13414.740143119054,
    "itl": 84.40741816347969,
    "ttft": 1840246.115657826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2727519799722447,
    "arrivals": 466310,
    "finished_requests": 104393,
    "scheduler_time": 285.95964000347175
}
#Debug simulation 
Total elapsed time: 91.60749739501625. Arrivals time: 0.5492260749451816 Scheduler time: 90.82410033559427 Scheduler overhead time: 0.09139340836554766 Adapter cache time: 0.017798301298171282 Engine time: 0.08950757887214422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 8640, 135, 135, 135, 17280, 135, 8640, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 135, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 135, 8640, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 135, 135, 8640, 135, 8640, 17280, 135, 135, 8640, 135, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 135, 17280, 17280, 17280, 8640, 8640, 135, 135, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 8640, 135, 135, 8640, 8640, 17280, 17280, 17280, 135, 17280, 8640, 8640, 135, 135, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 17280, 8640, 17280, 135, 135, 135, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1398195 . Total input tokens: 311712266 . Total output tokens: 274723048
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 93.06317627709359,
    "estimated_duration": 3600.0073575124907,
    "input_throughput": 7216.706917496865,
    "output_throughput": 6307.02183222447,
    "total_throughput": 13523.728749721335,
    "itl": 86.39635352946843,
    "ttft": 1843422.2758815035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9973741280846276,
    "arrivals": 466310,
    "finished_requests": 105392,
    "scheduler_time": 283.1327338604253
}
#Debug simulation 
Total elapsed time: 93.06334512634203. Arrivals time: 0.5211605848744512 Scheduler time: 92.30832843342796 Scheduler overhead time: 0.09077909914776683 Adapter cache time: 0.017826880794018507 Engine time: 0.08946588169783354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 8640, 135, 135, 135, 17280, 135, 8640, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 135, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 135, 8640, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 135, 135, 8640, 135, 8640, 17280, 135, 135, 8640, 135, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 135, 17280, 17280, 17280, 8640, 8640, 135, 135, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 8640, 135, 135, 8640, 8640, 17280, 17280, 17280, 135, 17280, 8640, 8640, 135, 135, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 17280, 8640, 17280, 135, 135, 135, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1398195 . Total input tokens: 311712266 . Total output tokens: 274723048
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 91.8758637602441,
    "estimated_duration": 3600.0280976857202,
    "input_throughput": 7154.921100909876,
    "output_throughput": 6259.896697608319,
    "total_throughput": 13414.817798518196,
    "itl": 84.40693880139422,
    "ttft": 1840236.85366048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2524544966640034,
    "arrivals": 466310,
    "finished_requests": 104393,
    "scheduler_time": 285.95940099716296
}
#Debug simulation 
Total elapsed time: 91.87603387329727. Arrivals time: 0.553803401067853 Scheduler time: 91.0884087276645 Scheduler overhead time: 0.09091492695733905 Adapter cache time: 0.017636547330766916 Engine time: 0.08960449509322643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 8640, 135, 135, 135, 17280, 135, 8640, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 135, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 135, 8640, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 135, 135, 8640, 135, 8640, 17280, 135, 135, 8640, 135, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 135, 17280, 17280, 17280, 8640, 8640, 135, 135, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 8640, 135, 135, 8640, 8640, 17280, 17280, 17280, 135, 17280, 8640, 8640, 135, 135, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 17280, 8640, 17280, 135, 135, 135, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1398195 . Total input tokens: 311712266 . Total output tokens: 274723048
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 93.01023014914244,
    "estimated_duration": 3600.0779695467054,
    "input_throughput": 7216.972304428011,
    "output_throughput": 6307.133954340158,
    "total_throughput": 13524.106258768168,
    "itl": 86.39260943731101,
    "ttft": 1843493.0625186707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.864104914646589,
    "arrivals": 466310,
    "finished_requests": 105400,
    "scheduler_time": 283.14614810797474
}
#Debug simulation 
Total elapsed time: 93.0104053132236. Arrivals time: 0.526634783949703 Scheduler time: 92.25265193311498 Scheduler overhead time: 0.09006601572036743 Adapter cache time: 0.017561418935656548 Engine time: 0.0885411947965622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 8640, 135, 135, 135, 17280, 135, 8640, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 135, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 135, 8640, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 135, 135, 8640, 135, 8640, 17280, 135, 135, 8640, 135, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 135, 17280, 17280, 17280, 8640, 8640, 135, 135, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 8640, 135, 135, 8640, 8640, 17280, 17280, 17280, 135, 17280, 8640, 8640, 135, 135, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 17280, 8640, 17280, 135, 135, 135, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 135, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1398195 . Total input tokens: 311712266 . Total output tokens: 274723048
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 91.85064730979502,
    "estimated_duration": 3600.006806812493,
    "input_throughput": 7154.963415973787,
    "output_throughput": 6259.933719390265,
    "total_throughput": 13414.897135364052,
    "itl": 84.40645460520494,
    "ttft": 1840228.582400871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2311214274726887,
    "arrivals": 466310,
    "finished_requests": 104393,
    "scheduler_time": 285.959139799462
}
#Debug simulation 
Total elapsed time: 91.85091588972136. Arrivals time: 0.5555706326849759 Scheduler time: 91.06067571230233 Scheduler overhead time: 0.09133861446753144 Adapter cache time: 0.01801284123212099 Engine time: 0.08943632058799267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_160_slots_16_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_160_slots_16_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 8640, 66, 66, 66, 17280, 66, 8640, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 66, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 66, 8640, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 66, 66, 8640, 66, 8640, 17280, 66, 66, 8640, 66, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 66, 17280, 17280, 17280, 8640, 8640, 66, 66, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 8640, 66, 66, 8640, 8640, 17280, 17280, 17280, 66, 17280, 8640, 8640, 66, 66, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 17280, 8640, 17280, 66, 66, 66, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1394538 . Total input tokens: 310895799 . Total output tokens: 274023387
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 92.54706952581182,
    "estimated_duration": 3600.0251118415185,
    "input_throughput": 7317.009793447132,
    "output_throughput": 6348.306550647775,
    "total_throughput": 13665.316344094907,
    "itl": 87.42654773143244,
    "ttft": 1833628.265288892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.06307161796838,
    "arrivals": 465116,
    "finished_requests": 106193,
    "scheduler_time": 280.13082415047995
}
#Debug simulation 
Total elapsed time: 92.54724564682692. Arrivals time: 0.5141225131228566 Scheduler time: 91.80320770246908 Scheduler overhead time: 0.09039923548698425 Adapter cache time: 0.016984559129923582 Engine time: 0.08789807884022593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_160_slots_16_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_160_slots_16_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 8640, 66, 66, 66, 17280, 66, 8640, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 66, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 66, 8640, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 66, 66, 8640, 66, 8640, 17280, 66, 66, 8640, 66, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 66, 17280, 17280, 17280, 8640, 8640, 66, 66, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 8640, 66, 66, 8640, 8640, 17280, 17280, 17280, 66, 17280, 8640, 8640, 66, 66, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 17280, 8640, 17280, 66, 66, 66, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1394538 . Total input tokens: 310895799 . Total output tokens: 274023387
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 95.38180507021025,
    "estimated_duration": 3600.0403884522484,
    "input_throughput": 7210.657992412221,
    "output_throughput": 6261.33642064249,
    "total_throughput": 13471.99441305471,
    "itl": 85.82764859350016,
    "ttft": 1840049.103668792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.145356588303114,
    "arrivals": 465116,
    "finished_requests": 104700,
    "scheduler_time": 284.26091200859645
}
#Debug simulation 
Total elapsed time: 95.38198911724612. Arrivals time: 0.510425603017211 Scheduler time: 94.63876489829272 Scheduler overhead time: 0.09106568526476622 Adapter cache time: 0.017729295883327723 Engine time: 0.08890339965000749 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_160_slots_16_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_160_slots_16_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 8640, 66, 66, 66, 17280, 66, 8640, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 66, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 66, 8640, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 66, 66, 8640, 66, 8640, 17280, 66, 66, 8640, 66, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 66, 17280, 17280, 17280, 8640, 8640, 66, 66, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 8640, 66, 66, 8640, 8640, 17280, 17280, 17280, 66, 17280, 8640, 8640, 66, 66, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 17280, 8640, 17280, 66, 66, 66, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1394538 . Total input tokens: 310895799 . Total output tokens: 274023387
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.82412823522463,
    "estimated_duration": 3600.0228832065645,
    "input_throughput": 7189.214024369568,
    "output_throughput": 6223.460996460131,
    "total_throughput": 13412.675020829698,
    "itl": 84.2678243861381,
    "ttft": 1847478.9164908598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.260485404613438,
    "arrivals": 465116,
    "finished_requests": 104244,
    "scheduler_time": 286.19321995928897
}
#Debug simulation 
Total elapsed time: 92.82430045306683. Arrivals time: 0.5102925975807011 Scheduler time: 92.07900819089264 Scheduler overhead time: 0.09284099331125617 Adapter cache time: 0.017205384094268084 Engine time: 0.08933087671175599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_160_slots_16_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_160_slots_16_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 8640, 66, 66, 66, 17280, 66, 8640, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 66, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 66, 8640, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 66, 66, 8640, 66, 8640, 17280, 66, 66, 8640, 66, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 66, 17280, 17280, 17280, 8640, 8640, 66, 66, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 8640, 66, 66, 8640, 8640, 17280, 17280, 17280, 66, 17280, 8640, 8640, 66, 66, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 17280, 8640, 17280, 66, 66, 66, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1394538 . Total input tokens: 310895799 . Total output tokens: 274023387
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 91.06849005399272,
    "estimated_duration": 3600.0808532702526,
    "input_throughput": 7278.349589342683,
    "output_throughput": 6311.398528552528,
    "total_throughput": 13589.748117895211,
    "itl": 86.72683008883784,
    "ttft": 1837419.1849010172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.141711198575792,
    "arrivals": 465116,
    "finished_requests": 105611,
    "scheduler_time": 281.86995412230175
}
#Debug simulation 
Total elapsed time: 91.06865763897076. Arrivals time: 0.5097233271226287 Scheduler time: 90.32747863512486 Scheduler overhead time: 0.09042832488194108 Adapter cache time: 0.017911816481500864 Engine time: 0.08806037250906229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_160_slots_16_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_160_slots_16_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 8640, 66, 66, 66, 17280, 66, 8640, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 66, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 66, 8640, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 66, 66, 8640, 66, 8640, 17280, 66, 66, 8640, 66, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 66, 17280, 17280, 17280, 8640, 8640, 66, 66, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 8640, 66, 66, 8640, 8640, 17280, 17280, 17280, 66, 17280, 8640, 8640, 66, 66, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 17280, 8640, 17280, 66, 66, 66, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1394538 . Total input tokens: 310895799 . Total output tokens: 274023387
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 92.9522676113993,
    "estimated_duration": 3600.0015859199975,
    "input_throughput": 7189.256555115073,
    "output_throughput": 6223.497813897323,
    "total_throughput": 13412.754369012395,
    "itl": 84.26733004333029,
    "ttft": 1847470.725323903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2391523354221237,
    "arrivals": 465116,
    "finished_requests": 104244,
    "scheduler_time": 286.19295234824847
}
#Debug simulation 
Total elapsed time: 92.95243978500366. Arrivals time: 0.5001464178785682 Scheduler time: 92.2186186700128 Scheduler overhead time: 0.09169906517490745 Adapter cache time: 0.017302560154348612 Engine time: 0.08877583686262369 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_160_slots_16_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_160_slots_16_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 8640, 66, 66, 66, 17280, 66, 8640, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 66, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 66, 8640, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 66, 66, 8640, 66, 8640, 17280, 66, 66, 8640, 66, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 66, 17280, 17280, 17280, 8640, 8640, 66, 66, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 8640, 66, 66, 8640, 8640, 17280, 17280, 17280, 66, 17280, 8640, 8640, 66, 66, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 17280, 8640, 17280, 66, 66, 66, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1394538 . Total input tokens: 310895799 . Total output tokens: 274023387
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 94.41997094266117,
    "estimated_duration": 3600.0323156828117,
    "input_throughput": 7284.462110453607,
    "output_throughput": 6318.772167934128,
    "total_throughput": 13603.234278387736,
    "itl": 86.69267221935688,
    "ttft": 1837459.5345377147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8960245193494414,
    "arrivals": 465116,
    "finished_requests": 105641,
    "scheduler_time": 282.0164360582573
}
#Debug simulation 
Total elapsed time: 94.42014724062756. Arrivals time: 0.5378196770325303 Scheduler time: 93.64953964250162 Scheduler overhead time: 0.09099287958815694 Adapter cache time: 0.01783776469528675 Engine time: 0.08906790893524885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_160_slots_16_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_160_slots_16_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 8640, 66, 66, 66, 17280, 66, 8640, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 66, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 66, 8640, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 66, 66, 8640, 66, 8640, 17280, 66, 66, 8640, 66, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 66, 17280, 17280, 17280, 8640, 8640, 66, 66, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 8640, 66, 66, 8640, 8640, 17280, 17280, 17280, 66, 17280, 8640, 8640, 66, 66, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 17280, 8640, 17280, 66, 66, 66, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 66, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1394538 . Total input tokens: 310895799 . Total output tokens: 274023387
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.98242705315351,
    "estimated_duration": 3600.0115835714746,
    "input_throughput": 7189.2365897122545,
    "output_throughput": 6223.480530519015,
    "total_throughput": 13412.71712023127,
    "itl": 84.26625915125024,
    "ttft": 1847484.3320866094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.218026383407424,
    "arrivals": 465116,
    "finished_requests": 104244,
    "scheduler_time": 286.1976196512222
}
#Debug simulation 
Total elapsed time: 92.98259933618829. Arrivals time: 0.5058468696661294 Scheduler time: 92.24223202001303 Scheduler overhead time: 0.09182706102728844 Adapter cache time: 0.017516062129288912 Engine time: 0.08931061765179038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 8640, 33, 33, 33, 17280, 33, 8640, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 33, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 33, 8640, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 33, 33, 8640, 33, 8640, 17280, 33, 33, 8640, 33, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 33, 17280, 17280, 17280, 8640, 8640, 33, 33, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 8640, 33, 33, 8640, 8640, 17280, 17280, 17280, 33, 17280, 8640, 8640, 33, 33, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 17280, 8640, 17280, 33, 33, 33, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1392789 . Total input tokens: 310511359 . Total output tokens: 273687506
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 90.30445703631267,
    "estimated_duration": 3600.0213869058425,
    "input_throughput": 7292.403343904532,
    "output_throughput": 6354.333361241865,
    "total_throughput": 13646.736705146397,
    "itl": 87.58536315754935,
    "ttft": 1833887.5958542256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 324,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1424205263517817,
    "arrivals": 464531,
    "finished_requests": 106432,
    "scheduler_time": 280.07439623727873
}
#Debug simulation 
Total elapsed time: 90.30462821712717. Arrivals time: 0.5069948341697454 Scheduler time: 89.56910747941583 Scheduler overhead time: 0.08899550884962082 Adapter cache time: 0.017217302229255438 Engine time: 0.08757054293528199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 8640, 33, 33, 33, 17280, 33, 8640, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 33, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 33, 8640, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 33, 33, 8640, 33, 8640, 17280, 33, 33, 8640, 33, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 33, 17280, 17280, 17280, 8640, 8640, 33, 33, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 8640, 33, 33, 8640, 8640, 17280, 17280, 17280, 33, 17280, 8640, 8640, 33, 33, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 17280, 8640, 17280, 33, 33, 33, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1392789 . Total input tokens: 310511359 . Total output tokens: 273687506
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 91.0367275220342,
    "estimated_duration": 3600.063909691341,
    "input_throughput": 7283.141260191685,
    "output_throughput": 6334.180329025076,
    "total_throughput": 13617.321589216761,
    "itl": 86.60852267867324,
    "ttft": 1837142.5589671326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2189133445220093,
    "arrivals": 464531,
    "finished_requests": 106215,
    "scheduler_time": 281.0627022917189
}
#Debug simulation 
Total elapsed time: 91.03690337622538. Arrivals time: 0.5100712166167796 Scheduler time: 90.295850018505 Scheduler overhead time: 0.09034100081771612 Adapter cache time: 0.017076422460377216 Engine time: 0.08850495517253876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 8640, 33, 33, 33, 17280, 33, 8640, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 33, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 33, 8640, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 33, 33, 8640, 33, 8640, 17280, 33, 33, 8640, 33, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 33, 17280, 17280, 17280, 8640, 8640, 33, 33, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 8640, 33, 33, 8640, 8640, 17280, 17280, 17280, 33, 17280, 8640, 8640, 33, 33, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 17280, 8640, 17280, 33, 33, 33, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1392789 . Total input tokens: 310511359 . Total output tokens: 273687506
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 90.4322844427079,
    "estimated_duration": 3600.0147324455424,
    "input_throughput": 7206.243565113642,
    "output_throughput": 6266.230189751382,
    "total_throughput": 13472.473754865023,
    "itl": 84.55047312654942,
    "ttft": 1845021.0275722195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0930646287603376,
    "arrivals": 464531,
    "finished_requests": 105058,
    "scheduler_time": 284.5311619946056
}
#Debug simulation 
Total elapsed time: 90.43245630059391. Arrivals time: 0.5147574958391488 Scheduler time: 89.68384187715128 Scheduler overhead time: 0.09124491643160582 Adapter cache time: 0.017429223749786615 Engine time: 0.08946313010528684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 8640, 33, 33, 33, 17280, 33, 8640, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 33, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 33, 8640, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 33, 33, 8640, 33, 8640, 17280, 33, 33, 8640, 33, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 33, 17280, 17280, 17280, 8640, 8640, 33, 33, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 8640, 33, 33, 8640, 8640, 17280, 17280, 17280, 33, 17280, 8640, 8640, 33, 33, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 17280, 8640, 17280, 33, 33, 33, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1392789 . Total input tokens: 310511359 . Total output tokens: 273687506
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 91.34247566899285,
    "estimated_duration": 3600.0476224936247,
    "input_throughput": 7283.226709606238,
    "output_throughput": 6334.353428415066,
    "total_throughput": 13617.580138021303,
    "itl": 86.60559810207306,
    "ttft": 1837088.1797462434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0773148052440935,
    "arrivals": 464531,
    "finished_requests": 106217,
    "scheduler_time": 281.0720891577282
}
#Debug simulation 
Total elapsed time: 91.34264269424602. Arrivals time: 0.5466942181810737 Scheduler time: 90.56519865477458 Scheduler overhead time: 0.09005439328029752 Adapter cache time: 0.01697831554338336 Engine time: 0.08879909990355372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 8640, 33, 33, 33, 17280, 33, 8640, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 33, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 33, 8640, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 33, 33, 8640, 33, 8640, 17280, 33, 33, 8640, 33, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 33, 17280, 17280, 17280, 8640, 8640, 33, 33, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 8640, 33, 33, 8640, 8640, 17280, 17280, 17280, 33, 17280, 8640, 8640, 33, 33, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 17280, 8640, 17280, 33, 33, 33, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1392789 . Total input tokens: 310511359 . Total output tokens: 273687506
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 90.24004733702168,
    "estimated_duration": 3600.0973606409016,
    "input_throughput": 7206.235387862264,
    "output_throughput": 6266.3930277662985,
    "total_throughput": 13472.628415628562,
    "itl": 84.55054453126235,
    "ttft": 1844997.4068446402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0733884969819405,
    "arrivals": 464531,
    "finished_requests": 105062,
    "scheduler_time": 284.53843508413763
}
#Debug simulation 
Total elapsed time: 90.24022305104882. Arrivals time: 0.5206611757166684 Scheduler time: 89.48668980272487 Scheduler overhead time: 0.09121902054175735 Adapter cache time: 0.017416231334209442 Engine time: 0.0889774402603507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 8640, 33, 33, 33, 17280, 33, 8640, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 33, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 33, 8640, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 33, 33, 8640, 33, 8640, 17280, 33, 33, 8640, 33, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 33, 17280, 17280, 17280, 8640, 8640, 33, 33, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 8640, 33, 33, 8640, 8640, 17280, 17280, 17280, 33, 17280, 8640, 8640, 33, 33, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 17280, 8640, 17280, 33, 33, 33, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1392789 . Total input tokens: 310511359 . Total output tokens: 273687506
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 91.29941661003977,
    "estimated_duration": 3600.0027692056856,
    "input_throughput": 7283.637452808265,
    "output_throughput": 6334.662349449169,
    "total_throughput": 13618.299802257434,
    "itl": 86.60164744020689,
    "ttft": 1837073.701474421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9343280449928644,
    "arrivals": 464531,
    "finished_requests": 106221,
    "scheduler_time": 281.0787350873372
}
#Debug simulation 
Total elapsed time: 91.29958586907014. Arrivals time: 0.5135494391433895 Scheduler time: 90.55573266418651 Scheduler overhead time: 0.09030051156878471 Adapter cache time: 0.017471603117883205 Engine time: 0.08777351817116141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 8640, 33, 33, 33, 17280, 33, 8640, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 33, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 33, 8640, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 33, 33, 8640, 33, 8640, 17280, 33, 33, 8640, 33, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 33, 17280, 17280, 17280, 8640, 8640, 33, 33, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 8640, 33, 33, 8640, 8640, 17280, 17280, 17280, 33, 17280, 8640, 8640, 33, 33, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 17280, 8640, 17280, 33, 33, 33, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 33, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1392789 . Total input tokens: 310511359 . Total output tokens: 273687506
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 90.32077202014625,
    "estimated_duration": 3600.077785004531,
    "input_throughput": 7206.274572194375,
    "output_throughput": 6266.427101649862,
    "total_throughput": 13472.701673844238,
    "itl": 84.55007247249013,
    "ttft": 1844989.6506097235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.053919482380158,
    "arrivals": 464531,
    "finished_requests": 105062,
    "scheduler_time": 284.5383284623685
}
#Debug simulation 
Total elapsed time: 90.32094374811277. Arrivals time: 0.5005053724162281 Scheduler time: 89.58737124316394 Scheduler overhead time: 0.09224592475220561 Adapter cache time: 0.01751536736264825 Engine time: 0.08811232913285494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_160_slots_16_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_160_slots_16_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 4320, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 1080, 17280, 17280, 17280, 4320, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1219320 . Total input tokens: 271850793 . Total output tokens: 239610326
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 91.48133672727272,
    "estimated_duration": 3600.0585630680857,
    "input_throughput": 7187.649463665301,
    "output_throughput": 6250.879147038588,
    "total_throughput": 13438.528610703888,
    "itl": 85.0624227992872,
    "ttft": 1794208.2024511257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 352,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.327567979246386,
    "arrivals": 406769,
    "finished_requests": 104854,
    "scheduler_time": 283.972163833126
}
#Debug simulation 
Total elapsed time: 91.48151002498344. Arrivals time: 0.5144269126467407 Scheduler time: 90.73718812363222 Scheduler overhead time: 0.09009049646556377 Adapter cache time: 0.0178375537507236 Engine time: 0.0867875600233674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_160_slots_16_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_160_slots_16_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 4320, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 1080, 17280, 17280, 17280, 4320, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1219320 . Total input tokens: 271850793 . Total output tokens: 239610326
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 99.92905138107017,
    "estimated_duration": 3600.044686296996,
    "input_throughput": 7162.204707664801,
    "output_throughput": 6257.929265642849,
    "total_throughput": 13420.133973307651,
    "itl": 84.54013755104101,
    "ttft": 1787351.2363429822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0704116111109054,
    "arrivals": 406769,
    "finished_requests": 104514,
    "scheduler_time": 284.46471169519515
}
#Debug simulation 
Total elapsed time: 99.92922638729215. Arrivals time: 0.516297179274261 Scheduler time: 99.1756273121573 Scheduler overhead time: 0.09359402442350984 Adapter cache time: 0.01817646622657776 Engine time: 0.09003310278058052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_160_slots_16_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_160_slots_16_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 4320, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 1080, 17280, 17280, 17280, 4320, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1219320 . Total input tokens: 271850793 . Total output tokens: 239610326
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 97.92255106614903,
    "estimated_duration": 3600.0288518256484,
    "input_throughput": 7101.149477464825,
    "output_throughput": 6192.320372292294,
    "total_throughput": 13293.46984975712,
    "itl": 82.47497144922004,
    "ttft": 1786031.497335021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.182674325066627,
    "arrivals": 406769,
    "finished_requests": 103571,
    "scheduler_time": 287.6731115183232
}
#Debug simulation 
Total elapsed time: 97.9227220970206. Arrivals time: 0.5182123747654259 Scheduler time: 97.16707237344235 Scheduler overhead time: 0.09294965583831072 Adapter cache time: 0.01809199946001172 Engine time: 0.09029094548895955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_160_slots_16_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_160_slots_16_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 4320, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 1080, 17280, 17280, 17280, 4320, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1219320 . Total input tokens: 271850793 . Total output tokens: 239610326
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 94.07846859842539,
    "estimated_duration": 3600.0168961641875,
    "input_throughput": 7151.380324751074,
    "output_throughput": 6248.6442838556195,
    "total_throughput": 13400.024608606693,
    "itl": 84.08062496321924,
    "ttft": 1781160.511955249,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.255790738458743,
    "arrivals": 406769,
    "finished_requests": 104338,
    "scheduler_time": 285.21310438888804
}
#Debug simulation 
Total elapsed time: 94.0786426612176. Arrivals time: 0.5082073770463467 Scheduler time: 93.33668424515054 Scheduler overhead time: 0.09114079503342509 Adapter cache time: 0.01783884409815073 Engine time: 0.089212107937783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_160_slots_16_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_160_slots_16_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 4320, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 1080, 17280, 17280, 17280, 4320, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1219320 . Total input tokens: 271850793 . Total output tokens: 239610326
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 99.21947683300823,
    "estimated_duration": 3600.0371383304655,
    "input_throughput": 7140.3746717793865,
    "output_throughput": 6225.2188349349135,
    "total_throughput": 13365.5935067143,
    "itl": 83.0023180169294,
    "ttft": 1789361.6415994738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.117959365835421,
    "arrivals": 406769,
    "finished_requests": 104163,
    "scheduler_time": 286.0474092939858
}
#Debug simulation 
Total elapsed time: 99.21964548015967. Arrivals time: 0.5087552787736058 Scheduler time: 98.47485984861851 Scheduler overhead time: 0.09223701292648911 Adapter cache time: 0.017898136284202337 Engine time: 0.09009099937975407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_160_slots_16_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_160_slots_16_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 4320, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 1080, 17280, 17280, 17280, 4320, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1219320 . Total input tokens: 271850793 . Total output tokens: 239610326
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 92.77774050692096,
    "estimated_duration": 3600.0392554977657,
    "input_throughput": 7214.036058173232,
    "output_throughput": 6281.989554825852,
    "total_throughput": 13496.025612999085,
    "itl": 85.01039678385165,
    "ttft": 1789758.7463503145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2216044873185368,
    "arrivals": 406769,
    "finished_requests": 105217,
    "scheduler_time": 282.5003187733896
}
#Debug simulation 
Total elapsed time: 92.77790988003835. Arrivals time: 0.5030377963557839 Scheduler time: 92.0422896030359 Scheduler overhead time: 0.0910895150154829 Adapter cache time: 0.0175242661498487 Engine time: 0.08868103753775358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_160_slots_16_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_160_slots_16_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [53 53 54]
Adapter prompts. [1080, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 4320, 17280, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 1080, 17280, 17280, 17280, 4320, 4320, 1080, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1219320 . Total input tokens: 271850793 . Total output tokens: 239610326
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 98.14054301241413,
    "estimated_duration": 3600.0433376347783,
    "input_throughput": 7102.101169925928,
    "output_throughput": 6197.060398349932,
    "total_throughput": 13299.16156827586,
    "itl": 82.4114306793504,
    "ttft": 1785339.0241519266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1299661760218513,
    "arrivals": 406769,
    "finished_requests": 103612,
    "scheduler_time": 287.72703354745744
}
#Debug simulation 
Total elapsed time: 98.14071485120803. Arrivals time: 0.5263659665361047 Scheduler time: 97.37634911341593 Scheduler overhead time: 0.09311187593266368 Adapter cache time: 0.017501989845186472 Engine time: 0.09106536768376827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_160_slots_16_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_160_slots_16_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 4320, 540, 540, 540, 17280, 540, 4320, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 540, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 540, 4320, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 540, 540, 4320, 540, 4320, 17280, 540, 540, 4320, 540, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 540, 17280, 17280, 17280, 4320, 4320, 540, 540, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 4320, 540, 540, 4320, 4320, 17280, 17280, 17280, 540, 17280, 4320, 4320, 540, 540, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 17280, 4320, 17280, 540, 540, 540, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1190700 . Total input tokens: 265501037 . Total output tokens: 233965036
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 96.43575356528163,
    "estimated_duration": 3600.0422500508275,
    "input_throughput": 7177.762983096983,
    "output_throughput": 6296.188607142036,
    "total_throughput": 13473.951590239018,
    "itl": 85.85387266413406,
    "ttft": 1771228.4336860022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.109358481192031,
    "arrivals": 397242,
    "finished_requests": 104676,
    "scheduler_time": 282.15091274770293
}
#Debug simulation 
Total elapsed time: 96.4359193649143. Arrivals time: 0.5188118349760771 Scheduler time: 95.68321227421984 Scheduler overhead time: 0.09092395892366767 Adapter cache time: 0.017928521148860455 Engine time: 0.08951097959652543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_160_slots_16_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_160_slots_16_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 4320, 540, 540, 540, 17280, 540, 4320, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 540, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 540, 4320, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 540, 540, 4320, 540, 4320, 17280, 540, 540, 4320, 540, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 540, 17280, 17280, 17280, 4320, 4320, 540, 540, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 4320, 540, 540, 4320, 4320, 17280, 17280, 17280, 540, 17280, 4320, 4320, 540, 540, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 17280, 4320, 17280, 540, 540, 540, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1190700 . Total input tokens: 265501037 . Total output tokens: 233965036
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 94.68984334077686,
    "estimated_duration": 3600.0058914591423,
    "input_throughput": 7191.333786819671,
    "output_throughput": 6288.385542287086,
    "total_throughput": 13479.719329106756,
    "itl": 85.24425586374811,
    "ttft": 1789441.7297423081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1942086978070465,
    "arrivals": 397242,
    "finished_requests": 104798,
    "scheduler_time": 281.648656152162
}
#Debug simulation 
Total elapsed time: 94.6900137476623. Arrivals time: 0.5484142522327602 Scheduler time: 93.9071516469121 Scheduler overhead time: 0.09090068191289902 Adapter cache time: 0.019619406666606665 Engine time: 0.08913271361961961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_160_slots_16_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_160_slots_16_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 4320, 540, 540, 540, 17280, 540, 4320, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 540, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 540, 4320, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 540, 540, 4320, 540, 4320, 17280, 540, 540, 4320, 540, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 540, 17280, 17280, 17280, 4320, 4320, 540, 540, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 4320, 540, 540, 4320, 4320, 17280, 17280, 17280, 540, 17280, 4320, 4320, 540, 540, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 17280, 4320, 17280, 540, 540, 540, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1190700 . Total input tokens: 265501037 . Total output tokens: 233965036
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 93.44660711614415,
    "estimated_duration": 3600.040517103574,
    "input_throughput": 7132.8694435527705,
    "output_throughput": 6241.5178088268,
    "total_throughput": 13374.38725237957,
    "itl": 83.30593626147481,
    "ttft": 1793596.7485913394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.172889445298358,
    "arrivals": 397242,
    "finished_requests": 103924,
    "scheduler_time": 284.1265170232721
}
#Debug simulation 
Total elapsed time: 93.44678640924394. Arrivals time: 0.5714111416600645 Scheduler time: 92.63743521599099 Scheduler overhead time: 0.0925581632182002 Adapter cache time: 0.018035092391073704 Engine time: 0.09135857224464417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_160_slots_16_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_160_slots_16_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 4320, 540, 540, 540, 17280, 540, 4320, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 540, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 540, 4320, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 540, 540, 4320, 540, 4320, 17280, 540, 540, 4320, 540, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 540, 17280, 17280, 17280, 4320, 4320, 540, 540, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 4320, 540, 540, 4320, 4320, 17280, 17280, 17280, 540, 17280, 4320, 4320, 540, 540, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 17280, 4320, 17280, 540, 540, 540, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1190700 . Total input tokens: 265501037 . Total output tokens: 233965036
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 98.33554332377389,
    "estimated_duration": 3600.0346678517135,
    "input_throughput": 7165.405164110084,
    "output_throughput": 6292.060518827489,
    "total_throughput": 13457.465682937573,
    "itl": 84.87036517004265,
    "ttft": 1782701.1338001357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9124377509579042,
    "arrivals": 397242,
    "finished_requests": 104597,
    "scheduler_time": 282.3817464497466
}
#Debug simulation 
Total elapsed time: 98.33571044495329. Arrivals time: 0.5113721783272922 Scheduler time: 97.58856795076281 Scheduler overhead time: 0.09195247385650873 Adapter cache time: 0.01768700499087572 Engine time: 0.09003269858658314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_160_slots_16_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_160_slots_16_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 4320, 540, 540, 540, 17280, 540, 4320, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 540, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 540, 4320, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 540, 540, 4320, 540, 4320, 17280, 540, 540, 4320, 540, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 540, 17280, 17280, 17280, 4320, 4320, 540, 540, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 4320, 540, 540, 4320, 4320, 17280, 17280, 17280, 540, 17280, 4320, 4320, 540, 540, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 17280, 4320, 17280, 540, 540, 540, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1190700 . Total input tokens: 265501037 . Total output tokens: 233965036
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 95.16523696435615,
    "estimated_duration": 3600.028726839967,
    "input_throughput": 7111.793527957067,
    "output_throughput": 6232.948874187547,
    "total_throughput": 13344.742402144615,
    "itl": 83.22502675814627,
    "ttft": 1784876.789795168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0665532714035417,
    "arrivals": 397242,
    "finished_requests": 103596,
    "scheduler_time": 284.964575539428
}
#Debug simulation 
Total elapsed time: 95.16541562229395. Arrivals time: 0.5648824013769627 Scheduler time: 94.36368475155905 Scheduler overhead time: 0.09307368006557226 Adapter cache time: 0.01785286096855998 Engine time: 0.0898030111566186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_160_slots_16_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_160_slots_16_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 4320, 540, 540, 540, 17280, 540, 4320, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 540, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 540, 4320, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 540, 540, 4320, 540, 4320, 17280, 540, 540, 4320, 540, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 540, 17280, 17280, 17280, 4320, 4320, 540, 540, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 4320, 540, 540, 4320, 4320, 17280, 17280, 17280, 540, 17280, 4320, 4320, 540, 540, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 17280, 4320, 17280, 540, 540, 540, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1190700 . Total input tokens: 265501037 . Total output tokens: 233965036
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 98.74805801222101,
    "estimated_duration": 3600.0293197449696,
    "input_throughput": 7165.5671964992325,
    "output_throughput": 6292.439029803447,
    "total_throughput": 13458.00622630268,
    "itl": 84.86743588574893,
    "ttft": 1782621.7663804926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.787497863359743,
    "arrivals": 397242,
    "finished_requests": 104601,
    "scheduler_time": 282.3928957746978
}
#Debug simulation 
Total elapsed time: 98.74822927312925. Arrivals time: 0.527675673365593 Scheduler time: 97.98814304266125 Scheduler overhead time: 0.09061830025166273 Adapter cache time: 0.017526625655591488 Engine time: 0.08923055417835712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_160_slots_16_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_160_slots_16_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 4320, 540, 540, 540, 17280, 540, 4320, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 540, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 540, 4320, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 540, 540, 4320, 540, 4320, 17280, 540, 540, 4320, 540, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 540, 17280, 17280, 17280, 4320, 4320, 540, 540, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 4320, 540, 540, 4320, 4320, 17280, 17280, 17280, 540, 17280, 4320, 4320, 540, 540, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 17280, 4320, 17280, 540, 540, 540, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 540, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1190700 . Total input tokens: 265501037 . Total output tokens: 233965036
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 95.1756895929575,
    "estimated_duration": 3600.010163204974,
    "input_throughput": 7111.830200281092,
    "output_throughput": 6232.981014704541,
    "total_throughput": 13344.811214985633,
    "itl": 83.2246251788192,
    "ttft": 1784869.5210375402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.047912725508218,
    "arrivals": 397242,
    "finished_requests": 103596,
    "scheduler_time": 284.9644501878867
}
#Debug simulation 
Total elapsed time: 95.17585927201435. Arrivals time: 0.5507823708467185 Scheduler time: 94.38708130642772 Scheduler overhead time: 0.0940804136916995 Adapter cache time: 0.01757892780005932 Engine time: 0.09021164290606976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_160_slots_16_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_160_slots_16_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 4320, 270, 270, 270, 17280, 270, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 270, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 270, 4320, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 270, 270, 4320, 270, 4320, 17280, 270, 270, 4320, 270, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 270, 17280, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 270, 4320, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 17280, 4320, 17280, 270, 270, 270, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1176390 . Total input tokens: 262321473 . Total output tokens: 231153521
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 93.33717087376863,
    "estimated_duration": 3600.0545252403977,
    "input_throughput": 7213.403246514972,
    "output_throughput": 6286.953389543074,
    "total_throughput": 13500.356636058046,
    "itl": 85.90564632438122,
    "ttft": 1783038.553176763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9175986192654795,
    "arrivals": 392500,
    "finished_requests": 105261,
    "scheduler_time": 281.8228285651259
}
#Debug simulation 
Total elapsed time: 93.33734221197665. Arrivals time: 0.5197843401692808 Scheduler time: 92.58225835021585 Scheduler overhead time: 0.09237799840047956 Adapter cache time: 0.017441886477172375 Engine time: 0.08997175376862288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_160_slots_16_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_160_slots_16_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 4320, 270, 270, 270, 17280, 270, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 270, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 270, 4320, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 270, 270, 4320, 270, 4320, 17280, 270, 270, 4320, 270, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 270, 17280, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 270, 4320, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 17280, 4320, 17280, 270, 270, 270, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1176390 . Total input tokens: 262321473 . Total output tokens: 231153521
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 98.07305010594428,
    "estimated_duration": 3600.0439747588316,
    "input_throughput": 7200.413989869808,
    "output_throughput": 6282.954085724814,
    "total_throughput": 13483.368075594622,
    "itl": 85.65386100548253,
    "ttft": 1775942.9169191984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.969930950156415,
    "arrivals": 392500,
    "finished_requests": 105083,
    "scheduler_time": 282.3207353297177
}
#Debug simulation 
Total elapsed time: 98.07322291098535. Arrivals time: 0.5126322936266661 Scheduler time: 97.32432327512652 Scheduler overhead time: 0.09260401595383883 Adapter cache time: 0.018112778663635254 Engine time: 0.08933369675651193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_160_slots_16_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_160_slots_16_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 4320, 270, 270, 270, 17280, 270, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 270, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 270, 4320, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 270, 270, 4320, 270, 4320, 17280, 270, 270, 4320, 270, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 270, 17280, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 270, 4320, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 17280, 4320, 17280, 270, 270, 270, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1176390 . Total input tokens: 262321473 . Total output tokens: 231153521
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 98.3181777652353,
    "estimated_duration": 3600.08544936216,
    "input_throughput": 7069.23164962905,
    "output_throughput": 6163.7275870581,
    "total_throughput": 13232.95923668715,
    "itl": 82.0779498447378,
    "ttft": 1790434.4589812406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.981708407923584,
    "arrivals": 392500,
    "finished_requests": 103195,
    "scheduler_time": 287.79379333586485
}
#Debug simulation 
Total elapsed time: 98.31835001241416. Arrivals time: 0.5199205074459314 Scheduler time: 97.55785161117092 Scheduler overhead time: 0.09326218441128731 Adapter cache time: 0.017896355129778385 Engine time: 0.0924960351549089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_160_slots_16_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_160_slots_16_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 4320, 270, 270, 270, 17280, 270, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 270, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 270, 4320, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 270, 270, 4320, 270, 4320, 17280, 270, 270, 4320, 270, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 270, 17280, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 270, 4320, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 17280, 4320, 17280, 270, 270, 270, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1176390 . Total input tokens: 262321473 . Total output tokens: 231153521
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 94.28969026496634,
    "estimated_duration": 3600.0023980319534,
    "input_throughput": 7172.791333171441,
    "output_throughput": 6256.8563877384595,
    "total_throughput": 13429.647720909901,
    "itl": 85.01952565108162,
    "ttft": 1780908.0393745643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8522060205461437,
    "arrivals": 392500,
    "finished_requests": 104742,
    "scheduler_time": 283.2883455965827
}
#Debug simulation 
Total elapsed time: 94.2898641419597. Arrivals time: 0.5265051792375743 Scheduler time: 93.52741440339014 Scheduler overhead time: 0.0919058695435524 Adapter cache time: 0.017830409575253725 Engine time: 0.09025271050632 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_160_slots_16_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_160_slots_16_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 4320, 270, 270, 270, 17280, 270, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 270, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 270, 4320, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 270, 270, 4320, 270, 4320, 17280, 270, 270, 4320, 270, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 270, 17280, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 270, 4320, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 17280, 4320, 17280, 270, 270, 270, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1176390 . Total input tokens: 262321473 . Total output tokens: 231153521
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 93.5580759854056,
    "estimated_duration": 3600.029340377161,
    "input_throughput": 7149.462286688891,
    "output_throughput": 6219.43542206083,
    "total_throughput": 13368.89770874972,
    "itl": 83.00214858825375,
    "ttft": 1783537.83681907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.259494984154598,
    "arrivals": 392500,
    "finished_requests": 104257,
    "scheduler_time": 285.11365507496873
}
#Debug simulation 
Total elapsed time: 93.55824498506263. Arrivals time: 0.5253267325460911 Scheduler time: 92.79670831840485 Scheduler overhead time: 0.09190237941220403 Adapter cache time: 0.01801865641027689 Engine time: 0.09036155417561531 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_160_slots_16_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_160_slots_16_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 4320, 270, 270, 270, 17280, 270, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 270, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 270, 4320, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 270, 270, 4320, 270, 4320, 17280, 270, 270, 4320, 270, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 270, 17280, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 270, 4320, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 17280, 4320, 17280, 270, 270, 270, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1176390 . Total input tokens: 262321473 . Total output tokens: 231153521
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 94.57684973394498,
    "estimated_duration": 3600.069348020322,
    "input_throughput": 7173.1768206633515,
    "output_throughput": 6257.450849492035,
    "total_throughput": 13430.627670155387,
    "itl": 85.01821906126538,
    "ttft": 1780848.500454428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7300425748946084,
    "arrivals": 392500,
    "finished_requests": 104752,
    "scheduler_time": 283.3022197553612
}
#Debug simulation 
Total elapsed time: 94.57701971614733. Arrivals time: 0.5295284893363714 Scheduler time: 93.81445497600362 Scheduler overhead time: 0.09046738687902689 Adapter cache time: 0.0176127627491951 Engine time: 0.08934956276789308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_160_slots_16_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_160_slots_16_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 4320, 270, 270, 270, 17280, 270, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 270, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 270, 4320, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 270, 270, 4320, 270, 4320, 17280, 270, 270, 4320, 270, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 270, 17280, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 270, 4320, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 17280, 4320, 17280, 270, 270, 270, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 270, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1176390 . Total input tokens: 262321473 . Total output tokens: 231153521
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 93.45783630292863,
    "estimated_duration": 3600.0087664625644,
    "input_throughput": 7149.5031455967555,
    "output_throughput": 6219.470965900168,
    "total_throughput": 13368.974111496924,
    "itl": 83.0017748986043,
    "ttft": 1783529.9438446823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.238990383669742,
    "arrivals": 392500,
    "finished_requests": 104257,
    "scheduler_time": 285.1134846296342
}
#Debug simulation 
Total elapsed time: 93.45799907203764. Arrivals time: 0.5169911072589457 Scheduler time: 92.70562729379162 Scheduler overhead time: 0.09137435490265489 Adapter cache time: 0.017661347053945065 Engine time: 0.09004273917526007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 4320, 135, 135, 135, 17280, 135, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 135, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 135, 4320, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 135, 135, 4320, 135, 4320, 17280, 135, 135, 4320, 135, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 135, 17280, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 135, 4320, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 17280, 4320, 17280, 135, 135, 135, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1169235 . Total input tokens: 260717263 . Total output tokens: 229762091
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 98.709910267964,
    "estimated_duration": 3600.085422356116,
    "input_throughput": 7154.807727629542,
    "output_throughput": 6269.5867880901915,
    "total_throughput": 13424.394515719732,
    "itl": 86.84522067128,
    "ttft": 1786566.8869407556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7589008024986812,
    "arrivals": 390109,
    "finished_requests": 104403,
    "scheduler_time": 281.7510137972443
}
#Debug simulation 
Total elapsed time: 98.71008087787777. Arrivals time: 0.530170613899827 Scheduler time: 97.94510006485507 Scheduler overhead time: 0.09222904033958912 Adapter cache time: 0.017206157092005014 Engine time: 0.09011889575049281 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 4320, 135, 135, 135, 17280, 135, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 135, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 135, 4320, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 135, 135, 4320, 135, 4320, 17280, 135, 135, 4320, 135, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 135, 17280, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 135, 4320, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 17280, 4320, 17280, 135, 135, 135, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1169235 . Total input tokens: 260717263 . Total output tokens: 229762091
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 94.50374067481607,
    "estimated_duration": 3600.048137042301,
    "input_throughput": 7119.984240282623,
    "output_throughput": 6249.132273682055,
    "total_throughput": 13369.116513964678,
    "itl": 85.95749786285583,
    "ttft": 1787722.760993184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0731880530575313,
    "arrivals": 390109,
    "finished_requests": 104044,
    "scheduler_time": 282.6445416267444
}
#Debug simulation 
Total elapsed time: 94.503904288169. Arrivals time: 0.5204235198907554 Scheduler time: 93.7484827581793 Scheduler overhead time: 0.09176482819020748 Adapter cache time: 0.017826726660132408 Engine time: 0.09000662202015519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 4320, 135, 135, 135, 17280, 135, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 135, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 135, 4320, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 135, 135, 4320, 135, 4320, 17280, 135, 135, 4320, 135, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 135, 17280, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 135, 4320, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 17280, 4320, 17280, 135, 135, 135, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1169235 . Total input tokens: 260717263 . Total output tokens: 229762091
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.80393102485687,
    "estimated_duration": 3600.00582286135,
    "input_throughput": 7067.466901977815,
    "output_throughput": 6198.539696322993,
    "total_throughput": 13266.006598300808,
    "itl": 83.86279924750436,
    "ttft": 1793283.6652682256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.100672743534676,
    "arrivals": 390109,
    "finished_requests": 103219,
    "scheduler_time": 285.2589731041729
}
#Debug simulation 
Total elapsed time: 92.80409767990932. Arrivals time: 0.5179093582555652 Scheduler time: 92.0491547351703 Scheduler overhead time: 0.09250042540952563 Adapter cache time: 0.017888618633151054 Engine time: 0.09091821126639843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 4320, 135, 135, 135, 17280, 135, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 135, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 135, 4320, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 135, 135, 4320, 135, 4320, 17280, 135, 135, 4320, 135, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 135, 17280, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 135, 4320, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 17280, 4320, 17280, 135, 135, 135, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1169235 . Total input tokens: 260717263 . Total output tokens: 229762091
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 94.99905992578715,
    "estimated_duration": 3600.0417020935533,
    "input_throughput": 7120.071132813198,
    "output_throughput": 6249.418440602093,
    "total_throughput": 13369.48957341529,
    "itl": 85.95500053269845,
    "ttft": 1787676.739559796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9385306186461801,
    "arrivals": 390109,
    "finished_requests": 104047,
    "scheduler_time": 282.6545022685048
}
#Debug simulation 
Total elapsed time: 94.99922082666308. Arrivals time: 0.526427524164319 Scheduler time: 94.23659564461559 Scheduler overhead time: 0.09201694652438164 Adapter cache time: 0.017746802419424057 Engine time: 0.09029551222920418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 4320, 135, 135, 135, 17280, 135, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 135, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 135, 4320, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 135, 135, 4320, 135, 4320, 17280, 135, 135, 4320, 135, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 135, 17280, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 135, 4320, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 17280, 4320, 17280, 135, 135, 135, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1169235 . Total input tokens: 260717263 . Total output tokens: 229762091
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 93.10000350745395,
    "estimated_duration": 3600.0821645960245,
    "input_throughput": 7067.49730609415,
    "output_throughput": 6198.6074149793985,
    "total_throughput": 13266.104721073549,
    "itl": 83.86294827045936,
    "ttft": 1793243.8663243158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0812037289328935,
    "arrivals": 390109,
    "finished_requests": 103223,
    "scheduler_time": 285.26612388281313
}
#Debug simulation 
Total elapsed time: 93.10029008099809. Arrivals time: 0.5188637254759669 Scheduler time: 92.34255850687623 Scheduler overhead time: 0.09371975203976035 Adapter cache time: 0.017708105500787497 Engine time: 0.09122182428836823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 4320, 135, 135, 135, 17280, 135, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 135, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 135, 4320, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 135, 135, 4320, 135, 4320, 17280, 135, 135, 4320, 135, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 135, 17280, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 135, 4320, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 17280, 4320, 17280, 135, 135, 135, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1169235 . Total input tokens: 260717263 . Total output tokens: 229762091
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 97.20018491707742,
    "estimated_duration": 3600.057456440248,
    "input_throughput": 7081.494200708775,
    "output_throughput": 6207.0537124414595,
    "total_throughput": 13288.547913150234,
    "itl": 84.57344561177072,
    "ttft": 1791056.161238465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.774730021478602,
    "arrivals": 390109,
    "finished_requests": 103274,
    "scheduler_time": 285.3613825792144
}
#Debug simulation 
Total elapsed time: 97.20035067433491. Arrivals time: 0.5232087150216103 Scheduler time: 96.44139102706686 Scheduler overhead time: 0.09206287423148751 Adapter cache time: 0.017758445348590612 Engine time: 0.09039543848484755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 4320, 135, 135, 135, 17280, 135, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 135, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 135, 4320, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 135, 135, 4320, 135, 4320, 17280, 135, 135, 4320, 135, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 135, 17280, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 135, 4320, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 17280, 4320, 17280, 135, 135, 135, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 135, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1169235 . Total input tokens: 260717263 . Total output tokens: 229762091
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.87432726891711,
    "estimated_duration": 3600.0630891300184,
    "input_throughput": 7067.534754272494,
    "output_throughput": 6198.6402592163195,
    "total_throughput": 13266.175013488813,
    "itl": 83.86259185668548,
    "ttft": 1793236.1616514963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0621489486843405,
    "arrivals": 390109,
    "finished_requests": 103223,
    "scheduler_time": 285.2660020658336
}
#Debug simulation 
Total elapsed time: 92.87450010282919. Arrivals time: 0.5271266335621476 Scheduler time: 92.10993565199897 Scheduler overhead time: 0.0931448875926435 Adapter cache time: 0.01769443228840828 Engine time: 0.09041011100634933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_160_slots_16_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_160_slots_16_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 4320, 66, 66, 66, 17280, 66, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 66, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 66, 4320, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 66, 66, 4320, 66, 4320, 17280, 66, 66, 4320, 66, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 66, 17280, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 66, 4320, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 17280, 4320, 17280, 66, 66, 66, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1165578 . Total input tokens: 259918053 . Total output tokens: 229056021
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 96.59849174134433,
    "estimated_duration": 3600.0296918026593,
    "input_throughput": 7228.606213791889,
    "output_throughput": 6317.054565350682,
    "total_throughput": 13545.66077914257,
    "itl": 86.40737957341331,
    "ttft": 1762767.798428213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8382497108820803,
    "arrivals": 388923,
    "finished_requests": 105294,
    "scheduler_time": 280.97623672045995
}
#Debug simulation 
Total elapsed time: 96.59864889411256. Arrivals time: 0.5171278454363346 Scheduler time: 95.85020742658526 Scheduler overhead time: 0.09058765880763531 Adapter cache time: 0.01754475012421608 Engine time: 0.08830737182870507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_160_slots_16_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_160_slots_16_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 4320, 66, 66, 66, 17280, 66, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 66, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 66, 4320, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 66, 66, 4320, 66, 4320, 17280, 66, 66, 4320, 66, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 66, 17280, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 66, 4320, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 17280, 4320, 17280, 66, 66, 66, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1165578 . Total input tokens: 259918053 . Total output tokens: 229056021
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 95.64796327007934,
    "estimated_duration": 3600.032188118313,
    "input_throughput": 7273.043581781304,
    "output_throughput": 6353.190695207288,
    "total_throughput": 13626.23427698859,
    "itl": 86.18210151926057,
    "ttft": 1762018.9427812092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1481330302497397,
    "arrivals": 388923,
    "finished_requests": 105790,
    "scheduler_time": 279.79371109457657
}
#Debug simulation 
Total elapsed time: 95.6481262864545. Arrivals time: 0.5365221025422215 Scheduler time: 94.8781572538428 Scheduler overhead time: 0.09111424023285508 Adapter cache time: 0.01737881312146783 Engine time: 0.08961803931742907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_160_slots_16_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_160_slots_16_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 4320, 66, 66, 66, 17280, 66, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 66, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 66, 4320, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 66, 66, 4320, 66, 4320, 17280, 66, 66, 4320, 66, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 66, 17280, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 66, 4320, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 17280, 4320, 17280, 66, 66, 66, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1165578 . Total input tokens: 259918053 . Total output tokens: 229056021
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 93.48331338260323,
    "estimated_duration": 3600.065343210737,
    "input_throughput": 7162.480550145559,
    "output_throughput": 6258.429737251888,
    "total_throughput": 13420.910287397446,
    "itl": 83.67535454159571,
    "ttft": 1772132.5919346602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1929271634342244,
    "arrivals": 388923,
    "finished_requests": 104269,
    "scheduler_time": 284.1811472855828
}
#Debug simulation 
Total elapsed time: 93.48347725486383. Arrivals time: 0.5189492804929614 Scheduler time: 92.73013312742114 Scheduler overhead time: 0.09146964596584439 Adapter cache time: 0.017532851547002792 Engine time: 0.08969003008678555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_160_slots_16_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_160_slots_16_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 4320, 66, 66, 66, 17280, 66, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 66, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 66, 4320, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 66, 66, 4320, 66, 4320, 17280, 66, 66, 4320, 66, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 66, 17280, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 66, 4320, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 17280, 4320, 17280, 66, 66, 66, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1165578 . Total input tokens: 259918053 . Total output tokens: 229056021
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 92.33774108998477,
    "estimated_duration": 3600.000625252106,
    "input_throughput": 7281.580679771207,
    "output_throughput": 6355.115285125217,
    "total_throughput": 13636.695964896424,
    "itl": 86.55959252403784,
    "ttft": 1767058.5750601185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.993766649090683,
    "arrivals": 388923,
    "finished_requests": 105984,
    "scheduler_time": 279.10968232051806
}
#Debug simulation 
Total elapsed time: 92.3379104831256. Arrivals time: 0.527338488958776 Scheduler time: 91.57841397542506 Scheduler overhead time: 0.09088827576488256 Adapter cache time: 0.01692797103896737 Engine time: 0.08867919072508812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_160_slots_16_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_160_slots_16_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 4320, 66, 66, 66, 17280, 66, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 66, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 66, 4320, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 66, 66, 4320, 66, 4320, 17280, 66, 66, 4320, 66, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 66, 17280, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 66, 4320, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 17280, 4320, 17280, 66, 66, 66, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1165578 . Total input tokens: 259918053 . Total output tokens: 229056021
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 93.5286080497317,
    "estimated_duration": 3600.0447372960343,
    "input_throughput": 7162.521546709226,
    "output_throughput": 6258.4655592148765,
    "total_throughput": 13420.987105924103,
    "itl": 83.67497502091072,
    "ttft": 1772124.028426252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.172422562949369,
    "arrivals": 388923,
    "finished_requests": 104269,
    "scheduler_time": 284.18084370892024
}
#Debug simulation 
Total elapsed time: 93.52876992058009. Arrivals time: 0.5202329414896667 Scheduler time: 92.77361646899953 Scheduler overhead time: 0.09207530179992318 Adapter cache time: 0.01785079389810562 Engine time: 0.08940293546766043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_160_slots_16_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_160_slots_16_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 4320, 66, 66, 66, 17280, 66, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 66, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 66, 4320, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 66, 66, 4320, 66, 4320, 17280, 66, 66, 4320, 66, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 66, 17280, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 66, 4320, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 17280, 4320, 17280, 66, 66, 66, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1165578 . Total input tokens: 259918053 . Total output tokens: 229056021
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 95.21263882378116,
    "estimated_duration": 3600.064802952434,
    "input_throughput": 7251.884460132298,
    "output_throughput": 6334.3718094458145,
    "total_throughput": 13586.256269578113,
    "itl": 86.16891278263905,
    "ttft": 1765193.2254424137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9151762821711529,
    "arrivals": 388923,
    "finished_requests": 105585,
    "scheduler_time": 280.1134828758693
}
#Debug simulation 
Total elapsed time: 95.21280755056068. Arrivals time: 0.5228492147289217 Scheduler time: 94.45871565910056 Scheduler overhead time: 0.0899574477225542 Adapter cache time: 0.017868227791041136 Engine time: 0.08762552076950669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_160_slots_16_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_160_slots_16_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 4320, 66, 66, 66, 17280, 66, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 66, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 66, 4320, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 66, 66, 4320, 66, 4320, 17280, 66, 66, 4320, 66, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 66, 17280, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 66, 4320, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 17280, 4320, 17280, 66, 66, 66, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 66, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1165578 . Total input tokens: 259918053 . Total output tokens: 229056021
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.57708221906796,
    "estimated_duration": 3600.0495931290034,
    "input_throughput": 7167.514594590021,
    "output_throughput": 6262.434285080173,
    "total_throughput": 13429.948879670195,
    "itl": 83.82800912999683,
    "ttft": 1773024.607988073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 294,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1738160246610736,
    "arrivals": 388923,
    "finished_requests": 104348,
    "scheduler_time": 283.7223654340267
}
#Debug simulation 
Total elapsed time: 92.57724659098312. Arrivals time: 0.5168912084773183 Scheduler time: 91.82616162346676 Scheduler overhead time: 0.0909329648129642 Adapter cache time: 0.017411476466804743 Engine time: 0.08947130478918552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259540487 . Total output tokens: 228701724
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 93.85008557187393,
    "estimated_duration": 3600.040765001416,
    "input_throughput": 7270.687391782828,
    "output_throughput": 6367.947058508095,
    "total_throughput": 13638.634450290923,
    "itl": 87.33292209455882,
    "ttft": 1777368.37542349,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8580869379779301,
    "arrivals": 388315,
    "finished_requests": 105900,
    "scheduler_time": 277.5055825086934
}
#Debug simulation 
Total elapsed time: 93.85025645187125. Arrivals time: 0.530020194593817 Scheduler time: 93.08909057592973 Scheduler overhead time: 0.09042563382536173 Adapter cache time: 0.017499441746622324 Engine time: 0.08832854498177767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259540487 . Total output tokens: 228701724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 94.16373342694715,
    "estimated_duration": 3600.0519037308673,
    "input_throughput": 7195.289038237291,
    "output_throughput": 6306.739904630373,
    "total_throughput": 13502.028942867662,
    "itl": 85.79353990744461,
    "ttft": 1780599.980180869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.064027690170335,
    "arrivals": 388315,
    "finished_requests": 104912,
    "scheduler_time": 280.5364865690957
}
#Debug simulation 
Total elapsed time: 94.16389520000666. Arrivals time: 0.529201845638454 Scheduler time: 93.40443489700556 Scheduler overhead time: 0.09028480015695095 Adapter cache time: 0.017349612899124622 Engine time: 0.08795477589592338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259540487 . Total output tokens: 228701724
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.68397426092997,
    "estimated_duration": 3600.0202292841136,
    "input_throughput": 7158.592274111954,
    "output_throughput": 6280.690818366946,
    "total_throughput": 13439.2830924789,
    "itl": 84.15552877093788,
    "ttft": 1779363.3975721386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8984659785963651,
    "arrivals": 388315,
    "finished_requests": 104252,
    "scheduler_time": 282.53420113160394
}
#Debug simulation 
Total elapsed time: 92.68413843214512. Arrivals time: 0.5175751144997776 Scheduler time: 91.9303424837999 Scheduler overhead time: 0.09352489979937673 Adapter cache time: 0.017212308943271637 Engine time: 0.09023639187216759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_160_slots_16_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259540487 . Total output tokens: 228701724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 97.18869750387967,
    "estimated_duration": 3600.0052378456103,
    "input_throughput": 7248.690842354581,
    "output_throughput": 6365.439071892472,
    "total_throughput": 13614.129914247053,
    "itl": 86.40555871941073,
    "ttft": 1767312.8794989593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8308349997038,
    "arrivals": 388315,
    "finished_requests": 105590,
    "scheduler_time": 278.7412468504761
}
#Debug simulation 
Total elapsed time: 97.18886347068474. Arrivals time: 0.5136297689750791 Scheduler time: 96.4418331622146 Scheduler overhead time: 0.09093142161145806 Adapter cache time: 0.017438490875065327 Engine time: 0.08951704483479261 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_160_slots_16_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259540487 . Total output tokens: 228701724
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 92.61255749687552,
    "estimated_duration": 3600.0015002487853,
    "input_throughput": 7158.62951674299,
    "output_throughput": 6280.723493708947,
    "total_throughput": 13439.353010451936,
    "itl": 84.1551171189186,
    "ttft": 1779355.2458494646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8802396670542714,
    "arrivals": 388315,
    "finished_requests": 104252,
    "scheduler_time": 282.5339006702611
}
#Debug simulation 
Total elapsed time: 92.61271785991266. Arrivals time: 0.5298449783585966 Scheduler time: 91.84838135167956 Scheduler overhead time: 0.09278928255662322 Adapter cache time: 0.017382643185555935 Engine time: 0.08898694859817624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_160_slots_16_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259540487 . Total output tokens: 228701724
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 93.89403793914244,
    "estimated_duration": 3600.08048690918,
    "input_throughput": 7209.50214707096,
    "output_throughput": 6316.953491093908,
    "total_throughput": 13526.455638164869,
    "itl": 86.18235233945472,
    "ttft": 1778406.0962315567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7300425748946084,
    "arrivals": 388315,
    "finished_requests": 105033,
    "scheduler_time": 280.0863421914766
}
#Debug simulation 
Total elapsed time: 93.89419706584886. Arrivals time: 0.5257275900803506 Scheduler time: 93.13512440863997 Scheduler overhead time: 0.09087819326668978 Adapter cache time: 0.01780783198773861 Engine time: 0.08899752562865615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_160_slots_16_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 4320, 33, 33, 33, 17280, 33, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 33, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 33, 4320, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 33, 33, 4320, 33, 4320, 17280, 33, 33, 4320, 33, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 33, 17280, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 33, 4320, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 17280, 4320, 17280, 33, 33, 33, 4320, 4320, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 33, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 17280, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1163829 . Total input tokens: 259540487 . Total output tokens: 228701724
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 92.6279498776421,
    "estimated_duration": 3600.0323810041878,
    "input_throughput": 7158.568110660009,
    "output_throughput": 6280.66961822522,
    "total_throughput": 13439.237728885228,
    "itl": 84.15480414341144,
    "ttft": 1779346.8458174192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8628418242186364,
    "arrivals": 388315,
    "finished_requests": 104252,
    "scheduler_time": 282.5389272164365
}
#Debug simulation 
Total elapsed time: 92.62811031704769. Arrivals time: 0.5045835846103728 Scheduler time: 91.89015708584338 Scheduler overhead time: 0.09156529931351542 Adapter cache time: 0.016724790912121534 Engine time: 0.0897621656768024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_160_slots_16_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_160_slots_16_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227184161 . Total output tokens: 200377611
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 98.71567687718198,
    "estimated_duration": 3600.047000408078,
    "input_throughput": 7210.890023673967,
    "output_throughput": 6309.493458675744,
    "total_throughput": 13520.38348234971,
    "itl": 85.67485817797358,
    "ttft": 1724202.1327058584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6134278037957828,
    "arrivals": 339810,
    "finished_requests": 104922,
    "scheduler_time": 279.1726514930087
}
#Debug simulation 
Total elapsed time: 98.71584756718948. Arrivals time: 0.5071959607303143 Scheduler time: 97.97268856875598 Scheduler overhead time: 0.0921208425424993 Adapter cache time: 0.017099042888730764 Engine time: 0.09105989150702953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_160_slots_16_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_160_slots_16_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227184161 . Total output tokens: 200377611
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 97.51389358798042,
    "estimated_duration": 3600.092792604684,
    "input_throughput": 7225.146822168652,
    "output_throughput": 6336.179180397252,
    "total_throughput": 13561.326002565904,
    "itl": 85.24886105604342,
    "ttft": 1713284.1747082088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 228,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.66793178336695,
    "arrivals": 339810,
    "finished_requests": 105258,
    "scheduler_time": 277.6434353046027
}
#Debug simulation 
Total elapsed time: 97.51406247308478. Arrivals time: 0.5204105693846941 Scheduler time: 96.75562963122502 Scheduler overhead time: 0.09271375881507993 Adapter cache time: 0.017321019899100065 Engine time: 0.09141469560563564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_160_slots_16_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_160_slots_16_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227184161 . Total output tokens: 200377611
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 91.21215254114941,
    "estimated_duration": 3600.0227501618724,
    "input_throughput": 7190.456782206741,
    "output_throughput": 6288.68164763182,
    "total_throughput": 13479.138429838562,
    "itl": 83.39431538217924,
    "ttft": 1723875.28479384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8678704914962918,
    "arrivals": 339810,
    "finished_requests": 104561,
    "scheduler_time": 280.1041251115227
}
#Debug simulation 
Total elapsed time: 91.21231173118576. Arrivals time: 0.5093694631941617 Scheduler time: 90.46688055153936 Scheduler overhead time: 0.09188178880140185 Adapter cache time: 0.01717544486746192 Engine time: 0.09077806724235415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_160_slots_16_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_160_slots_16_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227184161 . Total output tokens: 200377611
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 97.37970163812861,
    "estimated_duration": 3600.0263967497326,
    "input_throughput": 7220.034004047037,
    "output_throughput": 6344.062371492581,
    "total_throughput": 13564.096375539619,
    "itl": 85.12429804298623,
    "ttft": 1709001.9435279507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 230,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.573806610302998,
    "arrivals": 339810,
    "finished_requests": 105150,
    "scheduler_time": 278.4292291372211
}
#Debug simulation 
Total elapsed time: 97.37985967611894. Arrivals time: 0.5223102709278464 Scheduler time: 96.62018761225045 Scheduler overhead time: 0.09257626486942172 Adapter cache time: 0.017561940010637045 Engine time: 0.09084203792735934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_160_slots_16_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_160_slots_16_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227184161 . Total output tokens: 200377611
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 91.07579320902005,
    "estimated_duration": 3600.0378050364616,
    "input_throughput": 7173.431057827029,
    "output_throughput": 6290.350331410102,
    "total_throughput": 13463.78138923713,
    "itl": 83.26260682063108,
    "ttft": 1720000.5388053202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9694888532534292,
    "arrivals": 339810,
    "finished_requests": 104371,
    "scheduler_time": 280.8669338114513
}
#Debug simulation 
Total elapsed time: 91.07596109434962. Arrivals time: 0.5170941157266498 Scheduler time: 90.32103245519102 Scheduler overhead time: 0.09247813886031508 Adapter cache time: 0.017645773012191057 Engine time: 0.09169817389920354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_160_slots_16_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_160_slots_16_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227184161 . Total output tokens: 200377611
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 99.28817593213171,
    "estimated_duration": 3600.0045387420273,
    "input_throughput": 7167.757629832557,
    "output_throughput": 6265.123212283881,
    "total_throughput": 13432.880842116438,
    "itl": 84.54639774121333,
    "ttft": 1718637.9518292977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5512927885586345,
    "arrivals": 339810,
    "finished_requests": 104262,
    "scheduler_time": 280.8689149481775
}
#Debug simulation 
Total elapsed time: 99.28834318183362. Arrivals time: 0.5174108841456473 Scheduler time: 98.5345495142974 Scheduler overhead time: 0.09304808545857668 Adapter cache time: 0.01710139913484454 Engine time: 0.09092694707214832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_160_slots_16_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_160_slots_16_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [53 53 54]
Adapter prompts. [540, 17280, 540, 540, 1080, 540, 540, 540, 17280, 540, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 540, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 540, 1080, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 540, 540, 1080, 540, 1080, 17280, 540, 540, 1080, 540, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 540, 17280, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 540, 1080, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 17280, 1080, 17280, 540, 540, 540, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 540, 1080, 1080, 540, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 17280, 1080, 540, 540]
Prompts retrieved: 1018980 . Total input tokens: 227184161 . Total output tokens: 200377611
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 91.04756913334131,
    "estimated_duration": 3600.019029049055,
    "input_throughput": 7173.468471032381,
    "output_throughput": 6290.383138886299,
    "total_throughput": 13463.85160991868,
    "itl": 83.2622895501309,
    "ttft": 1719993.0469900502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9512625417113354,
    "arrivals": 339810,
    "finished_requests": 104371,
    "scheduler_time": 280.86658639803005
}
#Debug simulation 
Total elapsed time: 91.04773639235646. Arrivals time: 0.4952721521258354 Scheduler time: 90.3155404808931 Scheduler overhead time: 0.09328510100021958 Adapter cache time: 0.01742942025884986 Engine time: 0.09041935484856367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_160_slots_16_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_160_slots_16_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 224020250 . Total output tokens: 197597537
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 93.72179854428396,
    "estimated_duration": 3600.070873143687,
    "input_throughput": 7204.499276246555,
    "output_throughput": 6319.708639550425,
    "total_throughput": 13524.20791579698,
    "itl": 86.23340493944207,
    "ttft": 1711385.7379663757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.593590576699933,
    "arrivals": 335110,
    "finished_requests": 105311,
    "scheduler_time": 278.5858278801181
}
#Debug simulation 
Total elapsed time: 93.72197798918933. Arrivals time: 0.507998279761523 Scheduler time: 92.98157412745059 Scheduler overhead time: 0.09086718363687396 Adapter cache time: 0.01699899137020111 Engine time: 0.08920906623825431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_160_slots_16_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_160_slots_16_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 224020250 . Total output tokens: 197597537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 95.00821931194514,
    "estimated_duration": 3600.079670095374,
    "input_throughput": 7154.9883226105385,
    "output_throughput": 6276.848589687282,
    "total_throughput": 13431.83691229782,
    "itl": 85.1031134102281,
    "ttft": 1715141.774105173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7131764138769376,
    "arrivals": 335110,
    "finished_requests": 104571,
    "scheduler_time": 280.64514958367926
}
#Debug simulation 
Total elapsed time: 95.00839324016124. Arrivals time: 0.5061665019020438 Scheduler time: 94.268293349538 Scheduler overhead time: 0.09174165222793818 Adapter cache time: 0.016766300424933434 Engine time: 0.09008864359930158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_160_slots_16_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_160_slots_16_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 224020250 . Total output tokens: 197597537
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 97.86569933686405,
    "estimated_duration": 3600.0941786684034,
    "input_throughput": 7042.482430106244,
    "output_throughput": 6172.768793570739,
    "total_throughput": 13215.251223676983,
    "itl": 82.50472491103666,
    "ttft": 1724203.873602133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.830907737417151,
    "arrivals": 335110,
    "finished_requests": 102906,
    "scheduler_time": 285.91849995719633
}
#Debug simulation 
Total elapsed time: 97.86586715094745. Arrivals time: 0.5062163406983018 Scheduler time: 97.11883577238768 Scheduler overhead time: 0.09480930306017399 Adapter cache time: 0.0179689833894372 Engine time: 0.09162001498043537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_160_slots_16_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_160_slots_16_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 224020250 . Total output tokens: 197597537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 92.92002894869074,
    "estimated_duration": 3600.0200768878967,
    "input_throughput": 7175.910536124614,
    "output_throughput": 6298.113209301982,
    "total_throughput": 13474.023745426595,
    "itl": 85.1777524721821,
    "ttft": 1715068.8038932756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6290426407475007,
    "arrivals": 335110,
    "finished_requests": 104890,
    "scheduler_time": 279.8658372697344
}
#Debug simulation 
Total elapsed time: 92.9202020498924. Arrivals time: 0.5146976741962135 Scheduler time: 92.17121339635924 Scheduler overhead time: 0.0919659836217761 Adapter cache time: 0.017313416115939617 Engine time: 0.08967587677761912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_160_slots_16_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_160_slots_16_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 224020250 . Total output tokens: 197597537
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 98.00295984791592,
    "estimated_duration": 3600.0761836772135,
    "input_throughput": 7042.517631974987,
    "output_throughput": 6172.799648173361,
    "total_throughput": 13215.317280148349,
    "itl": 82.50439804011874,
    "ttft": 1724196.6955427523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8130956602282866,
    "arrivals": 335110,
    "finished_requests": 102906,
    "scheduler_time": 285.9182159119734
}
#Debug simulation 
Total elapsed time: 98.003134614788. Arrivals time: 0.4998410865664482 Scheduler time: 97.26281827641651 Scheduler overhead time: 0.09433031314983964 Adapter cache time: 0.01765295723453164 Engine time: 0.09236242715269327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_160_slots_16_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_160_slots_16_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 224020250 . Total output tokens: 197597537
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 92.86696078488603,
    "estimated_duration": 3600.068544455372,
    "input_throughput": 7172.317604832228,
    "output_throughput": 6292.345470724083,
    "total_throughput": 13464.663075556311,
    "itl": 85.30966084747106,
    "ttft": 1714559.633549668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.532141025736923,
    "arrivals": 335110,
    "finished_requests": 104861,
    "scheduler_time": 279.9561376202531
}
#Debug simulation 
Total elapsed time: 92.8671374139376. Arrivals time: 0.5006723068654537 Scheduler time: 92.1330569148995 Scheduler overhead time: 0.09149231482297182 Adapter cache time: 0.017045891378074884 Engine time: 0.08961878018453717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_160_slots_16_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_160_slots_16_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 1080, 270, 270, 270, 17280, 270, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 270, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 270, 1080, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 270, 270, 1080, 270, 1080, 17280, 270, 270, 1080, 270, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 270, 17280, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 270, 1080, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 17280, 1080, 17280, 270, 270, 270, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 270, 1080, 1080, 270, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 17280, 1080, 270, 270]
Prompts retrieved: 1004670 . Total input tokens: 224020250 . Total output tokens: 197597537
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 91.60545161226764,
    "estimated_duration": 3600.025467075797,
    "input_throughput": 7098.185897211592,
    "output_throughput": 6223.679028081793,
    "total_throughput": 13321.864925293385,
    "itl": 83.05876174631929,
    "ttft": 1722739.8713100192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7556798158958589,
    "arrivals": 335110,
    "finished_requests": 103703,
    "scheduler_time": 283.39315687323324
}
#Debug simulation 
Total elapsed time: 91.60562276793644. Arrivals time: 0.5068210186436772 Scheduler time: 90.86196161201224 Scheduler overhead time: 0.09213699633255601 Adapter cache time: 0.017217000480741262 Engine time: 0.09139580512419343 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_160_slots_16_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 97.57098271977156,
    "estimated_duration": 3600.085135154151,
    "input_throughput": 7158.509599772703,
    "output_throughput": 6243.318187262143,
    "total_throughput": 13401.827787034847,
    "itl": 85.51689831714747,
    "ttft": 1710917.1973561835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8580869379779301,
    "arrivals": 332795,
    "finished_requests": 103965,
    "scheduler_time": 282.00437571600503
}
#Debug simulation 
Total elapsed time: 97.57115719979629. Arrivals time: 0.5045236274600029 Scheduler time: 96.83044607518241 Scheduler overhead time: 0.09295686054974794 Adapter cache time: 0.017625376116484404 Engine time: 0.09000255726277828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_160_slots_16_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 98.61429326375946,
    "estimated_duration": 3600.048191471362,
    "input_throughput": 7115.908631636935,
    "output_throughput": 6220.005069112178,
    "total_throughput": 13335.913700749114,
    "itl": 84.71814733103085,
    "ttft": 1719889.269238294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6537757205124959,
    "arrivals": 332795,
    "finished_requests": 103446,
    "scheduler_time": 283.18678841874066
}
#Debug simulation 
Total elapsed time: 98.61447499319911. Arrivals time: 0.5014047035947442 Scheduler time: 97.8733288324438 Scheduler overhead time: 0.09452543314546347 Adapter cache time: 0.017232457641512156 Engine time: 0.09176900237798691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_160_slots_16_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 95.2639343822375,
    "estimated_duration": 3600.0921147856757,
    "input_throughput": 7113.429929979606,
    "output_throughput": 6214.701537249961,
    "total_throughput": 13328.131467229567,
    "itl": 82.97000399662096,
    "ttft": 1726191.4985351912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8274901246279514,
    "arrivals": 332795,
    "finished_requests": 103444,
    "scheduler_time": 283.54484675158926
}
#Debug simulation 
Total elapsed time: 95.26411293586716. Arrivals time: 0.4948584195226431 Scheduler time: 94.52737543312833 Scheduler overhead time: 0.09411752037703991 Adapter cache time: 0.018454402219504118 Engine time: 0.09235681919381022 
