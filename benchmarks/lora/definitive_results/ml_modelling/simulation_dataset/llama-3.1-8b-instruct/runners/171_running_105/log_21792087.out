INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:51 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.490792314056307,
    "estimated_duration": 3600.0063160140894,
    "input_throughput": 5122.693234721487,
    "output_throughput": 4473.2929851718,
    "total_throughput": 9595.986219893288,
    "itl": 98.90128262279978,
    "ttft": 2114585.1679085377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 657,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.8260173905454895,
    "arrivals": 750836,
    "finished_requests": 74651,
    "scheduler_time": 172.5812886916257
}
#Debug simulation 
Total elapsed time: 7.490892972797155. Arrivals time: 0.2377558322623372 Scheduler time: 7.106427581515163 Scheduler overhead time: 0.05229419842362404 Adapter cache time: 0.016404402907937765 Engine time: 0.05335538275539875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_192_slots_64_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_192_slots_64_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 11.067089301999658,
    "estimated_duration": 3600.1131487405296,
    "input_throughput": 5577.963850115456,
    "output_throughput": 4874.421795920272,
    "total_throughput": 10452.385646035727,
    "itl": 119.17235997797268,
    "ttft": 2070152.7190525348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0183109909202892,
    "arrivals": 749460,
    "finished_requests": 81604,
    "scheduler_time": 160.18432731755303
}
#Debug simulation 
Total elapsed time: 11.067196395248175. Arrivals time: 0.3515498717315495 Scheduler time: 10.59132582647726 Scheduler overhead time: 0.046332891564816236 Adapter cache time: 0.009264778345823288 Engine time: 0.047370002605021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_192_slots_64_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_192_slots_64_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.552107543684542,
    "estimated_duration": 3600.0561939179943,
    "input_throughput": 5422.117586102503,
    "output_throughput": 4737.6027154282,
    "total_throughput": 10159.720301530702,
    "itl": 111.22386609421412,
    "ttft": 2086399.5270196355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 359,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6111184415267807,
    "arrivals": 749460,
    "finished_requests": 79248,
    "scheduler_time": 164.55382805985087
}
#Debug simulation 
Total elapsed time: 9.552210027817637. Arrivals time: 0.3588361102156341 Scheduler time: 9.060043242294341 Scheduler overhead time: 0.04885809030383825 Adapter cache time: 0.012033701874315739 Engine time: 0.04983985936269164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_192_slots_64_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_192_slots_64_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.508210856001824,
    "estimated_duration": 3600.0272548337675,
    "input_throughput": 5117.946808669583,
    "output_throughput": 4469.163664913121,
    "total_throughput": 9587.110473582703,
    "itl": 98.57679259342282,
    "ttft": 2117131.6993561084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.669728520205274,
    "arrivals": 749460,
    "finished_requests": 74752,
    "scheduler_time": 172.82421269096
}
#Debug simulation 
Total elapsed time: 7.508331398013979. Arrivals time: 0.2517704484052956 Scheduler time: 7.111394525505602 Scheduler overhead time: 0.052496048621833324 Adapter cache time: 0.014547663740813732 Engine time: 0.05337247531861067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_192_slots_64_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_192_slots_64_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 9.521873448975384,
    "estimated_duration": 3600.062510111582,
    "input_throughput": 5422.539454570455,
    "output_throughput": 4738.526053946565,
    "total_throughput": 10161.06550851702,
    "itl": 111.2484885728667,
    "ttft": 2086277.3595872154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3437774106534164,
    "arrivals": 749460,
    "finished_requests": 79259,
    "scheduler_time": 164.5444490925921
}
#Debug simulation 
Total elapsed time: 9.521998289972544. Arrivals time: 0.3484422261826694 Scheduler time: 9.04083004547283 Scheduler overhead time: 0.04849888477474451 Adapter cache time: 0.011890998110175133 Engine time: 0.04971729591488838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_192_slots_64_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_192_slots_64_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 7.516745099797845,
    "estimated_duration": 3600.102352290652,
    "input_throughput": 5118.227260476615,
    "output_throughput": 4469.216268188203,
    "total_throughput": 9587.443528664817,
    "itl": 98.57558949628624,
    "ttft": 2117176.900338066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6355541860638483,
    "arrivals": 749460,
    "finished_requests": 74756,
    "scheduler_time": 172.82937302570892
}
#Debug simulation 
Total elapsed time: 7.516860675998032. Arrivals time: 0.32648612512275577 Scheduler time: 7.046059218700975 Scheduler overhead time: 0.052157639525830746 Adapter cache time: 0.01445507537573576 Engine time: 0.05309053137898445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_192_slots_64_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_192_slots_64_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 9.514248785562813,
    "estimated_duration": 3600.0288241355956,
    "input_throughput": 5422.652137983191,
    "output_throughput": 4738.607614925437,
    "total_throughput": 10161.259752908627,
    "itl": 111.24414482172034,
    "ttft": 2086202.686697949,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1896848826156843,
    "arrivals": 749460,
    "finished_requests": 79260,
    "scheduler_time": 164.54884059391574
}
#Debug simulation 
Total elapsed time: 9.514343776740134. Arrivals time: 0.34736931417137384 Scheduler time: 9.033979279920459 Scheduler overhead time: 0.04870287235826254 Adapter cache time: 0.011733617633581161 Engine time: 0.0498941745609045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_192_slots_64_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_192_slots_64_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.529803028795868,
    "estimated_duration": 3600.0704505472336,
    "input_throughput": 5118.272615248157,
    "output_throughput": 4469.255871799473,
    "total_throughput": 9587.52848704763,
    "itl": 98.57476095258752,
    "ttft": 2117163.7129804823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6038652580417985,
    "arrivals": 749460,
    "finished_requests": 74756,
    "scheduler_time": 172.82916021031264
}
#Debug simulation 
Total elapsed time: 7.529953620862216. Arrivals time: 0.3283210378140211 Scheduler time: 7.055800926871598 Scheduler overhead time: 0.05265091499313712 Adapter cache time: 0.014473219867795706 Engine time: 0.05386726139113307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 10.99644158501178,
    "estimated_duration": 3600.0899962744516,
    "input_throughput": 5624.085514793464,
    "output_throughput": 4876.045048364331,
    "total_throughput": 10500.130563157794,
    "itl": 119.10374843622049,
    "ttft": 2065306.1976512272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7802642657700918,
    "arrivals": 748703,
    "finished_requests": 81916,
    "scheduler_time": 160.18528554977667
}
#Debug simulation 
Total elapsed time: 10.996534429024905. Arrivals time: 0.3306489009410143 Scheduler time: 10.541097878478467 Scheduler overhead time: 0.04680406814441085 Adapter cache time: 0.008696723729372025 Engine time: 0.04786773445084691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.370645484887064,
    "estimated_duration": 3600.021929165529,
    "input_throughput": 5469.5100161693035,
    "output_throughput": 4740.491123607073,
    "total_throughput": 10210.001139776376,
    "itl": 111.3680862327108,
    "ttft": 2083081.7265162044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.422924961498941,
    "arrivals": 748703,
    "finished_requests": 79660,
    "scheduler_time": 164.39070900921178
}
#Debug simulation 
Total elapsed time: 9.370743121020496. Arrivals time: 0.2767886212095618 Scheduler time: 8.961048278491944 Scheduler overhead time: 0.04909082781523466 Adapter cache time: 0.011611692607402802 Engine time: 0.04984548594802618 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.133498071692884,
    "estimated_duration": 3600.0145990958654,
    "input_throughput": 5165.67127385274,
    "output_throughput": 4478.766559460456,
    "total_throughput": 9644.437833313195,
    "itl": 98.93929408053411,
    "ttft": 2113179.2004460436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.514574319710983,
    "arrivals": 748703,
    "finished_requests": 75213,
    "scheduler_time": 172.54534304448782
}
#Debug simulation 
Total elapsed time: 7.133584037888795. Arrivals time: 0.24229518184438348 Scheduler time: 6.747211990412325 Scheduler overhead time: 0.052194643300026655 Adapter cache time: 0.01406168844550848 Engine time: 0.05321619473397732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 9.359151491895318,
    "estimated_duration": 3600.031698612306,
    "input_throughput": 5470.084057201719,
    "output_throughput": 4740.89047787521,
    "total_throughput": 10210.97453507693,
    "itl": 111.39174401224471,
    "ttft": 2083048.75822835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3068621059833063,
    "arrivals": 748703,
    "finished_requests": 79666,
    "scheduler_time": 164.37827954227436
}
#Debug simulation 
Total elapsed time: 9.359242465812713. Arrivals time: 0.2684741346165538 Scheduler time: 8.957062867004424 Scheduler overhead time: 0.048825284000486135 Adapter cache time: 0.0116096674464643 Engine time: 0.05075580766424537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 7.161261376924813,
    "estimated_duration": 3600.09505249974,
    "input_throughput": 5165.844437103607,
    "output_throughput": 4478.85507600807,
    "total_throughput": 9644.699513111676,
    "itl": 98.93882828770106,
    "ttft": 2113160.0967163225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.485163680631695,
    "arrivals": 748703,
    "finished_requests": 75215,
    "scheduler_time": 172.5505287933339
}
#Debug simulation 
Total elapsed time: 7.161363324150443. Arrivals time: 0.29903655545786023 Scheduler time: 6.718282940797508 Scheduler overhead time: 0.05216883262619376 Adapter cache time: 0.014189300127327442 Engine time: 0.05307024484500289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 9.322078442201018,
    "estimated_duration": 3600.1245506948458,
    "input_throughput": 5470.401016042324,
    "output_throughput": 4741.165412375975,
    "total_throughput": 10211.566428418299,
    "itl": 111.38778877475544,
    "ttft": 2082988.7533173077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1513813569722613,
    "arrivals": 748703,
    "finished_requests": 79672,
    "scheduler_time": 164.38863047515247
}
#Debug simulation 
Total elapsed time: 9.322176040150225. Arrivals time: 0.275296782143414 Scheduler time: 8.91420164424926 Scheduler overhead time: 0.0484174988232553 Adapter cache time: 0.011670979671180248 Engine time: 0.049991840962320566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.139905729796737,
    "estimated_duration": 3600.0625509068655,
    "input_throughput": 5165.891074674586,
    "output_throughput": 4478.895511395557,
    "total_throughput": 9644.786586070144,
    "itl": 98.93796044375789,
    "ttft": 2113147.38548324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.452853401079801,
    "arrivals": 748703,
    "finished_requests": 75215,
    "scheduler_time": 172.55033748001134
}
#Debug simulation 
Total elapsed time: 7.1400156621821225. Arrivals time: 0.2606230191886425 Scheduler time: 6.734771184623241 Scheduler overhead time: 0.05221752868965268 Adapter cache time: 0.01419897424057126 Engine time: 0.053641792852431536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 10.886181779205799,
    "estimated_duration": 3600.085002653775,
    "input_throughput": 5582.392356065367,
    "output_throughput": 4876.95817933678,
    "total_throughput": 10459.350535402147,
    "itl": 119.35753223416538,
    "ttft": 2068992.2000946526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.94557449156884,
    "arrivals": 745105,
    "finished_requests": 81436,
    "scheduler_time": 160.13548705543496
}
#Debug simulation 
Total elapsed time: 10.886335164308548. Arrivals time: 0.2853040141053498 Scheduler time: 10.476171399466693 Scheduler overhead time: 0.046297292690724134 Adapter cache time: 0.008954405318945646 Engine time: 0.04826965508982539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.269722624216229,
    "estimated_duration": 3600.0368501338066,
    "input_throughput": 5423.9758682676365,
    "output_throughput": 4739.464263918806,
    "total_throughput": 10163.440132186442,
    "itl": 111.6047613117311,
    "ttft": 2087353.132085626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3024615006754203,
    "arrivals": 745105,
    "finished_requests": 79114,
    "scheduler_time": 164.3250761252248
}
#Debug simulation 
Total elapsed time: 8.269846538081765. Arrivals time: 0.2656946307979524 Scheduler time: 7.872747685294598 Scheduler overhead time: 0.048053378239274025 Adapter cache time: 0.011466204654425383 Engine time: 0.04933099681511521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.951011273544282,
    "estimated_duration": 3600.0877795561814,
    "input_throughput": 5124.925593418318,
    "output_throughput": 4477.838315927771,
    "total_throughput": 9602.76390934609,
    "itl": 99.14900526355535,
    "ttft": 2117396.525264701,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7539068667311537,
    "arrivals": 745105,
    "finished_requests": 74690,
    "scheduler_time": 172.4856051253916
}
#Debug simulation 
Total elapsed time: 6.951106883585453. Arrivals time: 0.2467787889763713 Scheduler time: 6.560148797463626 Scheduler overhead time: 0.05209553940221667 Adapter cache time: 0.014120423700660467 Engine time: 0.05343663599342108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 8.734967951197177,
    "estimated_duration": 3600.015180340441,
    "input_throughput": 5422.970188185095,
    "output_throughput": 4738.066687370737,
    "total_throughput": 10161.036875555832,
    "itl": 111.61416660893107,
    "ttft": 2086864.9911740317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5669407904520596,
    "arrivals": 745105,
    "finished_requests": 79088,
    "scheduler_time": 164.318777834709
}
#Debug simulation 
Total elapsed time: 8.73507332475856. Arrivals time: 0.5863002487458289 Scheduler time: 8.016699593514204 Scheduler overhead time: 0.048044729977846146 Adapter cache time: 0.01219151634722948 Engine time: 0.049349140375852585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 7.004881293978542,
    "estimated_duration": 3600.051172972736,
    "input_throughput": 5124.977705459891,
    "output_throughput": 4477.883848158867,
    "total_throughput": 9602.861553618759,
    "itl": 99.14806176301752,
    "ttft": 2117382.106962296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7174542436469658,
    "arrivals": 745105,
    "finished_requests": 74690,
    "scheduler_time": 172.48545116503044
}
#Debug simulation 
Total elapsed time: 7.004975761752576. Arrivals time: 0.29247507406398654 Scheduler time: 6.5682851653546095 Scheduler overhead time: 0.05220558634027839 Adapter cache time: 0.01432206854224205 Engine time: 0.05318594537675381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 8.48337657796219,
    "estimated_duration": 3600.030344700549,
    "input_throughput": 5417.273781791472,
    "output_throughput": 4734.181761853359,
    "total_throughput": 10151.455543644832,
    "itl": 111.32661444717586,
    "ttft": 2086671.169795346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.406738194595081,
    "arrivals": 745105,
    "finished_requests": 79018,
    "scheduler_time": 164.48881493887757
}
#Debug simulation 
Total elapsed time: 8.48353942297399. Arrivals time: 0.3099285224452615 Scheduler time: 8.040997685398906 Scheduler overhead time: 0.048396837431937456 Adapter cache time: 0.01217950414866209 Engine time: 0.04955419339239597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.946190195158124,
    "estimated_duration": 3600.0190938842434,
    "input_throughput": 5125.0233731658245,
    "output_throughput": 4477.9237497339645,
    "total_throughput": 9602.947122899788,
    "itl": 99.14725668160902,
    "ttft": 2117369.5997453295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6855581984483017,
    "arrivals": 745105,
    "finished_requests": 74690,
    "scheduler_time": 172.48526812173623
}
#Debug simulation 
Total elapsed time: 6.946305140852928. Arrivals time: 0.2464838270097971 Scheduler time: 6.555500976741314 Scheduler overhead time: 0.05214661359786987 Adapter cache time: 0.014268666505813599 Engine time: 0.05322692636400461 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_192_slots_64_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_192_slots_64_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 8.158538586925715,
    "estimated_duration": 3600.041074658093,
    "input_throughput": 5566.286768520594,
    "output_throughput": 4867.702516884284,
    "total_throughput": 10433.989285404878,
    "itl": 118.80038234454332,
    "ttft": 2063806.9226889638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 90,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5951168128754938,
    "arrivals": 743742,
    "finished_requests": 81206,
    "scheduler_time": 160.40082739107586
}
#Debug simulation 
Total elapsed time: 8.158636926207691. Arrivals time: 0.2688299501314759 Scheduler time: 7.767674743197858 Scheduler overhead time: 0.04569688206538558 Adapter cache time: 0.00813884474337101 Engine time: 0.04709692066535354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_192_slots_64_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_192_slots_64_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.242734988220036,
    "estimated_duration": 3600.1109107662433,
    "input_throughput": 5408.339765803464,
    "output_throughput": 4729.3992940834505,
    "total_throughput": 10137.739059886915,
    "itl": 111.04104904335273,
    "ttft": 2079721.1289275128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5281274692993643,
    "arrivals": 743742,
    "finished_requests": 78843,
    "scheduler_time": 164.63616466005138
}
#Debug simulation 
Total elapsed time: 8.24282542616129. Arrivals time: 0.26420131837949157 Scheduler time: 7.846394845284522 Scheduler overhead time: 0.04852230753749609 Adapter cache time: 0.011998332105576992 Engine time: 0.04911670181900263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_192_slots_64_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_192_slots_64_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.684910024050623,
    "estimated_duration": 3600.034701547096,
    "input_throughput": 5106.871606570675,
    "output_throughput": 4470.378575263148,
    "total_throughput": 9577.250181833824,
    "itl": 98.65810375914756,
    "ttft": 2109229.375224532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.366418372797805,
    "arrivals": 743742,
    "finished_requests": 74503,
    "scheduler_time": 172.82978815573594
}
#Debug simulation 
Total elapsed time: 6.6850094040855765. Arrivals time: 0.24770427029579878 Scheduler time: 6.292549299541861 Scheduler overhead time: 0.0526635660789907 Adapter cache time: 0.013802724424749613 Engine time: 0.05345603823661804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_192_slots_64_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_192_slots_64_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 8.198574452195317,
    "estimated_duration": 3600.0731247564477,
    "input_throughput": 5408.515139902125,
    "output_throughput": 4729.4500444770465,
    "total_throughput": 10137.96518437917,
    "itl": 111.03514221560104,
    "ttft": 2079600.5513306286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3643173944484412,
    "arrivals": 743742,
    "finished_requests": 78845,
    "scheduler_time": 164.64107213390093
}
#Debug simulation 
Total elapsed time: 8.198672372382134. Arrivals time: 0.2628993899561465 Scheduler time: 7.8033893634565175 Scheduler overhead time: 0.04849512409418821 Adapter cache time: 0.012000338174402714 Engine time: 0.049298674799501896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_192_slots_64_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_192_slots_64_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 6.653833567164838,
    "estimated_duration": 3600.003081764611,
    "input_throughput": 5106.916461579327,
    "output_throughput": 4470.417839784584,
    "total_throughput": 9577.334301363911,
    "itl": 98.65728508430779,
    "ttft": 2109217.6099772304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3349365619523703,
    "arrivals": 743742,
    "finished_requests": 74503,
    "scheduler_time": 172.82965018409627
}
#Debug simulation 
Total elapsed time: 6.653920044191182. Arrivals time: 0.2415615268982947 Scheduler time: 6.268711779732257 Scheduler overhead time: 0.052246302366256714 Adapter cache time: 0.013818294741213322 Engine time: 0.05298113264143467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_192_slots_64_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_192_slots_64_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 8.200808065012097,
    "estimated_duration": 3600.0432169524124,
    "input_throughput": 5408.562571780199,
    "output_throughput": 4729.526001194409,
    "total_throughput": 10138.088572974608,
    "itl": 111.0308554608141,
    "ttft": 2079640.5907894587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2088366454373958,
    "arrivals": 743742,
    "finished_requests": 78846,
    "scheduler_time": 164.64581190658723
}
#Debug simulation 
Total elapsed time: 8.200909059960395. Arrivals time: 0.2657907884567976 Scheduler time: 7.802980695385486 Scheduler overhead time: 0.048498344607651234 Adapter cache time: 0.011873373296111822 Engine time: 0.04908518120646477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_192_slots_64_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_192_slots_64_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.716429662890732,
    "estimated_duration": 3600.078078978268,
    "input_throughput": 5106.955626145181,
    "output_throughput": 4470.392487867247,
    "total_throughput": 9577.348114012428,
    "itl": 98.65669812391162,
    "ttft": 2109197.744234891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.304904571343238,
    "arrivals": 743742,
    "finished_requests": 74505,
    "scheduler_time": 172.83467750635813
}
#Debug simulation 
Total elapsed time: 6.716577519197017. Arrivals time: 0.2957231770269573 Scheduler time: 6.276225187815726 Scheduler overhead time: 0.052570369094610214 Adapter cache time: 0.013935410883277655 Engine time: 0.05326173221692443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 9.250544749200344,
    "estimated_duration": 3600.0025536751195,
    "input_throughput": 5615.494072181251,
    "output_throughput": 4872.436821494255,
    "total_throughput": 10487.930893675506,
    "itl": 119.16902404065486,
    "ttft": 2063541.7886388777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 132,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8728379922173908,
    "arrivals": 743017,
    "finished_requests": 81746,
    "scheduler_time": 160.240866888131
}
#Debug simulation 
Total elapsed time: 9.250652464106679. Arrivals time: 0.2930995114147663 Scheduler time: 8.833384362515062 Scheduler overhead time: 0.046399358194321394 Adapter cache time: 0.008924548048526049 Engine time: 0.04730344470590353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.916214978322387,
    "estimated_duration": 3600.0343094067725,
    "input_throughput": 5459.971297673273,
    "output_throughput": 4737.597348845954,
    "total_throughput": 10197.568646519227,
    "itl": 111.4092787102845,
    "ttft": 2079765.9398823367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.253609391171488,
    "arrivals": 743017,
    "finished_requests": 79494,
    "scheduler_time": 164.4612862127067
}
#Debug simulation 
Total elapsed time: 7.916333294007927. Arrivals time: 0.2636476089246571 Scheduler time: 7.522138823289424 Scheduler overhead time: 0.047669784631580114 Adapter cache time: 0.011531392578035593 Engine time: 0.0488861002959311 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.224321575835347,
    "estimated_duration": 3600.0389071471627,
    "input_throughput": 5156.882600113827,
    "output_throughput": 4475.649684788629,
    "total_throughput": 9632.532284902456,
    "itl": 98.92806169261893,
    "ttft": 2110140.738889754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4968763945717645,
    "arrivals": 743017,
    "finished_requests": 75054,
    "scheduler_time": 172.6512475341752
}
#Debug simulation 
Total elapsed time: 6.224413515999913. Arrivals time: 0.2471934724599123 Scheduler time: 5.833859128411859 Scheduler overhead time: 0.05182829452678561 Adapter cache time: 0.014056032057851553 Engine time: 0.05300513608381152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 7.964239682070911,
    "estimated_duration": 3600.0132733747614,
    "input_throughput": 5460.122368263767,
    "output_throughput": 4737.732809526917,
    "total_throughput": 10197.855177790683,
    "itl": 111.40482026742151,
    "ttft": 2079818.5334426116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1106226309202585,
    "arrivals": 743017,
    "finished_requests": 79497,
    "scheduler_time": 164.46594650509948
}
#Debug simulation 
Total elapsed time: 7.96433080220595. Arrivals time: 0.2654624469578266 Scheduler time: 7.5673140110448 Scheduler overhead time: 0.04828617721796036 Adapter cache time: 0.0116483005695045 Engine time: 0.04905036557465792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 6.281848224811256,
    "estimated_duration": 3600.0076736187684,
    "input_throughput": 5156.927341029324,
    "output_throughput": 4475.688515353502,
    "total_throughput": 9632.615856382827,
    "itl": 98.92725637962072,
    "ttft": 2110127.8651611963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.465808818079559,
    "arrivals": 743017,
    "finished_requests": 75054,
    "scheduler_time": 172.65108158227292
}
#Debug simulation 
Total elapsed time: 6.281941102817655. Arrivals time: 0.24877864262089133 Scheduler time: 5.889162882696837 Scheduler overhead time: 0.052331614308059216 Adapter cache time: 0.014170095790177584 Engine time: 0.052891205064952374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 8.106014139018953,
    "estimated_duration": 3600.0351244896897,
    "input_throughput": 5459.823396247059,
    "output_throughput": 4736.526286647578,
    "total_throughput": 10196.349682894637,
    "itl": 111.30925543413446,
    "ttft": 2079744.6327707754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.710890812072897,
    "arrivals": 743017,
    "finished_requests": 79478,
    "scheduler_time": 164.5287895795347
}
#Debug simulation 
Total elapsed time: 8.106119502801448. Arrivals time: 0.27671946585178375 Scheduler time: 7.698462380561978 Scheduler overhead time: 0.048094766680151224 Adapter cache time: 0.011078633833676577 Engine time: 0.04925123928114772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.237042671069503,
    "estimated_duration": 3600.0869859642885,
    "input_throughput": 5157.013170065709,
    "output_throughput": 4475.637689538825,
    "total_throughput": 9632.650859604533,
    "itl": 98.92613412659863,
    "ttft": 2110132.558496663,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.432670069821207,
    "arrivals": 743017,
    "finished_requests": 75057,
    "scheduler_time": 172.65630361170517
}
#Debug simulation 
Total elapsed time: 6.237141496036202. Arrivals time: 0.2465038844384253 Scheduler time: 5.844379152171314 Scheduler overhead time: 0.05223624873906374 Adapter cache time: 0.014120697043836117 Engine time: 0.0552839026786387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_192_slots_64_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_192_slots_64_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.3653548415750265,
    "estimated_duration": 3600.113040499736,
    "input_throughput": 5611.269916456803,
    "output_throughput": 4875.032201089933,
    "total_throughput": 10486.302117546737,
    "itl": 119.08574233711708,
    "ttft": 2064991.5907666786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6215664490032935,
    "arrivals": 740854,
    "finished_requests": 81899,
    "scheduler_time": 160.14003255541172
}
#Debug simulation 
Total elapsed time: 7.365499638952315. Arrivals time: 0.2710401928052306 Scheduler time: 6.972581897396594 Scheduler overhead time: 0.045773984864354134 Adapter cache time: 0.00808607367798686 Engine time: 0.04669632576406002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_192_slots_64_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_192_slots_64_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.3944906438700855,
    "estimated_duration": 3600.0616974872205,
    "input_throughput": 5457.778685769245,
    "output_throughput": 4737.126869770969,
    "total_throughput": 10194.905555540216,
    "itl": 111.33373198195457,
    "ttft": 2080983.7414890535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2042000977415617,
    "arrivals": 740854,
    "finished_requests": 79581,
    "scheduler_time": 164.34912784409124
}
#Debug simulation 
Total elapsed time: 7.394609482958913. Arrivals time: 0.26252386812120676 Scheduler time: 7.001048730686307 Scheduler overhead time: 0.04789659380912781 Adapter cache time: 0.011108025908470154 Engine time: 0.04961788188666105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_192_slots_64_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_192_slots_64_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.21409948496148,
    "estimated_duration": 3600.0638630775243,
    "input_throughput": 5151.118064929912,
    "output_throughput": 4478.778603170792,
    "total_throughput": 9629.896668100704,
    "itl": 98.9324293672052,
    "ttft": 2111077.5728061963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.485679541877484,
    "arrivals": 740854,
    "finished_requests": 75158,
    "scheduler_time": 172.51517338787295
}
#Debug simulation 
Total elapsed time: 6.214195947628468. Arrivals time: 0.24597776122391224 Scheduler time: 5.826021259184927 Scheduler overhead time: 0.052095246501266956 Adapter cache time: 0.012281331233680248 Engine time: 0.05325272586196661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_192_slots_64_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_192_slots_64_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 7.507582761812955,
    "estimated_duration": 3600.05287601236,
    "input_throughput": 5458.147609699869,
    "output_throughput": 4737.408195762691,
    "total_throughput": 10195.55580546256,
    "itl": 111.23611306404821,
    "ttft": 2081452.413816901,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.094521163166498,
    "arrivals": 740854,
    "finished_requests": 79593,
    "scheduler_time": 164.41233698912987
}
#Debug simulation 
Total elapsed time: 7.507675044704229. Arrivals time: 0.2753562889993191 Scheduler time: 7.102118278387934 Scheduler overhead time: 0.047867391258478165 Adapter cache time: 0.011025903280824423 Engine time: 0.048866741824895144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_192_slots_64_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_192_slots_64_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 6.123311723116785,
    "estimated_duration": 3600.029161842721,
    "input_throughput": 5151.143273102788,
    "output_throughput": 4478.784552885913,
    "total_throughput": 9629.927825988701,
    "itl": 98.93352131467029,
    "ttft": 2111141.854611038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4510424561798705,
    "arrivals": 740854,
    "finished_requests": 75157,
    "scheduler_time": 172.51285008508665
}
#Debug simulation 
Total elapsed time: 6.123399714939296. Arrivals time: 0.23863807320594788 Scheduler time: 5.742191219236702 Scheduler overhead time: 0.05233240453526378 Adapter cache time: 0.0123339151032269 Engine time: 0.053228773176670074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_192_slots_64_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_192_slots_64_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.494409835897386,
    "estimated_duration": 3600.0407439153882,
    "input_throughput": 5458.282113393168,
    "output_throughput": 4737.463049223991,
    "total_throughput": 10195.745162617159,
    "itl": 111.23244818867242,
    "ttft": 2081414.0851736842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9598637287551464,
    "arrivals": 740854,
    "finished_requests": 79594,
    "scheduler_time": 164.41700505289262
}
#Debug simulation 
Total elapsed time: 7.494497477076948. Arrivals time: 0.27061043959110975 Scheduler time: 7.09318788535893 Scheduler overhead time: 0.04810074996203184 Adapter cache time: 0.011104713659733534 Engine time: 0.048926614224910736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_192_slots_64_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_192_slots_64_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.158485264051706,
    "estimated_duration": 3600.0057921510156,
    "input_throughput": 5151.176712112938,
    "output_throughput": 4478.8136272319725,
    "total_throughput": 9629.99033934491,
    "itl": 98.93290928457053,
    "ttft": 2111131.9577082526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.427845332399024,
    "arrivals": 740854,
    "finished_requests": 75157,
    "scheduler_time": 172.51267751716168
}
#Debug simulation 
Total elapsed time: 6.158598523121327. Arrivals time: 0.24474894907325506 Scheduler time: 5.770429764408618 Scheduler overhead time: 0.05267743859440088 Adapter cache time: 0.012357417494058609 Engine time: 0.053501694928854704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.269026766996831,
    "estimated_duration": 3600.0823546902075,
    "input_throughput": 5569.605365798756,
    "output_throughput": 4868.9058396577575,
    "total_throughput": 10438.511205456512,
    "itl": 119.0383276302315,
    "ttft": 2069373.3657050012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 230,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5208540773484838,
    "arrivals": 740135,
    "finished_requests": 81192,
    "scheduler_time": 160.21756286869564
}
#Debug simulation 
Total elapsed time: 7.269119651988149. Arrivals time: 0.2663195012137294 Scheduler time: 6.879665390588343 Scheduler overhead time: 0.04557796195149422 Adapter cache time: 0.009882048238068819 Engine time: 0.04638293897733092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.747855603694916,
    "estimated_duration": 3600.0270584343143,
    "input_throughput": 5420.617868490962,
    "output_throughput": 4736.801619323479,
    "total_throughput": 10157.41948781444,
    "itl": 111.27089576288272,
    "ttft": 2085862.9099206286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1081579528283347,
    "arrivals": 740135,
    "finished_requests": 78977,
    "scheduler_time": 164.4446473540733
}
#Debug simulation 
Total elapsed time: 6.747993852943182. Arrivals time: 0.255643920507282 Scheduler time: 6.3627889808267355 Scheduler overhead time: 0.047661848831921816 Adapter cache time: 0.011025753803551197 Engine time: 0.04856939287856221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.6677634422667325,
    "estimated_duration": 3600.0948748243522,
    "input_throughput": 5114.847980471184,
    "output_throughput": 4472.986840599769,
    "total_throughput": 9587.834821070954,
    "itl": 98.85016285430441,
    "ttft": 2115152.2710401495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9150941810710536,
    "arrivals": 740135,
    "finished_requests": 74523,
    "scheduler_time": 172.64319642290346
}
#Debug simulation 
Total elapsed time: 5.667855650186539. Arrivals time: 0.24451146693900228 Scheduler time: 5.281509721186012 Scheduler overhead time: 0.05179188214242458 Adapter cache time: 0.012940694577991962 Engine time: 0.05265964847058058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 6.749621726106852,
    "estimated_duration": 3600.026522969084,
    "input_throughput": 5421.029782831852,
    "output_throughput": 4737.16398787389,
    "total_throughput": 10158.193770705742,
    "itl": 111.26835546625959,
    "ttft": 2085878.901191319,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9804416232835473,
    "arrivals": 740135,
    "finished_requests": 78983,
    "scheduler_time": 164.4495779515222
}
#Debug simulation 
Total elapsed time: 6.749719127081335. Arrivals time: 0.2626347057521343 Scheduler time: 6.357508322689682 Scheduler overhead time: 0.04752003634348512 Adapter cache time: 0.010949812363833189 Engine time: 0.048832246102392673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 5.753439283929765,
    "estimated_duration": 3600.0696657503086,
    "input_throughput": 5114.883796606269,
    "output_throughput": 4473.018162175997,
    "total_throughput": 9587.901958782266,
    "itl": 98.84951146087397,
    "ttft": 2115142.17191898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8900330027006746,
    "arrivals": 740135,
    "finished_requests": 74523,
    "scheduler_time": 172.64304852722975
}
#Debug simulation 
Total elapsed time: 5.753538818098605. Arrivals time: 0.25444659357890487 Scheduler time: 5.356854259036481 Scheduler overhead time: 0.05189156299456954 Adapter cache time: 0.012970932759344578 Engine time: 0.052881889045238495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.754639205057174,
    "estimated_duration": 3600.024844129684,
    "input_throughput": 5421.032588656485,
    "output_throughput": 4737.218141093934,
    "total_throughput": 10158.250729750418,
    "itl": 111.26528489663882,
    "ttft": 2085823.68441359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.851337072765448,
    "arrivals": 740135,
    "finished_requests": 78984,
    "scheduler_time": 164.45432826740222
}
#Debug simulation 
Total elapsed time: 6.754732850939035. Arrivals time: 0.25664696656167507 Scheduler time: 6.3681853003799915 Scheduler overhead time: 0.04774423548951745 Adapter cache time: 0.011057127732783556 Engine time: 0.048812334425747395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.6691301157698035,
    "estimated_duration": 3600.042967849061,
    "input_throughput": 5114.921728559781,
    "output_throughput": 4473.051334057066,
    "total_throughput": 9587.973062616846,
    "itl": 98.84886257704203,
    "ttft": 2115130.855116346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8635220040939924,
    "arrivals": 740135,
    "finished_requests": 74523,
    "scheduler_time": 172.642861624589
}
#Debug simulation 
Total elapsed time: 5.669218998868018. Arrivals time: 0.2415746282786131 Scheduler time: 5.284816071856767 Scheduler overhead time: 0.0521430061198771 Adapter cache time: 0.012939309235662222 Engine time: 0.053161779418587685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_192_slots_64_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.170491527765989,
    "estimated_duration": 3600.041613898261,
    "input_throughput": 5588.656509504611,
    "output_throughput": 4863.016564145405,
    "total_throughput": 10451.673073650016,
    "itl": 118.55832403472793,
    "ttft": 2063122.9956407447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 193,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2761949431663364,
    "arrivals": 738702,
    "finished_requests": 81312,
    "scheduler_time": 160.4366908676985
}
#Debug simulation 
Total elapsed time: 7.170585267711431. Arrivals time: 0.31049865623936057 Scheduler time: 6.736926076002419 Scheduler overhead time: 0.04565955512225628 Adapter cache time: 0.009395215660333633 Engine time: 0.04675541864708066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_192_slots_64_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.772286529187113,
    "estimated_duration": 3600.0246337607427,
    "input_throughput": 5425.243987732676,
    "output_throughput": 4718.401602228845,
    "total_throughput": 10143.645589961521,
    "itl": 110.20664150902608,
    "ttft": 2079464.6904383698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 214,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5563453546259565,
    "arrivals": 738702,
    "finished_requests": 78902,
    "scheduler_time": 165.0797992425001
}
#Debug simulation 
Total elapsed time: 6.772380280308425. Arrivals time: 0.3358490765094757 Scheduler time: 6.306545798201114 Scheduler overhead time: 0.04818191286176443 Adapter cache time: 0.010000738315284252 Engine time: 0.0492557929828763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_192_slots_64_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.629273423925042,
    "estimated_duration": 3600.0904954237644,
    "input_throughput": 5117.898570444468,
    "output_throughput": 4452.615571851935,
    "total_throughput": 9570.514142296402,
    "itl": 97.80110094391262,
    "ttft": 2109308.345362438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2013081674045027,
    "arrivals": 738702,
    "finished_requests": 74431,
    "scheduler_time": 173.45346225676948
}
#Debug simulation 
Total elapsed time: 5.62941621337086. Arrivals time: 0.31724850134924054 Scheduler time: 5.169603641610593 Scheduler overhead time: 0.05229898542165756 Adapter cache time: 0.011997552588582039 Engine time: 0.05336001934483647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_192_slots_64_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 6.713991948869079,
    "estimated_duration": 3600.0718229218173,
    "input_throughput": 5434.554354007644,
    "output_throughput": 4725.778494661292,
    "total_throughput": 10160.332848668937,
    "itl": 110.59957670329327,
    "ttft": 2078737.7503891694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 211,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.437241681725716,
    "arrivals": 738702,
    "finished_requests": 79051,
    "scheduler_time": 164.83539221859584
}
#Debug simulation 
Total elapsed time: 6.714080736041069. Arrivals time: 0.25889427680522203 Scheduler time: 6.325357499532402 Scheduler overhead time: 0.04822442680597305 Adapter cache time: 0.009951060637831688 Engine time: 0.049030864145606756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_192_slots_64_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 5.661482532974333,
    "estimated_duration": 3600.068592643687,
    "input_throughput": 5117.929707686429,
    "output_throughput": 4452.642661519015,
    "total_throughput": 9570.572369205443,
    "itl": 97.80057381318618,
    "ttft": 2109299.803295779,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1795608638599586,
    "arrivals": 738702,
    "finished_requests": 74431,
    "scheduler_time": 173.45330678023646
}
#Debug simulation 
Total elapsed time: 5.661582767963409. Arrivals time: 0.3169014076702297 Scheduler time: 5.201147680170834 Scheduler overhead time: 0.052556817419826984 Adapter cache time: 0.012097610160708427 Engine time: 0.05374475009739399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_192_slots_64_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.719967534765601,
    "estimated_duration": 3600.1029136790803,
    "input_throughput": 5434.606306852947,
    "output_throughput": 4725.9801755535755,
    "total_throughput": 10160.586482406523,
    "itl": 110.59773578426066,
    "ttft": 2078691.3580323015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 211,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3470073184603786,
    "arrivals": 738702,
    "finished_requests": 79053,
    "scheduler_time": 164.83999374111042
}
#Debug simulation 
Total elapsed time: 6.7200860399752855. Arrivals time: 0.24651534715667367 Scheduler time: 6.343919168226421 Scheduler overhead time: 0.04782314458861947 Adapter cache time: 0.010080033913254738 Engine time: 0.04912532027810812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_192_slots_64_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.67608843697235,
    "estimated_duration": 3600.051017684411,
    "input_throughput": 5117.95469272296,
    "output_throughput": 4452.6643987147,
    "total_throughput": 9570.61909143766,
    "itl": 97.80017289761982,
    "ttft": 2109291.827378452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1621630210243232,
    "arrivals": 738702,
    "finished_requests": 74431,
    "scheduler_time": 173.4531296637959
}
#Debug simulation 
Total elapsed time: 5.676203897688538. Arrivals time: 0.32172971311956644 Scheduler time: 5.210249911993742 Scheduler overhead time: 0.0527576245367527 Adapter cache time: 0.012128222733736038 Engine time: 0.054380970541387796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_192_slots_64_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_192_slots_64_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 26.32700077118352,
    "estimated_duration": 3600.064567598512,
    "input_throughput": 5581.67405686402,
    "output_throughput": 4863.7197114717765,
    "total_throughput": 10445.393768335796,
    "itl": 117.77754254659253,
    "ttft": 2049140.062024207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 729,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.820446184291592,
    "arrivals": 644931,
    "finished_requests": 81373,
    "scheduler_time": 160.6802839727471
}
#Debug simulation 
Total elapsed time: 26.32710811216384. Arrivals time: 0.3605939159169793 Scheduler time: 25.817113510798663 Scheduler overhead time: 0.05419579008594155 Adapter cache time: 0.017883127089589834 Engine time: 0.054800535552203655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_192_slots_64_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_192_slots_64_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 25.039906956721097,
    "estimated_duration": 3600.072659610446,
    "input_throughput": 5433.514500820283,
    "output_throughput": 4741.558188952523,
    "total_throughput": 10175.072689772805,
    "itl": 110.61263209050064,
    "ttft": 2066165.749096105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.620835378682249,
    "arrivals": 644931,
    "finished_requests": 79315,
    "scheduler_time": 164.67309379041274
}
#Debug simulation 
Total elapsed time: 25.040060496889055. Arrivals time: 0.34342258516699076 Scheduler time: 24.541151699144393 Scheduler overhead time: 0.0560775101184845 Adapter cache time: 0.018861673772335052 Engine time: 0.05658004526048899 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_192_slots_64_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_192_slots_64_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 18.127204327844083,
    "estimated_duration": 3600.0555478110246,
    "input_throughput": 5116.980767477587,
    "output_throughput": 4467.402734876976,
    "total_throughput": 9584.383502354562,
    "itl": 98.72565678955618,
    "ttft": 2098280.477140124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 913,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.8591042653844,
    "arrivals": 644931,
    "finished_requests": 74716,
    "scheduler_time": 172.15016129260835
}
#Debug simulation 
Total elapsed time: 18.127317004837096. Arrivals time: 0.3233890919946134 Scheduler time: 17.640913388691843 Scheduler overhead time: 0.05801371205598116 Adapter cache time: 0.02120169624686241 Engine time: 0.058275900315493345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_192_slots_64_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_192_slots_64_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 22.173216790892184,
    "estimated_duration": 3600.0406670312527,
    "input_throughput": 5425.369546201974,
    "output_throughput": 4740.48394960863,
    "total_throughput": 10165.853495810605,
    "itl": 110.98315466085478,
    "ttft": 2064363.3749723486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 911,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.23083004788029,
    "arrivals": 644931,
    "finished_requests": 79285,
    "scheduler_time": 164.33797641366382
}
#Debug simulation 
Total elapsed time: 22.17336655780673. Arrivals time: 0.3407723717391491 Scheduler time: 21.678160410840064 Scheduler overhead time: 0.05501386569812894 Adapter cache time: 0.020080012269318104 Engine time: 0.05568696046248078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_192_slots_64_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_192_slots_64_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 16.316850424278527,
    "estimated_duration": 3600.1008023427717,
    "input_throughput": 5107.844477030611,
    "output_throughput": 4460.455382124348,
    "total_throughput": 9568.29985915496,
    "itl": 98.45966676228306,
    "ttft": 2097718.444512445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.3134746224992,
    "arrivals": 644931,
    "finished_requests": 74580,
    "scheduler_time": 172.32808696143496
}
#Debug simulation 
Total elapsed time: 16.31696112686768. Arrivals time: 0.31436836114153266 Scheduler time: 15.839420818258077 Scheduler overhead time: 0.057249471079558134 Adapter cache time: 0.023189181927591562 Engine time: 0.057409968227148056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_192_slots_64_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_192_slots_64_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 22.81750513939187,
    "estimated_duration": 3600.095417348473,
    "input_throughput": 5428.056130354633,
    "output_throughput": 4737.686650694971,
    "total_throughput": 10165.742781049605,
    "itl": 110.73293674075337,
    "ttft": 2065543.5135732263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 864,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.515707692652914,
    "arrivals": 644931,
    "finished_requests": 79287,
    "scheduler_time": 164.5045973800243
}
#Debug simulation 
Total elapsed time: 22.817667574156076. Arrivals time: 0.34041814086958766 Scheduler time: 22.322353614494205 Scheduler overhead time: 0.05542488722130656 Adapter cache time: 0.019445331767201424 Engine time: 0.056147069204598665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_192_slots_64_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_192_slots_64_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 18.809856433887035,
    "estimated_duration": 3600.02428040645,
    "input_throughput": 5114.145507352344,
    "output_throughput": 4470.7629022387755,
    "total_throughput": 9584.908409591118,
    "itl": 98.44688410796562,
    "ttft": 2096759.17691181,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 943,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.957905414681907,
    "arrivals": 644931,
    "finished_requests": 74708,
    "scheduler_time": 172.51163377551825
}
#Debug simulation 
Total elapsed time: 18.809942006599158. Arrivals time: 0.6298337033949792 Scheduler time: 18.0164803173393 Scheduler overhead time: 0.05788171058520675 Adapter cache time: 0.02142843184992671 Engine time: 0.058873570524156094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_192_slots_64_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_192_slots_64_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 32.01913707423955,
    "estimated_duration": 3600.103320946676,
    "input_throughput": 5540.350434930041,
    "output_throughput": 4863.804296426569,
    "total_throughput": 10404.15473135661,
    "itl": 118.73986149439207,
    "ttft": 2023011.2215892829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.253305243719407,
    "arrivals": 576087,
    "finished_requests": 81198,
    "scheduler_time": 159.6812201539791
}
#Debug simulation 
Total elapsed time: 32.019292332232. Arrivals time: 0.3998493626713753 Scheduler time: 31.470425474457443 Scheduler overhead time: 0.05488745495676994 Adapter cache time: 0.015342696104198694 Engine time: 0.05583306169137359 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_192_slots_64_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_192_slots_64_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 29.052860483992845,
    "estimated_duration": 3600.01058899334,
    "input_throughput": 5388.9335935050185,
    "output_throughput": 4729.055812238749,
    "total_throughput": 10117.989405743769,
    "itl": 111.05814144984018,
    "ttft": 2040013.969112427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.039785377341328,
    "arrivals": 576087,
    "finished_requests": 78906,
    "scheduler_time": 163.85408171761324
}
#Debug simulation 
Total elapsed time: 29.05302699888125. Arrivals time: 0.40969102596864104 Scheduler time: 28.487573158927262 Scheduler overhead time: 0.05727353040128946 Adapter cache time: 0.01676465105265379 Engine time: 0.057470469269901514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_192_slots_64_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_192_slots_64_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 16.018154508899897,
    "estimated_duration": 3600.0955649599096,
    "input_throughput": 5085.067790472352,
    "output_throughput": 4467.413353283887,
    "total_throughput": 9552.481143756238,
    "itl": 98.72815274178114,
    "ttft": 2076813.3129225117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 966,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.273465703032006,
    "arrivals": 576087,
    "finished_requests": 74535,
    "scheduler_time": 171.85578705305903
}
#Debug simulation 
Total elapsed time: 16.018243656959385. Arrivals time: 0.3000113880261779 Scheduler time: 15.556655985768884 Scheduler overhead time: 0.056914547458291054 Adapter cache time: 0.02191872289404273 Engine time: 0.057373933494091034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_192_slots_64_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_192_slots_64_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 30.395375092048198,
    "estimated_duration": 3600.035395140146,
    "input_throughput": 5381.815419413608,
    "output_throughput": 4728.551286740144,
    "total_throughput": 10110.366706153753,
    "itl": 110.95597641090858,
    "ttft": 2040632.3714912415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 618,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.22568377788178,
    "arrivals": 576087,
    "finished_requests": 78920,
    "scheduler_time": 163.90640259837664
}
#Debug simulation 
Total elapsed time: 30.395499336067587. Arrivals time: 0.3949910504743457 Scheduler time: 29.843433255329728 Scheduler overhead time: 0.05779547477141023 Adapter cache time: 0.017531270161271095 Engine time: 0.05759981693699956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_192_slots_64_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_192_slots_64_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 17.93904866464436,
    "estimated_duration": 3600.091287634759,
    "input_throughput": 5086.4096315820325,
    "output_throughput": 4469.294724626541,
    "total_throughput": 9555.704356208575,
    "itl": 98.88845289331574,
    "ttft": 2074417.7500067577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.4521536546992335,
    "arrivals": 576087,
    "finished_requests": 74562,
    "scheduler_time": 171.73574544019962
}
#Debug simulation 
Total elapsed time: 17.939199285581708. Arrivals time: 0.3066628617234528 Scheduler time: 17.467971976846457 Scheduler overhead time: 0.05803534993901849 Adapter cache time: 0.022693720180541277 Engine time: 0.058285933919250965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_192_slots_64_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_192_slots_64_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 39.69146992499009,
    "estimated_duration": 3600.0501938812517,
    "input_throughput": 5381.019418263974,
    "output_throughput": 4721.610278903984,
    "total_throughput": 10102.629697167959,
    "itl": 110.70038591105724,
    "ttft": 2035743.273601888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9261113784508597,
    "arrivals": 576087,
    "finished_requests": 78795,
    "scheduler_time": 164.12910161213276
}
#Debug simulation 
Total elapsed time: 39.69163276301697. Arrivals time: 0.35698071122169495 Scheduler time: 39.17604525294155 Scheduler overhead time: 0.058428095653653145 Adapter cache time: 0.017431052401661873 Engine time: 0.05860560713335872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_192_slots_64_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_192_slots_64_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 18.299745228141546,
    "estimated_duration": 3600.0779070138524,
    "input_throughput": 5078.430098521102,
    "output_throughput": 4463.649513998745,
    "total_throughput": 9542.079612519847,
    "itl": 98.67613209074774,
    "ttft": 2075015.6253073728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 992,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.311948794759831,
    "arrivals": 576087,
    "finished_requests": 74512,
    "scheduler_time": 171.89431798703984
}
#Debug simulation 
Total elapsed time: 18.299851736053824. Arrivals time: 0.37197269778698683 Scheduler time: 17.76433754293248 Scheduler overhead time: 0.057606265880167484 Adapter cache time: 0.022298152092844248 Engine time: 0.05791635299101472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_192_slots_64_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_192_slots_64_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 43.90662534441799,
    "estimated_duration": 3600.05180751187,
    "input_throughput": 5578.643328991532,
    "output_throughput": 4867.638283269962,
    "total_throughput": 10446.281612261493,
    "itl": 118.80770594509562,
    "ttft": 2009514.5571692379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.863173110834348,
    "arrivals": 564621,
    "finished_requests": 81399,
    "scheduler_time": 159.55738789052089
}
#Debug simulation 
Total elapsed time: 43.906800345052034. Arrivals time: 0.36388189950957894 Scheduler time: 43.38887641625479 Scheduler overhead time: 0.05759056704118848 Adapter cache time: 0.015082935336977243 Engine time: 0.05793791497126222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_192_slots_64_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_192_slots_64_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 35.07481707306579,
    "estimated_duration": 3600.055236938788,
    "input_throughput": 5422.167082246883,
    "output_throughput": 4731.352126275616,
    "total_throughput": 10153.519208522499,
    "itl": 111.06429416433971,
    "ttft": 2030142.8187835405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.153591064102954,
    "arrivals": 564621,
    "finished_requests": 79067,
    "scheduler_time": 163.77060431843577
}
#Debug simulation 
Total elapsed time: 35.07496227370575. Arrivals time: 0.3506449870765209 Scheduler time: 34.565909119322896 Scheduler overhead time: 0.05849811527878046 Adapter cache time: 0.016966627910733223 Engine time: 0.05865222588181496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_192_slots_64_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_192_slots_64_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.170952245593071,
    "estimated_duration": 3600.078530982553,
    "input_throughput": 5128.311185745485,
    "output_throughput": 4472.42466002696,
    "total_throughput": 9600.735845772444,
    "itl": 98.96054485565249,
    "ttft": 2072557.0987834977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1050,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.897174061792919,
    "arrivals": 564621,
    "finished_requests": 74795,
    "scheduler_time": 171.57363782025107
}
#Debug simulation 
Total elapsed time: 15.171044075861573. Arrivals time: 0.29622095357626677 Scheduler time: 14.713511054869741 Scheduler overhead time: 0.056753966491669416 Adapter cache time: 0.02229580609127879 Engine time: 0.05689292587339878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_192_slots_64_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_192_slots_64_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 27.001499976962805,
    "estimated_duration": 3600.0383828347326,
    "input_throughput": 5426.092147556071,
    "output_throughput": 4733.090091829231,
    "total_throughput": 10159.182239385302,
    "itl": 111.2991705524699,
    "ttft": 2037881.1701412697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.832175222602666,
    "arrivals": 564621,
    "finished_requests": 79154,
    "scheduler_time": 163.61691822632488
}
#Debug simulation 
Total elapsed time: 27.001662654802203. Arrivals time: 0.3423591391183436 Scheduler time: 26.50616202643141 Scheduler overhead time: 0.05535218585282564 Adapter cache time: 0.018325283657759428 Engine time: 0.055882475804537535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_192_slots_64_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_192_slots_64_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 16.469367328099906,
    "estimated_duration": 3600.0922334397,
    "input_throughput": 5119.878271115614,
    "output_throughput": 4473.32316944922,
    "total_throughput": 9593.201440564833,
    "itl": 98.93937424447176,
    "ttft": 2071416.4853612673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.732175568463303,
    "arrivals": 564621,
    "finished_requests": 74733,
    "scheduler_time": 171.65140911839777
}
#Debug simulation 
Total elapsed time: 16.469532958231866. Arrivals time: 0.2991024381481111 Scheduler time: 16.008891249075532 Scheduler overhead time: 0.0568771967664361 Adapter cache time: 0.022435758728533983 Engine time: 0.057096514385193586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_192_slots_64_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_192_slots_64_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 25.17834022641182,
    "estimated_duration": 3600.0704041018794,
    "input_throughput": 5422.930889839207,
    "output_throughput": 4730.770537319201,
    "total_throughput": 10153.701427158408,
    "itl": 110.99408150704284,
    "ttft": 2036848.5218497845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.455976816518211,
    "arrivals": 564621,
    "finished_requests": 79070,
    "scheduler_time": 163.8391097160372
}
#Debug simulation 
Total elapsed time: 25.178503916133195. Arrivals time: 0.34145786659792066 Scheduler time: 24.68296738062054 Scheduler overhead time: 0.05565420584753156 Adapter cache time: 0.018144587986171246 Engine time: 0.056488880421966314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_192_slots_64_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_192_slots_64_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 17.24225539667532,
    "estimated_duration": 3600.0028827689903,
    "input_throughput": 5113.7100717653275,
    "output_throughput": 4466.418645651897,
    "total_throughput": 9580.128717417225,
    "itl": 98.71738682504227,
    "ttft": 2071767.0596240645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 985,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.2793914396502295,
    "arrivals": 564621,
    "finished_requests": 74634,
    "scheduler_time": 171.7928335138809
}
#Debug simulation 
Total elapsed time: 17.242347241844982. Arrivals time: 0.3313270336948335 Scheduler time: 16.747527598403394 Scheduler overhead time: 0.05778998928144574 Adapter cache time: 0.021992172114551067 Engine time: 0.05811603646725416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_192_slots_64_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_192_slots_64_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 37.71353344293311,
    "estimated_duration": 3600.07668581994,
    "input_throughput": 5565.483668422646,
    "output_throughput": 4868.378795661188,
    "total_throughput": 10433.862464083833,
    "itl": 119.02551526518302,
    "ttft": 2019967.6348257586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.167343926304055,
    "arrivals": 558945,
    "finished_requests": 81427,
    "scheduler_time": 159.431874560507
}
#Debug simulation 
Total elapsed time: 37.713695236016065. Arrivals time: 0.3550890777260065 Scheduler time: 37.209975042846054 Scheduler overhead time: 0.05453533539548516 Adapter cache time: 0.015230850782245398 Engine time: 0.05598623398691416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_192_slots_64_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_192_slots_64_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 28.227380401920527,
    "estimated_duration": 3600.014993855549,
    "input_throughput": 5408.835250195992,
    "output_throughput": 4730.379187049382,
    "total_throughput": 10139.214437245373,
    "itl": 111.12272281864016,
    "ttft": 2036677.0205667838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.513328850162222,
    "arrivals": 558945,
    "finished_requests": 79122,
    "scheduler_time": 163.643970917848
}
#Debug simulation 
Total elapsed time: 28.22756594978273. Arrivals time: 0.3442617626860738 Scheduler time: 27.729860393796116 Scheduler overhead time: 0.055954876355826855 Adapter cache time: 0.017160255927592516 Engine time: 0.056468871887773275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_192_slots_64_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_192_slots_64_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.118893179576844,
    "estimated_duration": 3600.003104264635,
    "input_throughput": 5106.058374845434,
    "output_throughput": 4470.033923286604,
    "total_throughput": 9576.092298132038,
    "itl": 98.89518952498062,
    "ttft": 2070320.905092722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.788633689680108,
    "arrivals": 558945,
    "finished_requests": 74752,
    "scheduler_time": 171.59658047991857
}
#Debug simulation 
Total elapsed time: 14.119048944674432. Arrivals time: 0.37495032884180546 Scheduler time: 13.583727607037872 Scheduler overhead time: 0.05585090769454837 Adapter cache time: 0.023172911256551743 Engine time: 0.05628273822367191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_192_slots_64_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_192_slots_64_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 26.467769810929894,
    "estimated_duration": 3600.0803169499973,
    "input_throughput": 5403.149732081428,
    "output_throughput": 4733.0032943364085,
    "total_throughput": 10136.153026417836,
    "itl": 111.27750590173827,
    "ttft": 2034953.7256537192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.981149377240793,
    "arrivals": 558945,
    "finished_requests": 79104,
    "scheduler_time": 163.59487804399237
}
#Debug simulation 
Total elapsed time: 26.467912680003792. Arrivals time: 0.3959780759178102 Scheduler time: 25.918613580986857 Scheduler overhead time: 0.0562322773039341 Adapter cache time: 0.016549116000533104 Engine time: 0.05682150041684508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_192_slots_64_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_192_slots_64_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 13.619101936928928,
    "estimated_duration": 3600.0307518019818,
    "input_throughput": 5100.865871995214,
    "output_throughput": 4467.5840593721305,
    "total_throughput": 9568.449931367344,
    "itl": 98.88932689067654,
    "ttft": 2068473.5697742868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.115583898988518,
    "arrivals": 558945,
    "finished_requests": 74663,
    "scheduler_time": 171.55698517000334
}
#Debug simulation 
Total elapsed time: 13.619192297104746. Arrivals time: 0.2908257902599871 Scheduler time: 13.167750398628414 Scheduler overhead time: 0.05540927033871412 Adapter cache time: 0.02407253161072731 Engine time: 0.05582857830449939 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_192_slots_64_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_192_slots_64_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 32.73708433099091,
    "estimated_duration": 3600.0398857116074,
    "input_throughput": 5409.458955522263,
    "output_throughput": 4729.776763746676,
    "total_throughput": 10139.23571926894,
    "itl": 111.00393536841462,
    "ttft": 2038457.652370244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.54307612201663,
    "arrivals": 558945,
    "finished_requests": 79106,
    "scheduler_time": 163.7521457767049
}
#Debug simulation 
Total elapsed time: 32.737248642835766. Arrivals time: 0.433078910689801 Scheduler time: 32.15126307075843 Scheduler overhead time: 0.056398962158709764 Adapter cache time: 0.015886878594756126 Engine time: 0.05667786719277501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_192_slots_64_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_192_slots_64_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.727940225042403,
    "estimated_duration": 3600.065489107641,
    "input_throughput": 5104.225202457304,
    "output_throughput": 4467.604561267774,
    "total_throughput": 9571.829763725078,
    "itl": 98.74685539393703,
    "ttft": 2069599.9665123827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1074,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.924166040122528,
    "arrivals": 558945,
    "finished_requests": 74679,
    "scheduler_time": 171.7094405955773
}
#Debug simulation 
Total elapsed time: 14.728035881184042. Arrivals time: 0.2926206230185926 Scheduler time: 14.276169038843364 Scheduler overhead time: 0.055925021413713694 Adapter cache time: 0.022042368073016405 Engine time: 0.05622347770258784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 24.373585833236575,
    "estimated_duration": 3600.1289956189557,
    "input_throughput": 5589.8644255495965,
    "output_throughput": 4861.501079905318,
    "total_throughput": 10451.365505454914,
    "itl": 118.38193387537538,
    "ttft": 2012523.4544422918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 696,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.602236686237237,
    "arrivals": 556042,
    "finished_requests": 81336,
    "scheduler_time": 159.68437186259615
}
#Debug simulation 
Total elapsed time: 24.373792198020965. Arrivals time: 0.3450244083069265 Scheduler time: 23.883037409279495 Scheduler overhead time: 0.05308181932196021 Adapter cache time: 0.01671474613249302 Engine time: 0.053397230338305235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 22.58808827633038,
    "estimated_duration": 3600.05220349197,
    "input_throughput": 5444.480771969927,
    "output_throughput": 4724.879540219129,
    "total_throughput": 10169.360312189056,
    "itl": 110.1410698162966,
    "ttft": 2031500.027661364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 681,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.986031808252454,
    "arrivals": 556042,
    "finished_requests": 79112,
    "scheduler_time": 164.30127887750825
}
#Debug simulation 
Total elapsed time: 22.58818753901869. Arrivals time: 0.3204184891656041 Scheduler time: 22.115404406096786 Scheduler overhead time: 0.054970829747617245 Adapter cache time: 0.017536067869514227 Engine time: 0.05606960551813245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.154188798274845,
    "estimated_duration": 3600.0696391969345,
    "input_throughput": 5136.52786009022,
    "output_throughput": 4458.8226364367565,
    "total_throughput": 9595.350496526977,
    "itl": 97.6447051248157,
    "ttft": 2066094.7971910292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.476742190634857,
    "arrivals": 556042,
    "finished_requests": 74597,
    "scheduler_time": 172.64386187517567
}
#Debug simulation 
Total elapsed time: 15.154330756049603. Arrivals time: 0.3103041839785874 Scheduler time: 14.68597621191293 Scheduler overhead time: 0.056436687242239714 Adapter cache time: 0.019805876072496176 Engine time: 0.05647055199369788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 20.503614469897002,
    "estimated_duration": 3600.095202668283,
    "input_throughput": 5441.59942922628,
    "output_throughput": 4724.138958157178,
    "total_throughput": 10165.738387383459,
    "itl": 110.40762372315461,
    "ttft": 2031630.8278683408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.497151560941705,
    "arrivals": 556042,
    "finished_requests": 79116,
    "scheduler_time": 164.07823828896483
}
#Debug simulation 
Total elapsed time: 20.50373455416411. Arrivals time: 0.3157320558093488 Scheduler time: 20.038435130380094 Scheduler overhead time: 0.05399815831333399 Adapter cache time: 0.016918558161705732 Engine time: 0.054852415807545185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.402981983032078,
    "estimated_duration": 3600.0829385334496,
    "input_throughput": 5146.006721597052,
    "output_throughput": 4470.300344401488,
    "total_throughput": 9616.30706599854,
    "itl": 98.01239484188574,
    "ttft": 2063310.7637075563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.716829730193152,
    "arrivals": 556042,
    "finished_requests": 74805,
    "scheduler_time": 172.4597321482562
}
#Debug simulation 
Total elapsed time: 14.40309125278145. Arrivals time: 0.3058363222517073 Scheduler time: 13.939025149215013 Scheduler overhead time: 0.05633155256509781 Adapter cache time: 0.019973318558186293 Engine time: 0.05654086824506521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 19.88235372910276,
    "estimated_duration": 3600.0276517072325,
    "input_throughput": 5445.601227730318,
    "output_throughput": 4730.197833876207,
    "total_throughput": 10175.799061606525,
    "itl": 110.60028159015616,
    "ttft": 2031851.7538904315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.011377938347844,
    "arrivals": 556042,
    "finished_requests": 79175,
    "scheduler_time": 163.98312238960852
}
#Debug simulation 
Total elapsed time: 19.882510754279792. Arrivals time: 0.31606870191171765 Scheduler time: 19.416725314222276 Scheduler overhead time: 0.053690561559051275 Adapter cache time: 0.017805377021431923 Engine time: 0.05481639225035906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_192_slots_64_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 14.20547866821289,
    "estimated_duration": 3600.0126286960153,
    "input_throughput": 5156.17385673549,
    "output_throughput": 4475.250134285128,
    "total_throughput": 9631.423991020618,
    "itl": 98.06952696637366,
    "ttft": 2062824.300899584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 905,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.670898592937757,
    "arrivals": 556042,
    "finished_requests": 74867,
    "scheduler_time": 172.4264554174962
}
#Debug simulation 
Total elapsed time: 14.205570665188134. Arrivals time: 0.2958993366919458 Scheduler time: 13.751699754968286 Scheduler overhead time: 0.05593249574303627 Adapter cache time: 0.01980109279975295 Engine time: 0.0568378334864974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_192_slots_64_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_192_slots_64_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 39.88723439630121,
    "estimated_duration": 3600.1186356807007,
    "input_throughput": 5574.231860335796,
    "output_throughput": 4871.4352983214985,
    "total_throughput": 10445.667158657294,
    "itl": 118.52489895059246,
    "ttft": 2012680.417304084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.823498656642647,
    "arrivals": 554638,
    "finished_requests": 81337,
    "scheduler_time": 159.88004931682613
}
#Debug simulation 
Total elapsed time: 39.88739565340802. Arrivals time: 0.35848753806203604 Scheduler time: 39.37833367753774 Scheduler overhead time: 0.05570199806243181 Adapter cache time: 0.014486206229776144 Engine time: 0.05738338688388467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_192_slots_64_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_192_slots_64_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 22.51038087857887,
    "estimated_duration": 3600.006977159858,
    "input_throughput": 5442.1336192677145,
    "output_throughput": 4748.199408626025,
    "total_throughput": 10190.33302789374,
    "itl": 110.76356092663916,
    "ttft": 2035971.4407496748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.085030007851316,
    "arrivals": 554638,
    "finished_requests": 79359,
    "scheduler_time": 164.19448048486532
}
#Debug simulation 
Total elapsed time: 22.51051965262741. Arrivals time: 0.36629212414845824 Scheduler time: 21.99619814567268 Scheduler overhead time: 0.054083270486444235 Adapter cache time: 0.01571863517165184 Engine time: 0.05480748973786831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_192_slots_64_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_192_slots_64_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.613143457099795,
    "estimated_duration": 3600.081639516191,
    "input_throughput": 5144.0205679582095,
    "output_throughput": 4496.28692369747,
    "total_throughput": 9640.30749165568,
    "itl": 98.26589426624193,
    "ttft": 2069452.3501172243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 748,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.622245316826767,
    "arrivals": 554638,
    "finished_requests": 75053,
    "scheduler_time": 172.6027564944097
}
#Debug simulation 
Total elapsed time: 15.613238089252263. Arrivals time: 0.29434274369850755 Scheduler time: 15.162718607112765 Scheduler overhead time: 0.055922357365489006 Adapter cache time: 0.018742469139397144 Engine time: 0.05631579924374819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_192_slots_64_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_192_slots_64_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 36.42750002397224,
    "estimated_duration": 3600.007486961153,
    "input_throughput": 5411.30180160934,
    "output_throughput": 4724.136841825273,
    "total_throughput": 10135.438643434612,
    "itl": 110.31253975716933,
    "ttft": 2025121.741322267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.364118826342742,
    "arrivals": 554638,
    "finished_requests": 78828,
    "scheduler_time": 164.35383207851345
}
#Debug simulation 
Total elapsed time: 36.427767840214074. Arrivals time: 0.347615837585181 Scheduler time: 35.92416716692969 Scheduler overhead time: 0.057335630524903536 Adapter cache time: 0.015625830739736557 Engine time: 0.05882013402879238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_192_slots_64_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_192_slots_64_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.647601759061217,
    "estimated_duration": 3600.0770212327766,
    "input_throughput": 5117.044410814252,
    "output_throughput": 4472.116542241888,
    "total_throughput": 9589.16095305614,
    "itl": 98.12975121058876,
    "ttft": 2073027.775155107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.299093734109805,
    "arrivals": 554638,
    "finished_requests": 74699,
    "scheduler_time": 172.3575622035654
}
#Debug simulation 
Total elapsed time: 14.647708526346833. Arrivals time: 0.33471052814275026 Scheduler time: 14.158300543669611 Scheduler overhead time: 0.05557286227121949 Adapter cache time: 0.017663017380982637 Engine time: 0.05633867625147104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_192_slots_64_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_192_slots_64_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 24.203240070026368,
    "estimated_duration": 3600.1171582888555,
    "input_throughput": 5435.522828735097,
    "output_throughput": 4742.204836498876,
    "total_throughput": 10177.727665233973,
    "itl": 110.77023128300299,
    "ttft": 2036063.868571413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3962459403835084,
    "arrivals": 554638,
    "finished_requests": 79263,
    "scheduler_time": 164.11773014974509
}
#Debug simulation 
Total elapsed time: 24.20339185697958. Arrivals time: 0.3194113033823669 Scheduler time: 23.73547791969031 Scheduler overhead time: 0.05440863315016031 Adapter cache time: 0.015267974697053432 Engine time: 0.055216869339346886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_192_slots_64_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_192_slots_64_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 15.230578189715743,
    "estimated_duration": 3600.048323860028,
    "input_throughput": 5131.074179635986,
    "output_throughput": 4480.275137725377,
    "total_throughput": 9611.349317361362,
    "itl": 98.07279384791909,
    "ttft": 2071825.870176201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.321341472063246,
    "arrivals": 554638,
    "finished_requests": 74807,
    "scheduler_time": 172.59751925950374
}
#Debug simulation 
Total elapsed time: 15.230709061957896. Arrivals time: 0.30332327634096146 Scheduler time: 14.77037317212671 Scheduler overhead time: 0.05629632668569684 Adapter cache time: 0.018510038033127785 Engine time: 0.056925731245428324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_192_slots_64_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 34.700325217098,
    "estimated_duration": 3600.1117007975104,
    "input_throughput": 5645.030679325319,
    "output_throughput": 4898.425233887453,
    "total_throughput": 10543.455913212772,
    "itl": 118.08628452200223,
    "ttft": 2012430.0656027384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.552389886332691,
    "arrivals": 553841,
    "finished_requests": 82133,
    "scheduler_time": 160.48046696919724
}
#Debug simulation 
Total elapsed time: 34.70048770541325. Arrivals time: 0.36482011433690786 Scheduler time: 34.18629391351715 Scheduler overhead time: 0.05584015417844057 Adapter cache time: 0.013904020190238953 Engine time: 0.056549614295363426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_192_slots_64_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 35.38950189296156,
    "estimated_duration": 3600.0219932002237,
    "input_throughput": 5472.3635125593255,
    "output_throughput": 4757.855099872265,
    "total_throughput": 10230.21861243159,
    "itl": 110.6987444249601,
    "ttft": 2027345.2325073811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.35630931014661,
    "arrivals": 553841,
    "finished_requests": 79737,
    "scheduler_time": 164.35769510814734
}
#Debug simulation 
Total elapsed time: 35.389744862914085. Arrivals time: 0.3433499038219452 Scheduler time: 34.89479209855199 Scheduler overhead time: 0.05649204505607486 Adapter cache time: 0.013342700898647308 Engine time: 0.05753936758264899 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_192_slots_64_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 13.731825146824121,
    "estimated_duration": 3600.1061910031617,
    "input_throughput": 5193.047929175259,
    "output_throughput": 4520.206387430339,
    "total_throughput": 9713.254316605598,
    "itl": 97.75566716982695,
    "ttft": 2059872.8222248561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.312709805034128,
    "arrivals": 553841,
    "finished_requests": 75681,
    "scheduler_time": 173.4145637748441
}
#Debug simulation 
Total elapsed time: 13.731918549630791. Arrivals time: 0.2895103539340198 Scheduler time: 13.28641355689615 Scheduler overhead time: 0.05619799671694636 Adapter cache time: 0.018153497949242592 Engine time: 0.05621279077604413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_192_slots_64_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 27.437558525707573,
    "estimated_duration": 3600.043102552305,
    "input_throughput": 5479.057177403175,
    "output_throughput": 4750.5075669442,
    "total_throughput": 10229.564744347375,
    "itl": 110.51483651457835,
    "ttft": 2027730.8190361084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.635501846703697,
    "arrivals": 553841,
    "finished_requests": 79734,
    "scheduler_time": 164.38231370236903
}
#Debug simulation 
Total elapsed time: 27.43772368878126. Arrivals time: 0.36084083234891295 Scheduler time: 26.9254529341124 Scheduler overhead time: 0.05622245231643319 Adapter cache time: 0.013997077476233244 Engine time: 0.05718846805393696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_192_slots_64_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 14.225244425237179,
    "estimated_duration": 3600.029143616402,
    "input_throughput": 5170.998693999346,
    "output_throughput": 4499.900515729311,
    "total_throughput": 9670.899209728657,
    "itl": 97.21635168526029,
    "ttft": 2061526.823657831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 717,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.306747793322457,
    "arrivals": 553841,
    "finished_requests": 75387,
    "scheduler_time": 173.7772842390259
}
#Debug simulation 
Total elapsed time: 14.225331790279597. Arrivals time: 0.28106153570115566 Scheduler time: 13.7872036783956 Scheduler overhead time: 0.05613602930679917 Adapter cache time: 0.018598943948745728 Engine time: 0.056903691962361336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_192_slots_64_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 26.788394892122597,
    "estimated_duration": 3600.0383122807716,
    "input_throughput": 5467.127094969923,
    "output_throughput": 4744.437563826653,
    "total_throughput": 10211.564658796577,
    "itl": 110.39276769426317,
    "ttft": 2031085.2550789183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4514256411790747,
    "arrivals": 553841,
    "finished_requests": 79517,
    "scheduler_time": 164.3866090929972
}
#Debug simulation 
Total elapsed time: 26.78854165505618. Arrivals time: 0.3221144652925432 Scheduler time: 26.315072299912572 Scheduler overhead time: 0.05651636002585292 Adapter cache time: 0.01395921129733324 Engine time: 0.05669263377785683 
