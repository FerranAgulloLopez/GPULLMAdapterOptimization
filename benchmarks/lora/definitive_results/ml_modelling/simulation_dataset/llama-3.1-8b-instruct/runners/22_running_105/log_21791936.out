INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12483698 . Total output tokens: 11063292
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6556874979287386,
    "estimated_duration": 3599.973924293695,
    "input_throughput": 1286.0837598728906,
    "output_throughput": 1132.7609826507494,
    "total_throughput": 2418.84474252364,
    "itl": 24.650670305347298,
    "ttft": 6509.357407580147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 18922,
    "finished_requests": 18888,
    "scheduler_time": 0.009053369446838528
}
#Debug simulation 
Total elapsed time: 1.655823929933831. Arrivals time: 0.053470803308300674 Scheduler time: 1.2590107665164396 Scheduler overhead time: 0.12497409502975643 Adapter cache time: 0.03364788775797933 Engine time: 0.1242017955519259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12483698 . Total output tokens: 11063292
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6623905550222844,
    "estimated_duration": 3599.9789391848963,
    "input_throughput": 1286.0819683151508,
    "output_throughput": 1132.759404676772,
    "total_throughput": 2418.8413729919225,
    "itl": 24.65094356442453,
    "ttft": 6509.430665205173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 18922,
    "finished_requests": 18888,
    "scheduler_time": 0.009033979392641306
}
#Debug simulation 
Total elapsed time: 1.6624836210394278. Arrivals time: 0.05265377042815089 Scheduler time: 1.2619978341972455 Scheduler overhead time: 0.13118322170339525 Adapter cache time: 0.03382946376223117 Engine time: 0.12104932707734406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12483698 . Total output tokens: 11063292
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.651564341969788,
    "estimated_duration": 3599.965589428653,
    "input_throughput": 1286.0867374942886,
    "output_throughput": 1132.763605289683,
    "total_throughput": 2418.850342783972,
    "itl": 24.65099794911955,
    "ttft": 6509.385218851884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 18922,
    "finished_requests": 18888,
    "scheduler_time": 0.009023512940535612
}
#Debug simulation 
Total elapsed time: 1.6516529750078917. Arrivals time: 0.0532537994440645 Scheduler time: 1.2562110116705298 Scheduler overhead time: 0.12671732099261135 Adapter cache time: 0.03373502264730632 Engine time: 0.12119681213516742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12483698 . Total output tokens: 11063292
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6498629050329328,
    "estimated_duration": 3599.9655870031393,
    "input_throughput": 1286.0867383608027,
    "output_throughput": 1132.7636060528941,
    "total_throughput": 2418.850344413697,
    "itl": 24.650872260959034,
    "ttft": 6509.365865408073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 18922,
    "finished_requests": 18888,
    "scheduler_time": 0.009028391734585887
}
#Debug simulation 
Total elapsed time: 1.6499413920100778. Arrivals time: 0.052213937626220286 Scheduler time: 1.2559508328558877 Scheduler overhead time: 0.1268022678559646 Adapter cache time: 0.033436242723837495 Engine time: 0.12139509001281112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12483698 . Total output tokens: 11063292
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6631562960101292,
    "estimated_duration": 3599.979082505055,
    "input_throughput": 1286.0819171144444,
    "output_throughput": 1132.7593595800495,
    "total_throughput": 2418.841276694494,
    "itl": 24.650981663221312,
    "ttft": 6509.450212787718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 18922,
    "finished_requests": 18888,
    "scheduler_time": 0.009046113816765055
}
#Debug simulation 
Total elapsed time: 1.6632489460753277. Arrivals time: 0.05542221118230373 Scheduler time: 1.259852418093942 Scheduler overhead time: 0.1284133978188038 Adapter cache time: 0.03379378037061542 Engine time: 0.12472050823271275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12483698 . Total output tokens: 11063292
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.662993982899934,
    "estimated_duration": 3599.96853714068,
    "input_throughput": 1286.085684425823,
    "output_throughput": 1132.7626777646594,
    "total_throughput": 2418.8483621904825,
    "itl": 24.650667459647998,
    "ttft": 6509.3099784026035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 18922,
    "finished_requests": 18888,
    "scheduler_time": 0.009036481350668384
}
#Debug simulation 
Total elapsed time: 1.663077552919276. Arrivals time: 0.05304307478945702 Scheduler time: 1.2588438473176211 Scheduler overhead time: 0.13283398118801415 Adapter cache time: 0.034796367515809834 Engine time: 0.12092155322898179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12483698 . Total output tokens: 11063292
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7991168389562517,
    "estimated_duration": 3599.9790723930364,
    "input_throughput": 1286.0819207269333,
    "output_throughput": 1132.759362761869,
    "total_throughput": 2418.841283488802,
    "itl": 24.65096039838912,
    "ttft": 6509.462670133009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 18922,
    "finished_requests": 18888,
    "scheduler_time": 0.009042902994732831
}
#Debug simulation 
Total elapsed time: 1.7992580839199945. Arrivals time: 0.053488849312998354 Scheduler time: 1.3979586635250598 Scheduler overhead time: 0.13003634451888502 Adapter cache time: 0.03374779364094138 Engine time: 0.12153935548849404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12185250 . Total output tokens: 10797344
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6120358100160956,
    "estimated_duration": 3599.9202738536123,
    "input_throughput": 1269.0697716784425,
    "output_throughput": 1093.8783918635556,
    "total_throughput": 2362.948163541998,
    "itl": 24.306119038665287,
    "ttft": 6462.138103522859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 18499,
    "finished_requests": 18466,
    "scheduler_time": 0.008180229891608303
}
#Debug simulation 
Total elapsed time: 1.61211333994288. Arrivals time: 0.05187044315971434 Scheduler time: 1.217444663750939 Scheduler overhead time: 0.12716476805508137 Adapter cache time: 0.03231022343970835 Engine time: 0.12246371048968285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12185250 . Total output tokens: 10797344
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.664368744008243,
    "estimated_duration": 3599.894761522588,
    "input_throughput": 1269.0787655325003,
    "output_throughput": 1093.8861441422978,
    "total_throughput": 2362.964909674798,
    "itl": 24.306138776718754,
    "ttft": 6462.0482473153925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 18499,
    "finished_requests": 18466,
    "scheduler_time": 0.00818106387761733
}
#Debug simulation 
Total elapsed time: 1.6644525369629264. Arrivals time: 0.053565640933811665 Scheduler time: 1.2633769771782681 Scheduler overhead time: 0.1270109424367547 Adapter cache time: 0.0326325393980369 Engine time: 0.12669063627254218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12185250 . Total output tokens: 10797344
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.677821566001512,
    "estimated_duration": 3599.9089693666137,
    "input_throughput": 1269.0737568299717,
    "output_throughput": 1093.8818268765417,
    "total_throughput": 2362.9555837065136,
    "itl": 24.3064225335908,
    "ttft": 6462.140446025372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 18499,
    "finished_requests": 18466,
    "scheduler_time": 0.008165718631461361
}
#Debug simulation 
Total elapsed time: 1.6779047979507595. Arrivals time: 0.053269358118996024 Scheduler time: 1.2722955510253087 Scheduler overhead time: 0.13133368140552193 Adapter cache time: 0.032892016461119056 Engine time: 0.126026674057357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12185250 . Total output tokens: 10797344
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.659593602991663,
    "estimated_duration": 3599.9090327944045,
    "input_throughput": 1269.073734469811,
    "output_throughput": 1093.881807603136,
    "total_throughput": 2362.955542072947,
    "itl": 24.305985799012223,
    "ttft": 6462.120615800254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 18499,
    "finished_requests": 18466,
    "scheduler_time": 0.008166552617470388
}
#Debug simulation 
Total elapsed time: 1.6596727359574288. Arrivals time: 0.053342351340688765 Scheduler time: 1.257751627243124 Scheduler overhead time: 0.12833642750047147 Adapter cache time: 0.03275474836118519 Engine time: 0.12505059759132564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12185250 . Total output tokens: 10797344
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6268797919619828,
    "estimated_duration": 3599.9073462986244,
    "input_throughput": 1269.0743290094176,
    "output_throughput": 1093.8823200682843,
    "total_throughput": 2362.956649077702,
    "itl": 24.306406144526253,
    "ttft": 6462.114006711193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 18499,
    "finished_requests": 18466,
    "scheduler_time": 0.008161673823420111
}
#Debug simulation 
Total elapsed time: 1.626971304998733. Arrivals time: 0.05293283052742481 Scheduler time: 1.2256692500086501 Scheduler overhead time: 0.12831665901467204 Adapter cache time: 0.03250830166507512 Engine time: 0.12618785467930138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12185250 . Total output tokens: 10797344
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6744396979920566,
    "estimated_duration": 3599.910403663197,
    "input_throughput": 1269.073251198456,
    "output_throughput": 1093.881391045982,
    "total_throughput": 2362.9546422444378,
    "itl": 24.305944826469897,
    "ttft": 6462.055726366364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 18499,
    "finished_requests": 18466,
    "scheduler_time": 0.008198911081800382
}
#Debug simulation 
Total elapsed time: 1.6745183019666001. Arrivals time: 0.05354794661980122 Scheduler time: 1.272677049622871 Scheduler overhead time: 0.12893360946327448 Adapter cache time: 0.03260405221953988 Engine time: 0.12511696689762175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12185250 . Total output tokens: 10797344
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.678006633068435,
    "estimated_duration": 3599.8969734887137,
    "input_throughput": 1269.0779857437283,
    "output_throughput": 1093.8854720010909,
    "total_throughput": 2362.963457744819,
    "itl": 24.30611695643364,
    "ttft": 6462.041110306166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 18499,
    "finished_requests": 18466,
    "scheduler_time": 0.008176185083567055
}
#Debug simulation 
Total elapsed time: 1.6781279480783269. Arrivals time: 0.05371228244621307 Scheduler time: 1.2619812223128974 Scheduler overhead time: 0.13908409548457712 Adapter cache time: 0.03358913608826697 Engine time: 0.12493302242364734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12041112 . Total output tokens: 10667282
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6479579419828951,
    "estimated_duration": 3599.9679577366232,
    "input_throughput": 1248.014997007009,
    "output_throughput": 1086.5663377902144,
    "total_throughput": 2334.5813347972235,
    "itl": 24.171915535738034,
    "ttft": 6343.687209904552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 18275,
    "finished_requests": 18243,
    "scheduler_time": 0.0034153622829803383
}
#Debug simulation 
Total elapsed time: 1.6480458360165358. Arrivals time: 0.052827671403065324 Scheduler time: 1.2483583352295682 Scheduler overhead time: 0.12819605134427547 Adapter cache time: 0.031699427287094295 Engine time: 0.12559320882428437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12041112 . Total output tokens: 10667282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.668702477007173,
    "estimated_duration": 3599.969257350377,
    "input_throughput": 1248.0145464649795,
    "output_throughput": 1086.5659455322655,
    "total_throughput": 2334.580491997245,
    "itl": 24.172021789027735,
    "ttft": 6343.678785878705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 18275,
    "finished_requests": 18243,
    "scheduler_time": 0.0034032278588565904
}
#Debug simulation 
Total elapsed time: 1.668780723004602. Arrivals time: 0.053540377295576036 Scheduler time: 1.2679334494750947 Scheduler overhead time: 0.12788305093999952 Adapter cache time: 0.031872284947894514 Engine time: 0.12595512403640896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12041112 . Total output tokens: 10667282
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6791915179928765,
    "estimated_duration": 3599.9843814732485,
    "input_throughput": 1248.0093033518585,
    "output_throughput": 1086.5613806911088,
    "total_throughput": 2334.570684042967,
    "itl": 24.172068283829276,
    "ttft": 6343.71269930656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 18275,
    "finished_requests": 18243,
    "scheduler_time": 0.0034000170368243677
}
#Debug simulation 
Total elapsed time: 1.679278088035062. Arrivals time: 0.05300625681411475 Scheduler time: 1.2799381621880457 Scheduler overhead time: 0.1286746134283021 Adapter cache time: 0.031734151183627546 Engine time: 0.12414019729476422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12041112 . Total output tokens: 10667282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6736487089656293,
    "estimated_duration": 3599.980084704215,
    "input_throughput": 1248.010792917801,
    "output_throughput": 1086.5626775603089,
    "total_throughput": 2334.57347047811,
    "itl": 24.171947750808414,
    "ttft": 6343.625032494536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469847,
    "arrivals": 18275,
    "finished_requests": 18243,
    "scheduler_time": 0.003419407091021588
}
#Debug simulation 
Total elapsed time: 1.6737274900078773. Arrivals time: 0.05279363412410021 Scheduler time: 1.2641456316923723 Scheduler overhead time: 0.13480947201605886 Adapter cache time: 0.03289835050236434 Engine time: 0.12465807877015322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12041112 . Total output tokens: 10667282
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6632412190083414,
    "estimated_duration": 3599.979343233774,
    "input_throughput": 1248.011049964585,
    "output_throughput": 1086.5629013544008,
    "total_throughput": 2334.573951318986,
    "itl": 24.172020293692277,
    "ttft": 6343.632805816623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 18275,
    "finished_requests": 18243,
    "scheduler_time": 0.003411317474939089
}
#Debug simulation 
Total elapsed time: 1.6633469839580357. Arrivals time: 0.05328561854548752 Scheduler time: 1.2553338145371526 Scheduler overhead time: 0.12778124306350946 Adapter cache time: 0.031834700726903975 Engine time: 0.131939266808331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12041112 . Total output tokens: 10667282
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6742006510030478,
    "estimated_duration": 3599.9651329925,
    "input_throughput": 1248.0159762728902,
    "output_throughput": 1086.5671903739933,
    "total_throughput": 2334.5831666468835,
    "itl": 24.171888357293525,
    "ttft": 6343.627548902552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 18275,
    "finished_requests": 18243,
    "scheduler_time": 0.0033951382427740914
}
#Debug simulation 
Total elapsed time: 1.6742804809473455. Arrivals time: 0.05270715698134154 Scheduler time: 1.2733729295432568 Scheduler overhead time: 0.12751883221790195 Adapter cache time: 0.03181703563313931 Engine time: 0.1273805774981156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12041112 . Total output tokens: 10667282
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.66869926196523,
    "estimated_duration": 3599.9710878335195,
    "input_throughput": 1248.0139118849972,
    "output_throughput": 1086.5653930443154,
    "total_throughput": 2334.579304929313,
    "itl": 24.17189278348054,
    "ttft": 6343.671011500997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 18275,
    "finished_requests": 18243,
    "scheduler_time": 0.0033983490648063146
}
#Debug simulation 
Total elapsed time: 1.668831747956574. Arrivals time: 0.053073695627972484 Scheduler time: 1.2652035171631724 Scheduler overhead time: 0.1300181937403977 Adapter cache time: 0.03172944555990398 Engine time: 0.1267315304139629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11965939 . Total output tokens: 10600341
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6804793949704617,
    "estimated_duration": 3599.8724388366863,
    "input_throughput": 1235.3679402698838,
    "output_throughput": 1096.6013565957608,
    "total_throughput": 2331.9692968656445,
    "itl": 24.2335512798472,
    "ttft": 4794.09620060242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 18174,
    "finished_requests": 18150,
    "scheduler_time": 0.00016746371574169702
}
#Debug simulation 
Total elapsed time: 1.6805571439908817. Arrivals time: 0.052786303916946054 Scheduler time: 1.2808655253611505 Scheduler overhead time: 0.12887027696706355 Adapter cache time: 0.031355638056993484 Engine time: 0.12469258846249431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11965939 . Total output tokens: 10600341
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6793689529877156,
    "estimated_duration": 3599.8727721316563,
    "input_throughput": 1235.3678258930859,
    "output_throughput": 1096.6012550666958,
    "total_throughput": 2331.9690809597814,
    "itl": 24.233742864481226,
    "ttft": 4794.077105759375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 18174,
    "finished_requests": 18150,
    "scheduler_time": 0.00016746371574169702
}
#Debug simulation 
Total elapsed time: 1.6794533970532939. Arrivals time: 0.05366284027695656 Scheduler time: 1.279285617521964 Scheduler overhead time: 0.128397811553441 Adapter cache time: 0.031175530748441815 Engine time: 0.12530012312345207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11965939 . Total output tokens: 10600341
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6812849389389157,
    "estimated_duration": 3599.8727718446967,
    "input_throughput": 1235.3678259915616,
    "output_throughput": 1096.60125515411,
    "total_throughput": 2331.9690811456717,
    "itl": 24.233663962666466,
    "ttft": 4794.061088200089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 18174,
    "finished_requests": 18150,
    "scheduler_time": 0.00016746371574169702
}
#Debug simulation 
Total elapsed time: 1.681365370983258. Arrivals time: 0.05289550754241645 Scheduler time: 1.2795812204713002 Scheduler overhead time: 0.12785222532693297 Adapter cache time: 0.03121271764393896 Engine time: 0.12742583872750401 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11965939 . Total output tokens: 10600341
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6798348049633205,
    "estimated_duration": 3599.8727102425873,
    "input_throughput": 1235.367847131549,
    "output_throughput": 1096.601273919482,
    "total_throughput": 2331.9691210510314,
    "itl": 24.2335857269537,
    "ttft": 4793.998147842015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 18174,
    "finished_requests": 18150,
    "scheduler_time": 0.00017234250979197274
}
#Debug simulation 
Total elapsed time: 1.6799145790282637. Arrivals time: 0.05275982466991991 Scheduler time: 1.2786242120200768 Scheduler overhead time: 0.12772290071006864 Adapter cache time: 0.031148121925070882 Engine time: 0.1279159381520003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11965939 . Total output tokens: 10600341
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.658218748983927,
    "estimated_duration": 3599.8724135338794,
    "input_throughput": 1235.367948953046,
    "output_throughput": 1096.6013643035596,
    "total_throughput": 2331.969313256606,
    "itl": 24.233653956147364,
    "ttft": 4794.057499347207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861723,
    "arrivals": 18174,
    "finished_requests": 18150,
    "scheduler_time": 0.00016746371574169702
}
#Debug simulation 
Total elapsed time: 1.6582974700722843. Arrivals time: 0.05229844024870545 Scheduler time: 1.257893172209151 Scheduler overhead time: 0.12802633235696703 Adapter cache time: 0.031078385654836893 Engine time: 0.12738548347260803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11965939 . Total output tokens: 10600341
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6607875929912552,
    "estimated_duration": 3599.8596406584693,
    "input_throughput": 1235.3723322353048,
    "output_throughput": 1096.6052552198728,
    "total_throughput": 2331.977587455178,
    "itl": 24.233376519928253,
    "ttft": 4793.985773006346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 18174,
    "finished_requests": 18150,
    "scheduler_time": 0.00016900656575586712
}
#Debug simulation 
Total elapsed time: 1.6608867620816454. Arrivals time: 0.05383877316489816 Scheduler time: 1.2605092601152137 Scheduler overhead time: 0.12932138703763485 Adapter cache time: 0.031046810909174383 Engine time: 0.12441291869617999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11965939 . Total output tokens: 10600341
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6732626830926165,
    "estimated_duration": 3599.872687875773,
    "input_throughput": 1235.367854807166,
    "output_throughput": 1096.6012807329112,
    "total_throughput": 2331.969135540077,
    "itl": 24.23368351231317,
    "ttft": 4794.090128330123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2367897061258555,
    "arrivals": 18174,
    "finished_requests": 18150,
    "scheduler_time": 0.00016746371574169702
}
#Debug simulation 
Total elapsed time: 1.673389472067356. Arrivals time: 0.05293202679604292 Scheduler time: 1.2738564506871626 Scheduler overhead time: 0.12776227039285004 Adapter cache time: 0.031129308743402362 Engine time: 0.12610664195381105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11524966 . Total output tokens: 10218965
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5969650499755517,
    "estimated_duration": 3599.810518129501,
    "input_throughput": 1217.475747106069,
    "output_throughput": 1054.1602067354938,
    "total_throughput": 2271.635953841563,
    "itl": 23.918025001751072,
    "ttft": 4762.647615878178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 17531,
    "finished_requests": 17508,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.5970546120079234. Arrivals time: 0.050005887751467526 Scheduler time: 1.1953862220980227 Scheduler overhead time: 0.12892340263351798 Adapter cache time: 0.029761319048702717 Engine time: 0.13108068832661957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11524966 . Total output tokens: 10218965
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.58762156101875,
    "estimated_duration": 3599.793478010958,
    "input_throughput": 1217.4815101953075,
    "output_throughput": 1054.165196748114,
    "total_throughput": 2271.6467069434216,
    "itl": 23.894145092775503,
    "ttft": 4762.513549021086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 17531,
    "finished_requests": 17508,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.5877130960579962. Arrivals time: 0.05023038829676807 Scheduler time: 1.1886853027390316 Scheduler overhead time: 0.1319790838751942 Adapter cache time: 0.03009315102826804 Engine time: 0.12384677107911557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11524966 . Total output tokens: 10218965
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6293919930467382,
    "estimated_duration": 3599.8116494168917,
    "input_throughput": 1217.475364498562,
    "output_throughput": 1054.1598754520085,
    "total_throughput": 2271.6352399505704,
    "itl": 23.89432231004063,
    "ttft": 4762.587257412877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 17531,
    "finished_requests": 17508,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.6294797530863434. Arrivals time: 0.050830669701099396 Scheduler time: 1.219015761744231 Scheduler overhead time: 0.1359556665411219 Adapter cache time: 0.03138757846318185 Engine time: 0.12730065896175802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11524966 . Total output tokens: 10218965
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.5965318119851872,
    "estimated_duration": 3599.8050899035666,
    "input_throughput": 1217.4775829647504,
    "output_throughput": 1054.1617963270496,
    "total_throughput": 2271.6393792917997,
    "itl": 23.918142949269487,
    "ttft": 4762.683286450705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 17531,
    "finished_requests": 17508,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.5966184699209407. Arrivals time: 0.050253729335963726 Scheduler time: 1.2029833374544978 Scheduler overhead time: 0.12826805259101093 Adapter cache time: 0.029814594076015055 Engine time: 0.1234779745573178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11524966 . Total output tokens: 10218965
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6026696249609813,
    "estimated_duration": 3599.7958173056954,
    "input_throughput": 1217.480719025965,
    "output_throughput": 1054.1645117084001,
    "total_throughput": 2271.645230734365,
    "itl": 23.89405744093697,
    "ttft": 4762.5390127140745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 17531,
    "finished_requests": 17508,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.6027690779883415. Arrivals time: 0.05140884930733591 Scheduler time: 1.2026169609744102 Scheduler overhead time: 0.12939331494271755 Adapter cache time: 0.030238536302931607 Engine time: 0.12698400672525167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11524966 . Total output tokens: 10218965
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5958302770741284,
    "estimated_duration": 3599.793536640097,
    "input_throughput": 1217.4814903664223,
    "output_throughput": 1054.1651795791302,
    "total_throughput": 2271.6466699455527,
    "itl": 23.894103821750132,
    "ttft": 4762.597633973782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 17531,
    "finished_requests": 17508,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.5959165890235454. Arrivals time: 0.05021009920164943 Scheduler time: 1.194900247384794 Scheduler overhead time: 0.13053850585129112 Adapter cache time: 0.030197563697583973 Engine time: 0.12662951124366373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11524966 . Total output tokens: 10218965
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6241815070388839,
    "estimated_duration": 3599.7954610000065,
    "input_throughput": 1217.480839531508,
    "output_throughput": 1054.1646160489986,
    "total_throughput": 2271.6454555805067,
    "itl": 23.894153468366124,
    "ttft": 4762.512058720571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 17531,
    "finished_requests": 17508,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.6243399570230395. Arrivals time: 0.05097477720119059 Scheduler time: 1.2238387149991468 Scheduler overhead time: 0.13005356502253562 Adapter cache time: 0.030412105843424797 Engine time: 0.126067616045475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11367893 . Total output tokens: 10084640
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5952882920391858,
    "estimated_duration": 3599.8229485771362,
    "input_throughput": 1186.0708320912331,
    "output_throughput": 1054.651590990225,
    "total_throughput": 2240.722423081458,
    "itl": 23.884271877978627,
    "ttft": 5030.762199678804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 17310,
    "finished_requests": 17286,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.5954058630159125. Arrivals time: 0.05038629600312561 Scheduler time: 1.198504067840986 Scheduler overhead time: 0.13039658742491156 Adapter cache time: 0.02971314627211541 Engine time: 0.12419411598239094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11367893 . Total output tokens: 10084640
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.582131871022284,
    "estimated_duration": 3599.822947370084,
    "input_throughput": 1186.070832488933,
    "output_throughput": 1054.651591343859,
    "total_throughput": 2240.722423832792,
    "itl": 23.88437610805871,
    "ttft": 5030.78168387274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 17310,
    "finished_requests": 17286,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.5822153720073402. Arrivals time: 0.04975630552507937 Scheduler time: 1.1851180440280586 Scheduler overhead time: 0.129628935479559 Adapter cache time: 0.029544985271058977 Engine time: 0.12596871762070805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11367893 . Total output tokens: 10084640
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5980721070664003,
    "estimated_duration": 3599.8334076763354,
    "input_throughput": 1186.0673860338507,
    "output_throughput": 1054.6485267635342,
    "total_throughput": 2240.7159127973846,
    "itl": 23.884512833373,
    "ttft": 5030.733430404009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 17310,
    "finished_requests": 17286,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.598174678045325. Arrivals time: 0.05290490877814591 Scheduler time: 1.1965769699309021 Scheduler overhead time: 0.1306094138417393 Adapter cache time: 0.029699246399104595 Engine time: 0.12613485241308808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11367893 . Total output tokens: 10084640
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6072983070043847,
    "estimated_duration": 3599.833793456465,
    "input_throughput": 1186.0672589276405,
    "output_throughput": 1054.64841374097,
    "total_throughput": 2240.7156726686108,
    "itl": 23.884324076901294,
    "ttft": 5030.781792511163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 17310,
    "finished_requests": 17286,
    "scheduler_time": 2.5019580270792122e-06
}
#Debug simulation 
Total elapsed time: 1.6073870210675523. Arrivals time: 0.05029630509670824 Scheduler time: 1.202860089368187 Scheduler overhead time: 0.12887592148035765 Adapter cache time: 0.029787934152409434 Engine time: 0.13355758332181722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11367893 . Total output tokens: 10084640
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5997607089811936,
    "estimated_duration": 3599.8296991025736,
    "input_throughput": 1186.0686079300945,
    "output_throughput": 1054.6496132710029,
    "total_throughput": 2240.718221201097,
    "itl": 23.8845524428932,
    "ttft": 5030.782312395379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 17310,
    "finished_requests": 17286,
    "scheduler_time": 2.5019580270792122e-06
}
#Debug simulation 
Total elapsed time: 1.5998474330408499. Arrivals time: 0.050584139535203576 Scheduler time: 1.1999101977562532 Scheduler overhead time: 0.12965409096796066 Adapter cache time: 0.029859199421480298 Engine time: 0.12667523347772658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11367893 . Total output tokens: 10084640
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.600956332986243,
    "estimated_duration": 3599.8379456031057,
    "input_throughput": 1186.0658908868402,
    "output_throughput": 1054.6471972820812,
    "total_throughput": 2240.7130881689213,
    "itl": 23.884288348590275,
    "ttft": 5030.720177815106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 17310,
    "finished_requests": 17286,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.6010572810191661. Arrivals time: 0.04991338180843741 Scheduler time: 1.1971638039685786 Scheduler overhead time: 0.1339439949952066 Adapter cache time: 0.03088710200972855 Engine time: 0.12516911572311074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11367893 . Total output tokens: 10084640
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6150571890175343,
    "estimated_duration": 3599.8228960840233,
    "input_throughput": 1186.0708493866812,
    "output_throughput": 1054.6516063692998,
    "total_throughput": 2240.7224557559807,
    "itl": 23.884360398665695,
    "ttft": 5030.756458146336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 17310,
    "finished_requests": 17286,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.6151906209997833. Arrivals time: 0.050074863829649985 Scheduler time: 1.2173802111065015 Scheduler overhead time: 0.129830171354115 Adapter cache time: 0.029653591685928404 Engine time: 0.12599407031666487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11293896 . Total output tokens: 10019902
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.568845520960167,
    "estimated_duration": 3599.913766546665,
    "input_throughput": 1192.5866224619044,
    "output_throughput": 1025.8181832901219,
    "total_throughput": 2218.4048057520263,
    "itl": 23.667402570711015,
    "ttft": 6113.4681604942025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 17187,
    "finished_requests": 17158,
    "scheduler_time": 6.671888072211233e-06
}
#Debug simulation 
Total elapsed time: 1.5689343009144068. Arrivals time: 0.05042310443241149 Scheduler time: 1.168996752356179 Scheduler overhead time: 0.12972060812171549 Adapter cache time: 0.029769700719043612 Engine time: 0.12720374146010727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11293896 . Total output tokens: 10019902
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5610031650867313,
    "estimated_duration": 3599.9134793040616,
    "input_throughput": 1192.5867176202153,
    "output_throughput": 1025.818265141724,
    "total_throughput": 2218.404982761939,
    "itl": 23.667491318450054,
    "ttft": 6113.47268198551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 17187,
    "finished_requests": 17158,
    "scheduler_time": 5.8379020631848285e-06
}
#Debug simulation 
Total elapsed time: 1.561092260060832. Arrivals time: 0.049254600424319506 Scheduler time: 1.1617852631025016 Scheduler overhead time: 0.13070613448508084 Adapter cache time: 0.029660813976079226 Engine time: 0.12696595129091293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11293896 . Total output tokens: 10019902
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5613409420475364,
    "estimated_duration": 3599.9137332080263,
    "input_throughput": 1192.5866335063954,
    "output_throughput": 1025.8181927901778,
    "total_throughput": 2218.404826296573,
    "itl": 23.667470942423602,
    "ttft": 6113.479557922758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 17187,
    "finished_requests": 17158,
    "scheduler_time": 5.8379020631848285e-06
}
#Debug simulation 
Total elapsed time: 1.5614255500258878. Arrivals time: 0.0491730198264122 Scheduler time: 1.165276910061948 Scheduler overhead time: 0.1301142501179129 Adapter cache time: 0.029552907566539943 Engine time: 0.12450953631196171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11293896 . Total output tokens: 10019902
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.5570657800417393,
    "estimated_duration": 3599.887966111612,
    "input_throughput": 1192.5951697428163,
    "output_throughput": 1025.82553533987,
    "total_throughput": 2218.4207050826863,
    "itl": 23.667332081377303,
    "ttft": 6113.441846903942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 17187,
    "finished_requests": 17158,
    "scheduler_time": 5.8379020631848285e-06
}
#Debug simulation 
Total elapsed time: 1.5571693551028147. Arrivals time: 0.05106108635663986 Scheduler time: 1.1586362113012 Scheduler overhead time: 0.13117185840383172 Adapter cache time: 0.02979763865005225 Engine time: 0.12368295807391405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11293896 . Total output tokens: 10019902
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6032956240233034,
    "estimated_duration": 3599.9135118487625,
    "input_throughput": 1192.5867068387402,
    "output_throughput": 1025.8182558679043,
    "total_throughput": 2218.4049627066447,
    "itl": 23.66747948897844,
    "ttft": 6113.437141415742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 17187,
    "finished_requests": 17158,
    "scheduler_time": 5.8379020631848285e-06
}
#Debug simulation 
Total elapsed time: 1.603383518056944. Arrivals time: 0.05061719007790089 Scheduler time: 1.1992709110490978 Scheduler overhead time: 0.13200769084505737 Adapter cache time: 0.02981722669210285 Engine time: 0.12870611541438848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11293896 . Total output tokens: 10019902
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5746153770014644,
    "estimated_duration": 3599.891720021399,
    "input_throughput": 1192.5939261235555,
    "output_throughput": 1025.8244656253296,
    "total_throughput": 2218.418391748885,
    "itl": 23.66731106232221,
    "ttft": 6113.506409838079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 17187,
    "finished_requests": 17158,
    "scheduler_time": 6.671888072211233e-06
}
#Debug simulation 
Total elapsed time: 1.5747293839231133. Arrivals time: 0.050120553467422724 Scheduler time: 1.1747208285378292 Scheduler overhead time: 0.13125036912970245 Adapter cache time: 0.029814410372637212 Engine time: 0.12614186061546206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11293896 . Total output tokens: 10019902
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.570930141955614,
    "estimated_duration": 3599.913985117526,
    "input_throughput": 1192.5865500533175,
    "output_throughput": 1025.8181210069772,
    "total_throughput": 2218.4046710602947,
    "itl": 23.66751267302424,
    "ttft": 6113.466940240445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 17187,
    "finished_requests": 17158,
    "scheduler_time": 5.8379020631848285e-06
}
#Debug simulation 
Total elapsed time: 1.5710670539410785. Arrivals time: 0.05002670001704246 Scheduler time: 1.173733960953541 Scheduler overhead time: 0.12998074386268854 Adapter cache time: 0.02967271802481264 Engine time: 0.12506390025373548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11040469 . Total output tokens: 9790219
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5392121010227129,
    "estimated_duration": 3599.558226289347,
    "input_throughput": 1157.691232653233,
    "output_throughput": 1009.9175430612365,
    "total_throughput": 2167.6087757144696,
    "itl": 23.583208019160594,
    "ttft": 5604.368743753336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 16818,
    "finished_requests": 16792,
    "scheduler_time": 0.001069706634998632
}
#Debug simulation 
Total elapsed time: 1.5392910040682182. Arrivals time: 0.049049554974772036 Scheduler time: 1.1404517774935812 Scheduler overhead time: 0.13095953909214586 Adapter cache time: 0.028914555674418807 Engine time: 0.12739026395138353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11040469 . Total output tokens: 9790219
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5366009279387072,
    "estimated_duration": 3599.5592707824267,
    "input_throughput": 1157.6908967230845,
    "output_throughput": 1009.9172500109476,
    "total_throughput": 2167.6081467340323,
    "itl": 23.58356830050218,
    "ttft": 5604.419331979649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2348263315111399,
    "arrivals": 16818,
    "finished_requests": 16792,
    "scheduler_time": 0.0010648278409483563
}
#Debug simulation 
Total elapsed time: 1.5366824439261109. Arrivals time: 0.04836927296128124 Scheduler time: 1.1420384971424937 Scheduler overhead time: 0.1311071739764884 Adapter cache time: 0.02851907559670508 Engine time: 0.12427186849527061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11040469 . Total output tokens: 9790219
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.548538587987423,
    "estimated_duration": 3599.5690151940366,
    "input_throughput": 1157.687762732163,
    "output_throughput": 1009.9145160588175,
    "total_throughput": 2167.6022787909806,
    "itl": 23.58334357112668,
    "ttft": 5604.356118501027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2413462840113789,
    "arrivals": 16818,
    "finished_requests": 16792,
    "scheduler_time": 0.001090764661213905
}
#Debug simulation 
Total elapsed time: 1.548643491929397. Arrivals time: 0.049227185314521194 Scheduler time: 1.1486677344655618 Scheduler overhead time: 0.13138871546834707 Adapter cache time: 0.028878433164209127 Engine time: 0.12757327768485993 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11040469 . Total output tokens: 9790219
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.5370125620393082,
    "estimated_duration": 3599.5718282493467,
    "input_throughput": 1157.6868580024166,
    "output_throughput": 1009.9137268134496,
    "total_throughput": 2167.600584815866,
    "itl": 23.58320904432594,
    "ttft": 5604.313377848402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046985,
    "arrivals": 16818,
    "finished_requests": 16792,
    "scheduler_time": 0.0010996882633054297
}
#Debug simulation 
Total elapsed time: 1.5370877740206197. Arrivals time: 0.048344891518354416 Scheduler time: 1.1407928838161752 Scheduler overhead time: 0.1308360827388242 Adapter cache time: 0.028677385998889804 Engine time: 0.12584986712317914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11040469 . Total output tokens: 9790219
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5462023889413103,
    "estimated_duration": 3599.5693413474064,
    "input_throughput": 1157.6876578352355,
    "output_throughput": 1009.9144245514756,
    "total_throughput": 2167.602082386711,
    "itl": 23.583345590519155,
    "ttft": 5604.3780941467985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861717,
    "arrivals": 16818,
    "finished_requests": 16792,
    "scheduler_time": 0.0010777962510811307
}
#Debug simulation 
Total elapsed time: 1.546277689980343. Arrivals time: 0.048795081442222 Scheduler time: 1.1490379254100844 Scheduler overhead time: 0.13053894834592938 Adapter cache time: 0.028668741113506258 Engine time: 0.12669223884586245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11040469 . Total output tokens: 9790219
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5331098349997774,
    "estimated_duration": 3599.5718415162573,
    "input_throughput": 1157.6868537355401,
    "output_throughput": 1009.9137230912194,
    "total_throughput": 2167.6005768267596,
    "itl": 23.583117813442435,
    "ttft": 5604.31757642798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 16818,
    "finished_requests": 16792,
    "scheduler_time": 0.001085885867163629
}
#Debug simulation 
Total elapsed time: 1.5331937110750005. Arrivals time: 0.04873657308053225 Scheduler time: 1.1361708500189707 Scheduler overhead time: 0.13072286429814994 Adapter cache time: 0.028611418325453997 Engine time: 0.12653339374810457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11040469 . Total output tokens: 9790219
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5480359699577093,
    "estimated_duration": 3599.5643450741877,
    "input_throughput": 1157.6892647307611,
    "output_throughput": 1009.9158263345552,
    "total_throughput": 2167.605091065316,
    "itl": 23.583357259752237,
    "ttft": 5604.379182917468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585545,
    "arrivals": 16818,
    "finished_requests": 16792,
    "scheduler_time": 0.0010616170189161336
}
#Debug simulation 
Total elapsed time: 1.548164316918701. Arrivals time: 0.04931109619792551 Scheduler time: 1.14941347646527 Scheduler overhead time: 0.13020696735475212 Adapter cache time: 0.02885809913277626 Engine time: 0.1276668692007661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10968303 . Total output tokens: 9719501
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5267219460802153,
    "estimated_duration": 3599.909136240045,
    "input_throughput": 1136.7050792492946,
    "output_throughput": 1005.3498194068504,
    "total_throughput": 2142.054898656145,
    "itl": 23.46709661200568,
    "ttft": 6081.530129065845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5267989550484344. Arrivals time: 0.04782698140479624 Scheduler time: 1.1320032535586506 Scheduler overhead time: 0.13076842506416142 Adapter cache time: 0.028110573650337756 Engine time: 0.12551604956388474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10968303 . Total output tokens: 9719501
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5289128670701757,
    "estimated_duration": 3599.910954319018,
    "input_throughput": 1136.704505174094,
    "output_throughput": 1005.3493116705785,
    "total_throughput": 2142.0538168446724,
    "itl": 23.46724467087493,
    "ttft": 6081.487910221731,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5289980580564588. Arrivals time: 0.047777536790817976 Scheduler time: 1.1319240732118487 Scheduler overhead time: 0.13099736149888486 Adapter cache time: 0.027806590078398585 Engine time: 0.12777648691553622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10968303 . Total output tokens: 9719501
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5280442769872025,
    "estimated_duration": 3599.912064318595,
    "input_throughput": 1136.704154681777,
    "output_throughput": 1005.3490016804201,
    "total_throughput": 2142.053156362197,
    "itl": 23.467286322404355,
    "ttft": 6081.460315519965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5281287470133975. Arrivals time: 0.047968899249099195 Scheduler time: 1.1336069223470986 Scheduler overhead time: 0.13120466482359916 Adapter cache time: 0.027986413100734353 Engine time: 0.12467130471486598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10968303 . Total output tokens: 9719501
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.5323568650055677,
    "estimated_duration": 3599.9123120505988,
    "input_throughput": 1136.7040764582057,
    "output_throughput": 1005.348932496201,
    "total_throughput": 2142.053008954407,
    "itl": 23.4671247704384,
    "ttft": 6081.4716948901705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5324254169827327. Arrivals time: 0.0480263700010255 Scheduler time: 1.1361429439857602 Scheduler overhead time: 0.13120049075223505 Adapter cache time: 0.027990748058073223 Engine time: 0.12642094132024795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10968303 . Total output tokens: 9719501
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.550748653942719,
    "estimated_duration": 3599.9110714017147,
    "input_throughput": 1136.7044682041728,
    "output_throughput": 1005.349278972824,
    "total_throughput": 2142.0537471769967,
    "itl": 23.46727876303684,
    "ttft": 6081.446758590368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.550829818006605. Arrivals time: 0.048909684526734054 Scheduler time: 1.1514983476372436 Scheduler overhead time: 0.1305734959896654 Adapter cache time: 0.027849102509208024 Engine time: 0.12934798933565617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10968303 . Total output tokens: 9719501
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5464963840786368,
    "estimated_duration": 3599.897782296623,
    "input_throughput": 1136.7086643747448,
    "output_throughput": 1005.3529902427072,
    "total_throughput": 2142.061654617452,
    "itl": 23.467052053895564,
    "ttft": 6081.671747403624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5465994890546426. Arrivals time: 0.047931017936207354 Scheduler time: 1.150047176051885 Scheduler overhead time: 0.13017899473197758 Adapter cache time: 0.02815597679000348 Engine time: 0.12741425924468786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10968303 . Total output tokens: 9719501
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5321941290749237,
    "estimated_duration": 3599.910992643227,
    "input_throughput": 1136.704493072878,
    "output_throughput": 1005.3493009677535,
    "total_throughput": 2142.0537940406316,
    "itl": 23.467251348949915,
    "ttft": 6081.469175498886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5323316960129887. Arrivals time: 0.047959002084098756 Scheduler time: 1.1350592472590506 Scheduler overhead time: 0.13273020402994007 Adapter cache time: 0.027919427142478526 Engine time: 0.12599162105470896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10788914 . Total output tokens: 9574998
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5085178789449856,
    "estimated_duration": 3599.941780404892,
    "input_throughput": 1119.4892156135725,
    "output_throughput": 978.8405521390613,
    "total_throughput": 2098.329767752634,
    "itl": 23.36569127231002,
    "ttft": 5292.105765980265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 16446,
    "finished_requests": 16422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5085887069581077. Arrivals time: 0.04814693587832153 Scheduler time: 1.1100274092750624 Scheduler overhead time: 0.13167299760971218 Adapter cache time: 0.027809906634502113 Engine time: 0.12770511768758297 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10788914 . Total output tokens: 9574998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.534907957073301,
    "estimated_duration": 3599.9297094549397,
    "input_throughput": 1119.4929693808358,
    "output_throughput": 978.8438342962893,
    "total_throughput": 2098.3368036771253,
    "itl": 23.387049515222117,
    "ttft": 5292.204329888666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 16446,
    "finished_requests": 16422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.534992729080841. Arrivals time: 0.053484158706851304 Scheduler time: 1.1304504917934537 Scheduler overhead time: 0.13117317634169012 Adapter cache time: 0.027069938369095325 Engine time: 0.1295569713693112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10788914 . Total output tokens: 9574998
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5113812829367816,
    "estimated_duration": 3599.921783783144,
    "input_throughput": 1119.4954340826782,
    "output_throughput": 978.8459893417142,
    "total_throughput": 2098.3414234243924,
    "itl": 23.365817902906436,
    "ttft": 5292.11855901296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 16446,
    "finished_requests": 16422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.511460757930763. Arrivals time: 0.04783236270304769 Scheduler time: 1.1117557927500457 Scheduler overhead time: 0.13223580573685467 Adapter cache time: 0.027824359480291605 Engine time: 0.12864014715887606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10788914 . Total output tokens: 9574998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.5097382069798186,
    "estimated_duration": 3599.9219133204224,
    "input_throughput": 1119.4953937994735,
    "output_throughput": 978.8459541195487,
    "total_throughput": 2098.341347919022,
    "itl": 23.365684907541652,
    "ttft": 5292.1350356783805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 16446,
    "finished_requests": 16422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5098375120433047. Arrivals time: 0.04824869194999337 Scheduler time: 1.109414661419578 Scheduler overhead time: 0.1322687113424763 Adapter cache time: 0.02772101724985987 Engine time: 0.1290161395445466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10788914 . Total output tokens: 9574998
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5097013169433922,
    "estimated_duration": 3599.9417475297073,
    "input_throughput": 1119.4892258369086,
    "output_throughput": 978.8405610779737,
    "total_throughput": 2098.3297869148823,
    "itl": 23.36582579744008,
    "ttft": 5292.104068710375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 16446,
    "finished_requests": 16422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.509780526976101. Arrivals time: 0.0481028500944376 Scheduler time: 1.1115581565536559 Scheduler overhead time: 0.13098627678118646 Adapter cache time: 0.027626764262095094 Engine time: 0.12788968801032752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10788914 . Total output tokens: 9574998
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5042491659987718,
    "estimated_duration": 3599.926865880932,
    "input_throughput": 1119.493853665775,
    "output_throughput": 978.844607482798,
    "total_throughput": 2098.338461148573,
    "itl": 23.365485982125797,
    "ttft": 5292.023674575961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 16446,
    "finished_requests": 16422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5043653110042214. Arrivals time: 0.04784213344100863 Scheduler time: 1.1058681721333414 Scheduler overhead time: 0.13220459420699626 Adapter cache time: 0.027722088620066643 Engine time: 0.12751788727473468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10788914 . Total output tokens: 9574998
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5099809649400413,
    "estimated_duration": 3599.93976859715,
    "input_throughput": 1119.4898412343373,
    "output_throughput": 978.8410991590472,
    "total_throughput": 2098.3309403933845,
    "itl": 23.36583814157062,
    "ttft": 5292.128853958562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 16446,
    "finished_requests": 16422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5101272229803726. Arrivals time: 0.05122606689110398 Scheduler time: 1.1090581426396966 Scheduler overhead time: 0.13238404307048768 Adapter cache time: 0.027802202384918928 Engine time: 0.1262390313204378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4543571 . Total output tokens: 4062450
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.942895216983743,
    "estimated_duration": 3599.569172148027,
    "input_throughput": 476.838176435359,
    "output_throughput": 412.3535148275129,
    "total_throughput": 889.1916912628719,
    "itl": 21.762997095603467,
    "ttft": 7316.8442244781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.94297931692563. Arrivals time: 0.028761315857991576 Scheduler time: 0.5433726542396471 Scheduler overhead time: 0.1338400401873514 Adapter cache time: 0.03681174386292696 Engine time: 0.13435857754666358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4543571 . Total output tokens: 4062450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9388152579776943,
    "estimated_duration": 3599.569172148027,
    "input_throughput": 476.838176435359,
    "output_throughput": 412.3535148275129,
    "total_throughput": 889.1916912628719,
    "itl": 21.763115058707882,
    "ttft": 7316.817147355759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9388800900196657. Arrivals time: 0.02878063323441893 Scheduler time: 0.5412950813770294 Scheduler overhead time: 0.1337419975316152 Adapter cache time: 0.036943368264473975 Engine time: 0.13242378062568605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4543571 . Total output tokens: 4062450
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9430969029199332,
    "estimated_duration": 3599.569172148027,
    "input_throughput": 476.838176435359,
    "output_throughput": 412.3535148275129,
    "total_throughput": 889.1916912628719,
    "itl": 21.763111349713984,
    "ttft": 7316.939300493401,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2413462840113789,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9431672039208934. Arrivals time: 0.028620385681279004 Scheduler time: 0.5449441317468882 Scheduler overhead time: 0.13414615124929696 Adapter cache time: 0.036751735606230795 Engine time: 0.13272257091011852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4543571 . Total output tokens: 4062450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9333465980598703,
    "estimated_duration": 3599.569172148027,
    "input_throughput": 476.838176435359,
    "output_throughput": 412.3535148275129,
    "total_throughput": 889.1916912628719,
    "itl": 21.762967979560678,
    "ttft": 7316.9463915558845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9333997550420463. Arrivals time: 0.028451571706682444 Scheduler time: 0.5366651598596945 Scheduler overhead time: 0.13407952582929283 Adapter cache time: 0.03717252693604678 Engine time: 0.13102217484265566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4543571 . Total output tokens: 4062450
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9412371600046754,
    "estimated_duration": 3599.569172148027,
    "input_throughput": 476.838176435359,
    "output_throughput": 412.3535148275129,
    "total_throughput": 889.1916912628719,
    "itl": 21.763082029247297,
    "ttft": 7316.869176444125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861717,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9413053540047258. Arrivals time: 0.02860236167907715 Scheduler time: 0.5410144936759025 Scheduler overhead time: 0.13330045947805047 Adapter cache time: 0.03657514590304345 Engine time: 0.13481071288697422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4543571 . Total output tokens: 4062450
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9339773880783468,
    "estimated_duration": 3599.569172148027,
    "input_throughput": 476.838176435359,
    "output_throughput": 412.3535148275129,
    "total_throughput": 889.1916912628719,
    "itl": 21.76299275640633,
    "ttft": 7316.987194154657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.93403423007112. Arrivals time: 0.028943453216925263 Scheduler time: 0.5376777232158929 Scheduler overhead time: 0.13381290214601904 Adapter cache time: 0.03648792137391865 Engine time: 0.13140694808680564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4543571 . Total output tokens: 4062450
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9400121759390458,
    "estimated_duration": 3599.569172148027,
    "input_throughput": 476.838176435359,
    "output_throughput": 412.3535148275129,
    "total_throughput": 889.1916912628719,
    "itl": 21.763097468684286,
    "ttft": 7316.8385724994505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585545,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.94008811598178. Arrivals time: 0.028728115605190396 Scheduler time: 0.5416275000898167 Scheduler overhead time: 0.13421078422106802 Adapter cache time: 0.03681456437334418 Engine time: 0.13254065730143338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4243071 . Total output tokens: 3796856
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9224036979721859,
    "estimated_duration": 3599.644812791594,
    "input_throughput": 427.4002241923619,
    "output_throughput": 392.9934961841198,
    "total_throughput": 820.3937203764817,
    "itl": 21.381120539058475,
    "ttft": 8406.229593802349,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 6451,
    "finished_requests": 6436,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9224760220386088. Arrivals time: 0.027761618490330875 Scheduler time: 0.5250781252980232 Scheduler overhead time: 0.1337564210407436 Adapter cache time: 0.03536935884039849 Engine time: 0.13418309472035617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4243071 . Total output tokens: 3796856
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9188619080232456,
    "estimated_duration": 3599.644812791594,
    "input_throughput": 427.4002241923619,
    "output_throughput": 392.9934961841198,
    "total_throughput": 820.3937203764817,
    "itl": 21.381274826142228,
    "ttft": 8406.16456707006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 6451,
    "finished_requests": 6436,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9189308200730011. Arrivals time: 0.02822073467541486 Scheduler time: 0.5234230952337384 Scheduler overhead time: 0.13419166393578053 Adapter cache time: 0.03512308048084378 Engine time: 0.13225924945436418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4243071 . Total output tokens: 3796856
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.92172345391009,
    "estimated_duration": 3599.644812791594,
    "input_throughput": 427.4002241923619,
    "output_throughput": 392.9934961841198,
    "total_throughput": 820.3937203764817,
    "itl": 21.3811630452297,
    "ttft": 8406.255734527984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 6451,
    "finished_requests": 6436,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9217853919835761. Arrivals time: 0.027567070676013827 Scheduler time: 0.5226535649271682 Scheduler overhead time: 0.1349136623321101 Adapter cache time: 0.035489948582835495 Engine time: 0.13484872865956277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4243071 . Total output tokens: 3796856
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9212948509957641,
    "estimated_duration": 3599.644812791594,
    "input_throughput": 427.4002241923619,
    "output_throughput": 392.9934961841198,
    "total_throughput": 820.3937203764817,
    "itl": 21.38109508865473,
    "ttft": 8406.20319838658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 6451,
    "finished_requests": 6436,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.921347797033377. Arrivals time: 0.027815040783025324 Scheduler time: 0.5247342872899026 Scheduler overhead time: 0.13383738917764276 Adapter cache time: 0.035210493369959295 Engine time: 0.13390388805419207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4243071 . Total output tokens: 3796856
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9153359320480376,
    "estimated_duration": 3599.644812791594,
    "input_throughput": 427.4002241923619,
    "output_throughput": 392.9934961841198,
    "total_throughput": 820.3937203764817,
    "itl": 21.381141163397515,
    "ttft": 8406.178240476807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861723,
    "arrivals": 6451,
    "finished_requests": 6436,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.915411196066998. Arrivals time: 0.027636589249596 Scheduler time: 0.5164644083706662 Scheduler overhead time: 0.13632979907561094 Adapter cache time: 0.035276967217214406 Engine time: 0.13311374885961413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4243071 . Total output tokens: 3796856
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9159730509854853,
    "estimated_duration": 3599.644812791594,
    "input_throughput": 427.4002241923619,
    "output_throughput": 392.9934961841198,
    "total_throughput": 820.3937203764817,
    "itl": 21.381158973916534,
    "ttft": 8406.16913314914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 6451,
    "finished_requests": 6436,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9160373240010813. Arrivals time: 0.02760154043789953 Scheduler time: 0.519796863431111 Scheduler overhead time: 0.13440834206994623 Adapter cache time: 0.03528707893565297 Engine time: 0.1326797892106697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4243071 . Total output tokens: 3796856
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9303815590683371,
    "estimated_duration": 3599.644812791594,
    "input_throughput": 427.4002241923619,
    "output_throughput": 392.9934961841198,
    "total_throughput": 820.3937203764817,
    "itl": 21.38123224656369,
    "ttft": 8406.215150215889,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2367897061258555,
    "arrivals": 6451,
    "finished_requests": 6436,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9304945750627667. Arrivals time: 0.027842525159940124 Scheduler time: 0.5292858084430918 Scheduler overhead time: 0.13566295010969043 Adapter cache time: 0.03549812163691968 Engine time: 0.1356359088094905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4096284 . Total output tokens: 3663500
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8985446579754353,
    "estimated_duration": 3600.0220928231165,
    "input_throughput": 419.23103833411807,
    "output_throughput": 373.57215187125763,
    "total_throughput": 792.8031902053757,
    "itl": 21.400212803148285,
    "ttft": 5800.987316300357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8985950070200488. Arrivals time: 0.02741864137351513 Scheduler time: 0.5013129599392414 Scheduler overhead time: 0.13551192998420447 Adapter cache time: 0.03456328192260116 Engine time: 0.133488948806189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4096284 . Total output tokens: 3663500
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.901944765006192,
    "estimated_duration": 3600.0220928231165,
    "input_throughput": 419.23103833411807,
    "output_throughput": 373.57215187125763,
    "total_throughput": 792.8031902053757,
    "itl": 21.400256020390138,
    "ttft": 5800.894519076182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9020224680425599. Arrivals time: 0.027154103852808475 Scheduler time: 0.5048086651368067 Scheduler overhead time: 0.1352423153584823 Adapter cache time: 0.034421744057908654 Engine time: 0.13384958892129362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4096284 . Total output tokens: 3663500
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8994749580742791,
    "estimated_duration": 3600.0220928231165,
    "input_throughput": 419.23103833411807,
    "output_throughput": 373.57215187125763,
    "total_throughput": 792.8031902053757,
    "itl": 21.40039714141907,
    "ttft": 5800.866805619486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8995321571128443. Arrivals time: 0.027247724472545087 Scheduler time: 0.5047316877171397 Scheduler overhead time: 0.13428882346488535 Adapter cache time: 0.03456774598453194 Engine time: 0.13271652976982296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4096284 . Total output tokens: 3663500
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.898205918027088,
    "estimated_duration": 3600.0220928231165,
    "input_throughput": 419.23103833411807,
    "output_throughput": 373.57215187125763,
    "total_throughput": 792.8031902053757,
    "itl": 21.400302631918816,
    "ttft": 5800.813227072253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8982772390590981. Arrivals time: 0.027810488361865282 Scheduler time: 0.4998355506686494 Scheduler overhead time: 0.13468911359086633 Adapter cache time: 0.035147359943948686 Engine time: 0.13437666941899806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4096284 . Total output tokens: 3663500
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8928765429882333,
    "estimated_duration": 3600.0220928231165,
    "input_throughput": 419.23103833411807,
    "output_throughput": 373.57215187125763,
    "total_throughput": 792.8031902053757,
    "itl": 21.40043699690404,
    "ttft": 5800.880431082871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.892928120912984. Arrivals time: 0.02691954141482711 Scheduler time: 0.4978328722063452 Scheduler overhead time: 0.13476201321464032 Adapter cache time: 0.0344824381172657 Engine time: 0.13272826909087598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4096284 . Total output tokens: 3663500
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.89695915998891,
    "estimated_duration": 3600.0220928231165,
    "input_throughput": 419.23103833411807,
    "output_throughput": 373.57215187125763,
    "total_throughput": 792.8031902053757,
    "itl": 21.40014174643571,
    "ttft": 5800.754383637207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8970292150042951. Arrivals time: 0.02688458317425102 Scheduler time: 0.5012101647444069 Scheduler overhead time: 0.1348565979860723 Adapter cache time: 0.03452919272240251 Engine time: 0.13301311014220119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4096284 . Total output tokens: 3663500
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9035155649762601,
    "estimated_duration": 3600.0220928231165,
    "input_throughput": 419.23103833411807,
    "output_throughput": 373.57215187125763,
    "total_throughput": 792.8031902053757,
    "itl": 21.400435847831293,
    "ttft": 5800.863575155804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9035769139882177. Arrivals time: 0.030628237291239202 Scheduler time: 0.5012763449922204 Scheduler overhead time: 0.13604223087895662 Adapter cache time: 0.03489394823554903 Engine time: 0.1341556126717478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4026439 . Total output tokens: 3604490
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8891423370223492,
    "estimated_duration": 3599.7609609813594,
    "input_throughput": 405.655546528819,
    "output_throughput": 369.42341850317274,
    "total_throughput": 775.0789650319917,
    "itl": 21.290061988182007,
    "ttft": 2969.167517076632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8892031350405887. Arrivals time: 0.026920027914457023 Scheduler time: 0.4937179299304262 Scheduler overhead time: 0.13374890293926 Adapter cache time: 0.033928541699424386 Engine time: 0.13475712342187762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4026439 . Total output tokens: 3604490
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8894885740010068,
    "estimated_duration": 3599.7609609813594,
    "input_throughput": 405.655546528819,
    "output_throughput": 369.42341850317274,
    "total_throughput": 775.0789650319917,
    "itl": 21.290211436674067,
    "ttft": 2969.221995686224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8895416639279574. Arrivals time: 0.027096596430055797 Scheduler time: 0.49445443565491587 Scheduler overhead time: 0.1346247779438272 Adapter cache time: 0.03390689007937908 Engine time: 0.13298964069690555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4026439 . Total output tokens: 3604490
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.899980230955407,
    "estimated_duration": 3599.7609609813594,
    "input_throughput": 405.655546528819,
    "output_throughput": 369.42341850317274,
    "total_throughput": 775.0789650319917,
    "itl": 21.290487128167946,
    "ttft": 2969.283349090981,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9000423450488597. Arrivals time: 0.02671100781299174 Scheduler time: 0.49830602400470525 Scheduler overhead time: 0.1412474507233128 Adapter cache time: 0.03434766014106572 Engine time: 0.1325788771500811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4026439 . Total output tokens: 3604490
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8938839059555903,
    "estimated_duration": 3599.7609609813594,
    "input_throughput": 405.655546528819,
    "output_throughput": 369.42341850317274,
    "total_throughput": 775.0789650319917,
    "itl": 21.290407885112486,
    "ttft": 2969.2790817391124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8939506459282711. Arrivals time: 0.027506327838636935 Scheduler time: 0.49605525471270084 Scheduler overhead time: 0.136019111960195 Adapter cache time: 0.03410647693090141 Engine time: 0.13412464770954102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4026439 . Total output tokens: 3604490
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8898600359680131,
    "estimated_duration": 3599.7609609813594,
    "input_throughput": 405.655546528819,
    "output_throughput": 369.42341850317274,
    "total_throughput": 775.0789650319917,
    "itl": 21.290426566657953,
    "ttft": 2969.3175758398556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861723,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8899337829789147. Arrivals time: 0.026944892364554107 Scheduler time: 0.49524394469335675 Scheduler overhead time: 0.13424073648639023 Adapter cache time: 0.03405225253663957 Engine time: 0.1332110142102465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4026439 . Total output tokens: 3604490
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8965170270530507,
    "estimated_duration": 3599.7609609813594,
    "input_throughput": 405.655546528819,
    "output_throughput": 369.42341850317274,
    "total_throughput": 775.0789650319917,
    "itl": 21.29016528249018,
    "ttft": 2969.067099490852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8965751940850168. Arrivals time: 0.027217970928177238 Scheduler time: 0.5004053018055856 Scheduler overhead time: 0.13484025397337973 Adapter cache time: 0.03427754563745111 Engine time: 0.13343694841023535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4026439 . Total output tokens: 3604490
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8849618650274351,
    "estimated_duration": 3599.7609609813594,
    "input_throughput": 405.655546528819,
    "output_throughput": 369.42341850317274,
    "total_throughput": 775.0789650319917,
    "itl": 21.29037043206237,
    "ttft": 2969.265661225232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2367897061258555,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8850345540558919. Arrivals time: 0.026611315086483955 Scheduler time: 0.4915697913384065 Scheduler overhead time: 0.13433586608152837 Adapter cache time: 0.034123564953915775 Engine time: 0.1321551853325218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3599288 . Total output tokens: 3224182
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8426362089812756,
    "estimated_duration": 3598.9044293710067,
    "input_throughput": 359.8061647406168,
    "output_throughput": 324.3425945056311,
    "total_throughput": 684.1487592462479,
    "itl": 21.04771737272645,
    "ttft": 4676.542649794947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 5429,
    "finished_requests": 5422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8426841519540176. Arrivals time: 0.025287281488999724 Scheduler time: 0.44840612495318055 Scheduler overhead time: 0.13580814853776246 Adapter cache time: 0.03260429832153022 Engine time: 0.1341508001787588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3599288 . Total output tokens: 3224182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8589171720668674,
    "estimated_duration": 3598.9044293710067,
    "input_throughput": 359.8061647406168,
    "output_throughput": 324.3425945056311,
    "total_throughput": 684.1487592462479,
    "itl": 21.047836670519782,
    "ttft": 4676.544509750385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 5429,
    "finished_requests": 5422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8589916980126873. Arrivals time: 0.026157112326472998 Scheduler time: 0.4614684407133609 Scheduler overhead time: 0.13510757579933852 Adapter cache time: 0.03320230124518275 Engine time: 0.13564980984665453 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3599288 . Total output tokens: 3224182
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8456716309301555,
    "estimated_duration": 3598.9044293710067,
    "input_throughput": 359.8061647406168,
    "output_throughput": 324.3425945056311,
    "total_throughput": 684.1487592462479,
    "itl": 21.047803383110505,
    "ttft": 4676.574043675192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 5429,
    "finished_requests": 5422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8457367999944836. Arrivals time: 0.024969339719973505 Scheduler time: 0.45087639312259853 Scheduler overhead time: 0.134942299220711 Adapter cache time: 0.03307862381916493 Engine time: 0.134394476772286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3599288 . Total output tokens: 3224182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8439232929376885,
    "estimated_duration": 3598.9044293710067,
    "input_throughput": 359.8061647406168,
    "output_throughput": 324.3425945056311,
    "total_throughput": 684.1487592462479,
    "itl": 21.047712730125465,
    "ttft": 4676.57333766433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 5429,
    "finished_requests": 5422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8439726259093732. Arrivals time: 0.025150505709461868 Scheduler time: 0.4494049602653831 Scheduler overhead time: 0.1346235303208232 Adapter cache time: 0.03294397657737136 Engine time: 0.1349690331844613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3599288 . Total output tokens: 3224182
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8460419129114598,
    "estimated_duration": 3598.9044293710067,
    "input_throughput": 359.8061647406168,
    "output_throughput": 324.3425945056311,
    "total_throughput": 684.1487592462479,
    "itl": 21.04780043681673,
    "ttft": 4676.571216607077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 5429,
    "finished_requests": 5422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8461155749391764. Arrivals time: 0.024926703074015677 Scheduler time: 0.4486846474464983 Scheduler overhead time: 0.13639012316707522 Adapter cache time: 0.033081485191360116 Engine time: 0.13570668606553227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3599288 . Total output tokens: 3224182
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8533281530253589,
    "estimated_duration": 3598.9044293710067,
    "input_throughput": 359.8061647406168,
    "output_throughput": 324.3425945056311,
    "total_throughput": 684.1487592462479,
    "itl": 21.047670611659917,
    "ttft": 4676.521112499329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 5429,
    "finished_requests": 5422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8534676280105487. Arrivals time: 0.025687254616059363 Scheduler time: 0.45538568252231926 Scheduler overhead time: 0.13595355674624443 Adapter cache time: 0.03325996070634574 Engine time: 0.135776286595501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3599288 . Total output tokens: 3224182
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8399822389474139,
    "estimated_duration": 3598.9044293710067,
    "input_throughput": 359.8061647406168,
    "output_throughput": 324.3425945056311,
    "total_throughput": 684.1487592462479,
    "itl": 21.047824246807767,
    "ttft": 4676.540408764273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 5429,
    "finished_requests": 5422,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8401158839697018. Arrivals time: 0.02465817960910499 Scheduler time: 0.4481064765714109 Scheduler overhead time: 0.13529226777609438 Adapter cache time: 0.03283664584159851 Engine time: 0.1322033191099763 
