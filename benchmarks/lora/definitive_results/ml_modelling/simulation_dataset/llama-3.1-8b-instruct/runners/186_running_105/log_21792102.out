INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:53 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_192_slots_128_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_192_slots_128_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.130168925970793,
    "estimated_duration": 3600.1114669502954,
    "input_throughput": 4801.509941758328,
    "output_throughput": 4130.110730320142,
    "total_throughput": 8931.620672078468,
    "itl": 105.54694074811088,
    "ttft": 2155911.636759246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1067,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.272533006728613,
    "arrivals": 765271,
    "finished_requests": 69594,
    "scheduler_time": 91.87456887207841
}
#Debug simulation 
Total elapsed time: 5.130272035021335. Arrivals time: 0.31158382166177034 Scheduler time: 4.651038576383144 Scheduler overhead time: 0.04906630888581276 Adapter cache time: 0.0451110415160656 Engine time: 0.050179858691990376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_192_slots_128_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_192_slots_128_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 1080, 1080, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 34560, 34560, 270, 1080, 34560, 270, 1080, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 1080, 270, 270, 270, 270, 270, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 270, 1080, 1080, 34560, 270, 270, 270, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 1080, 1080, 34560, 1080, 270, 1080, 34560, 34560, 1080, 34560, 1080, 270, 34560, 1080, 270, 1080, 1080, 270, 1080, 34560, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 1080, 270, 34560, 34560, 1080, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 2298240 . Total input tokens: 512614203 . Total output tokens: 451469517
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.155448201112449,
    "estimated_duration": 3600.0251001257097,
    "input_throughput": 4802.073185377605,
    "output_throughput": 4130.687310897008,
    "total_throughput": 8932.760496274614,
    "itl": 105.53913203855272,
    "ttft": 2155630.089555123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1064,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.792491880767013,
    "arrivals": 765271,
    "finished_requests": 69602,
    "scheduler_time": 91.88397664933589
}
#Debug simulation 
Total elapsed time: 5.155544043984264. Arrivals time: 0.2393158646300435 Scheduler time: 4.749466360080987 Scheduler overhead time: 0.049125935416668653 Adapter cache time: 0.044201734475791454 Engine time: 0.05015931325033307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.300553414970636,
    "estimated_duration": 3600.0736785037743,
    "input_throughput": 4959.035729352027,
    "output_throughput": 4342.035579254219,
    "total_throughput": 9301.071308606246,
    "itl": 119.76917020710331,
    "ttft": 2133312.090415699,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 820,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.422175406199056,
    "arrivals": 762397,
    "finished_requests": 72182,
    "scheduler_time": 91.37846322798141
}
#Debug simulation 
Total elapsed time: 5.300647319294512. Arrivals time: 0.24720879597589374 Scheduler time: 4.903429021127522 Scheduler overhead time: 0.04442985774949193 Adapter cache time: 0.039110840763896704 Engine time: 0.045479023829102516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.107020303141326,
    "estimated_duration": 3600.022751552767,
    "input_throughput": 4755.044115378583,
    "output_throughput": 4168.112824711425,
    "total_throughput": 8923.156940090008,
    "itl": 104.55423446813683,
    "ttft": 2156202.798379965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 788,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.752404607292273,
    "arrivals": 762397,
    "finished_requests": 69256,
    "scheduler_time": 92.83768269479246
}
#Debug simulation 
Total elapsed time: 5.107111648190767. Arrivals time: 0.24024763982743025 Scheduler time: 4.7028492712415755 Scheduler overhead time: 0.04948247177526355 Adapter cache time: 0.04063495760783553 Engine time: 0.05040753446519375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.154789236839861,
    "estimated_duration": 3600.002238431794,
    "input_throughput": 4755.668709655544,
    "output_throughput": 4168.683796857125,
    "total_throughput": 8924.352506512669,
    "itl": 104.54356025160698,
    "ttft": 2156072.6086250693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 788,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.3761967235244725,
    "arrivals": 762397,
    "finished_requests": 69261,
    "scheduler_time": 92.8461571956661
}
#Debug simulation 
Total elapsed time: 5.154881294816732. Arrivals time: 0.24078806303441525 Scheduler time: 4.749282079748809 Scheduler overhead time: 0.04978556698188186 Adapter cache time: 0.04071036446839571 Engine time: 0.050783276092261076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 1080, 1080, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 34560, 34560, 135, 1080, 34560, 135, 1080, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 1080, 135, 135, 135, 135, 135, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 135, 1080, 1080, 34560, 135, 135, 135, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 1080, 1080, 34560, 1080, 135, 1080, 34560, 34560, 1080, 34560, 1080, 135, 34560, 1080, 135, 1080, 1080, 135, 1080, 34560, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 1080, 135, 34560, 34560, 1080, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 2289600 . Total input tokens: 510664956 . Total output tokens: 449773587
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.117018916644156,
    "estimated_duration": 3600.014550218452,
    "input_throughput": 4756.356887213405,
    "output_throughput": 4169.19037149148,
    "total_throughput": 8925.547258704884,
    "itl": 104.53282035804997,
    "ttft": 2156007.707659115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 788,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.030529701169556,
    "arrivals": 762397,
    "finished_requests": 69272,
    "scheduler_time": 92.85469510397445
}
#Debug simulation 
Total elapsed time: 5.117110272869468. Arrivals time: 0.23890863684937358 Scheduler time: 4.713673962280154 Scheduler overhead time: 0.04963210457935929 Adapter cache time: 0.04077394353225827 Engine time: 0.05059734731912613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_192_slots_128_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_192_slots_128_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.33519176999107,
    "estimated_duration": 3600.088184620158,
    "input_throughput": 5072.291861630237,
    "output_throughput": 4381.479894683266,
    "total_throughput": 9453.771756313503,
    "itl": 118.40841718016891,
    "ttft": 2127963.735882144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.511189195965463,
    "arrivals": 760968,
    "finished_requests": 73410,
    "scheduler_time": 92.18985685662439
}
#Debug simulation 
Total elapsed time: 5.335301993880421. Arrivals time: 0.25773223862051964 Scheduler time: 4.929300237912685 Scheduler overhead time: 0.04479547590017319 Adapter cache time: 0.036452770698815584 Engine time: 0.04579832311719656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_192_slots_128_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_192_slots_128_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.183242540806532,
    "estimated_duration": 3600.07005978104,
    "input_throughput": 4842.168266319862,
    "output_throughput": 4193.045898922897,
    "total_throughput": 9035.21416524276,
    "itl": 103.12035104325606,
    "ttft": 2150802.8060074965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.710305121890274,
    "arrivals": 760968,
    "finished_requests": 70184,
    "scheduler_time": 93.58739864663725
}
#Debug simulation 
Total elapsed time: 5.183397081214935. Arrivals time: 0.24852464022114873 Scheduler time: 4.768399976659566 Scheduler overhead time: 0.050087153911590576 Adapter cache time: 0.04107489995658398 Engine time: 0.05147578474134207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_192_slots_128_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_192_slots_128_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.160728462040424,
    "estimated_duration": 3600.0623116836505,
    "input_throughput": 4842.29951893451,
    "output_throughput": 4193.151032694264,
    "total_throughput": 9035.450551628774,
    "itl": 103.11349923893577,
    "ttft": 2150701.3250357676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.479860440320331,
    "arrivals": 760968,
    "finished_requests": 70188,
    "scheduler_time": 93.59274825930001
}
#Debug simulation 
Total elapsed time: 5.160820303950459. Arrivals time: 0.24097202811390162 Scheduler time: 4.755188908893615 Scheduler overhead time: 0.050539893098175526 Adapter cache time: 0.038646083790808916 Engine time: 0.05148416664451361 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_192_slots_128_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_192_slots_128_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 1080, 1080, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 34560, 34560, 66, 1080, 34560, 66, 1080, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 1080, 66, 66, 66, 66, 66, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 66, 1080, 1080, 34560, 66, 66, 66, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 1080, 1080, 34560, 1080, 66, 1080, 34560, 34560, 1080, 34560, 1080, 66, 34560, 1080, 66, 1080, 1080, 66, 1080, 34560, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 1080, 66, 34560, 34560, 1080, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 2285184 . Total input tokens: 509690131 . Total output tokens: 448926029
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.144820604939014,
    "estimated_duration": 3600.0781841370826,
    "input_throughput": 4847.813882737456,
    "output_throughput": 4197.311065793404,
    "total_throughput": 9045.12494853086,
    "itl": 103.35403364654258,
    "ttft": 2150511.9238064704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2557996796909574,
    "arrivals": 760968,
    "finished_requests": 70271,
    "scheduler_time": 93.57253405355586
}
#Debug simulation 
Total elapsed time: 5.144914416130632. Arrivals time: 0.23962275264784694 Scheduler time: 4.74203437846154 Scheduler overhead time: 0.05004883883520961 Adapter cache time: 0.03859575791284442 Engine time: 0.050827665720134974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.460798962973058,
    "estimated_duration": 3600.100638598837,
    "input_throughput": 5083.589276305047,
    "output_throughput": 4416.022382693048,
    "total_throughput": 9499.611658998096,
    "itl": 117.89851185754885,
    "ttft": 2122812.588165525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2746687069907847,
    "arrivals": 760248,
    "finished_requests": 74076,
    "scheduler_time": 92.81151372478551
}
#Debug simulation 
Total elapsed time: 5.460909067187458. Arrivals time: 0.3005383210256696 Scheduler time: 5.0128293633461 Scheduler overhead time: 0.045382728800177574 Adapter cache time: 0.0343651007860899 Engine time: 0.04630586877465248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.2512382180429995,
    "estimated_duration": 3600.065268588165,
    "input_throughput": 4863.852928662862,
    "output_throughput": 4228.1722314355375,
    "total_throughput": 9092.0251600984,
    "itl": 103.07240550215401,
    "ttft": 2146584.46552119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4426339082466466,
    "arrivals": 760248,
    "finished_requests": 70902,
    "scheduler_time": 94.10312646394597
}
#Debug simulation 
Total elapsed time: 5.251349184196442. Arrivals time: 0.2542508007027209 Scheduler time: 4.833377671893686 Scheduler overhead time: 0.050732148345559835 Adapter cache time: 0.03709363518282771 Engine time: 0.0516602685675025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.321724158711731,
    "estimated_duration": 3600.028387711313,
    "input_throughput": 4864.137755072673,
    "output_throughput": 4228.445267810121,
    "total_throughput": 9092.583022882794,
    "itl": 103.06844914902793,
    "ttft": 2146511.20510902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2885413802089136,
    "arrivals": 760248,
    "finished_requests": 70903,
    "scheduler_time": 94.10568820176773
}
#Debug simulation 
Total elapsed time: 5.3218774646520615. Arrivals time: 0.25804097950458527 Scheduler time: 4.900179232470691 Scheduler overhead time: 0.05064569879323244 Adapter cache time: 0.03711878415197134 Engine time: 0.0517472242936492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 1080, 1080, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 34560, 34560, 33, 1080, 34560, 33, 1080, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 1080, 33, 33, 33, 33, 33, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 33, 1080, 1080, 34560, 33, 33, 33, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 1080, 1080, 34560, 1080, 33, 1080, 34560, 34560, 1080, 34560, 1080, 33, 34560, 1080, 33, 1080, 1080, 33, 1080, 34560, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 1080, 33, 34560, 34560, 1080, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 2283072 . Total input tokens: 509222057 . Total output tokens: 448499021
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.194595025852323,
    "estimated_duration": 3600.115109517782,
    "input_throughput": 4864.499180512522,
    "output_throughput": 4228.683399525841,
    "total_throughput": 9093.182580038363,
    "itl": 103.06420542487803,
    "ttft": 2146556.7877472313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1386135150911203,
    "arrivals": 760248,
    "finished_requests": 70911,
    "scheduler_time": 94.1111447865205
}
#Debug simulation 
Total elapsed time: 5.194685633759946. Arrivals time: 0.24029973149299622 Scheduler time: 4.791680614929646 Scheduler overhead time: 0.050498207565397024 Adapter cache time: 0.036895645782351494 Engine time: 0.051325674168765545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_192_slots_128_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_192_slots_128_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.416824222076684,
    "estimated_duration": 3600.0547306794165,
    "input_throughput": 5100.474402102952,
    "output_throughput": 4454.937271737877,
    "total_throughput": 9555.41167384083,
    "itl": 116.99889128277924,
    "ttft": 2119625.2651931797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.858594402307766,
    "arrivals": 753816,
    "finished_requests": 74364,
    "scheduler_time": 93.64219150829229
}
#Debug simulation 
Total elapsed time: 5.416915766894817. Arrivals time: 0.24976798612624407 Scheduler time: 5.020140751730651 Scheduler overhead time: 0.0455531794577837 Adapter cache time: 0.0334314052015543 Engine time: 0.04652676219120622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_192_slots_128_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_192_slots_128_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.213578273076564,
    "estimated_duration": 3600.0004879424164,
    "input_throughput": 4868.422951247206,
    "output_throughput": 4259.695811531592,
    "total_throughput": 9128.118762778799,
    "itl": 102.38739403093876,
    "ttft": 2140722.917784079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 858,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.285348773477609,
    "arrivals": 753816,
    "finished_requests": 70946,
    "scheduler_time": 94.84437756296228
}
#Debug simulation 
Total elapsed time: 5.213693994097412. Arrivals time: 0.24392323195934296 Scheduler time: 4.80838391603902 Scheduler overhead time: 0.050516530871391296 Adapter cache time: 0.03527471795678139 Engine time: 0.05151288164779544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_192_slots_128_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_192_slots_128_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.199827527161688,
    "estimated_duration": 3600.0419300980748,
    "input_throughput": 4868.706070743599,
    "output_throughput": 4260.162603045622,
    "total_throughput": 9128.86867378922,
    "itl": 102.37589458149719,
    "ttft": 2140541.7746628704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 858,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.87165892343036,
    "arrivals": 753816,
    "finished_requests": 70954,
    "scheduler_time": 94.8558063612358
}
#Debug simulation 
Total elapsed time: 5.1999182272702456. Arrivals time: 0.23825431149452925 Scheduler time: 4.8004380711354315 Scheduler overhead time: 0.05048908572643995 Adapter cache time: 0.03518823115155101 Engine time: 0.051668533124029636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_192_slots_128_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_192_slots_128_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 540, 540, 34560, 540, 270, 34560, 270, 540, 540, 270, 34560, 34560, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 270, 540, 540, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 34560, 34560, 270, 540, 34560, 270, 540, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 540, 270, 270, 270, 270, 270, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 270, 540, 540, 34560, 270, 270, 270, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 270, 34560, 540, 540, 540, 34560, 540, 270, 540, 34560, 34560, 540, 34560, 540, 270, 34560, 540, 270, 540, 540, 270, 540, 34560, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 540, 270, 34560, 34560, 540, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 2263680 . Total input tokens: 504926830 . Total output tokens: 444649599
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.1879116082564,
    "estimated_duration": 3600.1031825348787,
    "input_throughput": 4869.14627476241,
    "output_throughput": 4260.678992317019,
    "total_throughput": 9129.825267079428,
    "itl": 102.36380165323251,
    "ttft": 2140540.432592244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 858,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.477404167009491,
    "arrivals": 753816,
    "finished_requests": 70963,
    "scheduler_time": 94.86730494823702
}
#Debug simulation 
Total elapsed time: 5.188025765120983. Arrivals time: 0.24033351428806782 Scheduler time: 4.7866161162965 Scheduler overhead time: 0.050428023096174 Adapter cache time: 0.03529731277376413 Engine time: 0.05145028326660395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.490763119887561,
    "estimated_duration": 3600.052469813484,
    "input_throughput": 5169.382712070353,
    "output_throughput": 4512.075625620416,
    "total_throughput": 9681.458337690769,
    "itl": 115.64617819307904,
    "ttft": 2108407.698563037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 641,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.238554189479979,
    "arrivals": 750836,
    "finished_requests": 75369,
    "scheduler_time": 94.7154651549759
}
#Debug simulation 
Total elapsed time: 5.490856667049229. Arrivals time: 0.25207674968987703 Scheduler time: 5.094899858813733 Scheduler overhead time: 0.04591662436723709 Adapter cache time: 0.029582375660538673 Engine time: 0.04668108420446515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.317838549148291,
    "estimated_duration": 3600.0422397687544,
    "input_throughput": 4937.440678790969,
    "output_throughput": 4312.291347169637,
    "total_throughput": 9249.732025960606,
    "itl": 101.28838369034959,
    "ttft": 2132707.675724472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.463636225927627,
    "arrivals": 750836,
    "finished_requests": 71953,
    "scheduler_time": 95.85573080512185
}
#Debug simulation 
Total elapsed time: 5.317928477190435. Arrivals time: 0.2916375733911991 Scheduler time: 4.8678841716609895 Scheduler overhead time: 0.05108663998544216 Adapter cache time: 0.030928445048630238 Engine time: 0.052177788224071264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.276516667101532,
    "estimated_duration": 3600.1034113239343,
    "input_throughput": 4937.557333516427,
    "output_throughput": 4312.429179441439,
    "total_throughput": 9249.986512957867,
    "itl": 101.2800153279587,
    "ttft": 2132709.2294055913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.17488626347854,
    "arrivals": 750836,
    "finished_requests": 71956,
    "scheduler_time": 95.86444275128342
}
#Debug simulation 
Total elapsed time: 5.276665490120649. Arrivals time: 0.2437888947315514 Scheduler time: 4.874390440061688 Scheduler overhead time: 0.05088859610259533 Adapter cache time: 0.030922745820134878 Engine time: 0.052239127922803164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 540, 540, 34560, 540, 135, 34560, 135, 540, 540, 135, 34560, 34560, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 135, 540, 540, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 34560, 34560, 135, 540, 34560, 135, 540, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 540, 135, 135, 135, 135, 135, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 135, 540, 540, 34560, 135, 135, 135, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 135, 34560, 540, 540, 540, 34560, 540, 135, 540, 34560, 34560, 540, 34560, 540, 135, 34560, 540, 135, 540, 540, 135, 540, 34560, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 540, 135, 34560, 34560, 540, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 2255040 . Total input tokens: 503038871 . Total output tokens: 442951182
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.255729952827096,
    "estimated_duration": 3600.1099801310265,
    "input_throughput": 4930.919915772662,
    "output_throughput": 4307.391742358831,
    "total_throughput": 9238.311658131493,
    "itl": 100.95012010808219,
    "ttft": 2132774.9833692224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9005756946885777,
    "arrivals": 750836,
    "finished_requests": 71870,
    "scheduler_time": 95.90157045889491
}
#Debug simulation 
Total elapsed time: 5.255819655954838. Arrivals time: 0.24381093168631196 Scheduler time: 4.851092624012381 Scheduler overhead time: 0.051206478383392096 Adapter cache time: 0.03055646363645792 Engine time: 0.05284880008548498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_192_slots_128_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_192_slots_128_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.588947246782482,
    "estimated_duration": 3600.122864050291,
    "input_throughput": 5225.981365211868,
    "output_throughput": 4562.809831862041,
    "total_throughput": 9788.79119707391,
    "itl": 114.1983048303431,
    "ttft": 2106030.124254423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.816886247610697,
    "arrivals": 749460,
    "finished_requests": 76353,
    "scheduler_time": 95.9054921982325
}
#Debug simulation 
Total elapsed time: 5.5890390779823065. Arrivals time: 0.3290033144876361 Scheduler time: 5.117100745439529 Scheduler overhead time: 0.04639910440891981 Adapter cache time: 0.026938878931105137 Engine time: 0.047616980504244566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_192_slots_128_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_192_slots_128_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.367961075622588,
    "estimated_duration": 3600.0835178211196,
    "input_throughput": 4982.34107936916,
    "output_throughput": 4351.427660623062,
    "total_throughput": 9333.768739992223,
    "itl": 100.22540077131028,
    "ttft": 2131826.4359385082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.023873000009921,
    "arrivals": 749460,
    "finished_requests": 72803,
    "scheduler_time": 96.82181420805173
}
#Debug simulation 
Total elapsed time: 5.368053823709488. Arrivals time: 0.3297905847430229 Scheduler time: 4.881272188387811 Scheduler overhead time: 0.051416642032563686 Adapter cache time: 0.02849397622048855 Engine time: 0.05264038173481822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_192_slots_128_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_192_slots_128_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.433923764154315,
    "estimated_duration": 3600.1003972547937,
    "input_throughput": 4982.439937974459,
    "output_throughput": 4351.618363739547,
    "total_throughput": 9334.058301714007,
    "itl": 100.22001819334503,
    "ttft": 2131789.6814262685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8198045169329227,
    "arrivals": 749460,
    "finished_requests": 72805,
    "scheduler_time": 96.82732028199945
}
#Debug simulation 
Total elapsed time: 5.4340159320272505. Arrivals time: 0.2454909305088222 Scheduler time: 5.030580772086978 Scheduler overhead time: 0.05181086901575327 Adapter cache time: 0.028714335523545742 Engine time: 0.05284187523648143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_192_slots_128_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_192_slots_128_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 540, 540, 34560, 540, 66, 34560, 66, 540, 540, 66, 34560, 34560, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 66, 540, 540, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 34560, 34560, 66, 540, 34560, 66, 540, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 540, 66, 66, 66, 66, 66, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 66, 540, 540, 34560, 66, 66, 66, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 66, 34560, 540, 540, 540, 34560, 540, 66, 540, 34560, 34560, 540, 34560, 540, 66, 34560, 540, 66, 540, 540, 66, 540, 34560, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 540, 66, 34560, 34560, 540, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 2250624 . Total input tokens: 502085657 . Total output tokens: 442071140
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.4096067561767995,
    "estimated_duration": 3600.0271659982845,
    "input_throughput": 4982.573512060144,
    "output_throughput": 4351.728828039479,
    "total_throughput": 9334.302340099623,
    "itl": 100.21442104679826,
    "ttft": 2131685.578411309,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.636559348455619,
    "arrivals": 749460,
    "finished_requests": 72807,
    "scheduler_time": 96.82976089968075
}
#Debug simulation 
Total elapsed time: 5.409698135219514. Arrivals time: 0.3247753605246544 Scheduler time: 4.927119202911854 Scheduler overhead time: 0.05165605200454593 Adapter cache time: 0.02854340896010399 Engine time: 0.053085336461663246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.558326119091362,
    "estimated_duration": 3600.078122567042,
    "input_throughput": 5277.461030888001,
    "output_throughput": 4572.794933755894,
    "total_throughput": 9850.255964643895,
    "itl": 114.09485282862087,
    "ttft": 2101826.395469769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0961336631281307,
    "arrivals": 748703,
    "finished_requests": 76839,
    "scheduler_time": 96.01331273515632
}
#Debug simulation 
Total elapsed time: 5.558419552166015. Arrivals time: 0.3005852890200913 Scheduler time: 5.116237822920084 Scheduler overhead time: 0.04658175120130181 Adapter cache time: 0.025491468608379364 Engine time: 0.04746176302433014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.323254188988358,
    "estimated_duration": 3600.055422791864,
    "input_throughput": 5033.381398875099,
    "output_throughput": 4360.317316400253,
    "total_throughput": 9393.698715275352,
    "itl": 100.23418460420527,
    "ttft": 2127951.938596025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.240284365364353,
    "arrivals": 748703,
    "finished_requests": 73261,
    "scheduler_time": 96.91237050357084
}
#Debug simulation 
Total elapsed time: 5.323347724974155. Arrivals time: 0.24843722581863403 Scheduler time: 4.918520536739379 Scheduler overhead time: 0.052313906606286764 Adapter cache time: 0.0262603722512722 Engine time: 0.05314392829313874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.327772950287908,
    "estimated_duration": 3600.015313135439,
    "input_throughput": 5033.511922541721,
    "output_throughput": 4360.543674001147,
    "total_throughput": 9394.055596542868,
    "itl": 100.23050440043043,
    "ttft": 2127874.2981660366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.094521163166498,
    "arrivals": 748703,
    "finished_requests": 73263,
    "scheduler_time": 96.91489338198913
}
#Debug simulation 
Total elapsed time: 5.3279207069426775. Arrivals time: 0.25040404917672276 Scheduler time: 4.9221271481364965 Scheduler overhead time: 0.051832438446581364 Adapter cache time: 0.026112648658454418 Engine time: 0.05283091403543949 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 540, 540, 34560, 540, 33, 34560, 33, 540, 540, 33, 34560, 34560, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 33, 540, 540, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 34560, 34560, 33, 540, 34560, 33, 540, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 540, 33, 33, 33, 33, 33, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 33, 540, 540, 34560, 33, 33, 33, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 33, 34560, 540, 540, 540, 34560, 540, 33, 540, 34560, 34560, 540, 34560, 540, 33, 34560, 540, 33, 540, 540, 33, 540, 34560, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 540, 33, 34560, 34560, 540, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 540, 540, 540, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 2248512 . Total input tokens: 501620841 . Total output tokens: 441653538
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.291809298098087,
    "estimated_duration": 3600.0924014132206,
    "input_throughput": 5033.878017377004,
    "output_throughput": 4360.743072549279,
    "total_throughput": 9394.621089926282,
    "itl": 100.2269400114304,
    "ttft": 2127827.9261712967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9598637287551464,
    "arrivals": 748703,
    "finished_requests": 73269,
    "scheduler_time": 96.92023182311983
}
#Debug simulation 
Total elapsed time: 5.291900960262865. Arrivals time: 0.24758569058030844 Scheduler time: 4.887439992744476 Scheduler overhead time: 0.051466625183820724 Adapter cache time: 0.028227683622390032 Engine time: 0.05264786910265684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.8416076018475,
    "estimated_duration": 3600.070754572285,
    "input_throughput": 5292.436259982244,
    "output_throughput": 4626.1529662570965,
    "total_throughput": 9918.58922623934,
    "itl": 112.981764064208,
    "ttft": 2097919.1003982187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.253305243719407,
    "arrivals": 745105,
    "finished_requests": 77142,
    "scheduler_time": 97.16509383342638
}
#Debug simulation 
Total elapsed time: 5.841674574185163. Arrivals time: 0.573267221916467 Scheduler time: 5.129609820432961 Scheduler overhead time: 0.04667800944298506 Adapter cache time: 0.022190279327332973 Engine time: 0.04787973314523697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.429377736058086,
    "estimated_duration": 3600.05513061982,
    "input_throughput": 5039.823653166171,
    "output_throughput": 4405.556144155312,
    "total_throughput": 9445.379797321482,
    "itl": 99.34356949903642,
    "ttft": 2125650.8995905025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.476593158231122,
    "arrivals": 745105,
    "finished_requests": 73420,
    "scheduler_time": 97.92892010824058
}
#Debug simulation 
Total elapsed time: 5.429470216855407. Arrivals time: 0.31025160383433104 Scheduler time: 4.965233412571251 Scheduler overhead time: 0.05220328411087394 Adapter cache time: 0.023872619029134512 Engine time: 0.05318402266129851 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.393476762808859,
    "estimated_duration": 3600.0228336950618,
    "input_throughput": 5038.57109744556,
    "output_throughput": 4404.810394972955,
    "total_throughput": 9443.381492418514,
    "itl": 99.28922121253449,
    "ttft": 2125487.9300949136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2608617234416264,
    "arrivals": 745105,
    "finished_requests": 73400,
    "scheduler_time": 97.93759760608408
}
#Debug simulation 
Total elapsed time: 5.393568750005215. Arrivals time: 0.2932111332193017 Scheduler time: 4.945785403251648 Scheduler overhead time: 0.051926329266279936 Adapter cache time: 0.023947499226778746 Engine time: 0.05385699588805437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 270, 270, 34560, 270, 135, 34560, 135, 270, 270, 135, 34560, 34560, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 135, 270, 270, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 34560, 34560, 135, 270, 34560, 135, 270, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 270, 135, 135, 135, 135, 135, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 135, 270, 270, 34560, 135, 135, 135, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 135, 34560, 270, 270, 270, 34560, 270, 135, 270, 34560, 34560, 270, 34560, 270, 135, 34560, 270, 135, 270, 270, 135, 270, 34560, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 270, 135, 34560, 34560, 270, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 2237760 . Total input tokens: 499211302 . Total output tokens: 439533037
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.370731443166733,
    "estimated_duration": 3600.038721629934,
    "input_throughput": 5028.688133610844,
    "output_throughput": 4396.633820881176,
    "total_throughput": 9425.32195449202,
    "itl": 98.85425312275294,
    "ttft": 2125752.751736815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0387463677115605,
    "arrivals": 745105,
    "finished_requests": 73265,
    "scheduler_time": 97.97277502913357
}
#Debug simulation 
Total elapsed time: 5.370822312310338. Arrivals time: 0.24902671249583364 Scheduler time: 4.966857189312577 Scheduler overhead time: 0.05249095568433404 Adapter cache time: 0.023867654148489237 Engine time: 0.05373620102182031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_192_slots_128_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_192_slots_128_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.6327303987927735,
    "estimated_duration": 3600.0913809028243,
    "input_throughput": 5312.379041668619,
    "output_throughput": 4645.829572194257,
    "total_throughput": 9958.208613862877,
    "itl": 111.74690284947233,
    "ttft": 2088622.7734837576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.559002295364641,
    "arrivals": 743742,
    "finished_requests": 77474,
    "scheduler_time": 97.75606550023814
}
#Debug simulation 
Total elapsed time: 5.632824018131942. Arrivals time: 0.255654641892761 Scheduler time: 5.238961085677147 Scheduler overhead time: 0.04718415206298232 Adapter cache time: 0.0202086940407753 Engine time: 0.048405189998447895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_192_slots_128_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_192_slots_128_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.4632144989445806,
    "estimated_duration": 3600.0309658618485,
    "input_throughput": 5046.539647097355,
    "output_throughput": 4419.212265356531,
    "total_throughput": 9465.751912453885,
    "itl": 98.457185002956,
    "ttft": 2115270.6050397255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 369,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.688839860665615,
    "arrivals": 743742,
    "finished_requests": 73640,
    "scheduler_time": 98.40037551877258
}
#Debug simulation 
Total elapsed time: 5.463308107107878. Arrivals time: 0.2975857397541404 Scheduler time: 5.011810345109552 Scheduler overhead time: 0.05351116368547082 Adapter cache time: 0.021228769794106483 Engine time: 0.05396009609103203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_192_slots_128_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_192_slots_128_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.398425057996064,
    "estimated_duration": 3600.0802654848535,
    "input_throughput": 5047.752455472706,
    "output_throughput": 4420.073950172584,
    "total_throughput": 9467.82640564529,
    "itl": 98.48581413617158,
    "ttft": 2115240.7163329287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.521696159942072,
    "arrivals": 743742,
    "finished_requests": 73656,
    "scheduler_time": 98.40364256168796
}
#Debug simulation 
Total elapsed time: 5.398585131857544. Arrivals time: 0.2470403304323554 Scheduler time: 4.999702017288655 Scheduler overhead time: 0.05226724036037922 Adapter cache time: 0.021231770515441895 Engine time: 0.05346847977489233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_192_slots_128_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_192_slots_128_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 270, 270, 34560, 270, 66, 34560, 66, 270, 270, 66, 34560, 34560, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 66, 270, 270, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 34560, 34560, 66, 270, 34560, 66, 270, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 270, 66, 66, 66, 66, 66, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 66, 270, 270, 34560, 66, 66, 66, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 66, 34560, 270, 270, 270, 34560, 270, 66, 270, 34560, 34560, 270, 34560, 270, 66, 34560, 270, 66, 270, 270, 66, 270, 34560, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 270, 66, 34560, 34560, 270, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 2233344 . Total input tokens: 498197197 . Total output tokens: 438654740
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.376845718827099,
    "estimated_duration": 3600.027819578787,
    "input_throughput": 5047.889602732636,
    "output_throughput": 4420.138898221576,
    "total_throughput": 9468.028500954211,
    "itl": 98.48084086113188,
    "ttft": 2115252.3306979435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3620507480110877,
    "arrivals": 743742,
    "finished_requests": 73657,
    "scheduler_time": 98.40610610026683
}
#Debug simulation 
Total elapsed time: 5.376937325112522. Arrivals time: 0.24823349062353373 Scheduler time: 4.976673576049507 Scheduler overhead time: 0.052364750765264034 Adapter cache time: 0.021277355030179024 Engine time: 0.05348855908960104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.5895880297757685,
    "estimated_duration": 3600.0529445713896,
    "input_throughput": 5394.099003261177,
    "output_throughput": 4677.531763912666,
    "total_throughput": 10071.630767173843,
    "itl": 111.51919733256747,
    "ttft": 2086119.0675827707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6663270760513822,
    "arrivals": 743017,
    "finished_requests": 78523,
    "scheduler_time": 98.28361962329907
}
#Debug simulation 
Total elapsed time: 5.5896841627545655. Arrivals time: 0.25830909004434943 Scheduler time: 5.194784687831998 Scheduler overhead time: 0.04722986463457346 Adapter cache time: 0.018549556843936443 Engine time: 0.0484976046718657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.448541617020965,
    "estimated_duration": 3600.096581810354,
    "input_throughput": 5118.045469417525,
    "output_throughput": 4442.616923337454,
    "total_throughput": 9560.662392754979,
    "itl": 98.27188087550203,
    "ttft": 2112178.177682213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7939481280837224,
    "arrivals": 743017,
    "finished_requests": 74496,
    "scheduler_time": 98.86384577373471
}
#Debug simulation 
Total elapsed time: 5.44863359676674. Arrivals time: 0.24968944257125258 Scheduler time: 5.048014390282333 Scheduler overhead time: 0.05247537652030587 Adapter cache time: 0.02005576202645898 Engine time: 0.05349305039271712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.400344518944621,
    "estimated_duration": 3600.088999403863,
    "input_throughput": 5118.386518514198,
    "output_throughput": 4442.809331282789,
    "total_throughput": 9561.195849796986,
    "itl": 98.26944907572671,
    "ttft": 2112073.083556307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6801140082720645,
    "arrivals": 743017,
    "finished_requests": 74501,
    "scheduler_time": 98.86636249781574
}
#Debug simulation 
Total elapsed time: 5.400440637022257. Arrivals time: 0.2508103768341243 Scheduler time: 4.998419427312911 Scheduler overhead time: 0.05239782715216279 Adapter cache time: 0.02019931748509407 Engine time: 0.053652393631637096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 270, 270, 34560, 270, 33, 34560, 33, 270, 270, 33, 34560, 34560, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 33, 270, 270, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 34560, 34560, 33, 270, 34560, 33, 270, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 270, 33, 33, 33, 33, 33, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 33, 270, 270, 34560, 33, 33, 33, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 33, 34560, 270, 270, 270, 34560, 270, 33, 270, 34560, 34560, 270, 34560, 270, 33, 34560, 270, 33, 270, 270, 33, 270, 34560, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 270, 33, 34560, 34560, 270, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 270, 270, 270, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 2231232 . Total input tokens: 497728044 . Total output tokens: 438238833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.376049219630659,
    "estimated_duration": 3600.085719036438,
    "input_throughput": 5118.534234493734,
    "output_throughput": 4443.044485141078,
    "total_throughput": 9561.578719634812,
    "itl": 98.26704869524312,
    "ttft": 2112110.1313602957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.570444551380346,
    "arrivals": 743017,
    "finished_requests": 74503,
    "scheduler_time": 98.86872134380836
}
#Debug simulation 
Total elapsed time: 5.376141716726124. Arrivals time: 0.24832995887845755 Scheduler time: 4.975913650356233 Scheduler overhead time: 0.05249333614483476 Adapter cache time: 0.020004552323371172 Engine time: 0.05447256751358509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_192_slots_128_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_192_slots_128_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.660023455042392,
    "estimated_duration": 3600.0505618676316,
    "input_throughput": 5439.132774246844,
    "output_throughput": 4718.161511372833,
    "total_throughput": 10157.294285619677,
    "itl": 110.4803113560706,
    "ttft": 2082340.9716204214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.970497891521079,
    "arrivals": 740854,
    "finished_requests": 79281,
    "scheduler_time": 99.084050272624
}
#Debug simulation 
Total elapsed time: 5.6601170329377055. Arrivals time: 0.25928035797551274 Scheduler time: 5.266504490748048 Scheduler overhead time: 0.04762300988659263 Adapter cache time: 0.01559562236070633 Engine time: 0.048655430786311626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_192_slots_128_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_192_slots_128_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.4155132016167045,
    "estimated_duration": 3600.070135285984,
    "input_throughput": 5154.191530361944,
    "output_throughput": 4481.302972926225,
    "total_throughput": 9635.49450328817,
    "itl": 97.51078989669433,
    "ttft": 2110389.116014486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.068192353090274,
    "arrivals": 740854,
    "finished_requests": 75189,
    "scheduler_time": 99.583389084932
}
#Debug simulation 
Total elapsed time: 5.415608252864331. Arrivals time: 0.25047273514792323 Scheduler time: 5.017325778491795 Scheduler overhead time: 0.05250660236924887 Adapter cache time: 0.016476847231388092 Engine time: 0.05384275037795305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_192_slots_128_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_192_slots_128_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.445053874980658,
    "estimated_duration": 3600.0967790445816,
    "input_throughput": 5154.222549796131,
    "output_throughput": 4481.5009123953905,
    "total_throughput": 9635.723462191521,
    "itl": 97.50928853480475,
    "ttft": 2110299.3591167205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9349231396522353,
    "arrivals": 740854,
    "finished_requests": 75191,
    "scheduler_time": 99.58724148399509
}
#Debug simulation 
Total elapsed time: 5.4452072638086975. Arrivals time: 0.25007239263504744 Scheduler time: 5.0466235359199345 Scheduler overhead time: 0.052876509726047516 Adapter cache time: 0.01654309267178178 Engine time: 0.05382106686010957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_192_slots_128_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_192_slots_128_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 135, 135, 34560, 135, 66, 34560, 66, 135, 135, 66, 34560, 34560, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 66, 135, 135, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 34560, 34560, 66, 135, 34560, 66, 135, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 135, 66, 66, 66, 66, 66, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 66, 135, 135, 34560, 66, 66, 66, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 66, 34560, 135, 135, 135, 34560, 135, 66, 135, 34560, 34560, 135, 34560, 135, 66, 34560, 135, 66, 135, 135, 66, 135, 34560, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 135, 66, 34560, 34560, 135, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 2224704 . Total input tokens: 496278478 . Total output tokens: 436901577
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.408601647242904,
    "estimated_duration": 3600.070433942468,
    "input_throughput": 5154.451097691092,
    "output_throughput": 4481.730370572479,
    "total_throughput": 9636.18146826357,
    "itl": 97.5060183197099,
    "ttft": 2110227.2538329074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.800265705240884,
    "arrivals": 740854,
    "finished_requests": 75193,
    "scheduler_time": 99.58979629450742
}
#Debug simulation 
Total elapsed time: 5.408696969971061. Arrivals time: 0.25162208871915936 Scheduler time: 5.009279035497457 Scheduler overhead time: 0.052660043351352215 Adapter cache time: 0.016441069543361664 Engine time: 0.053668892942368984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.701376473996788,
    "estimated_duration": 3600.0615523129495,
    "input_throughput": 5412.101909058217,
    "output_throughput": 4734.483772659214,
    "total_throughput": 10146.58568171743,
    "itl": 110.06073846228396,
    "ttft": 2084803.9898552538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4811796231567842,
    "arrivals": 740135,
    "finished_requests": 78893,
    "scheduler_time": 99.4362257762158
}
#Debug simulation 
Total elapsed time: 5.701471334788948. Arrivals time: 0.2607198692858219 Scheduler time: 5.305426488630474 Scheduler overhead time: 0.04809622373431921 Adapter cache time: 0.015525764785706997 Engine time: 0.04890125896781683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.489040639251471,
    "estimated_duration": 3600.042846363362,
    "input_throughput": 5133.407514487874,
    "output_throughput": 4489.612954558887,
    "total_throughput": 9623.020469046762,
    "itl": 97.14184351641397,
    "ttft": 2112965.515029641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 217,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5879911062074843,
    "arrivals": 740135,
    "finished_requests": 74788,
    "scheduler_time": 99.86947503222947
}
#Debug simulation 
Total elapsed time: 5.489134204108268. Arrivals time: 0.295899101998657 Scheduler time: 5.042878639884293 Scheduler overhead time: 0.05307925445958972 Adapter cache time: 0.016826706938445568 Engine time: 0.05534311756491661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.449105110019445,
    "estimated_duration": 3600.0416718484094,
    "input_throughput": 5133.454744292244,
    "output_throughput": 4489.801361577298,
    "total_throughput": 9623.256105869543,
    "itl": 97.13967317046594,
    "ttft": 2112995.852550503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 217,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4824863122357035,
    "arrivals": 740135,
    "finished_requests": 74790,
    "scheduler_time": 99.87206642074256
}
#Debug simulation 
Total elapsed time: 5.449199077673256. Arrivals time: 0.25129922525957227 Scheduler time: 5.048725369852036 Scheduler overhead time: 0.053093817085027695 Adapter cache time: 0.016800079960376024 Engine time: 0.054278216790407896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 135, 135, 34560, 135, 33, 34560, 33, 135, 135, 33, 34560, 34560, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 33, 135, 135, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 34560, 34560, 33, 135, 34560, 33, 135, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 135, 33, 33, 33, 33, 33, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 33, 135, 135, 34560, 33, 33, 33, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 33, 34560, 135, 135, 135, 34560, 135, 33, 135, 34560, 34560, 135, 34560, 135, 33, 34560, 135, 33, 135, 135, 33, 135, 34560, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 135, 33, 34560, 34560, 135, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 135, 135, 135, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 2222592 . Total input tokens: 495800794 . Total output tokens: 436479780
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.4604858830571175,
    "estimated_duration": 3600.048399843169,
    "input_throughput": 5133.45403934155,
    "output_throughput": 4489.83324799304,
    "total_throughput": 9623.28728733459,
    "itl": 97.13766551018401,
    "ttft": 2112955.110712508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 217,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3853108441038016,
    "arrivals": 740135,
    "finished_requests": 74791,
    "scheduler_time": 99.87451610280363
}
#Debug simulation 
Total elapsed time: 5.460578691214323. Arrivals time: 0.2475157231092453 Scheduler time: 5.063615158665925 Scheduler overhead time: 0.05323922308161855 Adapter cache time: 0.016718375496566296 Engine time: 0.054307051468640566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_192_slots_128_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.781438805628568,
    "estimated_duration": 3600.0137593399268,
    "input_throughput": 5462.719676828623,
    "output_throughput": 4751.389062228547,
    "total_throughput": 10214.10873905717,
    "itl": 109.03179028135177,
    "ttft": 2076469.163467123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2563577160704866,
    "arrivals": 738702,
    "finished_requests": 79458,
    "scheduler_time": 99.97381359564369
}
#Debug simulation 
Total elapsed time: 5.781532612629235. Arrivals time: 0.30832364689558744 Scheduler time: 5.339238382410258 Scheduler overhead time: 0.048581575974822044 Adapter cache time: 0.012809415813535452 Engine time: 0.04959827195852995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_192_slots_128_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.487449173349887,
    "estimated_duration": 3600.0345068748957,
    "input_throughput": 5159.4749896227795,
    "output_throughput": 4486.856436835072,
    "total_throughput": 9646.331426457851,
    "itl": 95.63488185443516,
    "ttft": 2106393.692783983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3476118908030923,
    "arrivals": 738702,
    "finished_requests": 74994,
    "scheduler_time": 100.34281619735695
}
#Debug simulation 
Total elapsed time: 5.487542242277414. Arrivals time: 0.32677294174209237 Scheduler time: 5.013145091943443 Scheduler overhead time: 0.05351351574063301 Adapter cache time: 0.014122602995485067 Engine time: 0.05462285643443465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_192_slots_128_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.5300479689612985,
    "estimated_duration": 3600.000109589245,
    "input_throughput": 5159.122898504338,
    "output_throughput": 4486.587918977283,
    "total_throughput": 9645.71081748162,
    "itl": 95.60076991258565,
    "ttft": 2106602.3304006304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2601539694843797,
    "arrivals": 738702,
    "finished_requests": 74990,
    "scheduler_time": 100.34351488086276
}
#Debug simulation 
Total elapsed time: 5.5301860249601305. Arrivals time: 0.32533451821655035 Scheduler time: 5.056409903801978 Scheduler overhead time: 0.05378712946549058 Adapter cache time: 0.014282801654189825 Engine time: 0.05485366191715002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_192_slots_128_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 66, 66, 34560, 66, 33, 34560, 33, 66, 66, 33, 34560, 34560, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 33, 66, 66, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 34560, 34560, 33, 66, 34560, 33, 66, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 66, 33, 33, 33, 33, 33, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 33, 66, 66, 34560, 33, 33, 33, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 33, 34560, 66, 66, 66, 34560, 66, 33, 66, 34560, 34560, 66, 34560, 66, 33, 34560, 66, 33, 66, 66, 33, 66, 34560, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 66, 33, 34560, 34560, 66, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 66, 66, 66, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 2218176 . Total input tokens: 494805436 . Total output tokens: 435615501
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.473432227037847,
    "estimated_duration": 3600.026394184901,
    "input_throughput": 5159.085230597362,
    "output_throughput": 4486.555161398194,
    "total_throughput": 9645.640391995557,
    "itl": 95.5989938394214,
    "ttft": 2106587.476305942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1810253740055456,
    "arrivals": 738702,
    "finished_requests": 74990,
    "scheduler_time": 100.34604874279215
}
#Debug simulation 
Total elapsed time: 5.473527952097356. Arrivals time: 0.2503873500972986 Scheduler time: 5.074095266405493 Scheduler overhead time: 0.0537579832598567 Adapter cache time: 0.014468773733824492 Engine time: 0.05513379769399762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_192_slots_128_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_192_slots_128_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.479367423336953,
    "estimated_duration": 3600.0203765625683,
    "input_throughput": 3998.238480456511,
    "output_throughput": 3487.12498454988,
    "total_throughput": 7485.363465006391,
    "itl": 148.49423613391306,
    "ttft": 2225232.99622999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1610,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.645978541439675,
    "arrivals": 644931,
    "finished_requests": 58363,
    "scheduler_time": 73.40182487373484
}
#Debug simulation 
Total elapsed time: 5.479461203329265. Arrivals time: 0.2929521347396076 Scheduler time: 5.056807379703969 Scheduler overhead time: 0.03756628558039665 Adapter cache time: 0.037244596518576145 Engine time: 0.0374912042170763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_192_slots_128_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_192_slots_128_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.909186542965472,
    "estimated_duration": 3600.0851267851763,
    "input_throughput": 3774.481302928048,
    "output_throughput": 3291.991600927274,
    "total_throughput": 7066.472903855322,
    "itl": 131.41029053690102,
    "ttft": 2257909.54472209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.068482113289274,
    "arrivals": 644931,
    "finished_requests": 55074,
    "scheduler_time": 73.40045056776552
}
#Debug simulation 
Total elapsed time: 4.909275860060006. Arrivals time: 0.21573635702952743 Scheduler time: 4.539934613276273 Scheduler overhead time: 0.04114576429128647 Adapter cache time: 0.05201527010649443 Engine time: 0.04117002850398421 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_192_slots_128_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_192_slots_128_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.887991800904274,
    "estimated_duration": 3600.0540991965177,
    "input_throughput": 3775.8360361956275,
    "output_throughput": 3292.1146942333885,
    "total_throughput": 7067.950730429016,
    "itl": 131.29283496321284,
    "ttft": 2258050.116001454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.076423390563907,
    "arrivals": 644931,
    "finished_requests": 55095,
    "scheduler_time": 73.42062912958647
}
#Debug simulation 
Total elapsed time: 4.888086122926325. Arrivals time: 0.2814398044720292 Scheduler time: 4.453096458688378 Scheduler overhead time: 0.04131434438750148 Adapter cache time: 0.05163779156282544 Engine time: 0.04130529845133424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_192_slots_128_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_192_slots_128_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 8640, 4320, 8640, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 8640, 4320, 17280, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1935360 . Total input tokens: 431648218 . Total output tokens: 380123590
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.9136608289554715,
    "estimated_duration": 3600.1473416229283,
    "input_throughput": 3777.247903934342,
    "output_throughput": 3293.1527170928093,
    "total_throughput": 7070.400621027151,
    "itl": 131.25392703003155,
    "ttft": 2257872.416430639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.989446368460504,
    "arrivals": 644931,
    "finished_requests": 55113,
    "scheduler_time": 73.44428239102396
}
#Debug simulation 
Total elapsed time: 4.9137566331774. Arrivals time: 0.28214610600844026 Scheduler time: 4.477772069629282 Scheduler overhead time: 0.04145863838493824 Adapter cache time: 0.051789042074233294 Engine time: 0.0412983987480402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_192_slots_128_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_192_slots_128_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.7893003900535405,
    "estimated_duration": 3600.12269718164,
    "input_throughput": 3970.283015962119,
    "output_throughput": 3489.264132534706,
    "total_throughput": 7459.547148496825,
    "itl": 148.8947607910472,
    "ttft": 2207973.622221215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1798,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.889111439446303,
    "arrivals": 576087,
    "finished_requests": 58255,
    "scheduler_time": 73.3134637334829
}
#Debug simulation 
Total elapsed time: 4.789395319763571. Arrivals time: 0.27360254572704434 Scheduler time: 4.383916766848415 Scheduler overhead time: 0.03727756207808852 Adapter cache time: 0.040105162654072046 Engine time: 0.03717418573796749 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_192_slots_128_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_192_slots_128_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.716226532123983,
    "estimated_duration": 3600.0476422391466,
    "input_throughput": 3738.828853839338,
    "output_throughput": 3291.3353315041736,
    "total_throughput": 7030.164185343511,
    "itl": 131.6722217299544,
    "ttft": 2242088.8690016707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.72530812886966,
    "arrivals": 576087,
    "finished_requests": 54913,
    "scheduler_time": 73.29458515273119
}
#Debug simulation 
Total elapsed time: 4.716290427837521. Arrivals time: 0.5673962938599288 Scheduler time: 3.991678882855922 Scheduler overhead time: 0.04140882566571236 Adapter cache time: 0.05540239671245217 Engine time: 0.041230395901948214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_192_slots_128_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_192_slots_128_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.41064475197345,
    "estimated_duration": 3600.0145793312636,
    "input_throughput": 3747.4609345904546,
    "output_throughput": 3298.7371962826846,
    "total_throughput": 7046.198130873139,
    "itl": 132.25705076417904,
    "ttft": 2240337.2934365403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.96554471578023,
    "arrivals": 576087,
    "finished_requests": 55050,
    "scheduler_time": 73.3033520400207
}
#Debug simulation 
Total elapsed time: 4.410736868623644. Arrivals time: 0.264089526142925 Scheduler time: 3.9887367328628898 Scheduler overhead time: 0.040880363900214434 Adapter cache time: 0.05714887799695134 Engine time: 0.040807966608554125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_192_slots_128_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_192_slots_128_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 8640, 1080, 8640, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 8640, 1080, 17280, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 1080]
Prompts retrieved: 1728000 . Total input tokens: 385476951 . Total output tokens: 339395029
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.412315169814974,
    "estimated_duration": 3600.063189189024,
    "input_throughput": 3748.950863009799,
    "output_throughput": 3300.093186052186,
    "total_throughput": 7049.044049061985,
    "itl": 132.20903029605472,
    "ttft": 2240195.9089573147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.68118541771192,
    "arrivals": 576087,
    "finished_requests": 55073,
    "scheduler_time": 73.33052897526622
}
#Debug simulation 
Total elapsed time: 4.412407445721328. Arrivals time: 0.26634208764880896 Scheduler time: 3.987918745726347 Scheduler overhead time: 0.04091526661068201 Adapter cache time: 0.057014608290046453 Engine time: 0.0410756291821599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_192_slots_128_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_192_slots_128_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.550247926265001,
    "estimated_duration": 3600.0137718104784,
    "input_throughput": 4013.7860341387327,
    "output_throughput": 3484.2444487904977,
    "total_throughput": 7498.03048292923,
    "itl": 148.15336392727534,
    "ttft": 2208591.997683996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.731939858855027,
    "arrivals": 564621,
    "finished_requests": 58511,
    "scheduler_time": 73.32706828759918
}
#Debug simulation 
Total elapsed time: 4.5503445928916335. Arrivals time: 0.2742142206989229 Scheduler time: 4.1475126263685524 Scheduler overhead time: 0.03725770395249128 Adapter cache time: 0.03685759101063013 Engine time: 0.03714212030172348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_192_slots_128_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_192_slots_128_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.263021337799728,
    "estimated_duration": 3600.073047013093,
    "input_throughput": 3784.765426163989,
    "output_throughput": 3294.0464943729435,
    "total_throughput": 7078.811920536933,
    "itl": 131.44756355977833,
    "ttft": 2240763.073352027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.596704432628627,
    "arrivals": 564621,
    "finished_requests": 55236,
    "scheduler_time": 73.33074228830166
}
#Debug simulation 
Total elapsed time: 4.263116850052029. Arrivals time: 0.2624885612167418 Scheduler time: 3.8462724359706044 Scheduler overhead time: 0.04081722116097808 Adapter cache time: 0.05324765993282199 Engine time: 0.04115727823227644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_192_slots_128_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_192_slots_128_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.257449109107256,
    "estimated_duration": 3600.000800448854,
    "input_throughput": 3785.715269369042,
    "output_throughput": 3294.938434047307,
    "total_throughput": 7080.653703416349,
    "itl": 131.4039133818444,
    "ttft": 2240491.655720015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.430598815046608,
    "arrivals": 564621,
    "finished_requests": 55250,
    "scheduler_time": 73.35276467449481
}
#Debug simulation 
Total elapsed time: 4.257542746141553. Arrivals time: 0.26362913893535733 Scheduler time: 3.8400576282292604 Scheduler overhead time: 0.04081382090225816 Adapter cache time: 0.053027062211185694 Engine time: 0.040820085909217596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_192_slots_128_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_192_slots_128_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 8640, 8640, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 540, 8640, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 17280, 17280, 540, 8640, 17280, 540, 8640, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 8640, 540, 540, 540, 540, 540, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 540, 8640, 8640, 17280, 540, 540, 540, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 8640, 8640, 17280, 8640, 540, 8640, 17280, 17280, 8640, 17280, 8640, 540, 17280, 8640, 540, 8640, 8640, 540, 8640, 17280, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 8640, 540, 17280, 17280, 8640, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 17280, 8640, 540, 540]
Prompts retrieved: 1693440 . Total input tokens: 377775635 . Total output tokens: 332618947
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.300526406150311,
    "estimated_duration": 3600.127123521369,
    "input_throughput": 3786.796835847644,
    "output_throughput": 3296.1947155890657,
    "total_throughput": 7082.991551436709,
    "itl": 131.364895072714,
    "ttft": 2240270.161197473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.327794178310787,
    "arrivals": 564621,
    "finished_requests": 55269,
    "scheduler_time": 73.37753692079237
}
#Debug simulation 
Total elapsed time: 4.300670363008976. Arrivals time: 0.23862091964110732 Scheduler time: 3.908075504936278 Scheduler overhead time: 0.04088672762736678 Adapter cache time: 0.052882285322993994 Engine time: 0.04090726934373379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_192_slots_128_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_192_slots_128_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.418343060649931,
    "estimated_duration": 3600.007751890843,
    "input_throughput": 3993.733066949225,
    "output_throughput": 3492.8338677592014,
    "total_throughput": 7486.566934708426,
    "itl": 148.8958945924609,
    "ttft": 2200723.2603982473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.925225956957108,
    "arrivals": 558945,
    "finished_requests": 58439,
    "scheduler_time": 73.34932705021411
}
#Debug simulation 
Total elapsed time: 4.41843634378165. Arrivals time: 0.26556371711194515 Scheduler time: 4.02601534081623 Scheduler overhead time: 0.036918024998158216 Adapter cache time: 0.03571936395019293 Engine time: 0.03699543094262481 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_192_slots_128_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_192_slots_128_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.246012378018349,
    "estimated_duration": 3600.0965979348653,
    "input_throughput": 3798.3050254384875,
    "output_throughput": 3320.864225381628,
    "total_throughput": 7119.169250820115,
    "itl": 131.225494219322,
    "ttft": 2230854.826491762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.186991301188007,
    "arrivals": 558945,
    "finished_requests": 55603,
    "scheduler_time": 73.77856169222864
}
#Debug simulation 
Total elapsed time: 4.246103983838111. Arrivals time: 0.2642624881118536 Scheduler time: 3.830326712690294 Scheduler overhead time: 0.040259461384266615 Adapter cache time: 0.051288272719830275 Engine time: 0.04094006586819887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_192_slots_128_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_192_slots_128_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.287888925988227,
    "estimated_duration": 3600.0364240497524,
    "input_throughput": 3798.924341052999,
    "output_throughput": 3321.5780596320833,
    "total_throughput": 7120.502400685082,
    "itl": 131.19419290782542,
    "ttft": 2230525.8001829996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.270765458801966,
    "arrivals": 558945,
    "finished_requests": 55611,
    "scheduler_time": 73.79553305272252
}
#Debug simulation 
Total elapsed time: 4.287984488997608. Arrivals time: 0.20812488859519362 Scheduler time: 3.9282102449797094 Scheduler overhead time: 0.040489770937711 Adapter cache time: 0.0510338363237679 Engine time: 0.04105611192062497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_192_slots_128_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_192_slots_128_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 8640, 8640, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 270, 8640, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 17280, 17280, 270, 8640, 17280, 270, 8640, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 8640, 270, 270, 270, 270, 270, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 270, 8640, 8640, 17280, 270, 270, 270, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 8640, 8640, 17280, 8640, 270, 8640, 17280, 17280, 8640, 17280, 8640, 270, 17280, 8640, 270, 8640, 8640, 270, 8640, 17280, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 8640, 270, 17280, 17280, 8640, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 17280, 8640, 270, 270]
Prompts retrieved: 1676160 . Total input tokens: 373920213 . Total output tokens: 329192996
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.2576452530920506,
    "estimated_duration": 3600.0570946375724,
    "input_throughput": 3798.7753084168185,
    "output_throughput": 3321.2956588411353,
    "total_throughput": 7120.070967257954,
    "itl": 131.07702714229276,
    "ttft": 2230673.9279083214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1916,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.231592522133665,
    "arrivals": 558945,
    "finished_requests": 55609,
    "scheduler_time": 73.81262443798214
}
#Debug simulation 
Total elapsed time: 4.257735853083432. Arrivals time: 0.26317602302879095 Scheduler time: 3.8419661205261946 Scheduler overhead time: 0.04035782814025879 Adapter cache time: 0.05151255987584591 Engine time: 0.04167599370703101 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_192_slots_128_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_192_slots_128_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.324993648100644,
    "estimated_duration": 3600.119439369988,
    "input_throughput": 4045.2005121664865,
    "output_throughput": 3504.684556301275,
    "total_throughput": 7549.885068467761,
    "itl": 147.2506542559425,
    "ttft": 2193538.4677636726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.967952883499864,
    "arrivals": 556042,
    "finished_requests": 58709,
    "scheduler_time": 73.73238125031484
}
#Debug simulation 
Total elapsed time: 4.325138639193028. Arrivals time: 0.21791451144963503 Scheduler time: 3.9825547668151557 Scheduler overhead time: 0.03669664030894637 Adapter cache time: 0.03357022488489747 Engine time: 0.03719029389321804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_192_slots_128_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_192_slots_128_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.222278678789735,
    "estimated_duration": 3600.0522272342528,
    "input_throughput": 3863.902277519617,
    "output_throughput": 3346.5386720946767,
    "total_throughput": 7210.440949614294,
    "itl": 129.03474258273076,
    "ttft": 2220901.0501086307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.743885581372247,
    "arrivals": 556042,
    "finished_requests": 56053,
    "scheduler_time": 74.55724944140876
}
#Debug simulation 
Total elapsed time: 4.222371554002166. Arrivals time: 0.2096389653161168 Scheduler time: 3.8612307985313237 Scheduler overhead time: 0.04057551920413971 Adapter cache time: 0.050210718996822834 Engine time: 0.041482677683234215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_192_slots_128_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_192_slots_128_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.2131357728503644,
    "estimated_duration": 3600.051990269751,
    "input_throughput": 3864.2300271218082,
    "output_throughput": 3347.0191632141227,
    "total_throughput": 7211.249190335931,
    "itl": 129.0131078035448,
    "ttft": 2220893.403570818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.171938540367423,
    "arrivals": 556042,
    "finished_requests": 56062,
    "scheduler_time": 74.56861283097085
}
#Debug simulation 
Total elapsed time: 4.213229950983077. Arrivals time: 0.21187615767121315 Scheduler time: 3.8501998125575483 Scheduler overhead time: 0.04065687535330653 Adapter cache time: 0.049905224703252316 Engine time: 0.04134260676801205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_192_slots_128_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_192_slots_128_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 8640, 8640, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 135, 8640, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 17280, 17280, 135, 8640, 17280, 135, 8640, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 8640, 135, 135, 135, 135, 135, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 135, 8640, 8640, 17280, 135, 135, 135, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 8640, 8640, 17280, 8640, 135, 8640, 17280, 17280, 8640, 17280, 8640, 135, 17280, 8640, 135, 8640, 8640, 135, 8640, 17280, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 8640, 135, 17280, 17280, 8640, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 17280, 8640, 135, 135]
Prompts retrieved: 1667520 . Total input tokens: 372003301 . Total output tokens: 327509855
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.232728880830109,
    "estimated_duration": 3600.1301667505363,
    "input_throughput": 3867.7482077177524,
    "output_throughput": 3349.185568721549,
    "total_throughput": 7216.933776439301,
    "itl": 129.17734388606434,
    "ttft": 2220757.061921137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.535302297542833,
    "arrivals": 556042,
    "finished_requests": 56106,
    "scheduler_time": 74.56996606096912
}
#Debug simulation 
Total elapsed time: 4.232821245212108. Arrivals time: 0.20765423588454723 Scheduler time: 3.8737387689761817 Scheduler overhead time: 0.04081533616408706 Adapter cache time: 0.04996322002261877 Engine time: 0.04126400174573064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_192_slots_128_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_192_slots_128_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.353085265029222,
    "estimated_duration": 3600.058984600086,
    "input_throughput": 4027.9920584720226,
    "output_throughput": 3517.3682026231145,
    "total_throughput": 7545.360261095137,
    "itl": 147.39947749705837,
    "ttft": 2201125.8888674215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 832,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.501524314582458,
    "arrivals": 554638,
    "finished_requests": 58791,
    "scheduler_time": 73.94019009711238
}
#Debug simulation 
Total elapsed time: 4.353213866241276. Arrivals time: 0.2148474995046854 Scheduler time: 4.016615985427052 Scheduler overhead time: 0.03660407569259405 Adapter cache time: 0.030851349234580994 Engine time: 0.037057758308947086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_192_slots_128_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_192_slots_128_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.248803480062634,
    "estimated_duration": 3600.018008343947,
    "input_throughput": 3852.143230355493,
    "output_throughput": 3365.0609446736407,
    "total_throughput": 7217.204175029134,
    "itl": 129.34737409073597,
    "ttft": 2229301.274809285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.215673349373983,
    "arrivals": 554638,
    "finished_requests": 56245,
    "scheduler_time": 74.78500204542334
}
#Debug simulation 
Total elapsed time: 4.248940310906619. Arrivals time: 0.23522093007341027 Scheduler time: 3.8684545471332967 Scheduler overhead time: 0.040475180838257074 Adapter cache time: 0.044328886084258556 Engine time: 0.041193317621946335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_192_slots_128_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_192_slots_128_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.246466220822185,
    "estimated_duration": 3600.053198019635,
    "input_throughput": 3852.98250804469,
    "output_throughput": 3366.218034407475,
    "total_throughput": 7219.200542452165,
    "itl": 129.33699057092065,
    "ttft": 2229158.1183025995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.81447748808655,
    "arrivals": 554638,
    "finished_requests": 56258,
    "scheduler_time": 74.79349084437656
}
#Debug simulation 
Total elapsed time: 4.24655745504424. Arrivals time: 0.2219678768888116 Scheduler time: 3.879090182017535 Scheduler overhead time: 0.04064087010920048 Adapter cache time: 0.044172321911901236 Engine time: 0.041378915309906006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_192_slots_128_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_192_slots_128_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 8640, 8640, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 66, 8640, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 17280, 17280, 66, 8640, 17280, 66, 8640, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 8640, 66, 66, 66, 66, 66, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 66, 8640, 8640, 17280, 66, 66, 66, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 8640, 8640, 17280, 8640, 66, 8640, 17280, 17280, 8640, 17280, 8640, 66, 17280, 8640, 66, 8640, 8640, 66, 8640, 17280, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 8640, 66, 17280, 17280, 8640, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 17280, 8640, 66, 66]
Prompts retrieved: 1663104 . Total input tokens: 371012506 . Total output tokens: 326620308
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.21182964509353,
    "estimated_duration": 3600.050934142582,
    "input_throughput": 3848.733324463359,
    "output_throughput": 3361.810213633124,
    "total_throughput": 7210.543538096483,
    "itl": 129.03819111302963,
    "ttft": 2229126.179242436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.451868483247209,
    "arrivals": 554638,
    "finished_requests": 56193,
    "scheduler_time": 74.80863237418001
}
#Debug simulation 
Total elapsed time: 4.211924580391496. Arrivals time: 0.21010258933529258 Scheduler time: 3.855503766797483 Scheduler overhead time: 0.04046699404716492 Adapter cache time: 0.044971690978854895 Engine time: 0.041516062803566456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_192_slots_128_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_192_slots_128_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.372898472007364,
    "estimated_duration": 3600.0974566014966,
    "input_throughput": 4080.1506562176255,
    "output_throughput": 3534.787919883977,
    "total_throughput": 7614.938576101602,
    "itl": 146.65345826174658,
    "ttft": 2195496.4816064737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.995421291473351,
    "arrivals": 553841,
    "finished_requests": 59421,
    "scheduler_time": 74.25720779114803
}
#Debug simulation 
Total elapsed time: 4.372989370021969. Arrivals time: 0.21807296108454466 Scheduler time: 4.035751993302256 Scheduler overhead time: 0.0368189956061542 Adapter cache time: 0.028000612277537584 Engine time: 0.03711960278451443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_192_slots_128_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_192_slots_128_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.227138410788029,
    "estimated_duration": 3600.021662364435,
    "input_throughput": 3891.8518592463047,
    "output_throughput": 3377.2896777556102,
    "total_throughput": 7269.141537001915,
    "itl": 128.49213223466734,
    "ttft": 2221965.5545835793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4579985793354044,
    "arrivals": 553841,
    "finished_requests": 56687,
    "scheduler_time": 75.10580599175084
}
#Debug simulation 
Total elapsed time: 4.227230711840093. Arrivals time: 0.20786018669605255 Scheduler time: 3.876107911579311 Scheduler overhead time: 0.04061539750546217 Adapter cache time: 0.042031514924019575 Engine time: 0.041419862769544125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_192_slots_128_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_192_slots_128_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.235274597071111,
    "estimated_duration": 3600.080259922355,
    "input_throughput": 3891.9112876395116,
    "output_throughput": 3377.4627569726026,
    "total_throughput": 7269.374044612115,
    "itl": 128.48363539850132,
    "ttft": 2221904.0291666044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.220612792898896,
    "arrivals": 553841,
    "finished_requests": 56691,
    "scheduler_time": 75.11146530120013
}
#Debug simulation 
Total elapsed time: 4.235412600915879. Arrivals time: 0.21104187052696943 Scheduler time: 3.8802490290254354 Scheduler overhead time: 0.04070847202092409 Adapter cache time: 0.042322731111198664 Engine time: 0.041785167530179024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_192_slots_128_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_192_slots_128_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 8640, 8640, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 33, 8640, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 17280, 17280, 33, 8640, 17280, 33, 8640, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 8640, 33, 33, 33, 33, 33, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 33, 8640, 8640, 17280, 33, 33, 33, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 8640, 8640, 17280, 8640, 33, 8640, 17280, 17280, 8640, 17280, 8640, 33, 17280, 8640, 33, 8640, 8640, 33, 8640, 17280, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 8640, 33, 17280, 17280, 8640, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 17280, 8640, 33, 33]
Prompts retrieved: 1660992 . Total input tokens: 370536619 . Total output tokens: 326207799
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.246582554187626,
    "estimated_duration": 3600.0137525844875,
    "input_throughput": 3891.983187547886,
    "output_throughput": 3377.5251528611047,
    "total_throughput": 7269.50834040899,
    "itl": 128.47663376968083,
    "ttft": 2221815.7449097484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.006826763008708,
    "arrivals": 553841,
    "finished_requests": 56691,
    "scheduler_time": 75.11396514951237
}
#Debug simulation 
Total elapsed time: 4.246677905321121. Arrivals time: 0.21279041655361652 Scheduler time: 3.890017355326563 Scheduler overhead time: 0.04082722309976816 Adapter cache time: 0.042307799216359854 Engine time: 0.04145259130746126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_192_slots_128_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_192_slots_128_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 4320, 1080, 4320, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1451520 . Total input tokens: 323992672 . Total output tokens: 285102168
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.589901813771576,
    "estimated_duration": 3600.0211051800366,
    "input_throughput": 4021.81836633314,
    "output_throughput": 3486.786780760345,
    "total_throughput": 7508.605147093485,
    "itl": 149.32804733304107,
    "ttft": 2179558.59934414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.52949634369937,
    "arrivals": 484157,
    "finished_requests": 58812,
    "scheduler_time": 73.04167637184086
}
#Debug simulation 
Total elapsed time: 4.5899986657314. Arrivals time: 0.21635108022019267 Scheduler time: 4.228515747003257 Scheduler overhead time: 0.03725373325869441 Adapter cache time: 0.05352006712928414 Engine time: 0.03703106660395861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_192_slots_128_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_192_slots_128_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 4320, 1080, 4320, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1451520 . Total input tokens: 323992672 . Total output tokens: 285102168
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.3088762648403645,
    "estimated_duration": 3600.0973290680313,
    "input_throughput": 3785.889589692935,
    "output_throughput": 3289.604396074983,
    "total_throughput": 7075.493985767918,
    "itl": 132.39009599295832,
    "ttft": 2213029.6078524017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3860,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.2443682563483,
    "arrivals": 484157,
    "finished_requests": 55350,
    "scheduler_time": 72.95599662132268
}
#Debug simulation 
Total elapsed time: 4.308965124189854. Arrivals time: 0.2542860861867666 Scheduler time: 3.8761050794273615 Scheduler overhead time: 0.04080497892573476 Adapter cache time: 0.07690731668844819 Engine time: 0.04175045667216182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_192_slots_128_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_192_slots_128_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 4320, 1080, 4320, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1451520 . Total input tokens: 323992672 . Total output tokens: 285102168
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.612845044117421,
    "estimated_duration": 3600.076567033772,
    "input_throughput": 3788.0408224862267,
    "output_throughput": 3291.473050464385,
    "total_throughput": 7079.513872950612,
    "itl": 132.38658866765803,
    "ttft": 2212266.4350477527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.235650418699585,
    "arrivals": 484157,
    "finished_requests": 55386,
    "scheduler_time": 72.99581946003177
}
#Debug simulation 
Total elapsed time: 4.612911814358085. Arrivals time: 0.48699613520875573 Scheduler time: 3.949206795077771 Scheduler overhead time: 0.04089633235707879 Adapter cache time: 0.07571558561176062 Engine time: 0.04098215186968446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_192_slots_128_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_192_slots_128_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [64 64 64]
Adapter prompts. [17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 4320, 1080, 4320, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 4320, 1080, 17280, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 1080]
Prompts retrieved: 1451520 . Total input tokens: 323992672 . Total output tokens: 285102168
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.6089778752066195,
    "estimated_duration": 3600.08182539558,
    "input_throughput": 3789.462757141906,
    "output_throughput": 3292.5165523696246,
    "total_throughput": 7081.979309511531,
    "itl": 132.3224298769387,
    "ttft": 2211780.954150836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3852,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.590863463079867,
    "arrivals": 484157,
    "finished_requests": 55404,
    "scheduler_time": 73.03054517902231
}
#Debug simulation 
Total elapsed time: 4.6090421811677516. Arrivals time: 0.25941901933401823 Scheduler time: 4.173169327434152 Scheduler overhead time: 0.041016023606061935 Adapter cache time: 0.07530283508822322 Engine time: 0.041008979082107544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_192_slots_128_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_192_slots_128_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 4320, 4320, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 17280, 17280, 540, 4320, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 4320, 540, 540, 540, 540, 540, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 540, 4320, 4320, 17280, 540, 540, 540, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 4320, 540, 17280, 4320, 540, 4320, 4320, 540, 4320, 17280, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1416960 . Total input tokens: 316317584 . Total output tokens: 278283630
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.469887813087553,
    "estimated_duration": 3600.101009348773,
    "input_throughput": 4024.5254125858205,
    "output_throughput": 3487.7696396277865,
    "total_throughput": 7512.295052213607,
    "itl": 148.73374415396765,
    "ttft": 2182449.318328868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2843,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.79907887783346,
    "arrivals": 472692,
    "finished_requests": 58402,
    "scheduler_time": 73.10894032135809
}
#Debug simulation 
Total elapsed time: 4.469977956730872. Arrivals time: 0.25494176940992475 Scheduler time: 4.0648920512758195 Scheduler overhead time: 0.03710351465269923 Adapter cache time: 0.05840866873040795 Engine time: 0.03732128068804741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_192_slots_128_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_192_slots_128_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 4320, 4320, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 17280, 17280, 540, 4320, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 4320, 540, 540, 540, 540, 540, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 540, 4320, 4320, 17280, 540, 540, 540, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 4320, 540, 17280, 4320, 540, 4320, 4320, 540, 4320, 17280, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1416960 . Total input tokens: 316317584 . Total output tokens: 278283630
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.307201514951885,
    "estimated_duration": 3600.0138330493023,
    "input_throughput": 3848.880766178501,
    "output_throughput": 3339.6224452327956,
    "total_throughput": 7188.503211411296,
    "itl": 129.6199441702974,
    "ttft": 2212101.60468808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.03052650646715,
    "arrivals": 472692,
    "finished_requests": 55843,
    "scheduler_time": 74.1925339683041
}
#Debug simulation 
Total elapsed time: 4.307298086117953. Arrivals time: 0.20486132986843586 Scheduler time: 3.9225249802693725 Scheduler overhead time: 0.041062161326408386 Adapter cache time: 0.0774899092502892 Engine time: 0.041979867964982986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_192_slots_128_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_192_slots_128_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 4320, 4320, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 17280, 17280, 540, 4320, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 4320, 540, 540, 540, 540, 540, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 540, 4320, 4320, 17280, 540, 540, 540, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 4320, 540, 17280, 4320, 540, 4320, 4320, 540, 4320, 17280, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1416960 . Total input tokens: 316317584 . Total output tokens: 278283630
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.274265438783914,
    "estimated_duration": 3600.0536411708044,
    "input_throughput": 3854.627842569308,
    "output_throughput": 3344.052672527615,
    "total_throughput": 7198.680515096923,
    "itl": 129.95193671882618,
    "ttft": 2211463.149217437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.41604446987223,
    "arrivals": 472692,
    "finished_requests": 55929,
    "scheduler_time": 74.18981162958451
}
#Debug simulation 
Total elapsed time: 4.274361212737858. Arrivals time: 0.24984771059826016 Scheduler time: 3.847014858853072 Scheduler overhead time: 0.04062140500172973 Adapter cache time: 0.07636376330628991 Engine time: 0.04127204604446888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_192_slots_128_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_192_slots_128_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [64 64 64]
Adapter prompts. [17280, 540, 17280, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 4320, 4320, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 540, 4320, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 17280, 17280, 540, 4320, 17280, 540, 4320, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 17280, 4320, 540, 540, 540, 540, 540, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 540, 4320, 4320, 17280, 540, 540, 540, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 4320, 4320, 17280, 4320, 540, 4320, 17280, 17280, 4320, 17280, 4320, 540, 17280, 4320, 540, 4320, 4320, 540, 4320, 17280, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 4320, 540, 17280, 17280, 4320, 17280, 540, 17280, 17280, 17280, 540, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 17280, 4320, 540, 540]
Prompts retrieved: 1416960 . Total input tokens: 316317584 . Total output tokens: 278283630
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.60749665601179,
    "estimated_duration": 3600.115725073248,
    "input_throughput": 3855.4702292848083,
    "output_throughput": 3345.0460817492144,
    "total_throughput": 7200.516311034023,
    "itl": 129.90507081492987,
    "ttft": 2211034.128165718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.022251657300462,
    "arrivals": 472692,
    "finished_requests": 55945,
    "scheduler_time": 74.21884177041794
}
#Debug simulation 
Total elapsed time: 4.607590527739376. Arrivals time: 0.49233733862638474 Scheduler time: 3.9340755278244615 Scheduler overhead time: 0.04075679695233703 Adapter cache time: 0.07710289489477873 Engine time: 0.04404649930074811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_192_slots_128_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_192_slots_128_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 17280, 17280, 270, 4320, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 4320, 270, 270, 270, 270, 270, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 270, 4320, 4320, 17280, 270, 270, 270, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 4320, 270, 17280, 4320, 270, 4320, 4320, 270, 4320, 17280, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1399680 . Total input tokens: 312476132 . Total output tokens: 274914499
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.42737075407058,
    "estimated_duration": 3600.0960749690275,
    "input_throughput": 4104.357131671027,
    "output_throughput": 3545.237053183311,
    "total_throughput": 7649.594184854338,
    "itl": 146.45427007290377,
    "ttft": 2166858.531218478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.448113734811011,
    "arrivals": 466835,
    "finished_requests": 59612,
    "scheduler_time": 74.32296842834117
}
#Debug simulation 
Total elapsed time: 4.427515995223075. Arrivals time: 0.23549890471622348 Scheduler time: 4.046273165382445 Scheduler overhead time: 0.036792902275919914 Adapter cache time: 0.0542868091724813 Engine time: 0.03727000392973423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_192_slots_128_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_192_slots_128_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 17280, 17280, 270, 4320, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 4320, 270, 270, 270, 270, 270, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 270, 4320, 4320, 17280, 270, 270, 270, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 4320, 270, 17280, 4320, 270, 4320, 4320, 270, 4320, 17280, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1399680 . Total input tokens: 312476132 . Total output tokens: 274914499
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.303014493081719,
    "estimated_duration": 3600.0279763356875,
    "input_throughput": 3961.9164333599706,
    "output_throughput": 3421.169246727975,
    "total_throughput": 7383.085680087946,
    "itl": 127.02035266402564,
    "ttft": 2189232.766143252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2175,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.909054224830765,
    "arrivals": 466835,
    "finished_requests": 57472,
    "scheduler_time": 75.91280773398313
}
#Debug simulation 
Total elapsed time: 4.303128075785935. Arrivals time: 0.20882533583790064 Scheduler time: 3.923144971486181 Scheduler overhead time: 0.04147071111947298 Adapter cache time: 0.06728767231106758 Engine time: 0.04261019639670849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_192_slots_128_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_192_slots_128_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 17280, 17280, 270, 4320, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 4320, 270, 270, 270, 270, 270, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 270, 4320, 4320, 17280, 270, 270, 270, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 4320, 270, 17280, 4320, 270, 4320, 4320, 270, 4320, 17280, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1399680 . Total input tokens: 312476132 . Total output tokens: 274914499
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.333314017858356,
    "estimated_duration": 3600.008966994473,
    "input_throughput": 3963.2087394247606,
    "output_throughput": 3422.2553646264055,
    "total_throughput": 7385.464104051166,
    "itl": 126.9772891426631,
    "ttft": 2189069.6617743284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2176,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.82846112366796,
    "arrivals": 466835,
    "finished_requests": 57494,
    "scheduler_time": 75.9353512527844
}
#Debug simulation 
Total elapsed time: 4.333431403152645. Arrivals time: 0.20951191755011678 Scheduler time: 3.9522600350901484 Scheduler overhead time: 0.041642141062766314 Adapter cache time: 0.06731263408437371 Engine time: 0.042988169472664595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_192_slots_128_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_192_slots_128_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [64 64 64]
Adapter prompts. [17280, 270, 17280, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 270, 4320, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 17280, 17280, 270, 4320, 17280, 270, 4320, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 17280, 4320, 270, 270, 270, 270, 270, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 270, 4320, 4320, 17280, 270, 270, 270, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 4320, 17280, 17280, 4320, 17280, 4320, 270, 17280, 4320, 270, 4320, 4320, 270, 4320, 17280, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 4320, 270, 17280, 17280, 4320, 17280, 270, 17280, 17280, 17280, 270, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 17280, 4320, 270, 270]
Prompts retrieved: 1399680 . Total input tokens: 312476132 . Total output tokens: 274914499
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.348411886021495,
    "estimated_duration": 3600.1228697304264,
    "input_throughput": 3963.813879793647,
    "output_throughput": 3423.2506628094106,
    "total_throughput": 7387.064542603058,
    "itl": 126.94383103728305,
    "ttft": 2188857.8092225096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.897795887622797,
    "arrivals": 466835,
    "finished_requests": 57509,
    "scheduler_time": 75.95779876164048
}
#Debug simulation 
Total elapsed time: 4.348527377936989. Arrivals time: 0.20999288279563189 Scheduler time: 3.966990917455405 Scheduler overhead time: 0.0416700504720211 Adapter cache time: 0.06758837914094329 Engine time: 0.0426053898409009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_192_slots_128_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_192_slots_128_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 17280, 17280, 135, 4320, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 4320, 135, 135, 135, 135, 135, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 135, 4320, 4320, 17280, 135, 135, 135, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 4320, 135, 17280, 4320, 135, 4320, 4320, 135, 4320, 17280, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1391040 . Total input tokens: 310523549 . Total output tokens: 273206526
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.513747115619481,
    "estimated_duration": 3600.062500416266,
    "input_throughput": 4138.825644909539,
    "output_throughput": 3597.244769640135,
    "total_throughput": 7736.070414549674,
    "itl": 144.97939466518875,
    "ttft": 2165068.421259948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.389620825369146,
    "arrivals": 463927,
    "finished_requests": 60305,
    "scheduler_time": 75.28511987902654
}
#Debug simulation 
Total elapsed time: 4.513841555919498. Arrivals time: 0.25860618613660336 Scheduler time: 4.112263702787459 Scheduler overhead time: 0.037240848410874605 Adapter cache time: 0.05020304350182414 Engine time: 0.03805247973650694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_192_slots_128_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_192_slots_128_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 17280, 17280, 135, 4320, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 4320, 135, 135, 135, 135, 135, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 135, 4320, 4320, 17280, 135, 135, 135, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 4320, 135, 17280, 4320, 135, 4320, 4320, 135, 4320, 17280, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1391040 . Total input tokens: 310523549 . Total output tokens: 273206526
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.3986112480051816,
    "estimated_duration": 3600.000833510355,
    "input_throughput": 3982.0210224845123,
    "output_throughput": 3466.425308527392,
    "total_throughput": 7448.4463310119045,
    "itl": 125.57567862288357,
    "ttft": 2187186.815787215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.340668956963283,
    "arrivals": 463927,
    "finished_requests": 58015,
    "scheduler_time": 76.82157636640333
}
#Debug simulation 
Total elapsed time: 4.3987457868643105. Arrivals time: 0.21080222493037581 Scheduler time: 4.020609483122826 Scheduler overhead time: 0.04181974288076162 Adapter cache time: 0.06285749562084675 Engine time: 0.04284863546490669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_192_slots_128_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_192_slots_128_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 17280, 17280, 135, 4320, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 4320, 135, 135, 135, 135, 135, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 135, 4320, 4320, 17280, 135, 135, 135, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 4320, 135, 17280, 4320, 135, 4320, 4320, 135, 4320, 17280, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1391040 . Total input tokens: 310523549 . Total output tokens: 273206526
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.430774533189833,
    "estimated_duration": 3600.005777399237,
    "input_throughput": 3982.777774972978,
    "output_throughput": 3467.074991478775,
    "total_throughput": 7449.852766451753,
    "itl": 125.62533787303734,
    "ttft": 2186899.984471136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.634621665473167,
    "arrivals": 463927,
    "finished_requests": 58026,
    "scheduler_time": 76.82652669560301
}
#Debug simulation 
Total elapsed time: 4.430865147151053. Arrivals time: 0.23333400348201394 Scheduler time: 4.030053623020649 Scheduler overhead time: 0.04189124098047614 Adapter cache time: 0.06304551661014557 Engine time: 0.04273358080536127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_192_slots_128_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_192_slots_128_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 135, 4320, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 17280, 17280, 135, 4320, 17280, 135, 4320, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 4320, 135, 135, 135, 135, 135, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 135, 4320, 4320, 17280, 135, 135, 135, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 4320, 17280, 17280, 4320, 17280, 4320, 135, 17280, 4320, 135, 4320, 4320, 135, 4320, 17280, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 4320, 135, 17280, 17280, 4320, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 17280, 4320, 135, 135]
Prompts retrieved: 1391040 . Total input tokens: 310523549 . Total output tokens: 273206526
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.737016313243657,
    "estimated_duration": 3600.0167680629747,
    "input_throughput": 3981.747842722618,
    "output_throughput": 3466.2130217560466,
    "total_throughput": 7447.960864478664,
    "itl": 125.35604080198543,
    "ttft": 2187012.7816041834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.014096368085687,
    "arrivals": 463927,
    "finished_requests": 58012,
    "scheduler_time": 76.86553068810218
}
#Debug simulation 
Total elapsed time: 4.737080765888095. Arrivals time: 0.5514013287611306 Scheduler time: 4.016638571862131 Scheduler overhead time: 0.04208781709894538 Adapter cache time: 0.06391422636806965 Engine time: 0.043099446687847376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_192_slots_128_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_192_slots_128_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 17280, 17280, 66, 4320, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 4320, 66, 66, 66, 66, 66, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 66, 4320, 4320, 17280, 66, 66, 66, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 4320, 66, 17280, 4320, 66, 4320, 4320, 66, 4320, 17280, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1386624 . Total input tokens: 309542016 . Total output tokens: 272339745
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.533324770163745,
    "estimated_duration": 3600.1145621158316,
    "input_throughput": 4187.68756934767,
    "output_throughput": 3631.8910896867487,
    "total_throughput": 7819.57865903442,
    "itl": 142.76840662942752,
    "ttft": 2154398.679837068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.660222131349261,
    "arrivals": 462544,
    "finished_requests": 61002,
    "scheduler_time": 76.14210121451589
}
#Debug simulation 
Total elapsed time: 4.533414503093809. Arrivals time: 0.23572196904569864 Scheduler time: 4.156300417613238 Scheduler overhead time: 0.038543951231986284 Adapter cache time: 0.04640299687162042 Engine time: 0.038421147502958775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_192_slots_128_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_192_slots_128_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 17280, 17280, 66, 4320, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 4320, 66, 66, 66, 66, 66, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 66, 4320, 4320, 17280, 66, 66, 66, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 4320, 66, 17280, 4320, 66, 4320, 4320, 66, 4320, 17280, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1386624 . Total input tokens: 309542016 . Total output tokens: 272339745
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.41129399696365,
    "estimated_duration": 3600.0819928386245,
    "input_throughput": 4030.837083395972,
    "output_throughput": 3497.2611804523344,
    "total_throughput": 7528.0982638483065,
    "itl": 124.2188698663211,
    "ttft": 2179610.000094756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.101310478686362,
    "arrivals": 462544,
    "finished_requests": 58721,
    "scheduler_time": 77.52116999758933
}
#Debug simulation 
Total elapsed time: 4.411386663094163. Arrivals time: 0.20816947473213077 Scheduler time: 4.040112330578268 Scheduler overhead time: 0.04215735476464033 Adapter cache time: 0.05793301248922944 Engine time: 0.04309057584032416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_192_slots_128_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_192_slots_128_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 17280, 17280, 66, 4320, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 4320, 66, 66, 66, 66, 66, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 66, 4320, 4320, 17280, 66, 66, 66, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 4320, 66, 17280, 4320, 66, 4320, 4320, 66, 4320, 17280, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1386624 . Total input tokens: 309542016 . Total output tokens: 272339745
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.3997866925783455,
    "estimated_duration": 3600.1159504895313,
    "input_throughput": 4030.9996121171316,
    "output_throughput": 3497.444852654785,
    "total_throughput": 7528.4444647719165,
    "itl": 124.20476676714216,
    "ttft": 2179554.048343385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 838,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.716216085152691,
    "arrivals": 462544,
    "finished_requests": 58724,
    "scheduler_time": 77.52836342432488
}
#Debug simulation 
Total elapsed time: 4.399923231918365. Arrivals time: 0.20527399750426412 Scheduler time: 4.0301716211251915 Scheduler overhead time: 0.04211975168436766 Adapter cache time: 0.05895446287468076 Engine time: 0.04339425079524517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_192_slots_128_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_192_slots_128_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 66, 4320, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 17280, 17280, 66, 4320, 17280, 66, 4320, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 4320, 66, 66, 66, 66, 66, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 66, 4320, 4320, 17280, 66, 66, 66, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 4320, 17280, 17280, 4320, 17280, 4320, 66, 17280, 4320, 66, 4320, 4320, 66, 4320, 17280, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 4320, 66, 17280, 17280, 4320, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 17280, 4320, 66, 66]
Prompts retrieved: 1386624 . Total input tokens: 309542016 . Total output tokens: 272339745
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.383532105945051,
    "estimated_duration": 3600.040536694973,
    "input_throughput": 4031.6534916922697,
    "output_throughput": 3498.5014395317453,
    "total_throughput": 7530.154931224015,
    "itl": 124.19094324144085,
    "ttft": 2179520.7515773783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.362493590079222,
    "arrivals": 462544,
    "finished_requests": 58734,
    "scheduler_time": 77.53489153828919
}
#Debug simulation 
Total elapsed time: 4.383613028097898. Arrivals time: 0.20113902911543846 Scheduler time: 4.017890639603138 Scheduler overhead time: 0.0423561055213213 Adapter cache time: 0.058981580194085836 Engine time: 0.04327488876879215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_192_slots_128_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_192_slots_128_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 17280, 17280, 33, 4320, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 4320, 33, 33, 33, 33, 33, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 33, 4320, 4320, 17280, 33, 33, 33, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 4320, 33, 17280, 4320, 33, 4320, 4320, 33, 4320, 17280, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1384512 . Total input tokens: 309086144 . Total output tokens: 271925322
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.827513969037682,
    "estimated_duration": 3600.0646690147564,
    "input_throughput": 4178.899376304047,
    "output_throughput": 3635.169976983088,
    "total_throughput": 7814.069353287135,
    "itl": 142.5146869100449,
    "ttft": 2151261.522683247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.007119873361724,
    "arrivals": 461815,
    "finished_requests": 60945,
    "scheduler_time": 76.18890814299871
}
#Debug simulation 
Total elapsed time: 4.827600774820894. Arrivals time: 0.21304028760641813 Scheduler time: 4.476092337630689 Scheduler overhead time: 0.03763283742591739 Adapter cache time: 0.04465053929015994 Engine time: 0.03847292950376868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_192_slots_128_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_192_slots_128_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 17280, 17280, 33, 4320, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 4320, 33, 33, 33, 33, 33, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 33, 4320, 4320, 17280, 33, 33, 33, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 4320, 33, 17280, 4320, 33, 4320, 4320, 33, 4320, 17280, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1384512 . Total input tokens: 309086144 . Total output tokens: 271925322
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.425536007154733,
    "estimated_duration": 3600.074587713883,
    "input_throughput": 4015.968182809505,
    "output_throughput": 3499.191945353433,
    "total_throughput": 7515.160128162938,
    "itl": 123.89241357854128,
    "ttft": 2175395.518325131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2068816896481485,
    "arrivals": 461815,
    "finished_requests": 58608,
    "scheduler_time": 77.59995303546596
}
#Debug simulation 
Total elapsed time: 4.42563568521291. Arrivals time: 0.2384943561628461 Scheduler time: 4.023760750889778 Scheduler overhead time: 0.0424232566729188 Adapter cache time: 0.05751988058909774 Engine time: 0.043302244041115046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_192_slots_128_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_192_slots_128_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 33, 4320, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 17280, 17280, 33, 4320, 17280, 33, 4320, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 4320, 33, 33, 33, 33, 33, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 33, 4320, 4320, 17280, 33, 33, 33, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 4320, 17280, 17280, 4320, 17280, 4320, 33, 17280, 4320, 33, 4320, 4320, 33, 4320, 17280, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 4320, 33, 17280, 17280, 4320, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 17280, 4320, 33, 33]
Prompts retrieved: 1384512 . Total input tokens: 309086144 . Total output tokens: 271925322
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.422535659279674,
    "estimated_duration": 3600.0640491555373,
    "input_throughput": 4017.1279739848837,
    "output_throughput": 3500.110783572229,
    "total_throughput": 7517.238757557113,
    "itl": 123.95431236383806,
    "ttft": 2175237.443736865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9706007933802843,
    "arrivals": 461815,
    "finished_requests": 58620,
    "scheduler_time": 77.60025060651583
}
#Debug simulation 
Total elapsed time: 4.422614173032343. Arrivals time: 0.2363300621509552 Scheduler time: 4.012416357640177 Scheduler overhead time: 0.042284383438527584 Adapter cache time: 0.05676472093909979 Engine time: 0.054740119725465775 
