INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:53 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_192_slots_96_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_192_slots_96_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 540, 540, 17280, 540, 33, 17280, 33, 540, 540, 33, 17280, 17280, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 33, 540, 540, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 17280, 17280, 33, 540, 17280, 33, 540, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 540, 33, 33, 33, 33, 33, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 33, 540, 540, 17280, 33, 33, 33, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 33, 17280, 540, 540, 540, 17280, 540, 33, 540, 17280, 17280, 540, 17280, 540, 33, 17280, 540, 33, 540, 540, 33, 540, 17280, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 540, 33, 17280, 17280, 540, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 540, 540, 540, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 1142592 . Total input tokens: 255012711 . Total output tokens: 224437587
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.669762131990865,
    "estimated_duration": 3600.0901972326374,
    "input_throughput": 4439.328218022212,
    "output_throughput": 3875.6303969065207,
    "total_throughput": 8314.958614928733,
    "itl": 88.84636196714125,
    "ttft": 2087399.2237637804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.342621918655883,
    "arrivals": 381208,
    "finished_requests": 64492,
    "scheduler_time": 133.059117631871
}
#Debug simulation 
Total elapsed time: 4.669900913024321. Arrivals time: 0.2286859550513327 Scheduler time: 4.264556810026988 Scheduler overhead time: 0.055930964881554246 Adapter cache time: 0.037605646066367626 Engine time: 0.057247813092544675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_192_slots_96_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_192_slots_96_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 270, 270, 17280, 270, 135, 17280, 135, 270, 270, 135, 17280, 17280, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 135, 270, 270, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 17280, 17280, 135, 270, 17280, 135, 270, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 270, 135, 135, 135, 135, 135, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 135, 270, 270, 17280, 135, 135, 135, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 135, 17280, 270, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 270, 135, 17280, 270, 135, 270, 270, 135, 270, 17280, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 1131840 . Total input tokens: 252621056 . Total output tokens: 222300825
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.206340493867174,
    "estimated_duration": 3600.003320112909,
    "input_throughput": 5183.924385773813,
    "output_throughput": 4481.9591998303895,
    "total_throughput": 9665.883585604202,
    "itl": 122.4417084999923,
    "ttft": 1973552.49392812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.71515510411023,
    "arrivals": 377644,
    "finished_requests": 75179,
    "scheduler_time": 120.91164992653131
}
#Debug simulation 
Total elapsed time: 5.2064542719163. Arrivals time: 0.23820232599973679 Scheduler time: 4.836088358890265 Scheduler overhead time: 0.041791955940425396 Adapter cache time: 0.02781126508489251 Engine time: 0.04301084764301777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_192_slots_96_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_192_slots_96_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 270, 270, 17280, 270, 135, 17280, 135, 270, 270, 135, 17280, 17280, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 135, 270, 270, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 17280, 17280, 135, 270, 17280, 135, 270, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 270, 135, 135, 135, 135, 135, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 135, 270, 270, 17280, 135, 135, 135, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 135, 17280, 270, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 270, 135, 17280, 270, 135, 270, 270, 135, 270, 17280, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 1131840 . Total input tokens: 252621056 . Total output tokens: 222300825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.110915838042274,
    "estimated_duration": 3600.0433169632324,
    "input_throughput": 5027.660338061664,
    "output_throughput": 4350.536263327956,
    "total_throughput": 9378.19660138962,
    "itl": 111.01275314654511,
    "ttft": 1995987.564146553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.294225195902369,
    "arrivals": 377644,
    "finished_requests": 72979,
    "scheduler_time": 124.69229284458743
}
#Debug simulation 
Total elapsed time: 5.111009554937482. Arrivals time: 0.2447283286601305 Scheduler time: 4.723315965384245 Scheduler overhead time: 0.04558206186629832 Adapter cache time: 0.029055721359327435 Engine time: 0.046839236514642835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_192_slots_96_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_192_slots_96_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 270, 270, 17280, 270, 135, 17280, 135, 270, 270, 135, 17280, 17280, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 135, 270, 270, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 17280, 17280, 135, 270, 17280, 135, 270, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 270, 135, 135, 135, 135, 135, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 135, 270, 270, 17280, 135, 135, 135, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 135, 17280, 270, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 270, 135, 17280, 270, 135, 270, 270, 135, 270, 17280, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 1131840 . Total input tokens: 252621056 . Total output tokens: 222300825
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.724826766876504,
    "estimated_duration": 3600.0327528203325,
    "input_throughput": 4539.791752504551,
    "output_throughput": 3936.49668573092,
    "total_throughput": 8476.288438235471,
    "itl": 87.6344760570575,
    "ttft": 2064001.9087213322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.7140771949198,
    "arrivals": 377644,
    "finished_requests": 65977,
    "scheduler_time": 135.0364431895414
}
#Debug simulation 
Total elapsed time: 4.724945773836225. Arrivals time: 0.22674041939899325 Scheduler time: 4.328536812448874 Scheduler overhead time: 0.055115245981141925 Adapter cache time: 0.03208812000229955 Engine time: 0.05629199114628136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_192_slots_96_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_192_slots_96_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 270, 270, 17280, 270, 135, 17280, 135, 270, 270, 135, 17280, 17280, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 135, 270, 270, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 17280, 17280, 135, 270, 17280, 135, 270, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 270, 135, 135, 135, 135, 135, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 135, 270, 270, 17280, 135, 135, 135, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 135, 17280, 270, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 270, 135, 17280, 270, 135, 270, 270, 135, 270, 17280, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 1131840 . Total input tokens: 252621056 . Total output tokens: 222300825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.1262702501844615,
    "estimated_duration": 3600.0821586442075,
    "input_throughput": 5025.336979201973,
    "output_throughput": 4348.817696398377,
    "total_throughput": 9374.15467560035,
    "itl": 110.82269023286193,
    "ttft": 1996179.065632287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.675078641804888,
    "arrivals": 377644,
    "finished_requests": 72951,
    "scheduler_time": 124.7771430690447
}
#Debug simulation 
Total elapsed time: 5.126388209173456. Arrivals time: 0.2381782536394894 Scheduler time: 4.744386243866757 Scheduler overhead time: 0.04586891457438469 Adapter cache time: 0.029063025722280145 Engine time: 0.04722819663584232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_192_slots_96_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_192_slots_96_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 270, 270, 17280, 270, 135, 17280, 135, 270, 270, 135, 17280, 17280, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 135, 270, 270, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 17280, 17280, 135, 270, 17280, 135, 270, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 270, 135, 135, 135, 135, 135, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 135, 270, 270, 17280, 135, 135, 135, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 135, 17280, 270, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 270, 135, 17280, 270, 135, 270, 270, 135, 270, 17280, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 1131840 . Total input tokens: 252621056 . Total output tokens: 222300825
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.702619252027944,
    "estimated_duration": 3600.025973436185,
    "input_throughput": 4539.344749338565,
    "output_throughput": 3936.009935638087,
    "total_throughput": 8475.354684976652,
    "itl": 87.60618336008983,
    "ttft": 2064184.7968080493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.646761119491414,
    "arrivals": 377644,
    "finished_requests": 65967,
    "scheduler_time": 135.05664364351676
}
#Debug simulation 
Total elapsed time: 4.702710509998724. Arrivals time: 0.21916905720718205 Scheduler time: 4.315144354477525 Scheduler overhead time: 0.054668309865519404 Adapter cache time: 0.03174224868416786 Engine time: 0.05621331697329879 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_192_slots_96_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_192_slots_96_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 270, 270, 17280, 270, 135, 17280, 135, 270, 270, 135, 17280, 17280, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 135, 270, 270, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 17280, 17280, 135, 270, 17280, 135, 270, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 270, 135, 135, 135, 135, 135, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 135, 270, 270, 17280, 135, 135, 135, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 135, 17280, 270, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 270, 135, 17280, 270, 135, 270, 270, 135, 270, 17280, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 1131840 . Total input tokens: 252621056 . Total output tokens: 222300825
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.117218230152503,
    "estimated_duration": 3600.028600955428,
    "input_throughput": 5029.426709330794,
    "output_throughput": 4352.047090915315,
    "total_throughput": 9381.473800246109,
    "itl": 110.97382111003445,
    "ttft": 1995839.93060035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.139499199227407,
    "arrivals": 377644,
    "finished_requests": 73002,
    "scheduler_time": 124.73050299646549
}
#Debug simulation 
Total elapsed time: 5.117341689998284. Arrivals time: 0.2536695678718388 Scheduler time: 4.721724336734042 Scheduler overhead time: 0.045482116751372814 Adapter cache time: 0.02856738236732781 Engine time: 0.04654573230072856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_192_slots_96_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_192_slots_96_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [64 64 64]
Adapter prompts. [17280, 135, 17280, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 270, 270, 17280, 270, 135, 17280, 135, 270, 270, 135, 17280, 17280, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 135, 270, 270, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 17280, 17280, 135, 270, 17280, 135, 270, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 17280, 270, 135, 135, 135, 135, 135, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 135, 270, 270, 17280, 135, 135, 135, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 135, 17280, 270, 270, 270, 17280, 270, 135, 270, 17280, 17280, 270, 17280, 270, 135, 17280, 270, 135, 270, 270, 135, 270, 17280, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 270, 135, 17280, 17280, 270, 17280, 135, 17280, 17280, 17280, 135, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 1131840 . Total input tokens: 252621056 . Total output tokens: 222300825
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.7088559051044285,
    "estimated_duration": 3600.0334234697716,
    "input_throughput": 4541.478668895831,
    "output_throughput": 3938.2273252161226,
    "total_throughput": 8479.705994111953,
    "itl": 87.71171440557518,
    "ttft": 2063687.4552641292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1167,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.586901262421161,
    "arrivals": 377644,
    "finished_requests": 66005,
    "scheduler_time": 134.9998384157897
}
#Debug simulation 
Total elapsed time: 4.708990103099495. Arrivals time: 0.22071616631001234 Scheduler time: 4.3191512839403 Scheduler overhead time: 0.05463610985316336 Adapter cache time: 0.03181648883037269 Engine time: 0.05684380233287811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_192_slots_96_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_192_slots_96_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 270, 270, 17280, 270, 66, 17280, 66, 270, 270, 66, 17280, 17280, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 66, 270, 270, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 17280, 17280, 66, 270, 17280, 66, 270, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 270, 66, 66, 66, 66, 66, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 66, 270, 270, 17280, 66, 66, 66, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 66, 17280, 270, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 270, 66, 17280, 270, 66, 270, 270, 66, 270, 17280, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 1127424 . Total input tokens: 251622175 . Total output tokens: 221426589
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.2611141318921,
    "estimated_duration": 3600.1186113573635,
    "input_throughput": 5264.856257848037,
    "output_throughput": 4533.043702648178,
    "total_throughput": 9797.899960496215,
    "itl": 121.23182366774608,
    "ttft": 1966536.0560710363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1057,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.989316346771242,
    "arrivals": 376253,
    "finished_requests": 76388,
    "scheduler_time": 122.19105792662639
}
#Debug simulation 
Total elapsed time: 5.261205427814275. Arrivals time: 0.25952055724337697 Scheduler time: 4.871156369103119 Scheduler overhead time: 0.04215377080254257 Adapter cache time: 0.025520210154354572 Engine time: 0.04311758489347994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_192_slots_96_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_192_slots_96_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 270, 270, 17280, 270, 66, 17280, 66, 270, 270, 66, 17280, 17280, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 66, 270, 270, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 17280, 17280, 66, 270, 17280, 66, 270, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 270, 66, 66, 66, 66, 66, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 66, 270, 270, 17280, 66, 66, 66, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 66, 17280, 270, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 270, 66, 17280, 270, 66, 270, 270, 66, 270, 17280, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 1127424 . Total input tokens: 251622175 . Total output tokens: 221426589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.141693616984412,
    "estimated_duration": 3600.077310673198,
    "input_throughput": 5098.94605473553,
    "output_throughput": 4393.165378174206,
    "total_throughput": 9492.111432909736,
    "itl": 110.14088462285802,
    "ttft": 1988120.826471183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1026,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.48972848395818,
    "arrivals": 376253,
    "finished_requests": 74028,
    "scheduler_time": 125.78997384825617
}
#Debug simulation 
Total elapsed time: 5.141784748993814. Arrivals time: 0.2409278505947441 Scheduler time: 4.759805412264541 Scheduler overhead time: 0.04590179957449436 Adapter cache time: 0.026410171994939446 Engine time: 0.04711890150792897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_192_slots_96_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_192_slots_96_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 270, 270, 17280, 270, 66, 17280, 66, 270, 270, 66, 17280, 17280, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 66, 270, 270, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 17280, 17280, 66, 270, 17280, 66, 270, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 270, 66, 66, 66, 66, 66, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 66, 270, 270, 17280, 66, 66, 66, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 66, 17280, 270, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 270, 66, 17280, 270, 66, 270, 270, 66, 270, 17280, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 1127424 . Total input tokens: 251622175 . Total output tokens: 221426589
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.726461717858911,
    "estimated_duration": 3600.024084983687,
    "input_throughput": 4603.780866114706,
    "output_throughput": 3966.2573535434285,
    "total_throughput": 8570.038219658134,
    "itl": 87.18592831545303,
    "ttft": 2057856.682385931,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 935,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.999184138923904,
    "arrivals": 376253,
    "finished_requests": 66794,
    "scheduler_time": 135.79282349910082
}
#Debug simulation 
Total elapsed time: 4.726552108069882. Arrivals time: 0.22420452837832272 Scheduler time: 4.334982203552499 Scheduler overhead time: 0.05509731126949191 Adapter cache time: 0.030029096640646458 Engine time: 0.05625253915786743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_192_slots_96_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_192_slots_96_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 270, 270, 17280, 270, 66, 17280, 66, 270, 270, 66, 17280, 17280, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 66, 270, 270, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 17280, 17280, 66, 270, 17280, 66, 270, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 270, 66, 66, 66, 66, 66, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 66, 270, 270, 17280, 66, 66, 66, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 66, 17280, 270, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 270, 66, 17280, 270, 66, 270, 270, 66, 270, 17280, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 1127424 . Total input tokens: 251622175 . Total output tokens: 221426589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.150159556884319,
    "estimated_duration": 3600.1129265815566,
    "input_throughput": 5097.948418364489,
    "output_throughput": 4392.141947340048,
    "total_throughput": 9490.090365704538,
    "itl": 110.02440632073301,
    "ttft": 1987953.4147158044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1025,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.990526117491523,
    "arrivals": 376253,
    "finished_requests": 74007,
    "scheduler_time": 125.84504012073826
}
#Debug simulation 
Total elapsed time: 5.150253790896386. Arrivals time: 0.24028245802037418 Scheduler time: 4.769550142576918 Scheduler overhead time: 0.045715016312897205 Adapter cache time: 0.026327349711209536 Engine time: 0.046905075665563345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_192_slots_96_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_192_slots_96_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 270, 270, 17280, 270, 66, 17280, 66, 270, 270, 66, 17280, 17280, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 66, 270, 270, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 17280, 17280, 66, 270, 17280, 66, 270, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 270, 66, 66, 66, 66, 66, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 66, 270, 270, 17280, 66, 66, 66, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 66, 17280, 270, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 270, 66, 17280, 270, 66, 270, 270, 66, 270, 17280, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 1127424 . Total input tokens: 251622175 . Total output tokens: 221426589
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.742948904866353,
    "estimated_duration": 3600.05449680027,
    "input_throughput": 4604.291689120953,
    "output_throughput": 3966.3899567885364,
    "total_throughput": 8570.68164590949,
    "itl": 87.18523137022748,
    "ttft": 2057708.736637154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 933,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.915097558246947,
    "arrivals": 376253,
    "finished_requests": 66798,
    "scheduler_time": 135.79824940084754
}
#Debug simulation 
Total elapsed time: 4.743042923975736. Arrivals time: 0.22715545492246747 Scheduler time: 4.347310832701623 Scheduler overhead time: 0.05522792343981564 Adapter cache time: 0.02994588017463684 Engine time: 0.05729539063759148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_192_slots_96_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_192_slots_96_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 270, 270, 17280, 270, 66, 17280, 66, 270, 270, 66, 17280, 17280, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 66, 270, 270, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 17280, 17280, 66, 270, 17280, 66, 270, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 270, 66, 66, 66, 66, 66, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 66, 270, 270, 17280, 66, 66, 66, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 66, 17280, 270, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 270, 66, 17280, 270, 66, 270, 270, 66, 270, 17280, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 1127424 . Total input tokens: 251622175 . Total output tokens: 221426589
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.13755813613534,
    "estimated_duration": 3600.029661758358,
    "input_throughput": 5098.919376968209,
    "output_throughput": 4393.135747741393,
    "total_throughput": 9492.055124709603,
    "itl": 110.02231288190994,
    "ttft": 1987908.4143422344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1026,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.549902885025334,
    "arrivals": 376253,
    "finished_requests": 74024,
    "scheduler_time": 125.85357000492475
}
#Debug simulation 
Total elapsed time: 5.1376497119199485. Arrivals time: 0.24140387447550893 Scheduler time: 4.755405559437349 Scheduler overhead time: 0.04583596484735608 Adapter cache time: 0.0262966041918844 Engine time: 0.047213357873260975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_192_slots_96_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_192_slots_96_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 270, 270, 17280, 270, 66, 17280, 66, 270, 270, 66, 17280, 17280, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 66, 270, 270, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 17280, 17280, 66, 270, 17280, 66, 270, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 270, 66, 66, 66, 66, 66, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 66, 270, 270, 17280, 66, 66, 66, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 66, 17280, 270, 270, 270, 17280, 270, 66, 270, 17280, 17280, 270, 17280, 270, 66, 17280, 270, 66, 270, 270, 66, 270, 17280, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 270, 66, 17280, 17280, 270, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 1127424 . Total input tokens: 251622175 . Total output tokens: 221426589
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.768625954166055,
    "estimated_duration": 3600.0798773087586,
    "input_throughput": 4603.990068239944,
    "output_throughput": 3966.3100505076286,
    "total_throughput": 8570.300118747573,
    "itl": 87.18590862666696,
    "ttft": 2057743.2636018149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 933,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.858192203659586,
    "arrivals": 376253,
    "finished_requests": 66797,
    "scheduler_time": 135.79779488956245
}
#Debug simulation 
Total elapsed time: 4.768723331158981. Arrivals time: 0.22648115921765566 Scheduler time: 4.373557876097038 Scheduler overhead time: 0.05529890093021095 Adapter cache time: 0.030503721442073584 Engine time: 0.05672769411467016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_192_slots_96_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_192_slots_96_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 270, 270, 17280, 270, 33, 17280, 33, 270, 270, 33, 17280, 17280, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 33, 270, 270, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 17280, 17280, 33, 270, 17280, 33, 270, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 270, 33, 33, 33, 33, 33, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 33, 270, 270, 17280, 33, 33, 33, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 33, 17280, 270, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 270, 33, 17280, 270, 33, 270, 270, 33, 270, 17280, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 1125312 . Total input tokens: 251148876 . Total output tokens: 221006149
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.355898794019595,
    "estimated_duration": 3600.0270741685017,
    "input_throughput": 5255.613252400341,
    "output_throughput": 4566.75454414388,
    "total_throughput": 9822.36779654422,
    "itl": 120.13281008389461,
    "ttft": 1969267.2075766856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 937,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.1958272629372235,
    "arrivals": 375490,
    "finished_requests": 76466,
    "scheduler_time": 123.08397638323714
}
#Debug simulation 
Total elapsed time: 5.356060921913013. Arrivals time: 0.2496144170872867 Scheduler time: 4.975415525725111 Scheduler overhead time: 0.04282533144578338 Adapter cache time: 0.02365725999698043 Engine time: 0.044241143856197596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_192_slots_96_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_192_slots_96_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 270, 270, 17280, 270, 33, 17280, 33, 270, 270, 33, 17280, 17280, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 33, 270, 270, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 17280, 17280, 33, 270, 17280, 33, 270, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 270, 33, 33, 33, 33, 33, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 33, 270, 270, 17280, 33, 33, 33, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 33, 17280, 270, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 270, 33, 17280, 270, 33, 270, 270, 33, 270, 17280, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 1125312 . Total input tokens: 251148876 . Total output tokens: 221006149
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.2092467420734465,
    "estimated_duration": 3600.051418823508,
    "input_throughput": 5075.77305825582,
    "output_throughput": 4414.983885200782,
    "total_throughput": 9490.756943456603,
    "itl": 108.95229788970198,
    "ttft": 1991043.3768034596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.618427030239262,
    "arrivals": 375490,
    "finished_requests": 73811,
    "scheduler_time": 126.73729635554953
}
#Debug simulation 
Total elapsed time: 5.209362706169486. Arrivals time: 0.2409814482089132 Scheduler time: 4.8254226595163345 Scheduler overhead time: 0.048094822093844414 Adapter cache time: 0.025158839533105493 Engine time: 0.04763930686749518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_192_slots_96_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_192_slots_96_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 270, 270, 17280, 270, 33, 17280, 33, 270, 270, 33, 17280, 17280, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 33, 270, 270, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 17280, 17280, 33, 270, 17280, 33, 270, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 270, 33, 33, 33, 33, 33, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 33, 270, 270, 17280, 33, 33, 33, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 33, 17280, 270, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 270, 33, 17280, 270, 33, 270, 270, 33, 270, 17280, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 1125312 . Total input tokens: 251148876 . Total output tokens: 221006149
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.791873371927068,
    "estimated_duration": 3600.059513295578,
    "input_throughput": 4566.788115385846,
    "output_throughput": 3980.2228121731423,
    "total_throughput": 8547.010927558988,
    "itl": 86.35270280201999,
    "ttft": 2063475.4094105319,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 832,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.240827256403892,
    "arrivals": 375490,
    "finished_requests": 66458,
    "scheduler_time": 136.69115644389893
}
#Debug simulation 
Total elapsed time: 4.791965656913817. Arrivals time: 0.2260286258533597 Scheduler time: 4.39853492192924 Scheduler overhead time: 0.055941454134881496 Adapter cache time: 0.027746356558054686 Engine time: 0.05716622923500836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_192_slots_96_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_192_slots_96_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 270, 270, 17280, 270, 33, 17280, 33, 270, 270, 33, 17280, 17280, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 33, 270, 270, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 17280, 17280, 33, 270, 17280, 33, 270, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 270, 33, 33, 33, 33, 33, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 33, 270, 270, 17280, 33, 33, 33, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 33, 17280, 270, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 270, 33, 17280, 270, 33, 270, 270, 33, 270, 17280, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 1125312 . Total input tokens: 251148876 . Total output tokens: 221006149
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.188243014039472,
    "estimated_duration": 3600.0497248156926,
    "input_throughput": 5078.827348957261,
    "output_throughput": 4417.332874704709,
    "total_throughput": 9496.16022366197,
    "itl": 109.03615963317233,
    "ttft": 1990892.9389688468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.186690307538945,
    "arrivals": 375490,
    "finished_requests": 73856,
    "scheduler_time": 126.71613764075268
}
#Debug simulation 
Total elapsed time: 5.188364317873493. Arrivals time: 0.27324006194248796 Scheduler time: 4.775056675774977 Scheduler overhead time: 0.04607220506295562 Adapter cache time: 0.024974202271550894 Engine time: 0.04721728106960654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_192_slots_96_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_192_slots_96_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 270, 270, 17280, 270, 33, 17280, 33, 270, 270, 33, 17280, 17280, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 33, 270, 270, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 17280, 17280, 33, 270, 17280, 33, 270, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 270, 33, 33, 33, 33, 33, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 33, 270, 270, 17280, 33, 33, 33, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 33, 17280, 270, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 270, 33, 17280, 270, 33, 270, 270, 33, 270, 17280, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 1125312 . Total input tokens: 251148876 . Total output tokens: 221006149
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.798038083827123,
    "estimated_duration": 3600.055128398884,
    "input_throughput": 4567.158116634883,
    "output_throughput": 3980.360991408768,
    "total_throughput": 8547.51910804365,
    "itl": 86.3484334415821,
    "ttft": 2063455.7406448708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 832,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.1815917438920875,
    "arrivals": 375490,
    "finished_requests": 66463,
    "scheduler_time": 136.69370628181593
}
#Debug simulation 
Total elapsed time: 4.798158323857933. Arrivals time: 0.2574584784451872 Scheduler time: 4.37400989793241 Scheduler overhead time: 0.055484841112047434 Adapter cache time: 0.02767352433875203 Engine time: 0.057104993145912886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_192_slots_96_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_192_slots_96_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 270, 270, 17280, 270, 33, 17280, 33, 270, 270, 33, 17280, 17280, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 33, 270, 270, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 17280, 17280, 33, 270, 17280, 33, 270, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 270, 33, 33, 33, 33, 33, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 33, 270, 270, 17280, 33, 33, 33, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 33, 17280, 270, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 270, 33, 17280, 270, 33, 270, 270, 33, 270, 17280, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 1125312 . Total input tokens: 251148876 . Total output tokens: 221006149
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.2061827960424125,
    "estimated_duration": 3600.03728679887,
    "input_throughput": 5079.355724190201,
    "output_throughput": 4418.338681748399,
    "total_throughput": 9497.694405938599,
    "itl": 109.03003764400113,
    "ttft": 1990808.8091471978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.802984134978586,
    "arrivals": 375490,
    "finished_requests": 73868,
    "scheduler_time": 126.7265967716803
}
#Debug simulation 
Total elapsed time: 5.206301925936714. Arrivals time: 0.2729909874033183 Scheduler time: 4.792639818741009 Scheduler overhead time: 0.046173813519999385 Adapter cache time: 0.025053418474271894 Engine time: 0.04765576054342091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_192_slots_96_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_192_slots_96_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 270, 270, 17280, 270, 33, 17280, 33, 270, 270, 33, 17280, 17280, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 33, 270, 270, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 17280, 17280, 33, 270, 17280, 33, 270, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 270, 33, 33, 33, 33, 33, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 33, 270, 270, 17280, 33, 33, 33, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 33, 17280, 270, 270, 270, 17280, 270, 33, 270, 17280, 17280, 270, 17280, 270, 33, 17280, 270, 33, 270, 270, 33, 270, 17280, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 270, 33, 17280, 17280, 270, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 270, 270, 270, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 1125312 . Total input tokens: 251148876 . Total output tokens: 221006149
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.781388793839142,
    "estimated_duration": 3600.0261919047853,
    "input_throughput": 4566.830385003718,
    "output_throughput": 3980.259652616155,
    "total_throughput": 8547.090037619873,
    "itl": 86.35301797966369,
    "ttft": 2063557.4283497513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.1422364873066835,
    "arrivals": 375490,
    "finished_requests": 66458,
    "scheduler_time": 136.68984811640783
}
#Debug simulation 
Total elapsed time: 4.7814806250389665. Arrivals time: 0.22255460964515805 Scheduler time: 4.390704112127423 Scheduler overhead time: 0.05715793720446527 Adapter cache time: 0.02764543704688549 Engine time: 0.05714571080170572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 135, 135, 17280, 135, 66, 17280, 66, 135, 135, 66, 17280, 17280, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 66, 135, 135, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 17280, 17280, 66, 135, 17280, 66, 135, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 135, 66, 66, 66, 66, 66, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 66, 135, 135, 17280, 66, 66, 66, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 66, 17280, 135, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 135, 66, 17280, 135, 66, 135, 135, 66, 135, 17280, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 1118784 . Total input tokens: 249696988 . Total output tokens: 219712035
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.444766020169482,
    "estimated_duration": 3600.008865274333,
    "input_throughput": 5328.290767566838,
    "output_throughput": 4634.92497503294,
    "total_throughput": 9963.21574259978,
    "itl": 118.250536711499,
    "ttft": 1956561.8338149965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 736,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.866733047515243,
    "arrivals": 373265,
    "finished_requests": 77436,
    "scheduler_time": 124.97091333590832
}
#Debug simulation 
Total elapsed time: 5.444879776099697. Arrivals time: 0.2877898945007473 Scheduler time: 5.029031451325864 Scheduler overhead time: 0.04313372913748026 Adapter cache time: 0.019993423018604517 Engine time: 0.04446604545228183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 135, 135, 17280, 135, 66, 17280, 66, 135, 135, 66, 17280, 17280, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 66, 135, 135, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 17280, 17280, 66, 135, 17280, 66, 135, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 135, 66, 66, 66, 66, 66, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 66, 135, 135, 17280, 66, 66, 66, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 66, 17280, 135, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 135, 66, 17280, 135, 66, 135, 135, 66, 135, 17280, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 1118784 . Total input tokens: 249696988 . Total output tokens: 219712035
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.2880070600658655,
    "estimated_duration": 3600.0778413263442,
    "input_throughput": 5138.168343933647,
    "output_throughput": 4474.552970794988,
    "total_throughput": 9612.721314728635,
    "itl": 107.52013200170138,
    "ttft": 1980600.0404699368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 722,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.271372323362164,
    "arrivals": 373265,
    "finished_requests": 74690,
    "scheduler_time": 128.39240460865972
}
#Debug simulation 
Total elapsed time: 5.288162229117006. Arrivals time: 0.2806688535492867 Scheduler time: 4.869495364371687 Scheduler overhead time: 0.04697783454321325 Adapter cache time: 0.020584471058100462 Engine time: 0.04806519718840718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 135, 135, 17280, 135, 66, 17280, 66, 135, 135, 66, 17280, 17280, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 66, 135, 135, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 17280, 17280, 66, 135, 17280, 66, 135, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 135, 66, 66, 66, 66, 66, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 66, 135, 135, 17280, 66, 66, 66, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 66, 17280, 135, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 135, 66, 17280, 135, 66, 135, 135, 66, 135, 17280, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 1118784 . Total input tokens: 249696988 . Total output tokens: 219712035
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.810528557980433,
    "estimated_duration": 3600.011065604597,
    "input_throughput": 4601.165857032761,
    "output_throughput": 4017.8479278009722,
    "total_throughput": 8619.013784833733,
    "itl": 85.59998485521297,
    "ttft": 2054422.960013273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.894320893404107,
    "arrivals": 373265,
    "finished_requests": 66970,
    "scheduler_time": 137.92697284314195
}
#Debug simulation 
Total elapsed time: 4.810620493954048. Arrivals time: 0.25887123635038733 Scheduler time: 4.388394211884588 Scheduler overhead time: 0.05613626539707184 Adapter cache time: 0.023293661884963512 Engine time: 0.05752195371314883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 135, 135, 17280, 135, 66, 17280, 66, 135, 135, 66, 17280, 17280, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 66, 135, 135, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 17280, 17280, 66, 135, 17280, 66, 135, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 135, 66, 66, 66, 66, 66, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 66, 135, 135, 17280, 66, 66, 66, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 66, 17280, 135, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 135, 66, 17280, 135, 66, 135, 135, 66, 135, 17280, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 1118784 . Total input tokens: 249696988 . Total output tokens: 219712035
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.2594485220033675,
    "estimated_duration": 3600.031112806836,
    "input_throughput": 5141.583897470379,
    "output_throughput": 4477.121584494711,
    "total_throughput": 9618.705481965091,
    "itl": 107.61305961169643,
    "ttft": 1980411.0926826121,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.922097822013304,
    "arrivals": 373265,
    "finished_requests": 74738,
    "scheduler_time": 128.36620409885407
}
#Debug simulation 
Total elapsed time: 5.259550191927701. Arrivals time: 0.29000085103325546 Scheduler time: 4.832412174204364 Scheduler overhead time: 0.046742836479097605 Adapter cache time: 0.02059005363844335 Engine time: 0.0479470444843173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 135, 135, 17280, 135, 66, 17280, 66, 135, 135, 66, 17280, 17280, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 66, 135, 135, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 17280, 17280, 66, 135, 17280, 66, 135, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 135, 66, 66, 66, 66, 66, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 66, 135, 135, 17280, 66, 66, 66, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 66, 17280, 135, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 135, 66, 17280, 135, 66, 135, 135, 66, 135, 17280, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 1118784 . Total input tokens: 249696988 . Total output tokens: 219712035
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.832131938077509,
    "estimated_duration": 3600.0011479989894,
    "input_throughput": 4600.637144020336,
    "output_throughput": 4017.741496565784,
    "total_throughput": 8618.37864058612,
    "itl": 85.60145948029134,
    "ttft": 2054470.1456473682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.847512411489183,
    "arrivals": 373265,
    "finished_requests": 66967,
    "scheduler_time": 137.92892379312286
}
#Debug simulation 
Total elapsed time: 4.832222332013771. Arrivals time: 0.22962751681916416 Scheduler time: 4.439864076441154 Scheduler overhead time: 0.055881472770124674 Adapter cache time: 0.023188320454210043 Engine time: 0.05726870009675622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 135, 135, 17280, 135, 66, 17280, 66, 135, 135, 66, 17280, 17280, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 66, 135, 135, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 17280, 17280, 66, 135, 17280, 66, 135, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 135, 66, 66, 66, 66, 66, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 66, 135, 135, 17280, 66, 66, 66, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 66, 17280, 135, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 135, 66, 17280, 135, 66, 135, 135, 66, 135, 17280, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 1118784 . Total input tokens: 249696988 . Total output tokens: 219712035
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.268920924048871,
    "estimated_duration": 3600.0912069246633,
    "input_throughput": 5142.209720795942,
    "output_throughput": 4477.700445198008,
    "total_throughput": 9619.910165993952,
    "itl": 107.60281790572449,
    "ttft": 1980287.0004243734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 722,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.609190919091903,
    "arrivals": 373265,
    "finished_requests": 74748,
    "scheduler_time": 128.3788438461911
}
#Debug simulation 
Total elapsed time: 5.269011197146028. Arrivals time: 0.27813135855831206 Scheduler time: 4.852848748676479 Scheduler overhead time: 0.04708631080575287 Adapter cache time: 0.020569733576849103 Engine time: 0.048315448919311166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [64 64 64]
Adapter prompts. [17280, 66, 17280, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 135, 135, 17280, 135, 66, 17280, 66, 135, 135, 66, 17280, 17280, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 66, 135, 135, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 17280, 17280, 66, 135, 17280, 66, 135, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 17280, 135, 66, 66, 66, 66, 66, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 66, 135, 135, 17280, 66, 66, 66, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 66, 17280, 135, 135, 135, 17280, 135, 66, 135, 17280, 17280, 135, 17280, 135, 66, 17280, 135, 66, 135, 135, 66, 135, 17280, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 135, 66, 17280, 17280, 135, 17280, 66, 17280, 17280, 17280, 66, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 1118784 . Total input tokens: 249696988 . Total output tokens: 219712035
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.804788678884506,
    "estimated_duration": 3600.0380553219375,
    "input_throughput": 4600.908864147769,
    "output_throughput": 4017.882805048985,
    "total_throughput": 8618.791669196755,
    "itl": 85.59882648457794,
    "ttft": 2054456.896211128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.80505339028317,
    "arrivals": 373265,
    "finished_requests": 66969,
    "scheduler_time": 137.93163846222023
}
#Debug simulation 
Total elapsed time: 4.804880692856386. Arrivals time: 0.2583003386389464 Scheduler time: 4.384210865944624 Scheduler overhead time: 0.05568906432017684 Adapter cache time: 0.023133421083912253 Engine time: 0.05724892555736005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 135, 135, 17280, 135, 33, 17280, 33, 135, 135, 33, 17280, 17280, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 33, 135, 135, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 17280, 17280, 33, 135, 17280, 33, 135, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 135, 33, 33, 33, 33, 33, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 33, 135, 135, 17280, 33, 33, 33, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 33, 17280, 135, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 135, 33, 17280, 135, 33, 135, 135, 33, 135, 17280, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 1116672 . Total input tokens: 249214610 . Total output tokens: 219298663
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.456869699060917,
    "estimated_duration": 3600.0488774537475,
    "input_throughput": 5364.285779824974,
    "output_throughput": 4683.210860160498,
    "total_throughput": 10047.496639985473,
    "itl": 116.96718213052364,
    "ttft": 1948403.1306931374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.696336648860067,
    "arrivals": 372565,
    "finished_requests": 78155,
    "scheduler_time": 126.28666757334726
}
#Debug simulation 
Total elapsed time: 5.456960214069113. Arrivals time: 0.28166729933582246 Scheduler time: 5.04809357249178 Scheduler overhead time: 0.043808243004605174 Adapter cache time: 0.017861658008769155 Engine time: 0.044973972253501415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 135, 135, 17280, 135, 33, 17280, 33, 135, 135, 33, 17280, 17280, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 33, 135, 135, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 17280, 17280, 33, 135, 17280, 33, 135, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 135, 33, 33, 33, 33, 33, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 33, 135, 135, 17280, 33, 33, 33, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 33, 17280, 135, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 135, 33, 17280, 135, 33, 135, 135, 33, 135, 17280, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 1116672 . Total input tokens: 249214610 . Total output tokens: 219298663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.290739098098129,
    "estimated_duration": 3600.1105870620736,
    "input_throughput": 5178.970631348143,
    "output_throughput": 4521.278890291863,
    "total_throughput": 9700.249521640006,
    "itl": 106.44807456418624,
    "ttft": 1973356.4373204974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.948465079274034,
    "arrivals": 372565,
    "finished_requests": 75418,
    "scheduler_time": 129.6479465386142
}
#Debug simulation 
Total elapsed time: 5.290829556062818. Arrivals time: 0.24321085610426962 Scheduler time: 4.912058856105432 Scheduler overhead time: 0.046959483064711094 Adapter cache time: 0.01840250100940466 Engine time: 0.048080137465149164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 135, 135, 17280, 135, 33, 17280, 33, 135, 135, 33, 17280, 17280, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 33, 135, 135, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 17280, 17280, 33, 135, 17280, 33, 135, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 135, 33, 33, 33, 33, 33, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 33, 135, 135, 17280, 33, 33, 33, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 33, 17280, 135, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 135, 33, 17280, 135, 33, 135, 135, 33, 135, 17280, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 1116672 . Total input tokens: 249214610 . Total output tokens: 219298663
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.87009934685193,
    "estimated_duration": 3600.0154934128595,
    "input_throughput": 4623.30204702017,
    "output_throughput": 4048.4220211461657,
    "total_throughput": 8671.724068166335,
    "itl": 84.95627610883486,
    "ttft": 2049159.9236951284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.597206887844979,
    "arrivals": 372565,
    "finished_requests": 67404,
    "scheduler_time": 138.9378118118438
}
#Debug simulation 
Total elapsed time: 4.870242682984099. Arrivals time: 0.2572680772282183 Scheduler time: 4.448911636834964 Scheduler overhead time: 0.05817729304544628 Adapter cache time: 0.021033428143709898 Engine time: 0.05802370281890035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 135, 135, 17280, 135, 33, 17280, 33, 135, 135, 33, 17280, 17280, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 33, 135, 135, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 17280, 17280, 33, 135, 17280, 33, 135, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 135, 33, 33, 33, 33, 33, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 33, 135, 135, 17280, 33, 33, 33, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 33, 17280, 135, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 135, 33, 17280, 135, 33, 135, 135, 33, 135, 17280, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 1116672 . Total input tokens: 249214610 . Total output tokens: 219298663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.29241446685046,
    "estimated_duration": 3600.0273235675413,
    "input_throughput": 5179.644298233105,
    "output_throughput": 4521.947345629524,
    "total_throughput": 9701.591643862628,
    "itl": 106.4416334125066,
    "ttft": 1973205.5378145478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.691644199211145,
    "arrivals": 372565,
    "finished_requests": 75424,
    "scheduler_time": 129.651288883835
}
#Debug simulation 
Total elapsed time: 5.292507993988693. Arrivals time: 0.2435946324840188 Scheduler time: 4.91289581800811 Scheduler overhead time: 0.04706706362776458 Adapter cache time: 0.01852501928806305 Engine time: 0.04832306155003607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 135, 135, 17280, 135, 33, 17280, 33, 135, 135, 33, 17280, 17280, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 33, 135, 135, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 17280, 17280, 33, 135, 17280, 33, 135, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 135, 33, 33, 33, 33, 33, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 33, 135, 135, 17280, 33, 33, 33, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 33, 17280, 135, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 135, 33, 17280, 135, 33, 135, 135, 33, 135, 17280, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 1116672 . Total input tokens: 249214610 . Total output tokens: 219298663
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.8578462628647685,
    "estimated_duration": 3600.0739630683997,
    "input_throughput": 4623.226958874504,
    "output_throughput": 4048.35626976342,
    "total_throughput": 8671.583228637925,
    "itl": 84.95484897615026,
    "ttft": 2049100.7991168713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.562618319350323,
    "arrivals": 372565,
    "finished_requests": 67404,
    "scheduler_time": 138.941796872457
}
#Debug simulation 
Total elapsed time: 4.8579377208370715. Arrivals time: 0.2581566576845944 Scheduler time: 4.43801728496328 Scheduler overhead time: 0.05640670284628868 Adapter cache time: 0.02082842425443232 Engine time: 0.05791659140959382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 135, 135, 17280, 135, 33, 17280, 33, 135, 135, 33, 17280, 17280, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 33, 135, 135, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 17280, 17280, 33, 135, 17280, 33, 135, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 135, 33, 33, 33, 33, 33, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 33, 135, 135, 17280, 33, 33, 33, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 33, 17280, 135, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 135, 33, 17280, 135, 33, 135, 135, 33, 135, 17280, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 1116672 . Total input tokens: 249214610 . Total output tokens: 219298663
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.299569943919778,
    "estimated_duration": 3600.0715528440296,
    "input_throughput": 5180.0409314831,
    "output_throughput": 4522.188451265299,
    "total_throughput": 9702.229382748399,
    "itl": 106.43258247429767,
    "ttft": 1973285.378979432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4473173079080723,
    "arrivals": 372565,
    "finished_requests": 75431,
    "scheduler_time": 129.6607413727969
}
#Debug simulation 
Total elapsed time: 5.299665055936202. Arrivals time: 0.24244621046818793 Scheduler time: 4.920993310632184 Scheduler overhead time: 0.04711749078705907 Adapter cache time: 0.018492550821974874 Engine time: 0.048332308419048786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_192_slots_96_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_192_slots_96_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 135, 135, 17280, 135, 33, 17280, 33, 135, 135, 33, 17280, 17280, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 33, 135, 135, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 17280, 17280, 33, 135, 17280, 33, 135, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 135, 33, 33, 33, 33, 33, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 33, 135, 135, 17280, 33, 33, 33, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 33, 17280, 135, 135, 135, 17280, 135, 33, 135, 17280, 17280, 135, 17280, 135, 33, 17280, 135, 33, 135, 135, 33, 135, 17280, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 135, 33, 17280, 17280, 135, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 135, 135, 135, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 1116672 . Total input tokens: 249214610 . Total output tokens: 219298663
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.8589415699243546,
    "estimated_duration": 3600.045107632706,
    "input_throughput": 4623.584566957103,
    "output_throughput": 4048.6606595838934,
    "total_throughput": 8672.245226540996,
    "itl": 84.95097762190747,
    "ttft": 2048998.465442301,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.530100922621815,
    "arrivals": 372565,
    "finished_requests": 67410,
    "scheduler_time": 138.94140415933228
}
#Debug simulation 
Total elapsed time: 4.859029250917956. Arrivals time: 0.2590274349786341 Scheduler time: 4.438128286972642 Scheduler overhead time: 0.05651083565317094 Adapter cache time: 0.02083040843717754 Engine time: 0.05782649852335453 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_192_slots_96_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_192_slots_96_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 66, 66, 17280, 66, 33, 17280, 33, 66, 66, 33, 17280, 17280, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 33, 66, 66, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 17280, 17280, 33, 66, 17280, 33, 66, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 66, 33, 33, 33, 33, 33, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 33, 66, 66, 17280, 33, 33, 33, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 33, 17280, 66, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 66, 33, 17280, 66, 33, 66, 66, 33, 66, 17280, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 66, 66, 66, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 1112256 . Total input tokens: 248197193 . Total output tokens: 218436314
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.505522527033463,
    "estimated_duration": 3600.062016288541,
    "input_throughput": 5455.056027130948,
    "output_throughput": 4741.496652770962,
    "total_throughput": 10196.55267990191,
    "itl": 116.11717516656766,
    "ttft": 1934113.6026403739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8896227469621487,
    "arrivals": 371093,
    "finished_requests": 79482,
    "scheduler_time": 127.5135638036892
}
#Debug simulation 
Total elapsed time: 5.505631186999381. Arrivals time: 0.2614518217742443 Scheduler time: 5.119746574666351 Scheduler overhead time: 0.04386118846014142 Adapter cache time: 0.014781013829633594 Engine time: 0.04513407964259386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_192_slots_96_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_192_slots_96_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 66, 66, 17280, 66, 33, 17280, 33, 66, 66, 33, 17280, 17280, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 33, 66, 66, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 17280, 17280, 33, 66, 17280, 33, 66, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 66, 33, 33, 33, 33, 33, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 33, 66, 66, 17280, 33, 33, 33, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 33, 17280, 66, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 66, 33, 17280, 66, 33, 66, 66, 33, 66, 17280, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 66, 66, 66, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 1112256 . Total input tokens: 248197193 . Total output tokens: 218436314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.326274724910036,
    "estimated_duration": 3600.0968592205786,
    "input_throughput": 5256.236079186165,
    "output_throughput": 4572.00671083153,
    "total_throughput": 9828.242790017695,
    "itl": 105.83816094845517,
    "ttft": 1959548.519398911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.099649014249448,
    "arrivals": 371093,
    "finished_requests": 76580,
    "scheduler_time": 130.70782685286832
}
#Debug simulation 
Total elapsed time: 5.326369737042114. Arrivals time: 0.24438669229857624 Scheduler time: 4.948021747171879 Scheduler overhead time: 0.04749987996183336 Adapter cache time: 0.01518948283046484 Engine time: 0.048828564351424575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_192_slots_96_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_192_slots_96_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 66, 66, 17280, 66, 33, 17280, 33, 66, 66, 33, 17280, 17280, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 33, 66, 66, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 17280, 17280, 33, 66, 17280, 33, 66, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 66, 33, 33, 33, 33, 33, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 33, 66, 66, 17280, 33, 33, 33, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 33, 17280, 66, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 66, 33, 17280, 66, 33, 66, 66, 33, 66, 17280, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 66, 66, 66, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 1112256 . Total input tokens: 248197193 . Total output tokens: 218436314
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.847862410126254,
    "estimated_duration": 3600.0882717921836,
    "input_throughput": 4694.515168536845,
    "output_throughput": 4086.8570127241915,
    "total_throughput": 8781.372181261037,
    "itl": 84.55527289345167,
    "ttft": 2038673.797506081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8778264963953006,
    "arrivals": 371093,
    "finished_requests": 68433,
    "scheduler_time": 139.79040221761008
}
#Debug simulation 
Total elapsed time: 4.847957480000332. Arrivals time: 0.2271426385268569 Scheduler time: 4.460847749374807 Scheduler overhead time: 0.05642477446235716 Adapter cache time: 0.01875686109997332 Engine time: 0.05799885559827089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_192_slots_96_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_192_slots_96_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 66, 66, 17280, 66, 33, 17280, 33, 66, 66, 33, 17280, 17280, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 33, 66, 66, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 17280, 17280, 33, 66, 17280, 33, 66, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 66, 33, 33, 33, 33, 33, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 33, 66, 66, 17280, 33, 33, 33, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 33, 17280, 66, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 66, 33, 17280, 66, 33, 66, 66, 33, 66, 17280, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 66, 66, 66, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 1112256 . Total input tokens: 248197193 . Total output tokens: 218436314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.347062258049846,
    "estimated_duration": 3600.003799203994,
    "input_throughput": 5256.408619397605,
    "output_throughput": 4572.149341519989,
    "total_throughput": 9828.557960917595,
    "itl": 105.83188833145239,
    "ttft": 1959516.1591781992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.894192310199137,
    "arrivals": 371093,
    "finished_requests": 76581,
    "scheduler_time": 130.71062610263218
}
#Debug simulation 
Total elapsed time: 5.3472122750245035. Arrivals time: 0.26401515025645494 Scheduler time: 4.949405452236533 Scheduler overhead time: 0.047420527786016464 Adapter cache time: 0.01526282518170774 Engine time: 0.048654895508661866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_192_slots_96_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_192_slots_96_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 66, 66, 17280, 66, 33, 17280, 33, 66, 66, 33, 17280, 17280, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 33, 66, 66, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 17280, 17280, 33, 66, 17280, 33, 66, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 66, 33, 33, 33, 33, 33, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 33, 66, 66, 17280, 33, 33, 33, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 33, 17280, 66, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 66, 33, 17280, 66, 33, 66, 66, 33, 66, 17280, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 66, 66, 66, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 1112256 . Total input tokens: 248197193 . Total output tokens: 218436314
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.886630141176283,
    "estimated_duration": 3600.055793728123,
    "input_throughput": 4695.827500632533,
    "output_throughput": 4088.4421918244175,
    "total_throughput": 8784.26969245695,
    "itl": 84.63049963143882,
    "ttft": 2038260.5219278077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.849865677552316,
    "arrivals": 371093,
    "finished_requests": 68459,
    "scheduler_time": 139.74818712494442
}
#Debug simulation 
Total elapsed time: 4.886730524012819. Arrivals time: 0.22950017638504505 Scheduler time: 4.4966502813622355 Scheduler overhead time: 0.05708053708076477 Adapter cache time: 0.018589819315820932 Engine time: 0.05815387237817049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_192_slots_96_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_192_slots_96_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 66, 66, 17280, 66, 33, 17280, 33, 66, 66, 33, 17280, 17280, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 33, 66, 66, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 17280, 17280, 33, 66, 17280, 33, 66, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 66, 33, 33, 33, 33, 33, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 33, 66, 66, 17280, 33, 33, 33, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 33, 17280, 66, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 66, 33, 17280, 66, 33, 66, 66, 33, 66, 17280, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 66, 66, 66, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 1112256 . Total input tokens: 248197193 . Total output tokens: 218436314
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.597959904000163,
    "estimated_duration": 3600.05650814849,
    "input_throughput": 5256.439991196791,
    "output_throughput": 4572.4087837904135,
    "total_throughput": 9828.848774987204,
    "itl": 105.8288797112184,
    "ttft": 1959460.494822158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7067824788018946,
    "arrivals": 371093,
    "finished_requests": 76584,
    "scheduler_time": 130.7179243086236
}
#Debug simulation 
Total elapsed time: 5.598078239010647. Arrivals time: 0.24779582675546408 Scheduler time: 5.216062660096213 Scheduler overhead time: 0.04754137038253248 Adapter cache time: 0.015254683094099164 Engine time: 0.04881109646521509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_192_slots_96_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_192_slots_96_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [64 64 64]
Adapter prompts. [17280, 33, 17280, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 66, 66, 17280, 66, 33, 17280, 33, 66, 66, 33, 17280, 17280, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 33, 66, 66, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 17280, 17280, 33, 66, 17280, 33, 66, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 17280, 66, 33, 33, 33, 33, 33, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 33, 66, 66, 17280, 33, 33, 33, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 33, 17280, 66, 66, 66, 17280, 66, 33, 66, 17280, 17280, 66, 17280, 66, 33, 17280, 66, 33, 66, 66, 33, 66, 17280, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 66, 33, 17280, 17280, 66, 17280, 33, 17280, 17280, 17280, 33, 17280, 17280, 17280, 66, 66, 66, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 1112256 . Total input tokens: 248197193 . Total output tokens: 218436314
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.875163692981005,
    "estimated_duration": 3600.076456155242,
    "input_throughput": 4697.142742923682,
    "output_throughput": 4090.251465305275,
    "total_throughput": 8787.394208228956,
    "itl": 84.68082948495851,
    "ttft": 2038164.7979091324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8245973820053223,
    "arrivals": 371093,
    "finished_requests": 68485,
    "scheduler_time": 139.7226651322906
}
#Debug simulation 
Total elapsed time: 4.87526109488681. Arrivals time: 0.22954763984307647 Scheduler time: 4.484870289685205 Scheduler overhead time: 0.05685388296842575 Adapter cache time: 0.01873686257749796 Engine time: 0.05835371115244925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_192_slots_96_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_192_slots_96_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [64 64 64]
Adapter prompts. [8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 4320, 1080, 4320, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 898560 . Total input tokens: 200518759 . Total output tokens: 176404998
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 9.029601657064632,
    "estimated_duration": 3600.0345037292723,
    "input_throughput": 4723.24528622871,
    "output_throughput": 4076.6134282316457,
    "total_throughput": 8799.858714460355,
    "itl": 133.88631812858807,
    "ttft": 1973267.0906203631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1359,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.986263874420187,
    "arrivals": 299534,
    "finished_requests": 68576,
    "scheduler_time": 109.40779489761323
}
#Debug simulation 
Total elapsed time: 9.02969292900525. Arrivals time: 0.25677249673753977 Scheduler time: 8.642122359480709 Scheduler overhead time: 0.04191100690513849 Adapter cache time: 0.028485317714512348 Engine time: 0.04146068939007819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_192_slots_96_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_192_slots_96_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [64 64 64]
Adapter prompts. [8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 4320, 1080, 4320, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 898560 . Total input tokens: 200518759 . Total output tokens: 176404998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.31053320504725,
    "estimated_duration": 3600.023971033571,
    "input_throughput": 4531.419826995334,
    "output_throughput": 3910.481739364152,
    "total_throughput": 8441.901566359486,
    "itl": 122.51825404234047,
    "ttft": 2003558.8734475428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1809,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.23936612698697,
    "arrivals": 299534,
    "finished_requests": 65744,
    "scheduler_time": 111.61966377151947
}
#Debug simulation 
Total elapsed time: 7.310628026956692. Arrivals time: 0.24033446423709393 Scheduler time: 6.929074905347079 Scheduler overhead time: 0.04350754013285041 Adapter cache time: 0.034358385717496276 Engine time: 0.04333011503331363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_192_slots_96_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_192_slots_96_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [64 64 64]
Adapter prompts. [8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 4320, 1080, 4320, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 898560 . Total input tokens: 200518759 . Total output tokens: 176404998
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.536497605033219,
    "estimated_duration": 3600.0517173951275,
    "input_throughput": 4004.0877552809543,
    "output_throughput": 3461.2036098792473,
    "total_throughput": 7465.291365160202,
    "itl": 98.42837774383851,
    "ttft": 2092150.2541313497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.468133340310484,
    "arrivals": 299534,
    "finished_requests": 58129,
    "scheduler_time": 118.45419088476149
}
#Debug simulation 
Total elapsed time: 5.536607427056879. Arrivals time: 0.2239370779134333 Scheduler time: 5.136196585837752 Scheduler overhead time: 0.05164642375893891 Adapter cache time: 0.049818693194538355 Engine time: 0.051229323260486126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_192_slots_96_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_192_slots_96_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [64 64 64]
Adapter prompts. [8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 4320, 1080, 4320, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 898560 . Total input tokens: 200518759 . Total output tokens: 176404998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 7.671197089133784,
    "estimated_duration": 3600.115706221564,
    "input_throughput": 4540.356570137977,
    "output_throughput": 3918.647385588159,
    "total_throughput": 8459.003955726135,
    "itl": 122.41228780047646,
    "ttft": 2002384.5927740815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1767,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.092497571376313,
    "arrivals": 299534,
    "finished_requests": 65889,
    "scheduler_time": 111.77714215199899
}
#Debug simulation 
Total elapsed time: 7.671317140106112. Arrivals time: 0.24532097508199513 Scheduler time: 7.282895142678171 Scheduler overhead time: 0.044508746825158596 Adapter cache time: 0.034627839690074325 Engine time: 0.04374402202665806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_192_slots_96_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_192_slots_96_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [64 64 64]
Adapter prompts. [8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 4320, 1080, 4320, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 898560 . Total input tokens: 200518759 . Total output tokens: 176404998
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 5.47250693384558,
    "estimated_duration": 3600.0830211072516,
    "input_throughput": 4016.358765957814,
    "output_throughput": 3472.0604849150272,
    "total_throughput": 7488.419250872841,
    "itl": 98.9962473896291,
    "ttft": 2089609.76145919,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.13198495696322,
    "arrivals": 299534,
    "finished_requests": 58316,
    "scheduler_time": 118.22671198951663
}
#Debug simulation 
Total elapsed time: 5.472653692821041. Arrivals time: 0.21454554121010005 Scheduler time: 5.080738388234749 Scheduler overhead time: 0.05104309297166765 Adapter cache time: 0.05129692191258073 Engine time: 0.05158306751400232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_192_slots_96_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_192_slots_96_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [64 64 64]
Adapter prompts. [8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 4320, 1080, 4320, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 898560 . Total input tokens: 200518759 . Total output tokens: 176404998
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.52536795893684,
    "estimated_duration": 3600.033626021943,
    "input_throughput": 4544.309775816601,
    "output_throughput": 3921.9991996580147,
    "total_throughput": 8466.308975474616,
    "itl": 122.68582188290164,
    "ttft": 2001841.7666810483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1793,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.446370246443385,
    "arrivals": 299534,
    "finished_requests": 65960,
    "scheduler_time": 111.7013813305412
}
#Debug simulation 
Total elapsed time: 7.525460667908192. Arrivals time: 0.24730950128287077 Scheduler time: 7.136777630774304 Scheduler overhead time: 0.044016138883307576 Adapter cache time: 0.03398186061531305 Engine time: 0.04339693346992135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_192_slots_96_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_192_slots_96_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [64 64 64]
Adapter prompts. [8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 4320, 1080, 4320, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 4320, 1080, 8640, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 898560 . Total input tokens: 200518759 . Total output tokens: 176404998
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.510350763099268,
    "estimated_duration": 3600.0149450090234,
    "input_throughput": 4014.465001051204,
    "output_throughput": 3469.9678170276843,
    "total_throughput": 7484.432818078889,
    "itl": 98.83922480128109,
    "ttft": 2090176.7803098024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2784,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.546643621102156,
    "arrivals": 299534,
    "finished_requests": 58280,
    "scheduler_time": 118.30103822952985
}
#Debug simulation 
Total elapsed time: 5.5104573799762875. Arrivals time: 0.23144911439158022 Scheduler time: 5.100832696072757 Scheduler overhead time: 0.05144002474844456 Adapter cache time: 0.05198503169231117 Engine time: 0.051157275680452585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_192_slots_96_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_192_slots_96_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 8640, 8640, 540, 4320, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 4320, 540, 540, 540, 540, 540, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 540, 4320, 4320, 8640, 540, 540, 540, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 4320, 540, 8640, 4320, 540, 4320, 4320, 540, 4320, 8640, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 864000 . Total input tokens: 192869648 . Total output tokens: 169605729
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 9.098244487075135,
    "estimated_duration": 3600.12177915452,
    "input_throughput": 4703.273955353956,
    "output_throughput": 4084.50099803384,
    "total_throughput": 8787.774953387796,
    "itl": 134.2886268030418,
    "ttft": 1965431.7079086031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.78280543060526,
    "arrivals": 287913,
    "finished_requests": 68328,
    "scheduler_time": 109.27985646314525
}
#Debug simulation 
Total elapsed time: 9.098385598976165. Arrivals time: 0.2586815943941474 Scheduler time: 8.71333351940848 Scheduler overhead time: 0.041369694750756025 Adapter cache time: 0.024943874217569828 Engine time: 0.04116372624412179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_192_slots_96_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_192_slots_96_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 8640, 8640, 540, 4320, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 4320, 540, 540, 540, 540, 540, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 540, 4320, 4320, 8640, 540, 540, 540, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 4320, 540, 8640, 4320, 540, 4320, 4320, 540, 4320, 8640, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 864000 . Total input tokens: 192869648 . Total output tokens: 169605729
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.398163612000644,
    "estimated_duration": 3600.041191849722,
    "input_throughput": 4507.63147842265,
    "output_throughput": 3922.395119247138,
    "total_throughput": 8430.026597669788,
    "itl": 122.72550498678629,
    "ttft": 1997963.6422311314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.509352058349124,
    "arrivals": 287913,
    "finished_requests": 65544,
    "scheduler_time": 111.59316509102467
}
#Debug simulation 
Total elapsed time: 7.3982784249819815. Arrivals time: 0.23729619872756302 Scheduler time: 7.025436877971515 Scheduler overhead time: 0.04391519958153367 Adapter cache time: 0.02769842790439725 Engine time: 0.043754391837865114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_192_slots_96_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_192_slots_96_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 8640, 8640, 540, 4320, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 4320, 540, 540, 540, 540, 540, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 540, 4320, 4320, 8640, 540, 540, 540, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 4320, 540, 8640, 4320, 540, 4320, 4320, 540, 4320, 8640, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 864000 . Total input tokens: 192869648 . Total output tokens: 169605729
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.243920176057145,
    "estimated_duration": 3600.001412888627,
    "input_throughput": 3998.0620419954475,
    "output_throughput": 3478.6847458349685,
    "total_throughput": 7476.746787830416,
    "itl": 99.2719047159396,
    "ttft": 2089350.1769047633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.823614374217662,
    "arrivals": 287913,
    "finished_requests": 58103,
    "scheduler_time": 118.00154484962292
}
#Debug simulation 
Total elapsed time: 5.244063682155684. Arrivals time: 0.212001588428393 Scheduler time: 4.858034897828475 Scheduler overhead time: 0.050892081344500184 Adapter cache time: 0.0486171948723495 Engine time: 0.050833695800974965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_192_slots_96_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_192_slots_96_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 8640, 8640, 540, 4320, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 4320, 540, 540, 540, 540, 540, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 540, 4320, 4320, 8640, 540, 540, 540, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 4320, 540, 8640, 4320, 540, 4320, 4320, 540, 4320, 8640, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 864000 . Total input tokens: 192869648 . Total output tokens: 169605729
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 7.631697407923639,
    "estimated_duration": 3600.102939088234,
    "input_throughput": 4519.1291124915415,
    "output_throughput": 3931.7597967309357,
    "total_throughput": 8450.888909222476,
    "itl": 122.93024354029096,
    "ttft": 1998550.8201684249,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.842543047615367,
    "arrivals": 287913,
    "finished_requests": 65701,
    "scheduler_time": 111.59903530477932
}
#Debug simulation 
Total elapsed time: 7.6317673090379685. Arrivals time: 0.24409928731620312 Scheduler time: 7.2513113669119775 Scheduler overhead time: 0.04345509293489158 Adapter cache time: 0.02972088777460158 Engine time: 0.04330423870123923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_192_slots_96_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_192_slots_96_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 8640, 8640, 540, 4320, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 4320, 540, 540, 540, 540, 540, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 540, 4320, 4320, 8640, 540, 540, 540, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 4320, 540, 8640, 4320, 540, 4320, 4320, 540, 4320, 8640, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 864000 . Total input tokens: 192869648 . Total output tokens: 169605729
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 5.322101084049791,
    "estimated_duration": 3600.085546894229,
    "input_throughput": 3990.719335098651,
    "output_throughput": 3474.5699337037195,
    "total_throughput": 7465.28926880237,
    "itl": 99.08115597643818,
    "ttft": 2089793.6561907222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.623285402492684,
    "arrivals": 287913,
    "finished_requests": 58011,
    "scheduler_time": 118.08103297689203
}
#Debug simulation 
Total elapsed time: 5.322199153946713. Arrivals time: 0.2160179412458092 Scheduler time: 4.932176359929144 Scheduler overhead time: 0.05148624558933079 Adapter cache time: 0.04803827730938792 Engine time: 0.05078557855449617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_192_slots_96_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_192_slots_96_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 8640, 8640, 540, 4320, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 4320, 540, 540, 540, 540, 540, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 540, 4320, 4320, 8640, 540, 540, 540, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 4320, 540, 8640, 4320, 540, 4320, 4320, 540, 4320, 8640, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 864000 . Total input tokens: 192869648 . Total output tokens: 169605729
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.234360720962286,
    "estimated_duration": 3600.090780896521,
    "input_throughput": 4509.641558526758,
    "output_throughput": 3926.610149669534,
    "total_throughput": 8436.251708196292,
    "itl": 122.96419923895536,
    "ttft": 1997219.3520407418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1464,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.346060256995399,
    "arrivals": 287913,
    "finished_requests": 65579,
    "scheduler_time": 111.5305757783992
}
#Debug simulation 
Total elapsed time: 7.234454148914665. Arrivals time: 0.2380613216664642 Scheduler time: 6.860167120583355 Scheduler overhead time: 0.04355842084623873 Adapter cache time: 0.02953685843385756 Engine time: 0.043187279952690005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_192_slots_96_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_192_slots_96_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 8640, 8640, 540, 4320, 8640, 540, 4320, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 4320, 540, 540, 540, 540, 540, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 540, 4320, 4320, 8640, 540, 540, 540, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 4320, 4320, 8640, 4320, 540, 4320, 8640, 8640, 4320, 8640, 4320, 540, 8640, 4320, 540, 4320, 4320, 540, 4320, 8640, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 4320, 540, 8640, 8640, 4320, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 864000 . Total input tokens: 192869648 . Total output tokens: 169605729
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.486146413953975,
    "estimated_duration": 3600.01863526533,
    "input_throughput": 3996.791255204025,
    "output_throughput": 3478.6819927327965,
    "total_throughput": 7475.473247936821,
    "itl": 99.29891825419544,
    "ttft": 2089318.9582370932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.725748605858616,
    "arrivals": 287913,
    "finished_requests": 58105,
    "scheduler_time": 117.99401868668973
}
#Debug simulation 
Total elapsed time: 5.486209726892412. Arrivals time: 0.2132929505314678 Scheduler time: 5.09913742239587 Scheduler overhead time: 0.05085620959289372 Adapter cache time: 0.04870206699706614 Engine time: 0.05070678098127246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_192_slots_96_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_192_slots_96_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 8640, 8640, 270, 4320, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 4320, 270, 270, 270, 270, 270, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 270, 4320, 4320, 8640, 270, 270, 270, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 4320, 270, 8640, 4320, 270, 4320, 4320, 270, 4320, 8640, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 846720 . Total input tokens: 189006803 . Total output tokens: 166193050
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 8.458158852066845,
    "estimated_duration": 3600.118441730957,
    "input_throughput": 4697.456562531566,
    "output_throughput": 4082.016533026676,
    "total_throughput": 8779.473095558242,
    "itl": 134.36181314056265,
    "ttft": 1959078.8575220664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1004,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.638858668077884,
    "arrivals": 282093,
    "finished_requests": 68366,
    "scheduler_time": 109.12146345623164
}
#Debug simulation 
Total elapsed time: 8.458223724970594. Arrivals time: 0.5018131965771317 Scheduler time: 7.832942373119295 Scheduler overhead time: 0.041267171036452055 Adapter cache time: 0.022665414260700345 Engine time: 0.04083435260690749 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_192_slots_96_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_192_slots_96_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 8640, 8640, 270, 4320, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 4320, 270, 270, 270, 270, 270, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 270, 4320, 4320, 8640, 270, 270, 270, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 4320, 270, 8640, 4320, 270, 4320, 4320, 270, 4320, 8640, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 846720 . Total input tokens: 189006803 . Total output tokens: 166193050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.095024220878258,
    "estimated_duration": 3600.0124636406485,
    "input_throughput": 4506.842730092154,
    "output_throughput": 3925.4250208092076,
    "total_throughput": 8432.267750901361,
    "itl": 123.07892097402285,
    "ttft": 1990314.5264778896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.61815256746015,
    "arrivals": 282093,
    "finished_requests": 65682,
    "scheduler_time": 111.34925339724464
}
#Debug simulation 
Total elapsed time: 7.095105433836579. Arrivals time: 0.49290287494659424 Scheduler time: 6.467736087972298 Scheduler overhead time: 0.04344554152339697 Adapter cache time: 0.027834190987050533 Engine time: 0.04323923820629716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_192_slots_96_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_192_slots_96_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 8640, 8640, 270, 4320, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 4320, 270, 270, 270, 270, 270, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 270, 4320, 4320, 8640, 270, 270, 270, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 4320, 270, 8640, 4320, 270, 4320, 4320, 270, 4320, 8640, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 846720 . Total input tokens: 189006803 . Total output tokens: 166193050
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.310290994122624,
    "estimated_duration": 3600.0217012613725,
    "input_throughput": 3979.4471224938547,
    "output_throughput": 3466.8363236885566,
    "total_throughput": 7446.283446182411,
    "itl": 98.62746730221865,
    "ttft": 2082153.2814376454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.63796926955211,
    "arrivals": 282093,
    "finished_requests": 58052,
    "scheduler_time": 118.21039721612166
}
#Debug simulation 
Total elapsed time: 5.31038439203985. Arrivals time: 0.46349009685218334 Scheduler time: 4.675469664623961 Scheduler overhead time: 0.051299163373187184 Adapter cache time: 0.04517183103598654 Engine time: 0.05101937102153897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_192_slots_96_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_192_slots_96_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 8640, 8640, 270, 4320, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 4320, 270, 270, 270, 270, 270, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 270, 4320, 4320, 8640, 270, 270, 270, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 4320, 270, 8640, 4320, 270, 4320, 4320, 270, 4320, 8640, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 846720 . Total input tokens: 189006803 . Total output tokens: 166193050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 7.134763535112143,
    "estimated_duration": 3600.020555455707,
    "input_throughput": 4503.5084523143005,
    "output_throughput": 3923.8420398996523,
    "total_throughput": 8427.350492213953,
    "itl": 122.89380302262549,
    "ttft": 1989636.364193599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.903521052375458,
    "arrivals": 282093,
    "finished_requests": 65624,
    "scheduler_time": 111.41569328577691
}
#Debug simulation 
Total elapsed time: 7.1348733911290765. Arrivals time: 0.2395288716070354 Scheduler time: 6.757860016077757 Scheduler overhead time: 0.04566328437067568 Adapter cache time: 0.027974878204986453 Engine time: 0.043582828948274255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_192_slots_96_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_192_slots_96_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 8640, 8640, 270, 4320, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 4320, 270, 270, 270, 270, 270, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 270, 4320, 4320, 8640, 270, 270, 270, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 4320, 270, 8640, 4320, 270, 4320, 4320, 270, 4320, 8640, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 846720 . Total input tokens: 189006803 . Total output tokens: 166193050
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 5.33636152301915,
    "estimated_duration": 3600.022422350615,
    "input_throughput": 3984.044630098455,
    "output_throughput": 3470.2056082869844,
    "total_throughput": 7454.250238385439,
    "itl": 98.7351497425265,
    "ttft": 2081731.1073166474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.25044713480378,
    "arrivals": 282093,
    "finished_requests": 58112,
    "scheduler_time": 118.17393337038096
}
#Debug simulation 
Total elapsed time: 5.33642504690215. Arrivals time: 0.46485994663089514 Scheduler time: 4.702139069791883 Scheduler overhead time: 0.05071419780142605 Adapter cache time: 0.0442349964287132 Engine time: 0.05085311410948634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_192_slots_96_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_192_slots_96_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 8640, 8640, 270, 4320, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 4320, 270, 270, 270, 270, 270, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 270, 4320, 4320, 8640, 270, 270, 270, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 4320, 270, 8640, 4320, 270, 4320, 4320, 270, 4320, 8640, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 846720 . Total input tokens: 189006803 . Total output tokens: 166193050
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.081830067094415,
    "estimated_duration": 3600.093270553339,
    "input_throughput": 4508.710408357047,
    "output_throughput": 3927.998231508731,
    "total_throughput": 8436.708639865778,
    "itl": 123.0826834693922,
    "ttft": 1990198.6986287176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.560837981305118,
    "arrivals": 282093,
    "finished_requests": 65714,
    "scheduler_time": 111.37487628935698
}
#Debug simulation 
Total elapsed time: 7.081941242096946. Arrivals time: 0.23779397527687252 Scheduler time: 6.709100112784654 Scheduler overhead time: 0.04354208195582032 Adapter cache time: 0.02818475617095828 Engine time: 0.043238015845417976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_192_slots_96_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_192_slots_96_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 8640, 8640, 270, 4320, 8640, 270, 4320, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 4320, 270, 270, 270, 270, 270, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 270, 4320, 4320, 8640, 270, 270, 270, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 4320, 4320, 8640, 4320, 270, 4320, 8640, 8640, 4320, 8640, 4320, 270, 8640, 4320, 270, 4320, 4320, 270, 4320, 8640, 270, 4320, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 4320, 270, 8640, 8640, 4320, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 846720 . Total input tokens: 189006803 . Total output tokens: 166193050
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.347315130988136,
    "estimated_duration": 3600.076257558289,
    "input_throughput": 3991.2526768934295,
    "output_throughput": 3477.2907861931067,
    "total_throughput": 7468.543463086537,
    "itl": 98.98294023958047,
    "ttft": 2080699.6404918232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2296,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.897307527623823,
    "arrivals": 282093,
    "finished_requests": 58232,
    "scheduler_time": 118.08804920954472
}
#Debug simulation 
Total elapsed time: 5.347406950080767. Arrivals time: 0.46099465852603316 Scheduler time: 4.717713691992685 Scheduler overhead time: 0.050581777933984995 Adapter cache time: 0.04388182424008846 Engine time: 0.05072872433811426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 8640, 8640, 135, 4320, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 4320, 135, 135, 135, 135, 135, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 135, 4320, 4320, 8640, 135, 135, 135, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 4320, 135, 8640, 4320, 135, 4320, 4320, 135, 4320, 8640, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 838080 . Total input tokens: 187058170 . Total output tokens: 164517372
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.800998392049223,
    "estimated_duration": 3600.124636684623,
    "input_throughput": 4727.62937887447,
    "output_throughput": 4080.4148418395075,
    "total_throughput": 8808.044220713977,
    "itl": 134.36972855650026,
    "ttft": 1957515.1658681945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 835,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.521361541678308,
    "arrivals": 279137,
    "finished_requests": 68561,
    "scheduler_time": 109.00886768773543
}
#Debug simulation 
Total elapsed time: 7.801089518936351. Arrivals time: 0.24916741554625332 Scheduler time: 7.431480536004528 Scheduler overhead time: 0.04078263184055686 Adapter cache time: 0.020080255577340722 Engine time: 0.040861954214051366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 8640, 8640, 135, 4320, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 4320, 135, 135, 135, 135, 135, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 135, 4320, 4320, 8640, 135, 135, 135, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 4320, 135, 8640, 4320, 135, 4320, 4320, 135, 4320, 8640, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 838080 . Total input tokens: 187058170 . Total output tokens: 164517372
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.553625382948667,
    "estimated_duration": 3600.106238635978,
    "input_throughput": 4540.93127157101,
    "output_throughput": 3919.322115712352,
    "total_throughput": 8460.253387283363,
    "itl": 122.44300671881246,
    "ttft": 1988730.282981301,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.252777134808712,
    "arrivals": 279137,
    "finished_requests": 65779,
    "scheduler_time": 111.48056091790458
}
#Debug simulation 
Total elapsed time: 6.55371654802002. Arrivals time: 0.23302638763561845 Scheduler time: 6.189786254195496 Scheduler overhead time: 0.04340009274892509 Adapter cache time: 0.02431354601867497 Engine time: 0.04321689228527248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 8640, 8640, 135, 4320, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 4320, 135, 135, 135, 135, 135, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 135, 4320, 4320, 8640, 135, 135, 135, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 4320, 135, 8640, 4320, 135, 4320, 4320, 135, 4320, 8640, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 838080 . Total input tokens: 187058170 . Total output tokens: 164517372
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.928729076171294,
    "estimated_duration": 3600.100696446354,
    "input_throughput": 4017.546235380843,
    "output_throughput": 3481.1604054216627,
    "total_throughput": 7498.706640802506,
    "itl": 99.1050797326808,
    "ttft": 2077189.9951238888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2103,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.72288318560894,
    "arrivals": 279137,
    "finished_requests": 58244,
    "scheduler_time": 118.04800730466441
}
#Debug simulation 
Total elapsed time: 4.928819905035198. Arrivals time: 0.21045458456501365 Scheduler time: 4.551399214193225 Scheduler overhead time: 0.051782842725515366 Adapter cache time: 0.04087010398507118 Engine time: 0.0507397863548249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 8640, 8640, 135, 4320, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 4320, 135, 135, 135, 135, 135, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 135, 4320, 4320, 8640, 135, 135, 135, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 4320, 135, 8640, 4320, 135, 4320, 4320, 135, 4320, 8640, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 838080 . Total input tokens: 187058170 . Total output tokens: 164517372
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 6.784292808035389,
    "estimated_duration": 3600.087487537349,
    "input_throughput": 4546.732004892752,
    "output_throughput": 3923.1113268475747,
    "total_throughput": 8469.843331740327,
    "itl": 122.7219148154276,
    "ttft": 1988078.3848416405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.700274665113526,
    "arrivals": 279137,
    "finished_requests": 65857,
    "scheduler_time": 111.42139061832415
}
#Debug simulation 
Total elapsed time: 6.784357220167294. Arrivals time: 0.23698609927669168 Scheduler time: 6.416873219888657 Scheduler overhead time: 0.04338282742537558 Adapter cache time: 0.024250852409750223 Engine time: 0.043026790488511324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 8640, 8640, 135, 4320, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 4320, 135, 135, 135, 135, 135, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 135, 4320, 4320, 8640, 135, 135, 135, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 4320, 135, 8640, 4320, 135, 4320, 4320, 135, 4320, 8640, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 838080 . Total input tokens: 187058170 . Total output tokens: 164517372
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.917704747058451,
    "estimated_duration": 3600.0730544614166,
    "input_throughput": 3994.6494925091047,
    "output_throughput": 3459.3239669307586,
    "total_throughput": 7453.973459439863,
    "itl": 98.15322461595765,
    "ttft": 2081839.5059305094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2152,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.93468857558413,
    "arrivals": 279137,
    "finished_requests": 57903,
    "scheduler_time": 118.41338811632374
}
#Debug simulation 
Total elapsed time: 4.917875644983724. Arrivals time: 0.20787535212002695 Scheduler time: 4.542820118600503 Scheduler overhead time: 0.05095647252164781 Adapter cache time: 0.041289884597063065 Engine time: 0.0511090662330389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 8640, 8640, 135, 4320, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 4320, 135, 135, 135, 135, 135, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 135, 4320, 4320, 8640, 135, 135, 135, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 4320, 135, 8640, 4320, 135, 4320, 4320, 135, 4320, 8640, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 838080 . Total input tokens: 187058170 . Total output tokens: 164517372
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.508084696019068,
    "estimated_duration": 3600.0866998651586,
    "input_throughput": 4549.603486108675,
    "output_throughput": 3923.9418874354083,
    "total_throughput": 8473.545373544082,
    "itl": 122.6886840387639,
    "ttft": 1988033.494945222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.2074467419040955,
    "arrivals": 279137,
    "finished_requests": 65889,
    "scheduler_time": 111.43682469240943
}
#Debug simulation 
Total elapsed time: 6.50818302994594. Arrivals time: 0.23583025904372334 Scheduler time: 6.141504765022546 Scheduler overhead time: 0.04347947333008051 Adapter cache time: 0.024207964539527893 Engine time: 0.04313432169146836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 8640, 8640, 135, 4320, 8640, 135, 4320, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 4320, 135, 135, 135, 135, 135, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 135, 4320, 4320, 8640, 135, 135, 135, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 4320, 4320, 8640, 4320, 135, 4320, 8640, 8640, 4320, 8640, 4320, 135, 8640, 4320, 135, 4320, 4320, 135, 4320, 8640, 135, 4320, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 4320, 135, 8640, 8640, 4320, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 838080 . Total input tokens: 187058170 . Total output tokens: 164517372
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.910255179041997,
    "estimated_duration": 3600.005425768434,
    "input_throughput": 4016.0472805159543,
    "output_throughput": 3479.7066999770077,
    "total_throughput": 7495.753980492962,
    "itl": 99.02049359105631,
    "ttft": 2077692.585630244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2132,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.668367969244397,
    "arrivals": 279137,
    "finished_requests": 58225,
    "scheduler_time": 118.07219757336625
}
#Debug simulation 
Total elapsed time: 4.910372600890696. Arrivals time: 0.20896504214033484 Scheduler time: 4.536068844841793 Scheduler overhead time: 0.05032547074370086 Adapter cache time: 0.04109798278659582 Engine time: 0.05044285883195698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 8640, 8640, 66, 4320, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 4320, 66, 66, 66, 66, 66, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 66, 4320, 4320, 8640, 66, 66, 66, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 4320, 66, 8640, 4320, 66, 4320, 4320, 66, 4320, 8640, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 833664 . Total input tokens: 186055288 . Total output tokens: 163650260
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.532040189951658,
    "estimated_duration": 3600.1304489472154,
    "input_throughput": 4704.868681898239,
    "output_throughput": 4081.9504205180715,
    "total_throughput": 8786.81910241631,
    "itl": 134.21432283140635,
    "ttft": 1954208.3792164281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.70803523074844,
    "arrivals": 277607,
    "finished_requests": 68447,
    "scheduler_time": 108.9229620205898
}
#Debug simulation 
Total elapsed time: 7.532159372931346. Arrivals time: 0.24608038319274783 Scheduler time: 7.169167174957693 Scheduler overhead time: 0.040544900111854076 Adapter cache time: 0.017610419541597366 Engine time: 0.040318490006029606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 8640, 8640, 66, 4320, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 4320, 66, 66, 66, 66, 66, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 66, 4320, 4320, 8640, 66, 66, 66, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 4320, 66, 8640, 4320, 66, 4320, 4320, 66, 4320, 8640, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 833664 . Total input tokens: 186055288 . Total output tokens: 163650260
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.389409600989893,
    "estimated_duration": 3600.055968476038,
    "input_throughput": 4508.170190162427,
    "output_throughput": 3913.567767660048,
    "total_throughput": 8421.737957822475,
    "itl": 121.86358837567276,
    "ttft": 1987141.4967219934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 958,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.995928358146931,
    "arrivals": 277607,
    "finished_requests": 65556,
    "scheduler_time": 111.51036588634905
}
#Debug simulation 
Total elapsed time: 6.389532878994942. Arrivals time: 0.23640383407473564 Scheduler time: 6.024200628977269 Scheduler overhead time: 0.043418121756985784 Adapter cache time: 0.022181146079674363 Engine time: 0.04335505096241832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 8640, 8640, 66, 4320, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 4320, 66, 66, 66, 66, 66, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 66, 4320, 4320, 8640, 66, 66, 66, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 4320, 66, 8640, 4320, 66, 4320, 4320, 66, 4320, 8640, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 833664 . Total input tokens: 186055288 . Total output tokens: 163650260
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.867794926976785,
    "estimated_duration": 3600.0871466628473,
    "input_throughput": 4002.8881004611926,
    "output_throughput": 3481.958210822709,
    "total_throughput": 7484.846311283902,
    "itl": 98.92035981099289,
    "ttft": 2074587.7017120947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1832,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.705147940804945,
    "arrivals": 277607,
    "finished_requests": 58241,
    "scheduler_time": 117.96256273077644
}
#Debug simulation 
Total elapsed time: 4.867888023843989. Arrivals time: 0.21216304088011384 Scheduler time: 4.493389698443934 Scheduler overhead time: 0.05148773593828082 Adapter cache time: 0.03632826800458133 Engine time: 0.05098087014630437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 8640, 8640, 66, 4320, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 4320, 66, 66, 66, 66, 66, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 66, 4320, 4320, 8640, 66, 66, 66, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 4320, 66, 8640, 4320, 66, 4320, 4320, 66, 4320, 8640, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 833664 . Total input tokens: 186055288 . Total output tokens: 163650260
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 6.374592982931063,
    "estimated_duration": 3600.019185423015,
    "input_throughput": 4510.602350607181,
    "output_throughput": 3916.268295760029,
    "total_throughput": 8426.87064636721,
    "itl": 122.06194369544696,
    "ttft": 1985939.252698665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.413744497136202,
    "arrivals": 277607,
    "finished_requests": 65593,
    "scheduler_time": 111.47229144016652
}
#Debug simulation 
Total elapsed time: 6.374717694008723. Arrivals time: 0.23586177825927734 Scheduler time: 6.010144931264222 Scheduler overhead time: 0.0434729743283242 Adapter cache time: 0.02180518605746329 Engine time: 0.04330751672387123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 8640, 8640, 66, 4320, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 4320, 66, 66, 66, 66, 66, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 66, 4320, 4320, 8640, 66, 66, 66, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 4320, 66, 8640, 4320, 66, 4320, 4320, 66, 4320, 8640, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 833664 . Total input tokens: 186055288 . Total output tokens: 163650260
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.853627963922918,
    "estimated_duration": 3600.0624030067565,
    "input_throughput": 3998.208194385287,
    "output_throughput": 3478.3927605091844,
    "total_throughput": 7476.600954894471,
    "itl": 98.77823835406045,
    "ttft": 2075186.490230622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.982806117343477,
    "arrivals": 277607,
    "finished_requests": 58184,
    "scheduler_time": 118.00374494527674
}
#Debug simulation 
Total elapsed time: 4.85375479189679. Arrivals time: 0.21213733311742544 Scheduler time: 4.478777411626652 Scheduler overhead time: 0.05068815080448985 Adapter cache time: 0.03761134366504848 Engine time: 0.05096334661357105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 8640, 8640, 66, 4320, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 4320, 66, 66, 66, 66, 66, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 66, 4320, 4320, 8640, 66, 66, 66, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 4320, 66, 8640, 4320, 66, 4320, 4320, 66, 4320, 8640, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 833664 . Total input tokens: 186055288 . Total output tokens: 163650260
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.307107139844447,
    "estimated_duration": 3600.0141834594197,
    "input_throughput": 4520.36941264552,
    "output_throughput": 3926.181753655673,
    "total_throughput": 8446.551166301193,
    "itl": 122.6550648747827,
    "ttft": 1984073.493028941,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 971,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.198787233293957,
    "arrivals": 277607,
    "finished_requests": 65743,
    "scheduler_time": 111.3255144628289
}
#Debug simulation 
Total elapsed time: 6.307254966814071. Arrivals time: 0.23281376739032567 Scheduler time: 5.945746014826 Scheduler overhead time: 0.04299148404970765 Adapter cache time: 0.022388740442693233 Engine time: 0.043408390367403626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 8640, 8640, 66, 4320, 8640, 66, 4320, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 4320, 66, 66, 66, 66, 66, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 66, 4320, 4320, 8640, 66, 66, 66, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 4320, 4320, 8640, 4320, 66, 4320, 8640, 8640, 4320, 8640, 4320, 66, 8640, 4320, 66, 4320, 4320, 66, 4320, 8640, 66, 4320, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 4320, 66, 8640, 8640, 4320, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 833664 . Total input tokens: 186055288 . Total output tokens: 163650260
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.829388097859919,
    "estimated_duration": 3600.082112697925,
    "input_throughput": 3996.5060655846337,
    "output_throughput": 3476.154323219477,
    "total_throughput": 7472.660388804111,
    "itl": 98.69369623942622,
    "ttft": 2075436.892919451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1893,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.915331021677453,
    "arrivals": 277607,
    "finished_requests": 58143,
    "scheduler_time": 118.04250616378891
}
#Debug simulation 
Total elapsed time: 4.829501018859446. Arrivals time: 0.20871792756952345 Scheduler time: 4.459032462676987 Scheduler overhead time: 0.05049634142778814 Adapter cache time: 0.03723234240897 Engine time: 0.05051766987890005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 8640, 8640, 33, 4320, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 4320, 33, 33, 33, 33, 33, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 33, 4320, 4320, 8640, 33, 33, 33, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 4320, 33, 8640, 4320, 33, 4320, 4320, 33, 4320, 8640, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 831552 . Total input tokens: 185582658 . Total output tokens: 163230499
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.276511551113799,
    "estimated_duration": 3600.12654363816,
    "input_throughput": 4693.623903265313,
    "output_throughput": 4082.311502625099,
    "total_throughput": 8775.935405890412,
    "itl": 133.96694475590184,
    "ttft": 1952441.0361352041,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.9659191829944955,
    "arrivals": 276925,
    "finished_requests": 68313,
    "scheduler_time": 109.11322657116156
}
#Debug simulation 
Total elapsed time: 7.276636768132448. Arrivals time: 0.24108950328081846 Scheduler time: 6.918145030969754 Scheduler overhead time: 0.04049636563286185 Adapter cache time: 0.017961157485842705 Engine time: 0.04033907689154148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 8640, 8640, 33, 4320, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 4320, 33, 33, 33, 33, 33, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 33, 4320, 4320, 8640, 33, 33, 33, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 4320, 33, 8640, 4320, 33, 4320, 4320, 33, 4320, 8640, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 831552 . Total input tokens: 185582658 . Total output tokens: 163230499
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.235495186876506,
    "estimated_duration": 3600.0325246932503,
    "input_throughput": 4509.622590530158,
    "output_throughput": 3923.922326563886,
    "total_throughput": 8433.544917094045,
    "itl": 122.62086900800897,
    "ttft": 1984698.803407757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.277850484685049,
    "arrivals": 276925,
    "finished_requests": 65590,
    "scheduler_time": 111.36199098743482
}
#Debug simulation 
Total elapsed time: 6.235616012010723. Arrivals time: 0.230803000042215 Scheduler time: 5.8779635089449584 Scheduler overhead time: 0.043268088018521667 Adapter cache time: 0.020503418054431677 Engine time: 0.04320367029868066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 8640, 8640, 33, 4320, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 4320, 33, 33, 33, 33, 33, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 33, 4320, 4320, 8640, 33, 33, 33, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 4320, 33, 8640, 4320, 33, 4320, 4320, 33, 4320, 8640, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 831552 . Total input tokens: 185582658 . Total output tokens: 163230499
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.785306063015014,
    "estimated_duration": 3600.0970319904955,
    "input_throughput": 3999.2185966275397,
    "output_throughput": 3479.2820550935276,
    "total_throughput": 7478.500651721067,
    "itl": 98.94248233685707,
    "ttft": 2076663.5021089427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1871,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.967141804145388,
    "arrivals": 276925,
    "finished_requests": 58185,
    "scheduler_time": 117.96280737698251
}
#Debug simulation 
Total elapsed time: 4.785398510983214. Arrivals time: 0.20678340108133852 Scheduler time: 4.416618667077273 Scheduler overhead time: 0.05040735867805779 Adapter cache time: 0.037285822443664074 Engine time: 0.05078488425351679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 8640, 8640, 33, 4320, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 4320, 33, 33, 33, 33, 33, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 33, 4320, 4320, 8640, 33, 33, 33, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 4320, 33, 8640, 4320, 33, 4320, 4320, 33, 4320, 8640, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 831552 . Total input tokens: 185582658 . Total output tokens: 163230499
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 6.158791473833844,
    "estimated_duration": 3600.0776196692423,
    "input_throughput": 4512.010772004516,
    "output_throughput": 3924.7448229458287,
    "total_throughput": 8436.755594950346,
    "itl": 122.6923308564089,
    "ttft": 1984422.904170961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.073998988629308,
    "arrivals": 276925,
    "finished_requests": 65610,
    "scheduler_time": 111.34654688750247
}
#Debug simulation 
Total elapsed time: 6.158885455923155. Arrivals time: 0.2293400806374848 Scheduler time: 5.802556125912815 Scheduler overhead time: 0.04321126756258309 Adapter cache time: 0.02082397509366274 Engine time: 0.04308870527893305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 8640, 8640, 33, 4320, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 4320, 33, 33, 33, 33, 33, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 33, 4320, 4320, 8640, 33, 33, 33, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 4320, 33, 8640, 4320, 33, 4320, 4320, 33, 4320, 8640, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 831552 . Total input tokens: 185582658 . Total output tokens: 163230499
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.821266590850428,
    "estimated_duration": 3600.078603977571,
    "input_throughput": 3996.4846834465498,
    "output_throughput": 3477.7946198638065,
    "total_throughput": 7474.279303310356,
    "itl": 98.81429744592621,
    "ttft": 2077254.890131911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.71344942103582,
    "arrivals": 276925,
    "finished_requests": 58155,
    "scheduler_time": 118.01645727350085
}
#Debug simulation 
Total elapsed time: 4.821373902959749. Arrivals time: 0.22627865336835384 Scheduler time: 4.433857866330072 Scheduler overhead time: 0.050377869280055165 Adapter cache time: 0.03680117824114859 Engine time: 0.05056840414181352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 8640, 8640, 33, 4320, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 4320, 33, 33, 33, 33, 33, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 33, 4320, 4320, 8640, 33, 33, 33, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 4320, 33, 8640, 4320, 33, 4320, 4320, 33, 4320, 8640, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 831552 . Total input tokens: 185582658 . Total output tokens: 163230499
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.259292809059843,
    "estimated_duration": 3600.1097529415724,
    "input_throughput": 4513.016300884893,
    "output_throughput": 3924.493687576002,
    "total_throughput": 8437.509988460894,
    "itl": 122.56048557470423,
    "ttft": 1984960.8318114565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 870,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.554011218296337,
    "arrivals": 276925,
    "finished_requests": 65617,
    "scheduler_time": 111.39394182228695
}
#Debug simulation 
Total elapsed time: 6.2594127871561795. Arrivals time: 0.23396151140332222 Scheduler time: 5.898568206466734 Scheduler overhead time: 0.04337344877421856 Adapter cache time: 0.020469010807573795 Engine time: 0.0430452530272305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 8640, 8640, 33, 4320, 8640, 33, 4320, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 4320, 33, 33, 33, 33, 33, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 33, 4320, 4320, 8640, 33, 33, 33, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 4320, 4320, 8640, 4320, 33, 4320, 8640, 8640, 4320, 8640, 4320, 33, 8640, 4320, 33, 4320, 4320, 33, 4320, 8640, 33, 4320, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 4320, 33, 8640, 8640, 4320, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 831552 . Total input tokens: 185582658 . Total output tokens: 163230499
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.7734992280602455,
    "estimated_duration": 3600.0959981260926,
    "input_throughput": 3993.98294031169,
    "output_throughput": 3474.6020679757103,
    "total_throughput": 7468.5850082874,
    "itl": 98.65507944604208,
    "ttft": 2078185.3425744085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1826,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.39411771334685,
    "arrivals": 276925,
    "finished_requests": 58116,
    "scheduler_time": 118.08321944101102
}
#Debug simulation 
Total elapsed time: 4.77364316303283. Arrivals time: 0.20991558698005974 Scheduler time: 4.402905425056815 Scheduler overhead time: 0.05047765886411071 Adapter cache time: 0.03624165942892432 Engine time: 0.05061695980839431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_192_slots_96_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_192_slots_96_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 8640, 8640, 540, 1080, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 1080, 540, 540, 540, 540, 540, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 540, 1080, 1080, 8640, 540, 540, 540, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 1080, 540, 8640, 1080, 540, 1080, 1080, 540, 1080, 8640, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 656640 . Total input tokens: 146503211 . Total output tokens: 128977697
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.142981704091653,
    "estimated_duration": 3600.0874548827787,
    "input_throughput": 4654.785254528112,
    "output_throughput": 4079.5611729043985,
    "total_throughput": 8734.34642743251,
    "itl": 134.76536186721347,
    "ttft": 1873718.9961439495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.409458052464997,
    "arrivals": 218234,
    "finished_requests": 68248,
    "scheduler_time": 107.39562094052079
}
#Debug simulation 
Total elapsed time: 6.14307187194936. Arrivals time: 0.253974596504122 Scheduler time: 5.7622218150645494 Scheduler overhead time: 0.040533216670155525 Adapter cache time: 0.027472599409520626 Engine time: 0.04034004476852715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_192_slots_96_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_192_slots_96_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 8640, 8640, 540, 1080, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 1080, 540, 540, 540, 540, 540, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 540, 1080, 1080, 8640, 540, 540, 540, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 1080, 540, 8640, 1080, 540, 1080, 1080, 540, 1080, 8640, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 656640 . Total input tokens: 146503211 . Total output tokens: 128977697
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.940952049102634,
    "estimated_duration": 3600.120478776082,
    "input_throughput": 4467.448546463032,
    "output_throughput": 3920.3385228924817,
    "total_throughput": 8387.787069355512,
    "itl": 123.2331984524828,
    "ttft": 1908958.499574372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1801,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.189682980435702,
    "arrivals": 218234,
    "finished_requests": 65511,
    "scheduler_time": 109.64255478532063
}
#Debug simulation 
Total elapsed time: 5.94101827009581. Arrivals time: 0.2515328030567616 Scheduler time: 5.5487445869948715 Scheduler overhead time: 0.0433308957144618 Adapter cache time: 0.034359337063506246 Engine time: 0.04313111398369074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_192_slots_96_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_192_slots_96_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 8640, 8640, 540, 1080, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 1080, 540, 540, 540, 540, 540, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 540, 1080, 1080, 8640, 540, 540, 540, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 1080, 540, 8640, 1080, 540, 1080, 1080, 540, 1080, 8640, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 656640 . Total input tokens: 146503211 . Total output tokens: 128977697
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.702650025952607,
    "estimated_duration": 3600.0318501198117,
    "input_throughput": 3936.8146144396815,
    "output_throughput": 3466.457109146042,
    "total_throughput": 7403.2717235857235,
    "itl": 99.21661137766614,
    "ttft": 2011252.719350113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.47769602594039,
    "arrivals": 218234,
    "finished_requests": 57768,
    "scheduler_time": 116.04237147947738
}
#Debug simulation 
Total elapsed time: 4.702751060947776. Arrivals time: 0.21128619648516178 Scheduler time: 4.3052418942097574 Scheduler overhead time: 0.050911875907331705 Adapter cache time: 0.06038450845517218 Engine time: 0.051214877516031265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_192_slots_96_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_192_slots_96_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 8640, 8640, 540, 1080, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 1080, 540, 540, 540, 540, 540, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 540, 1080, 1080, 8640, 540, 540, 540, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 1080, 540, 8640, 1080, 540, 1080, 1080, 540, 1080, 8640, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 656640 . Total input tokens: 146503211 . Total output tokens: 128977697
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.721874058013782,
    "estimated_duration": 3600.0276412259977,
    "input_throughput": 4469.8248468225665,
    "output_throughput": 3921.8465542647405,
    "total_throughput": 8391.671401087307,
    "itl": 123.1856859624514,
    "ttft": 1908807.2051329915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.146902564773484,
    "arrivals": 218234,
    "finished_requests": 65539,
    "scheduler_time": 109.66831564536953
}
#Debug simulation 
Total elapsed time: 5.722001764923334. Arrivals time: 0.24923622398637235 Scheduler time: 5.333792460616678 Scheduler overhead time: 0.04327342100441456 Adapter cache time: 0.03256495203822851 Engine time: 0.04308811551891267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_192_slots_96_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_192_slots_96_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 8640, 8640, 540, 1080, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 1080, 540, 540, 540, 540, 540, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 540, 1080, 1080, 8640, 540, 540, 540, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 1080, 540, 8640, 1080, 540, 1080, 1080, 540, 1080, 8640, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 656640 . Total input tokens: 146503211 . Total output tokens: 128977697
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.672976976959035,
    "estimated_duration": 3600.02140654265,
    "input_throughput": 3940.5862904643077,
    "output_throughput": 3469.3754812960533,
    "total_throughput": 7409.9617717603605,
    "itl": 99.27497851007207,
    "ttft": 2011588.3145880138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.108326306301862,
    "arrivals": 218234,
    "finished_requests": 57820,
    "scheduler_time": 116.02616099189254
}
#Debug simulation 
Total elapsed time: 4.673069298034534. Arrivals time: 0.22855486907064915 Scheduler time: 4.261226966744289 Scheduler overhead time: 0.05080121639184654 Adapter cache time: 0.05798664526082575 Engine time: 0.050814367132261395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_192_slots_96_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_192_slots_96_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 8640, 8640, 540, 1080, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 1080, 540, 540, 540, 540, 540, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 540, 1080, 1080, 8640, 540, 540, 540, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 1080, 540, 8640, 1080, 540, 1080, 1080, 540, 1080, 8640, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 656640 . Total input tokens: 146503211 . Total output tokens: 128977697
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.712013238109648,
    "estimated_duration": 3600.07176350385,
    "input_throughput": 4470.3583865052,
    "output_throughput": 3922.680137424682,
    "total_throughput": 8393.038523929881,
    "itl": 123.14822066621231,
    "ttft": 1908721.4832870564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1784,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.388914957978242,
    "arrivals": 218234,
    "finished_requests": 65545,
    "scheduler_time": 109.69427103141243
}
#Debug simulation 
Total elapsed time: 5.712104784091935. Arrivals time: 0.2282511976081878 Scheduler time: 5.3446366682183 Scheduler overhead time: 0.04327846202068031 Adapter cache time: 0.0329698002897203 Engine time: 0.043052525259554386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_192_slots_96_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_192_slots_96_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [64 64 64]
Adapter prompts. [8640, 540, 8640, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 8640, 8640, 540, 1080, 8640, 540, 1080, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 540, 8640, 8640, 8640, 1080, 540, 540, 540, 540, 540, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 540, 1080, 1080, 8640, 540, 540, 540, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 1080, 1080, 8640, 1080, 540, 1080, 8640, 8640, 1080, 8640, 1080, 540, 8640, 1080, 540, 1080, 1080, 540, 1080, 8640, 540, 1080, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 1080, 540, 8640, 8640, 1080, 8640, 540, 8640, 8640, 8640, 540, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 656640 . Total input tokens: 146503211 . Total output tokens: 128977697
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.687756763072684,
    "estimated_duration": 3600.022848393541,
    "input_throughput": 3946.265509492395,
    "output_throughput": 3473.748508451949,
    "total_throughput": 7420.014017944343,
    "itl": 99.41743168180957,
    "ttft": 2011433.3961867522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.818529838100744,
    "arrivals": 218234,
    "finished_requests": 57894,
    "scheduler_time": 115.97229081528504
}
#Debug simulation 
Total elapsed time: 4.687849086942151. Arrivals time: 0.20892200409434736 Scheduler time: 4.295681931078434 Scheduler overhead time: 0.05063432874158025 Adapter cache time: 0.05845268117263913 Engine time: 0.050649280892685056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_192_slots_96_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_192_slots_96_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 8640, 8640, 270, 1080, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 1080, 270, 270, 270, 270, 270, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 270, 1080, 1080, 8640, 270, 270, 270, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 1080, 270, 8640, 1080, 270, 1080, 1080, 270, 1080, 8640, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 639360 . Total input tokens: 142594515 . Total output tokens: 125631008
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.666253197006881,
    "estimated_duration": 3600.022525945749,
    "input_throughput": 4658.944736906558,
    "output_throughput": 4071.817855125527,
    "total_throughput": 8730.762592032084,
    "itl": 134.3821174802661,
    "ttft": 1865883.985233018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.42115663435337,
    "arrivals": 212464,
    "finished_requests": 67792,
    "scheduler_time": 107.3077549498097
}
#Debug simulation 
Total elapsed time: 5.6664006020873785. Arrivals time: 0.23457190301269293 Scheduler time: 5.303325050044805 Scheduler overhead time: 0.040470379404723644 Adapter cache time: 0.029214730253443122 Engine time: 0.04026472754776478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_192_slots_96_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_192_slots_96_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 8640, 8640, 270, 1080, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 1080, 270, 270, 270, 270, 270, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 270, 1080, 1080, 8640, 270, 270, 270, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 1080, 270, 8640, 1080, 270, 1080, 1080, 270, 1080, 8640, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 639360 . Total input tokens: 142594515 . Total output tokens: 125631008
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.272286864928901,
    "estimated_duration": 3600.0367350381193,
    "input_throughput": 4480.851776594217,
    "output_throughput": 3913.7656187974453,
    "total_throughput": 8394.617395391662,
    "itl": 122.84504077468904,
    "ttft": 1902272.0706563385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1926,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.091789671005463,
    "arrivals": 212464,
    "finished_requests": 65152,
    "scheduler_time": 109.55946315762205
}
#Debug simulation 
Total elapsed time: 5.272410322912037. Arrivals time: 0.22102703992277384 Scheduler time: 4.909198764711618 Scheduler overhead time: 0.043470673728734255 Adapter cache time: 0.03506895317696035 Engine time: 0.043679086258634925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_192_slots_96_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_192_slots_96_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 8640, 8640, 270, 1080, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 1080, 270, 270, 270, 270, 270, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 270, 1080, 1080, 8640, 270, 270, 270, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 1080, 270, 8640, 1080, 270, 1080, 1080, 270, 1080, 8640, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 639360 . Total input tokens: 142594515 . Total output tokens: 125631008
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.671524336095899,
    "estimated_duration": 3600.0055827470705,
    "input_throughput": 3963.1657985132633,
    "output_throughput": 3461.047688290599,
    "total_throughput": 7424.213486803863,
    "itl": 98.99588693040954,
    "ttft": 2009137.7795714203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.43360121281437,
    "arrivals": 212464,
    "finished_requests": 57633,
    "scheduler_time": 115.91141568789338
}
#Debug simulation 
Total elapsed time: 4.671589156147093. Arrivals time: 0.20706186862662435 Scheduler time: 4.280172131489962 Scheduler overhead time: 0.05041992967016995 Adapter cache time: 0.05960474302992225 Engine time: 0.050754978554323316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_192_slots_96_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_192_slots_96_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 8640, 8640, 270, 1080, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 1080, 270, 270, 270, 270, 270, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 270, 1080, 1080, 8640, 270, 270, 270, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 1080, 270, 8640, 1080, 270, 1080, 1080, 270, 1080, 8640, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 639360 . Total input tokens: 142594515 . Total output tokens: 125631008
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.300843809032813,
    "estimated_duration": 3600.052551090977,
    "input_throughput": 4482.4901222927165,
    "output_throughput": 3914.334527069487,
    "total_throughput": 8396.824649362205,
    "itl": 122.81002535162186,
    "ttft": 1902126.7758367294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1924,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.15169021895178,
    "arrivals": 212464,
    "finished_requests": 65174,
    "scheduler_time": 109.5876446756382
}
#Debug simulation 
Total elapsed time: 5.3009352521039546. Arrivals time: 0.22323274426162243 Scheduler time: 4.935850083827972 Scheduler overhead time: 0.043689896585419774 Adapter cache time: 0.034615874756127596 Engine time: 0.04344297596253455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_192_slots_96_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_192_slots_96_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 8640, 8640, 270, 1080, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 1080, 270, 270, 270, 270, 270, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 270, 1080, 1080, 8640, 270, 270, 270, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 1080, 270, 8640, 1080, 270, 1080, 1080, 270, 1080, 8640, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 639360 . Total input tokens: 142594515 . Total output tokens: 125631008
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.456071685999632,
    "estimated_duration": 3600.025078065431,
    "input_throughput": 3963.144614444457,
    "output_throughput": 3460.739225376463,
    "total_throughput": 7423.88383982092,
    "itl": 98.9677596740011,
    "ttft": 2009243.5608182687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.18541961446953,
    "arrivals": 212464,
    "finished_requests": 57628,
    "scheduler_time": 115.92860176879876
}
#Debug simulation 
Total elapsed time: 4.456167197786272. Arrivals time: 0.2120407687034458 Scheduler time: 4.059488755185157 Scheduler overhead time: 0.050754489842802286 Adapter cache time: 0.059429368702694774 Engine time: 0.05088400328531861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_192_slots_96_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_192_slots_96_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 8640, 8640, 270, 1080, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 1080, 270, 270, 270, 270, 270, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 270, 1080, 1080, 8640, 270, 270, 270, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 1080, 270, 8640, 1080, 270, 1080, 1080, 270, 1080, 8640, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 639360 . Total input tokens: 142594515 . Total output tokens: 125631008
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.288725696038455,
    "estimated_duration": 3600.007237763203,
    "input_throughput": 4482.539321233846,
    "output_throughput": 3914.4512967023456,
    "total_throughput": 8396.990617936191,
    "itl": 122.79840365926921,
    "ttft": 1901538.116969238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1925,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.289047810598808,
    "arrivals": 212464,
    "finished_requests": 65174,
    "scheduler_time": 109.60797285332569
}
#Debug simulation 
Total elapsed time: 5.288815166102722. Arrivals time: 0.2214196971617639 Scheduler time: 4.926165081793442 Scheduler overhead time: 0.04362926841713488 Adapter cache time: 0.034625540021806955 Engine time: 0.04302766406908631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_192_slots_96_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_192_slots_96_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 8640, 8640, 270, 1080, 8640, 270, 1080, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 1080, 270, 270, 270, 270, 270, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 270, 1080, 1080, 8640, 270, 270, 270, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 1080, 1080, 8640, 1080, 270, 1080, 8640, 8640, 1080, 8640, 1080, 270, 8640, 1080, 270, 1080, 1080, 270, 1080, 8640, 270, 1080, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 1080, 270, 8640, 8640, 1080, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 639360 . Total input tokens: 142594515 . Total output tokens: 125631008
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.432042037835345,
    "estimated_duration": 3600.0051186564683,
    "input_throughput": 3954.6929881347655,
    "output_throughput": 3452.8073128515316,
    "total_throughput": 7407.500300986298,
    "itl": 98.62025657701588,
    "ttft": 2010409.3115202216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3566,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.28870452147062,
    "arrivals": 212464,
    "finished_requests": 57498,
    "scheduler_time": 116.06231762666766
}
#Debug simulation 
Total elapsed time: 4.432134178001434. Arrivals time: 0.2055386113934219 Scheduler time: 4.040715702576563 Scheduler overhead time: 0.05080045061185956 Adapter cache time: 0.06026004790328443 Engine time: 0.051103699719533324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 8640, 8640, 135, 1080, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 1080, 135, 135, 135, 135, 135, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 135, 1080, 1080, 8640, 135, 135, 135, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 1080, 135, 8640, 1080, 135, 1080, 1080, 135, 1080, 8640, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 630720 . Total input tokens: 140669414 . Total output tokens: 123916359
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.413514168001711,
    "estimated_duration": 3600.031236922909,
    "input_throughput": 4660.724837027102,
    "output_throughput": 4076.5735167742564,
    "total_throughput": 8737.298353801358,
    "itl": 134.69974597107756,
    "ttft": 1857852.4610148405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.282296044682417,
    "arrivals": 209539,
    "finished_requests": 67895,
    "scheduler_time": 107.1317272228034
}
#Debug simulation 
Total elapsed time: 5.413615824887529. Arrivals time: 0.23409808962605894 Scheduler time: 5.051213386934251 Scheduler overhead time: 0.040720966877415776 Adapter cache time: 0.0285676340572536 Engine time: 0.04043648159131408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 8640, 8640, 135, 1080, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 1080, 135, 135, 135, 135, 135, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 135, 1080, 1080, 8640, 135, 135, 135, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 1080, 135, 8640, 1080, 135, 1080, 1080, 135, 1080, 8640, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 630720 . Total input tokens: 140669414 . Total output tokens: 123916359
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.077584573999047,
    "estimated_duration": 3600.0001782702743,
    "input_throughput": 4482.501444695344,
    "output_throughput": 3920.670916961367,
    "total_throughput": 8403.17236165671,
    "itl": 123.16912123060554,
    "ttft": 1894643.214284809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1899,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.88888294419716,
    "arrivals": 209539,
    "finished_requests": 65274,
    "scheduler_time": 109.36388282557756
}
#Debug simulation 
Total elapsed time: 5.077718164073303. Arrivals time: 0.22369745140895247 Scheduler time: 4.714297530241311 Scheduler overhead time: 0.04310925188474357 Adapter cache time: 0.0337963595520705 Engine time: 0.04286704305559397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 8640, 8640, 135, 1080, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 1080, 135, 135, 135, 135, 135, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 135, 1080, 1080, 8640, 135, 135, 135, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 1080, 135, 8640, 1080, 135, 1080, 1080, 135, 1080, 8640, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 630720 . Total input tokens: 140669414 . Total output tokens: 123916359
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.353331601945683,
    "estimated_duration": 3600.045470372271,
    "input_throughput": 3962.524395150172,
    "output_throughput": 3467.3856490788135,
    "total_throughput": 7429.9100442289855,
    "itl": 99.1225666787366,
    "ttft": 2001907.222480115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.18385279942388,
    "arrivals": 209539,
    "finished_requests": 57685,
    "scheduler_time": 115.71227575547583
}
#Debug simulation 
Total elapsed time: 4.353427053894848. Arrivals time: 0.21069763298146427 Scheduler time: 3.95813584048301 Scheduler overhead time: 0.05049889977090061 Adapter cache time: 0.05961117381229997 Engine time: 0.0510083450935781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 8640, 8640, 135, 1080, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 1080, 135, 135, 135, 135, 135, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 135, 1080, 1080, 8640, 135, 135, 135, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 1080, 135, 8640, 1080, 135, 1080, 1080, 135, 1080, 8640, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 630720 . Total input tokens: 140669414 . Total output tokens: 123916359
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.081565534928814,
    "estimated_duration": 3600.0092205507135,
    "input_throughput": 4479.031028018683,
    "output_throughput": 3918.50885255289,
    "total_throughput": 8397.539880571572,
    "itl": 122.94635984059414,
    "ttft": 1894419.1819952722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1865,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.737556917178633,
    "arrivals": 209539,
    "finished_requests": 65225,
    "scheduler_time": 109.44721050291668
}
#Debug simulation 
Total elapsed time: 5.081655954942107. Arrivals time: 0.21400753082707524 Scheduler time: 4.727478955173865 Scheduler overhead time: 0.04341016849502921 Adapter cache time: 0.03350643673911691 Engine time: 0.0431045270524919 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 8640, 8640, 135, 1080, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 1080, 135, 135, 135, 135, 135, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 135, 1080, 1080, 8640, 135, 135, 135, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 1080, 135, 8640, 1080, 135, 1080, 1080, 135, 1080, 8640, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 630720 . Total input tokens: 140669414 . Total output tokens: 123916359
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.317003421019763,
    "estimated_duration": 3600.0707533591294,
    "input_throughput": 3947.063536665579,
    "output_throughput": 3453.860174386305,
    "total_throughput": 7400.923711051884,
    "itl": 98.46630394233748,
    "ttft": 2004789.0868229624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.671012667930437,
    "arrivals": 209539,
    "finished_requests": 57461,
    "scheduler_time": 115.97037543185299
}
#Debug simulation 
Total elapsed time: 4.3170848451554775. Arrivals time: 0.1846296803560108 Scheduler time: 3.9508256032131612 Scheduler overhead time: 0.05053236591629684 Adapter cache time: 0.05629450595006347 Engine time: 0.05120742251165211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 8640, 8640, 135, 1080, 8640, 135, 1080, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 1080, 135, 135, 135, 135, 135, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 135, 1080, 1080, 8640, 135, 135, 135, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 1080, 1080, 8640, 1080, 135, 1080, 8640, 8640, 1080, 8640, 1080, 135, 8640, 1080, 135, 1080, 1080, 135, 1080, 8640, 135, 1080, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 1080, 135, 8640, 8640, 1080, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 630720 . Total input tokens: 140669414 . Total output tokens: 123916359
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.067975655896589,
    "estimated_duration": 3600.085249061051,
    "input_throughput": 4485.337674770758,
    "output_throughput": 3923.71680745176,
    "total_throughput": 8409.054482222518,
    "itl": 123.15727573747137,
    "ttft": 1894251.9249460169,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.989003526391953,
    "arrivals": 209539,
    "finished_requests": 65325,
    "scheduler_time": 109.40888324038751
}
#Debug simulation 
Total elapsed time: 5.068055619951338. Arrivals time: 0.20210217707790434 Scheduler time: 4.726148545043543 Scheduler overhead time: 0.043140332447364926 Adapter cache time: 0.033482766011729836 Engine time: 0.043211628682911396 
