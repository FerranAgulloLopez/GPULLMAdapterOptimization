INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10038919 . Total output tokens: 8932037
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.4678810657933354,
    "estimated_duration": 3599.7477765088142,
    "input_throughput": 1052.9093245738184,
    "output_throughput": 911.0091049713772,
    "total_throughput": 1963.9184295451955,
    "itl": 25.540942946265897,
    "ttft": 6603.193675521072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.945063184052959,
    "arrivals": 15365,
    "finished_requests": 15337,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.4679756606929004. Arrivals time: 0.046643408481031656 Scheduler time: 1.0463616638444364 Scheduler overhead time: 0.1234771222807467 Adapter cache time: 0.07043136050924659 Engine time: 0.12153595127165318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10038919 . Total output tokens: 8932037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.473481907043606,
    "estimated_duration": 3599.738807201219,
    "input_throughput": 1052.9119480607178,
    "output_throughput": 911.0113748918692,
    "total_throughput": 1963.923322952587,
    "itl": 25.551888357074805,
    "ttft": 6603.460407626343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.98769266303152,
    "arrivals": 15365,
    "finished_requests": 15337,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.47357123112306. Arrivals time: 0.0461825798265636 Scheduler time: 1.0530058941803873 Scheduler overhead time: 0.12394017912447453 Adapter cache time: 0.07185749616473913 Engine time: 0.11926931794732809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10038919 . Total output tokens: 8932037
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4987238100729883,
    "estimated_duration": 3599.7345681946344,
    "input_throughput": 1052.9131879578813,
    "output_throughput": 911.0124476885279,
    "total_throughput": 1963.9256356464093,
    "itl": 25.553936180475702,
    "ttft": 6603.506363278056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.287657626708834,
    "arrivals": 15365,
    "finished_requests": 15337,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.4988028341904283. Arrivals time: 0.04720596829429269 Scheduler time: 1.0765557903796434 Scheduler overhead time: 0.12321701878681779 Adapter cache time: 0.07177287992089987 Engine time: 0.12059796415269375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10038919 . Total output tokens: 8932037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.4796222737058997,
    "estimated_duration": 3599.7332385415853,
    "input_throughput": 1052.9135768781534,
    "output_throughput": 911.0127841941517,
    "total_throughput": 1963.9263610723053,
    "itl": 25.544329010237682,
    "ttft": 6603.265847123095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.318012969968919,
    "arrivals": 15365,
    "finished_requests": 15337,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.4797039958648384. Arrivals time: 0.04690167726948857 Scheduler time: 1.0568423131480813 Scheduler overhead time: 0.12419728143140674 Adapter cache time: 0.07188899349421263 Engine time: 0.12085825111716986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10038919 . Total output tokens: 8932037
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.488739504944533,
    "estimated_duration": 3599.738199183162,
    "input_throughput": 1052.9121259040612,
    "output_throughput": 911.0115287673278,
    "total_throughput": 1963.923654671389,
    "itl": 25.553057060634377,
    "ttft": 6603.258276951227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.180424294718408,
    "arrivals": 15365,
    "finished_requests": 15337,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.4888190347701311. Arrivals time: 0.04731522686779499 Scheduler time: 1.0669560162350535 Scheduler overhead time: 0.1234453939832747 Adapter cache time: 0.07152819260954857 Engine time: 0.12058513099327683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10038919 . Total output tokens: 8932037
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.4831654811277986,
    "estimated_duration": 3599.7277489686803,
    "input_throughput": 1052.915182567874,
    "output_throughput": 911.0141734856329,
    "total_throughput": 1963.9293560535068,
    "itl": 25.539736541840472,
    "ttft": 6603.159051747815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.614184936499397,
    "arrivals": 15365,
    "finished_requests": 15337,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.4832451161928475. Arrivals time: 0.046522899996489286 Scheduler time: 1.0598972835578024 Scheduler overhead time: 0.1242543701082468 Adapter cache time: 0.07193484110757709 Engine time: 0.1212320071645081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10038919 . Total output tokens: 8932037
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5250689489766955,
    "estimated_duration": 3599.7382516532057,
    "input_throughput": 1052.9121105567383,
    "output_throughput": 911.0115154883582,
    "total_throughput": 1963.9236260450966,
    "itl": 25.551738572687402,
    "ttft": 6603.340515387499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.075415886174756,
    "arrivals": 15365,
    "finished_requests": 15337,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.5251507661305368. Arrivals time: 0.047704669181257486 Scheduler time: 1.101532676257193 Scheduler overhead time: 0.12239074660465121 Adapter cache time: 0.073523233179003 Engine time: 0.12112859357148409 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9794058 . Total output tokens: 8729348
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.5143522741273046,
    "estimated_duration": 3599.7542773132104,
    "input_throughput": 1016.6377252648177,
    "output_throughput": 896.1628354277007,
    "total_throughput": 1912.8005606925183,
    "itl": 25.32782804758517,
    "ttft": 6760.915396707341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 822,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.435400224262956,
    "arrivals": 15003,
    "finished_requests": 14975,
    "scheduler_time": 3.3359440361056163e-06
}
#Debug simulation 
Total elapsed time: 1.5144331492483616. Arrivals time: 0.047096113208681345 Scheduler time: 1.0885321386158466 Scheduler overhead time: 0.12497879890725017 Adapter cache time: 0.06902637239545584 Engine time: 0.12432962004095316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9794058 . Total output tokens: 8729348
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5116004780866206,
    "estimated_duration": 3599.7479100860032,
    "input_throughput": 1016.6395234916786,
    "output_throughput": 896.1644205588071,
    "total_throughput": 1912.8039440504856,
    "itl": 25.330783741014137,
    "ttft": 6760.978651738612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 822,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.999998780684554,
    "arrivals": 15003,
    "finished_requests": 14975,
    "scheduler_time": 3.3359440361056163e-06
}
#Debug simulation 
Total elapsed time: 1.51168138301. Arrivals time: 0.04666973510757089 Scheduler time: 1.0905234534293413 Scheduler overhead time: 0.12419599015265703 Adapter cache time: 0.06932372180745006 Engine time: 0.12177568208426237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9794058 . Total output tokens: 8729348
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.48863691277802,
    "estimated_duration": 3599.74463923655,
    "input_throughput": 1016.6404472446562,
    "output_throughput": 896.1652348440408,
    "total_throughput": 1912.805682088697,
    "itl": 25.332050219561697,
    "ttft": 6760.8094335438855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 822,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.1600665226672096,
    "arrivals": 15003,
    "finished_requests": 14975,
    "scheduler_time": 3.3359440361056163e-06
}
#Debug simulation 
Total elapsed time: 1.4887198880314827. Arrivals time: 0.046845469158142805 Scheduler time: 1.0662681837566197 Scheduler overhead time: 0.12482343474403024 Adapter cache time: 0.06901622842997313 Engine time: 0.1216607317328453 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9794058 . Total output tokens: 8729348
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.5109166321344674,
    "estimated_duration": 3599.748643735058,
    "input_throughput": 1016.6393162948158,
    "output_throughput": 896.1642379154491,
    "total_throughput": 1912.803554210265,
    "itl": 25.46228895524065,
    "ttft": 6761.030139975821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 822,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.633508443729944,
    "arrivals": 15003,
    "finished_requests": 14975,
    "scheduler_time": 3.3359440361056163e-06
}
#Debug simulation 
Total elapsed time: 1.5110214203596115. Arrivals time: 0.04716035118326545 Scheduler time: 1.0872273314744234 Scheduler overhead time: 0.1245086113922298 Adapter cache time: 0.06819325312972069 Engine time: 0.12422863533720374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9794058 . Total output tokens: 8729348
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5219266028143466,
    "estimated_duration": 3599.75173777277,
    "input_throughput": 1016.6384424788937,
    "output_throughput": 896.1634676495669,
    "total_throughput": 1912.8019101284606,
    "itl": 25.333774420256898,
    "ttft": 6760.860675576923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 822,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.105387588040928,
    "arrivals": 15003,
    "finished_requests": 14975,
    "scheduler_time": 3.3359440361056163e-06
}
#Debug simulation 
Total elapsed time: 1.5220300308428705. Arrivals time: 0.047103787772357464 Scheduler time: 1.0917268255725503 Scheduler overhead time: 0.12465561181306839 Adapter cache time: 0.06931672338396311 Engine time: 0.12722032004967332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9794058 . Total output tokens: 8729348
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.5310247158631682,
    "estimated_duration": 3599.7434930695335,
    "input_throughput": 1016.6407709454284,
    "output_throughput": 896.1655201852146,
    "total_throughput": 1912.806291130643,
    "itl": 25.325508400949683,
    "ttft": 6760.766161526155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 822,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.247583013148953,
    "arrivals": 15003,
    "finished_requests": 14975,
    "scheduler_time": 3.3359440361056163e-06
}
#Debug simulation 
Total elapsed time: 1.5311041758395731. Arrivals time: 0.04728570953011513 Scheduler time: 1.107959220185876 Scheduler overhead time: 0.12416542647406459 Adapter cache time: 0.06916425842791796 Engine time: 0.122765873093158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9794058 . Total output tokens: 8729348
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5146515821106732,
    "estimated_duration": 3599.7466103748875,
    "input_throughput": 1016.6398905557618,
    "output_throughput": 896.164744124598,
    "total_throughput": 1912.8046346803599,
    "itl": 25.331724760633595,
    "ttft": 6760.976911985488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 822,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.047809012942041,
    "arrivals": 15003,
    "finished_requests": 14975,
    "scheduler_time": 3.3359440361056163e-06
}
#Debug simulation 
Total elapsed time: 1.5147288353182375. Arrivals time: 0.04794826125726104 Scheduler time: 1.086206085048616 Scheduler overhead time: 0.1252310387790203 Adapter cache time: 0.06936307530850172 Engine time: 0.12553568463772535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9071342 . Total output tokens: 8100246
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.412305561825633,
    "estimated_duration": 3599.9315686427217,
    "input_throughput": 938.8267347743638,
    "output_throughput": 833.6836250283337,
    "total_throughput": 1772.5103598026976,
    "itl": 24.87151776839587,
    "ttft": 5222.936009142281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1123,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.4257353428799515,
    "arrivals": 13896,
    "finished_requests": 13876,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4123759348876774. Arrivals time: 0.04452002188190818 Scheduler time: 0.9884857446886599 Scheduler overhead time: 0.128052547108382 Adapter cache time: 0.0653901812620461 Engine time: 0.12489504087716341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9071342 . Total output tokens: 8100246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4023927301168442,
    "estimated_duration": 3599.9347250885717,
    "input_throughput": 938.825911605063,
    "output_throughput": 833.6828940491856,
    "total_throughput": 1772.5088056542486,
    "itl": 24.8792828454097,
    "ttft": 5222.97978971311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.227524781851097,
    "arrivals": 13896,
    "finished_requests": 13876,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4024520902894437. Arrivals time: 0.04422694118693471 Scheduler time: 0.9817686770111322 Scheduler overhead time: 0.12702832790091634 Adapter cache time: 0.0654989411123097 Engine time: 0.12341057555750012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9071342 . Total output tokens: 8100246
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4455307549796999,
    "estimated_duration": 3599.9269587795065,
    "input_throughput": 938.8279369828751,
    "output_throughput": 833.684692596515,
    "total_throughput": 1772.5126295793903,
    "itl": 24.881019859337353,
    "ttft": 5222.885408703859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1123,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.46280412854626,
    "arrivals": 13896,
    "finished_requests": 13876,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4456123909913003. Arrivals time: 0.045487833209335804 Scheduler time: 1.0235241907648742 Scheduler overhead time: 0.1258158697746694 Adapter cache time: 0.06591723207384348 Engine time: 0.12400886230170727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9071342 . Total output tokens: 8100246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.4433610853739083,
    "estimated_duration": 3599.939156018165,
    "input_throughput": 938.8247560656679,
    "output_throughput": 833.6818679234523,
    "total_throughput": 1772.5066239891203,
    "itl": 24.873674201232852,
    "ttft": 5222.836246255798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.690283265179011,
    "arrivals": 13896,
    "finished_requests": 13876,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4434222751297057. Arrivals time: 0.04478392703458667 Scheduler time: 1.0222337367013097 Scheduler overhead time: 0.1257243030704558 Adapter cache time: 0.06587479310110211 Engine time: 0.12377653457224369 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9071342 . Total output tokens: 8100246
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4011618816293776,
    "estimated_duration": 3599.9392257415525,
    "input_throughput": 938.8247378825714,
    "output_throughput": 833.6818517767564,
    "total_throughput": 1772.5065896593278,
    "itl": 24.88166259362807,
    "ttft": 5222.802279544088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1123,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.382442664019761,
    "arrivals": 13896,
    "finished_requests": 13876,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4012322137132287. Arrivals time: 0.0442361356690526 Scheduler time: 0.9740375080145895 Scheduler overhead time: 0.1313578258268535 Adapter cache time: 0.06537746917456388 Engine time: 0.12493307702243328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9071342 . Total output tokens: 8100246
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.4234618190675974,
    "estimated_duration": 3599.949779247414,
    "input_throughput": 938.821985651851,
    "output_throughput": 833.6794077797983,
    "total_throughput": 1772.5013934316494,
    "itl": 24.86917179887264,
    "ttft": 5222.780078185626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1123,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.1691432162606725,
    "arrivals": 13896,
    "finished_requests": 13876,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4235341851599514. Arrivals time: 0.044439494609832764 Scheduler time: 1.0018262835219502 Scheduler overhead time: 0.12693780101835728 Adapter cache time: 0.06574216950684786 Engine time: 0.12377634970471263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9071342 . Total output tokens: 8100246
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4275455409660935,
    "estimated_duration": 3599.9399049664357,
    "input_throughput": 938.8245607481914,
    "output_throughput": 833.6816944803921,
    "total_throughput": 1772.5062552285835,
    "itl": 24.87979539139731,
    "ttft": 5222.880063036165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.295869180709124,
    "arrivals": 13896,
    "finished_requests": 13876,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.427613175008446. Arrivals time: 0.044557271525263786 Scheduler time: 0.9988282541744411 Scheduler overhead time: 0.13103818939998746 Adapter cache time: 0.06589230382815003 Engine time: 0.12563915131613612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8842285 . Total output tokens: 7885916
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.377269291318953,
    "estimated_duration": 3599.994218459545,
    "input_throughput": 932.3337195347547,
    "output_throughput": 805.7543495837135,
    "total_throughput": 1738.0880691184682,
    "itl": 24.451074317829782,
    "ttft": 6161.886557979906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.7014228217164895,
    "arrivals": 13527,
    "finished_requests": 13504,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.377336106263101. Arrivals time: 0.04332932783290744 Scheduler time: 0.9570869999006391 Scheduler overhead time: 0.12819570302963257 Adapter cache time: 0.06254323478788137 Engine time: 0.12433049269020557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8842285 . Total output tokens: 7885916
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3852801099419594,
    "estimated_duration": 3599.988322939018,
    "input_throughput": 932.3352463709799,
    "output_throughput": 805.7556691272458,
    "total_throughput": 1738.0909154982257,
    "itl": 24.454792685668423,
    "ttft": 6161.983526741359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.190043425229385,
    "arrivals": 13527,
    "finished_requests": 13504,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.385341675952077. Arrivals time: 0.043860507663339376 Scheduler time: 0.9632899798452854 Scheduler overhead time: 0.1269958559423685 Adapter cache time: 0.06288531795144081 Engine time: 0.12669843761250377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8842285 . Total output tokens: 7885916
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3761787652038038,
    "estimated_duration": 3599.991712970381,
    "input_throughput": 932.3343684118128,
    "output_throughput": 805.7549103652244,
    "total_throughput": 1738.0892787770372,
    "itl": 24.455649106137187,
    "ttft": 6162.0651551511255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.328557021184854,
    "arrivals": 13527,
    "finished_requests": 13504,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3762392401695251. Arrivals time: 0.043649458326399326 Scheduler time: 0.956821602769196 Scheduler overhead time: 0.128106283955276 Adapter cache time: 0.062036531046032906 Engine time: 0.12428658781573176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8842285 . Total output tokens: 7885916
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.38389782467857,
    "estimated_duration": 3599.98384992981,
    "input_throughput": 932.3364048051051,
    "output_throughput": 805.7566702852171,
    "total_throughput": 1738.0930750903221,
    "itl": 24.452446794899465,
    "ttft": 6162.047662609258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.845764623847782,
    "arrivals": 13527,
    "finished_requests": 13504,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3839651457965374. Arrivals time: 0.044829458463937044 Scheduler time: 0.9581792955286801 Scheduler overhead time: 0.13184370612725616 Adapter cache time: 0.06315953051671386 Engine time: 0.1238808031193912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8842285 . Total output tokens: 7885916
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3813690058887005,
    "estimated_duration": 3599.980270345249,
    "input_throughput": 932.3373318593525,
    "output_throughput": 805.7574714768681,
    "total_throughput": 1738.0948033362206,
    "itl": 24.455402703573178,
    "ttft": 6161.934889820594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.277191961384409,
    "arrivals": 13527,
    "finished_requests": 13504,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.381440158933401. Arrivals time: 0.04334910400211811 Scheduler time: 0.962026187684387 Scheduler overhead time: 0.12730403058230877 Adapter cache time: 0.06287914235144854 Engine time: 0.12455688742920756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8842285 . Total output tokens: 7885916
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.3671906809322536,
    "estimated_duration": 3599.981811212535,
    "input_throughput": 932.3369327995324,
    "output_throughput": 805.7571265958678,
    "total_throughput": 1738.0940593954,
    "itl": 24.449851426051403,
    "ttft": 6161.930955583962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.5389677887456275,
    "arrivals": 13527,
    "finished_requests": 13504,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3672649888321757. Arrivals time: 0.04312497470527887 Scheduler time: 0.9487085705623031 Scheduler overhead time: 0.12705699307844043 Adapter cache time: 0.06269735423848033 Engine time: 0.12424192950129509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8842285 . Total output tokens: 7885916
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3988350569270551,
    "estimated_duration": 3599.9805331222055,
    "input_throughput": 932.3372638043271,
    "output_throughput": 805.7574126614123,
    "total_throughput": 1738.0946764657394,
    "itl": 24.455441485139737,
    "ttft": 6161.911776730113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.2314190653525605,
    "arrivals": 13527,
    "finished_requests": 13504,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3989079468883574. Arrivals time: 0.04377498337998986 Scheduler time: 0.9764545108191669 Scheduler overhead time: 0.12817321298643947 Adapter cache time: 0.06277680117636919 Engine time: 0.12611671816557646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8351156 . Total output tokens: 7442954
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.3214085437357426,
    "estimated_duration": 3599.8319168871412,
    "input_throughput": 874.9983534574988,
    "output_throughput": 757.8603843145855,
    "total_throughput": 1632.8587377720842,
    "itl": 24.117768836371397,
    "ttft": 5696.723428121509,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4186154695181608,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3215068667195737. Arrivals time: 0.04146701795980334 Scheduler time: 0.9028800674714148 Scheduler overhead time: 0.1309753730893135 Adapter cache time: 0.05859507992863655 Engine time: 0.1251553613692522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8351156 . Total output tokens: 7442954
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3432514001615345,
    "estimated_duration": 3599.8455126061494,
    "input_throughput": 874.9950488068673,
    "output_throughput": 757.8575220648594,
    "total_throughput": 1632.8525708717268,
    "itl": 24.120031338231936,
    "ttft": 5696.850062478326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.779423362067906,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3433501403778791. Arrivals time: 0.0441212491132319 Scheduler time: 0.9085617726668715 Scheduler overhead time: 0.1426150444895029 Adapter cache time: 0.058916236739605665 Engine time: 0.12645578291267157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8351156 . Total output tokens: 7442954
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3355956142768264,
    "estimated_duration": 3599.8360268124807,
    "input_throughput": 874.99735447369,
    "output_throughput": 757.8595190669537,
    "total_throughput": 1632.8568735406436,
    "itl": 24.120710992635665,
    "ttft": 5696.8801402977615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8814152343152433,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3356709629297256. Arrivals time: 0.04255828959867358 Scheduler time: 0.9104870087467134 Scheduler overhead time: 0.13384801940992475 Adapter cache time: 0.05896814865991473 Engine time: 0.12670643394812942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8351156 . Total output tokens: 7442954
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.3290705592371523,
    "estimated_duration": 3599.8455566957296,
    "input_throughput": 874.9950380902508,
    "output_throughput": 757.8575127829001,
    "total_throughput": 1632.852550873151,
    "itl": 24.11854122221503,
    "ttft": 5696.783903883052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.540649354658085,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3291342742741108. Arrivals time: 0.0417898646555841 Scheduler time: 0.9106951178982854 Scheduler overhead time: 0.12937100743874907 Adapter cache time: 0.05889005772769451 Engine time: 0.12629941431805491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8351156 . Total output tokens: 7442954
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.310832231771201,
    "estimated_duration": 3599.8451964665687,
    "input_throughput": 874.9951256492183,
    "output_throughput": 757.8575886201545,
    "total_throughput": 1632.8527142693727,
    "itl": 24.120841198162264,
    "ttft": 5696.920966116896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8457910799375146,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3109053787775338. Arrivals time: 0.041616144590079784 Scheduler time: 0.8948639137670398 Scheduler overhead time: 0.12878439715132117 Adapter cache time: 0.0586836296133697 Engine time: 0.12477551866322756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8351156 . Total output tokens: 7442954
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.3254727637395263,
    "estimated_duration": 3599.843061122607,
    "input_throughput": 874.9956446761664,
    "output_throughput": 757.8580381638146,
    "total_throughput": 1632.853682839981,
    "itl": 24.11679128652174,
    "ttft": 5696.801037520838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.300487126274951,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3255430827848613. Arrivals time: 0.04176233196631074 Scheduler time: 0.9050177060998976 Scheduler overhead time: 0.1297073196619749 Adapter cache time: 0.058890742249786854 Engine time: 0.12767911283299327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8351156 . Total output tokens: 7442954
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.316311917733401,
    "estimated_duration": 3599.828140322408,
    "input_throughput": 874.9992714146329,
    "output_throughput": 757.8611793827633,
    "total_throughput": 1632.8604507973962,
    "itl": 24.120840237104197,
    "ttft": 5696.886979619044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8099598083831703,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3163861706852913. Arrivals time: 0.04128375602886081 Scheduler time: 0.8988730902783573 Scheduler overhead time: 0.1297985059209168 Adapter cache time: 0.05883008148521185 Engine time: 0.1253611552529037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_96_slots_64_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_96_slots_64_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6689008 . Total output tokens: 5959246
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.1849067388102412,
    "estimated_duration": 3599.8788064218124,
    "input_throughput": 689.452932574414,
    "output_throughput": 611.82893048259,
    "total_throughput": 1301.281863057004,
    "itl": 23.435768948152194,
    "ttft": 5701.373951370012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.658184587657889,
    "arrivals": 10175,
    "finished_requests": 10159,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1849639089778066. Arrivals time: 0.03711612103506923 Scheduler time: 0.7584533579647541 Scheduler overhead time: 0.13086614990606904 Adapter cache time: 0.06608464755117893 Engine time: 0.12878235382959247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_96_slots_64_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_96_slots_64_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6689008 . Total output tokens: 5959246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.191735444124788,
    "estimated_duration": 3599.889808852033,
    "input_throughput": 689.4508253827544,
    "output_throughput": 611.8270605350438,
    "total_throughput": 1301.2778859177981,
    "itl": 23.448901115873166,
    "ttft": 5701.472926023953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.304961041211747,
    "arrivals": 10175,
    "finished_requests": 10159,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1917997980490327. Arrivals time: 0.03661970654502511 Scheduler time: 0.7630838169716299 Scheduler overhead time: 0.1315686348825693 Adapter cache time: 0.06574086053296924 Engine time: 0.13110217079520226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_96_slots_64_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_96_slots_64_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6689008 . Total output tokens: 5959246
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.174415037035942,
    "estimated_duration": 3599.894213185791,
    "input_throughput": 689.4499818658717,
    "output_throughput": 611.8263119878873,
    "total_throughput": 1301.276293853759,
    "itl": 23.65939567124428,
    "ttft": 5701.742219361611,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.73752687362942,
    "arrivals": 10175,
    "finished_requests": 10159,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.17448720196262. Arrivals time: 0.036150278989225626 Scheduler time: 0.7515954123809934 Scheduler overhead time: 0.13103485014289618 Adapter cache time: 0.0650445413775742 Engine time: 0.12778535019606352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_96_slots_64_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_96_slots_64_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6689008 . Total output tokens: 5959246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.1991544826887548,
    "estimated_duration": 3599.8912058590963,
    "input_throughput": 689.4505578280929,
    "output_throughput": 611.8268231037782,
    "total_throughput": 1301.277380931871,
    "itl": 23.440456846776637,
    "ttft": 5701.319115234635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.227701565921624,
    "arrivals": 10175,
    "finished_requests": 10159,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1992146046832204. Arrivals time: 0.03690631687641144 Scheduler time: 0.7675267644226551 Scheduler overhead time: 0.13155235117301345 Adapter cache time: 0.06567443907260895 Engine time: 0.13360469415783882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_96_slots_64_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_96_slots_64_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6689008 . Total output tokens: 5959246
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1702832118608057,
    "estimated_duration": 3599.8970203410054,
    "input_throughput": 689.449444241295,
    "output_throughput": 611.8258348932893,
    "total_throughput": 1301.2752791345843,
    "itl": 23.65803539756154,
    "ttft": 5701.782245004698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.575614607012692,
    "arrivals": 10175,
    "finished_requests": 10159,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1703417138196528. Arrivals time: 0.03623583307489753 Scheduler time: 0.7492310721427202 Scheduler overhead time: 0.1309568122960627 Adapter cache time: 0.06509826937690377 Engine time: 0.12601879006251693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_96_slots_64_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_96_slots_64_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6689008 . Total output tokens: 5959246
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.1773616732098162,
    "estimated_duration": 3599.8863950456675,
    "input_throughput": 689.4514791955023,
    "output_throughput": 611.8276407364403,
    "total_throughput": 1301.2791199319427,
    "itl": 23.430897932051426,
    "ttft": 5701.108875147004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.117124787271932,
    "arrivals": 10175,
    "finished_requests": 10159,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1774318902753294. Arrivals time: 0.03659259108826518 Scheduler time: 0.7540721702389419 Scheduler overhead time: 0.13091328740119934 Adapter cache time: 0.0650531048886478 Engine time: 0.12730663688853383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_96_slots_64_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_96_slots_64_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6689008 . Total output tokens: 5959246
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1826674910262227,
    "estimated_duration": 3599.893459499009,
    "input_throughput": 689.4501262116263,
    "output_throughput": 611.8264400820683,
    "total_throughput": 1301.2765662936945,
    "itl": 23.448892805796888,
    "ttft": 5701.483790296396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.436481457780882,
    "arrivals": 10175,
    "finished_requests": 10159,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1827171337790787. Arrivals time: 0.03678950108587742 Scheduler time: 0.7563341185450554 Scheduler overhead time: 0.1313289673998952 Adapter cache time: 0.06538528529927135 Engine time: 0.12929901713505387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6199612 . Total output tokens: 5515691
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.1355322008021176,
    "estimated_duration": 3599.9933044533514,
    "input_throughput": 648.1509277013255,
    "output_throughput": 576.8719062424329,
    "total_throughput": 1225.0228339437583,
    "itl": 23.31862294376331,
    "ttft": 6864.709708403484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.242621590490716,
    "arrivals": 9494,
    "finished_requests": 9476,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.135616173967719. Arrivals time: 0.034614178352057934 Scheduler time: 0.7132667358964682 Scheduler overhead time: 0.13294547330588102 Adapter cache time: 0.06093260971829295 Engine time: 0.13002422358840704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6199612 . Total output tokens: 5515691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1504447818733752,
    "estimated_duration": 3600.000018006972,
    "input_throughput": 648.1497189802184,
    "output_throughput": 576.870830447862,
    "total_throughput": 1225.0205494280804,
    "itl": 23.32858451890217,
    "ttft": 6864.8420140291555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.287746424921691,
    "arrivals": 9494,
    "finished_requests": 9476,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1505237589590251. Arrivals time: 0.03505318285897374 Scheduler time: 0.726361473556608 Scheduler overhead time: 0.1332558966241777 Adapter cache time: 0.06138402409851551 Engine time: 0.13008394977077842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6199612 . Total output tokens: 5515691
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1393598327413201,
    "estimated_duration": 3599.988499575066,
    "input_throughput": 648.1517927836219,
    "output_throughput": 576.8726761891414,
    "total_throughput": 1225.0244689727633,
    "itl": 23.329310946201005,
    "ttft": 6864.800634690531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.60417026667377,
    "arrivals": 9494,
    "finished_requests": 9476,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.13941019307822. Arrivals time: 0.03461399441584945 Scheduler time: 0.7195206470787525 Scheduler overhead time: 0.13253767555579543 Adapter cache time: 0.06016535358503461 Engine time: 0.12886592000722885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6199612 . Total output tokens: 5515691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.1246953043155372,
    "estimated_duration": 3600.0081979995657,
    "input_throughput": 648.1482462447108,
    "output_throughput": 576.8695196733134,
    "total_throughput": 1225.0177659180242,
    "itl": 23.32181487131156,
    "ttft": 6864.8770207014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.57780832363303,
    "arrivals": 9494,
    "finished_requests": 9476,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1247658520005643. Arrivals time: 0.03403163934126496 Scheduler time: 0.705705831758678 Scheduler overhead time: 0.13298883754760027 Adapter cache time: 0.059867565520107746 Engine time: 0.1283567133359611 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6199612 . Total output tokens: 5515691
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.152645745780319,
    "estimated_duration": 3599.9966751835514,
    "input_throughput": 648.1503208280133,
    "output_throughput": 576.8713661087241,
    "total_throughput": 1225.0216869367373,
    "itl": 23.329256096355536,
    "ttft": 6864.977289478977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.497090686363972,
    "arrivals": 9494,
    "finished_requests": 9476,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1527147111482918. Arrivals time: 0.03521802881732583 Scheduler time: 0.7276539644226432 Scheduler overhead time: 0.13269187370315194 Adapter cache time: 0.06083250045776367 Engine time: 0.13204164151102304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6199612 . Total output tokens: 5515691
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.155765837058425,
    "estimated_duration": 3599.9957013005424,
    "input_throughput": 648.1504961678295,
    "output_throughput": 576.8715221659165,
    "total_throughput": 1225.022018333746,
    "itl": 23.316794646602116,
    "ttft": 6864.57537053441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.882309616003395,
    "arrivals": 9494,
    "finished_requests": 9476,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1558184786699712. Arrivals time: 0.03546274546533823 Scheduler time: 0.734288168605417 Scheduler overhead time: 0.13264661561697721 Adapter cache time: 0.06053623044863343 Engine time: 0.12868603458628058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6199612 . Total output tokens: 5515691
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1269523408263922,
    "estimated_duration": 3599.992689811198,
    "input_throughput": 648.1510383629063,
    "output_throughput": 576.8720047342414,
    "total_throughput": 1225.0230430971478,
    "itl": 23.329280820450517,
    "ttft": 6864.896729379934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.393117863703393,
    "arrivals": 9494,
    "finished_requests": 9476,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.127022909000516. Arrivals time: 0.03434038022533059 Scheduler time: 0.7070850753225386 Scheduler overhead time: 0.1328086550347507 Adapter cache time: 0.06064964085817337 Engine time: 0.12838093377649784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5970497 . Total output tokens: 5305411
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0916286390274763,
    "estimated_duration": 3599.9293377410313,
    "input_throughput": 614.0298302041323,
    "output_throughput": 541.1814558622731,
    "total_throughput": 1155.2112860664054,
    "itl": 22.97838185987548,
    "ttft": 5183.439060268999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.579346986790332,
    "arrivals": 9096,
    "finished_requests": 9083,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0916852410882711. Arrivals time: 0.03377007879316807 Scheduler time: 0.6716801528818905 Scheduler overhead time: 0.1335249119438231 Adapter cache time: 0.05760021507740021 Engine time: 0.13051500171422958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5970497 . Total output tokens: 5305411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.096270591020584,
    "estimated_duration": 3599.948335312188,
    "input_throughput": 614.0265898589092,
    "output_throughput": 541.1785999509491,
    "total_throughput": 1155.2051898098584,
    "itl": 22.98471857485007,
    "ttft": 5183.7240390309125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.236298095867978,
    "arrivals": 9096,
    "finished_requests": 9083,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0963316760025918. Arrivals time: 0.033656975254416466 Scheduler time: 0.6768387607298791 Scheduler overhead time: 0.1333603044040501 Adapter cache time: 0.0578277176246047 Engine time: 0.13022027490660548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5970497 . Total output tokens: 5305411
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.098076481372118,
    "estimated_duration": 3599.9456425124176,
    "input_throughput": 614.0270491576944,
    "output_throughput": 541.1790047586197,
    "total_throughput": 1155.2060539163142,
    "itl": 22.984868653169745,
    "ttft": 5183.567360558191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.417573050553923,
    "arrivals": 9096,
    "finished_requests": 9083,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0981453829444945. Arrivals time: 0.03334584413096309 Scheduler time: 0.6717738499864936 Scheduler overhead time: 0.13690773351117969 Adapter cache time: 0.05766179831698537 Engine time: 0.1334963538683951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5970497 . Total output tokens: 5305411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.1046406980603933,
    "estimated_duration": 3599.946857708756,
    "input_throughput": 614.0268418870176,
    "output_throughput": 541.1788220784939,
    "total_throughput": 1155.2056639655113,
    "itl": 22.979840030652916,
    "ttft": 5183.567850591886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.814278919980851,
    "arrivals": 9096,
    "finished_requests": 9083,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1046881871297956. Arrivals time: 0.03406030312180519 Scheduler time: 0.683993436396122 Scheduler overhead time: 0.13241466041654348 Adapter cache time: 0.05789033975452185 Engine time: 0.13219116628170013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5970497 . Total output tokens: 5305411
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1022903281264007,
    "estimated_duration": 3599.943825817548,
    "input_throughput": 614.0273590235823,
    "output_throughput": 541.1792778620817,
    "total_throughput": 1155.206636885664,
    "itl": 22.983759543563885,
    "ttft": 5183.702406926352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.354609428863054,
    "arrivals": 9096,
    "finished_requests": 9083,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.102361958939582. Arrivals time: 0.033923850394785404 Scheduler time: 0.6822005528956652 Scheduler overhead time: 0.13363446947187185 Adapter cache time: 0.05798773607239127 Engine time: 0.12993205804377794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5970497 . Total output tokens: 5305411
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.1002713781781495,
    "estimated_duration": 3599.936538121425,
    "input_throughput": 614.0286020579404,
    "output_throughput": 541.180373423096,
    "total_throughput": 1155.2089754810363,
    "itl": 22.97701087593263,
    "ttft": 5183.561228920234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.352001335867649,
    "arrivals": 9096,
    "finished_requests": 9083,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1003774758428335. Arrivals time: 0.03360269730910659 Scheduler time: 0.6771364309825003 Scheduler overhead time: 0.13481998397037387 Adapter cache time: 0.0577137665823102 Engine time: 0.13235299987718463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5970497 . Total output tokens: 5305411
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1046438342891634,
    "estimated_duration": 3599.9329402156536,
    "input_throughput": 614.029215740775,
    "output_throughput": 541.1809142987237,
    "total_throughput": 1155.2101300394986,
    "itl": 22.984650881608747,
    "ttft": 5183.6241320259205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.2856394090503604,
    "arrivals": 9096,
    "finished_requests": 9083,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1046933843754232. Arrivals time: 0.0339555568061769 Scheduler time: 0.6838911245577037 Scheduler overhead time: 0.13395008258521557 Adapter cache time: 0.05799307441338897 Engine time: 0.1303855120204389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5259212 . Total output tokens: 4661994
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0422432119958103,
    "estimated_duration": 3599.837806015059,
    "input_throughput": 538.6884366733849,
    "output_throughput": 486.7933208190407,
    "total_throughput": 1025.4817574924255,
    "itl": 22.547065313528822,
    "ttft": 6744.334890241474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.273649935145098,
    "arrivals": 8052,
    "finished_requests": 8037,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.042417879216373. Arrivals time: 0.03138570161536336 Scheduler time: 0.6251264503225684 Scheduler overhead time: 0.13499555783346295 Adapter cache time: 0.05373395560309291 Engine time: 0.13221313897520304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5259212 . Total output tokens: 4661994
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0504001174122095,
    "estimated_duration": 3599.834338974403,
    "input_throughput": 538.6889554902345,
    "output_throughput": 486.79378965512456,
    "total_throughput": 1025.482745145359,
    "itl": 22.553313220024062,
    "ttft": 6744.493658855625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.036545382193301,
    "arrivals": 8052,
    "finished_requests": 8037,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0504481373354793. Arrivals time: 0.03139332355931401 Scheduler time: 0.6309239128604531 Scheduler overhead time: 0.13479554606601596 Adapter cache time: 0.05451077036559582 Engine time: 0.13364148745313287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5259212 . Total output tokens: 4661994
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.046933616977185,
    "estimated_duration": 3599.834217216513,
    "input_throughput": 538.6889737104154,
    "output_throughput": 486.79380612004525,
    "total_throughput": 1025.4827798304607,
    "itl": 22.554203056521455,
    "ttft": 6744.447479590566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.25095438643359,
    "arrivals": 8052,
    "finished_requests": 8037,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.047002511098981. Arrivals time: 0.0317881191149354 Scheduler time: 0.6280270712450147 Scheduler overhead time: 0.13401014730334282 Adapter cache time: 0.05489707784727216 Engine time: 0.13279698276892304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5259212 . Total output tokens: 4661994
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.0386095908470452,
    "estimated_duration": 3599.8386375000523,
    "input_throughput": 538.688312247988,
    "output_throughput": 486.79320838029497,
    "total_throughput": 1025.481520628283,
    "itl": 22.713194808290645,
    "ttft": 6744.659736552579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1098,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.509304743139061,
    "arrivals": 8052,
    "finished_requests": 8037,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0386626031249762. Arrivals time: 0.031945128459483385 Scheduler time: 0.6241102432832122 Scheduler overhead time: 0.13425593124702573 Adapter cache time: 0.052998908795416355 Engine time: 0.13044775929301977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5259212 . Total output tokens: 4661994
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0447864970192313,
    "estimated_duration": 3599.844443428392,
    "input_throughput": 538.6874434366304,
    "output_throughput": 486.79242326679116,
    "total_throughput": 1025.4798667034215,
    "itl": 22.554157834563973,
    "ttft": 6744.50067395527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.175149499792616,
    "arrivals": 8052,
    "finished_requests": 8037,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0448594000190496. Arrivals time: 0.031709827948361635 Scheduler time: 0.6241736258380115 Scheduler overhead time: 0.13520714174956083 Adapter cache time: 0.05453017121180892 Engine time: 0.13347467267885804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5259212 . Total output tokens: 4661994
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0604657898657024,
    "estimated_duration": 3599.843943176196,
    "input_throughput": 538.6875182953133,
    "output_throughput": 486.79249091388436,
    "total_throughput": 1025.4800092091978,
    "itl": 22.545156127363846,
    "ttft": 6744.290126861837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.028696955568122,
    "arrivals": 8052,
    "finished_requests": 8037,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.060621407814324. Arrivals time: 0.0318585904315114 Scheduler time: 0.6353245438076556 Scheduler overhead time: 0.1394997499883175 Adapter cache time: 0.05460949055850506 Engine time: 0.13284043408930302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5259212 . Total output tokens: 4661994
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.048372883349657,
    "estimated_duration": 3599.8254243876836,
    "input_throughput": 538.6902894964271,
    "output_throughput": 486.7949951484307,
    "total_throughput": 1025.485284644858,
    "itl": 22.552751506774708,
    "ttft": 6744.380176871547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.094220049232256,
    "arrivals": 8052,
    "finished_requests": 8037,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0484446403570473. Arrivals time: 0.03152244305238128 Scheduler time: 0.6303889490664005 Scheduler overhead time: 0.13495934149250388 Adapter cache time: 0.05433032615110278 Engine time: 0.13149153254926205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5036055 . Total output tokens: 4457254
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0166089674457908,
    "estimated_duration": 3599.440792365532,
    "input_throughput": 518.0415813353485,
    "output_throughput": 458.1153282191686,
    "total_throughput": 976.156909554517,
    "itl": 22.24790633499304,
    "ttft": 6637.393506025453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.5228877778538354,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.016666419338435. Arrivals time: 0.03048344235867262 Scheduler time: 0.594883855432272 Scheduler overhead time: 0.13948116917163134 Adapter cache time: 0.05139261484146118 Engine time: 0.13426358997821808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5036055 . Total output tokens: 4457254
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.9966781749390066,
    "estimated_duration": 3599.4479228167456,
    "input_throughput": 518.0405551029091,
    "output_throughput": 458.1144206997189,
    "total_throughput": 976.154975802628,
    "itl": 22.25094973228457,
    "ttft": 6637.620490274289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.995466024260975,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9967403491027653. Arrivals time: 0.030253691598773003 Scheduler time: 0.5806323080323637 Scheduler overhead time: 0.1357203358784318 Adapter cache time: 0.050902394112199545 Engine time: 0.13330401293933392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5036055 . Total output tokens: 4457254
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0064521366730332,
    "estimated_duration": 3599.4354058077515,
    "input_throughput": 518.0423565849629,
    "output_throughput": 458.11601378910035,
    "total_throughput": 976.1583703740633,
    "itl": 22.25246570161133,
    "ttft": 6637.534166972651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.129299910436411,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.006509036757052. Arrivals time: 0.03020424908027053 Scheduler time: 0.5916762463748455 Scheduler overhead time: 0.13521964708343148 Adapter cache time: 0.05113038932904601 Engine time: 0.13248669682070613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5036055 . Total output tokens: 4457254
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.0116937668062747,
    "estimated_duration": 3599.4320771889147,
    "input_throughput": 518.0428356509682,
    "output_throughput": 458.1164374374872,
    "total_throughput": 976.1592730884554,
    "itl": 22.249398450925625,
    "ttft": 6637.485305059629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 685,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.682559121339574,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0117541840299964. Arrivals time: 0.03020742628723383 Scheduler time: 0.5943613885901868 Scheduler overhead time: 0.13589383382350206 Adapter cache time: 0.051191321574151516 Engine time: 0.13387226546183228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5036055 . Total output tokens: 4457254
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.014693055767566,
    "estimated_duration": 3599.425075434889,
    "input_throughput": 518.0438433698216,
    "output_throughput": 458.117328584974,
    "total_throughput": 976.1611719547956,
    "itl": 22.250910799044373,
    "ttft": 6637.474725381021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.081455842638416,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0147499041631818. Arrivals time: 0.03059931192547083 Scheduler time: 0.5962876765988767 Scheduler overhead time: 0.1359234070405364 Adapter cache time: 0.05092040868476033 Engine time: 0.13490348076447845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5036055 . Total output tokens: 4457254
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0054012080654502,
    "estimated_duration": 3599.432900953503,
    "input_throughput": 518.0427170919187,
    "output_throughput": 458.1163325931662,
    "total_throughput": 976.1590496850849,
    "itl": 22.2464338057502,
    "ttft": 6637.366467304034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.366601923350224,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0054580569267273. Arrivals time: 0.030429436825215816 Scheduler time: 0.5886802584864199 Scheduler overhead time: 0.13545509846881032 Adapter cache time: 0.05096507025882602 Engine time: 0.1335287424735725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5036055 . Total output tokens: 4457254
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0075666178017855,
    "estimated_duration": 3599.430521938207,
    "input_throughput": 518.0430594881785,
    "output_throughput": 458.11663538155335,
    "total_throughput": 976.1596948697319,
    "itl": 22.25200139544874,
    "ttft": 6637.63317417713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 685,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.043344785627006,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0076352478936315. Arrivals time: 0.030240117572247982 Scheduler time: 0.5913982861675322 Scheduler overhead time: 0.13529429445043206 Adapter cache time: 0.05087633477523923 Engine time: 0.13389409240335226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4545729 . Total output tokens: 4043414
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.9711474371142685,
    "estimated_duration": 3599.365404596704,
    "input_throughput": 468.7840244964122,
    "output_throughput": 420.6899910929334,
    "total_throughput": 889.4740155893456,
    "itl": 21.967503510049827,
    "ttft": 5739.319062771249,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4120030604862106,
    "arrivals": 6944,
    "finished_requests": 6933,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9711952959187329. Arrivals time: 0.029169222339987755 Scheduler time: 0.5564690246246755 Scheduler overhead time: 0.1366677563637495 Adapter cache time: 0.04839241271838546 Engine time: 0.13391528837382793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4545729 . Total output tokens: 4043414
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.9684034758247435,
    "estimated_duration": 3599.355779773861,
    "input_throughput": 468.78527804384225,
    "output_throughput": 420.69111603497413,
    "total_throughput": 889.4763940788164,
    "itl": 21.969833869375,
    "ttft": 5739.398970547573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7688747782073966,
    "arrivals": 6944,
    "finished_requests": 6933,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9684733967296779. Arrivals time: 0.029120491351932287 Scheduler time: 0.55378886917606 Scheduler overhead time: 0.135639654006809 Adapter cache time: 0.04815748427063227 Engine time: 0.13533925730735064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4545729 . Total output tokens: 4043414
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.9673004038631916,
    "estimated_duration": 3599.3558189805563,
    "input_throughput": 468.78527293750585,
    "output_throughput": 420.69111145251287,
    "total_throughput": 889.4763843900188,
    "itl": 21.96975644605249,
    "ttft": 5739.352434658346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.869921548152377,
    "arrivals": 6944,
    "finished_requests": 6933,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9673536708578467. Arrivals time: 0.0289419605396688 Scheduler time: 0.5540936975739896 Scheduler overhead time: 0.1362613090313971 Adapter cache time: 0.04800338624045253 Engine time: 0.13388825953006744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4545729 . Total output tokens: 4043414
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.9748247750103474,
    "estimated_duration": 3599.367123732188,
    "input_throughput": 468.7838005950365,
    "output_throughput": 420.68979016230685,
    "total_throughput": 889.4735907573433,
    "itl": 21.968154985255648,
    "ttft": 5739.333975456415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.530100770797575,
    "arrivals": 6944,
    "finished_requests": 6933,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9748976617120206. Arrivals time: 0.02888897666707635 Scheduler time: 0.5603456743992865 Scheduler overhead time: 0.13730047224089503 Adapter cache time: 0.0479599772952497 Engine time: 0.13378215674310923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4545729 . Total output tokens: 4043414
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.9744413360022008,
    "estimated_duration": 3599.3695208724857,
    "input_throughput": 468.78348839020924,
    "output_throughput": 420.6895099875587,
    "total_throughput": 889.472998377768,
    "itl": 21.971134779070947,
    "ttft": 5739.499842169964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8342973937746483,
    "arrivals": 6944,
    "finished_requests": 6933,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9744924758560956. Arrivals time: 0.02920872624963522 Scheduler time: 0.5594709105789661 Scheduler overhead time: 0.1366502968594432 Adapter cache time: 0.048004763666540384 Engine time: 0.13485925924032927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4545729 . Total output tokens: 4043414
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.9710444565862417,
    "estimated_duration": 3599.360745365579,
    "input_throughput": 468.7846313189211,
    "output_throughput": 420.69053565960485,
    "total_throughput": 889.475166978526,
    "itl": 21.96650294599003,
    "ttft": 5739.276281936262,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2941032053343804,
    "arrivals": 6944,
    "finished_requests": 6933,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9711429476737976. Arrivals time: 0.028960501309484243 Scheduler time: 0.5579464845359325 Scheduler overhead time: 0.13669454539194703 Adapter cache time: 0.04791727336123586 Engine time: 0.13353618793189526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4545729 . Total output tokens: 4043414
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.9706099559552968,
    "estimated_duration": 3599.363109942329,
    "input_throughput": 468.7843233540934,
    "output_throughput": 420.6902592898613,
    "total_throughput": 889.4745826439547,
    "itl": 21.970070473684032,
    "ttft": 5739.465919873832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7990874737501485,
    "arrivals": 6944,
    "finished_requests": 6933,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9706598613411188. Arrivals time: 0.029015088453888893 Scheduler time: 0.5592033746652305 Scheduler overhead time: 0.13625189568847418 Adapter cache time: 0.04771713353693485 Engine time: 0.13252120837569237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3332730 . Total output tokens: 3000837
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8451339672319591,
    "estimated_duration": 3599.493149963582,
    "input_throughput": 348.8357798410323,
    "output_throughput": 300.5184216035928,
    "total_throughput": 649.3542014446251,
    "itl": 21.235472202860436,
    "ttft": 5717.053035472013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.159712745426418,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8451908812858164. Arrivals time: 0.025106503162533045 Scheduler time: 0.43032138142734766 Scheduler overhead time: 0.13879758585244417 Adapter cache time: 0.04481104388833046 Engine time: 0.13786557642742991 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3332730 . Total output tokens: 3000837
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8401159509085119,
    "estimated_duration": 3599.4921506716364,
    "input_throughput": 348.8358766849121,
    "output_throughput": 300.51850503359503,
    "total_throughput": 649.3543817185072,
    "itl": 21.24281260579537,
    "ttft": 5717.272686520231,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.999440987100796,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8401756291277707. Arrivals time: 0.024817579425871372 Scheduler time: 0.42855285899713635 Scheduler overhead time: 0.13907249504700303 Adapter cache time: 0.04511179914698005 Engine time: 0.13469200255349278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3332730 . Total output tokens: 3000837
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8498281929641962,
    "estimated_duration": 3599.5042068182515,
    "input_throughput": 348.83470829720306,
    "output_throughput": 300.51749847965067,
    "total_throughput": 649.3522067768537,
    "itl": 21.24074068938479,
    "ttft": 5717.277884430351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.237923019006804,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8498754119500518. Arrivals time: 0.024747812189161777 Scheduler time: 0.4333064039237797 Scheduler overhead time: 0.14219475677236915 Adapter cache time: 0.04488497180864215 Engine time: 0.1360351862385869 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3332730 . Total output tokens: 3000837
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.8393618767149746,
    "estimated_duration": 3599.488936289503,
    "input_throughput": 348.8361881990824,
    "output_throughput": 300.5187733998355,
    "total_throughput": 649.354961598918,
    "itl": 21.237818092179847,
    "ttft": 5716.981551345019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.43859971388244,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8395340256392956. Arrivals time: 0.024933932349085808 Scheduler time: 0.42766409227624536 Scheduler overhead time: 0.13804113632068038 Adapter cache time: 0.04452491272240877 Engine time: 0.1362040122039616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3332730 . Total output tokens: 3000837
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.850627030711621,
    "estimated_duration": 3599.505388791768,
    "input_throughput": 348.83459374996886,
    "output_throughput": 300.5173997983914,
    "total_throughput": 649.3519935483603,
    "itl": 21.242164848437366,
    "ttft": 5717.280994458948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1235,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.16061494663354,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8506766180507839. Arrivals time: 0.02493612701073289 Scheduler time: 0.43600779492408037 Scheduler overhead time: 0.13889195350930095 Adapter cache time: 0.045145767740905285 Engine time: 0.1378925135359168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3332730 . Total output tokens: 3000837
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.83986771479249,
    "estimated_duration": 3599.4974226921304,
    "input_throughput": 348.8353657608372,
    "output_throughput": 300.5180648777812,
    "total_throughput": 649.3534306386184,
    "itl": 21.235402553814893,
    "ttft": 5716.811811970947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1235,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.884142361604568,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8399139055982232. Arrivals time: 0.024486477952450514 Scheduler time: 0.427553225774318 Scheduler overhead time: 0.13947918452322483 Adapter cache time: 0.04536917293444276 Engine time: 0.13522718846797943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3332730 . Total output tokens: 3000837
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8395836907438934,
    "estimated_duration": 3599.4863620589726,
    "input_throughput": 348.8364376748896,
    "output_throughput": 300.51898832066684,
    "total_throughput": 649.3554259955565,
    "itl": 21.24529924712877,
    "ttft": 5717.326877230839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.070572340302135,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8396392031572759. Arrivals time: 0.024483497720211744 Scheduler time: 0.4282051627524197 Scheduler overhead time: 0.1385432998649776 Adapter cache time: 0.04453348368406296 Engine time: 0.13607742870226502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3084908 . Total output tokens: 2787633
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.819630010984838,
    "estimated_duration": 3598.5821336519593,
    "input_throughput": 318.60548333142134,
    "output_throughput": 284.90804486919615,
    "total_throughput": 603.5135282006174,
    "itl": 21.082606273341003,
    "ttft": 7682.452507968108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.078330136537648,
    "arrivals": 4708,
    "finished_requests": 4698,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8196778129786253. Arrivals time: 0.023915933910757303 Scheduler time: 0.41029389668256044 Scheduler overhead time: 0.13863965217024088 Adapter cache time: 0.04256395297124982 Engine time: 0.1364991976879537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3084908 . Total output tokens: 2787633
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8268907330930233,
    "estimated_duration": 3598.5743219379133,
    "input_throughput": 318.60617495391034,
    "output_throughput": 284.9086633419514,
    "total_throughput": 603.5148382958618,
    "itl": 21.087335627260963,
    "ttft": 7682.419430189214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.60945575777442,
    "arrivals": 4708,
    "finished_requests": 4698,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8269515191204846. Arrivals time: 0.024187148083001375 Scheduler time: 0.4160671103745699 Scheduler overhead time: 0.13907504035159945 Adapter cache time: 0.042485824320465326 Engine time: 0.13760033249855042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3084908 . Total output tokens: 2787633
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.818012482021004,
    "estimated_duration": 3598.5782806031175,
    "input_throughput": 318.6058244668345,
    "output_throughput": 284.90834992428364,
    "total_throughput": 603.5141743911182,
    "itl": 21.088377412209322,
    "ttft": 7682.628409499043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.759843494775732,
    "arrivals": 4708,
    "finished_requests": 4698,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8180745709687471. Arrivals time: 0.023617007303982973 Scheduler time: 0.40789528330788016 Scheduler overhead time: 0.1389398560859263 Adapter cache time: 0.04225541977211833 Engine time: 0.13737293286249042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3084908 . Total output tokens: 2787633
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.823202608153224,
    "estimated_duration": 3598.5888342197136,
    "input_throughput": 318.60489008842353,
    "output_throughput": 284.9075143707851,
    "total_throughput": 603.5124044592087,
    "itl": 21.08526204738929,
    "ttft": 7682.374184889985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.254071188606314,
    "arrivals": 4708,
    "finished_requests": 4698,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8232500939629972. Arrivals time: 0.02404262963682413 Scheduler time: 0.4135417975485325 Scheduler overhead time: 0.13948775734752417 Adapter cache time: 0.042705217376351357 Engine time: 0.13588899467140436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3084908 . Total output tokens: 2787633
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8293928066268563,
    "estimated_duration": 3598.5770362092985,
    "input_throughput": 318.6059346412492,
    "output_throughput": 284.9084484460566,
    "total_throughput": 603.5143830873058,
    "itl": 21.087876551305236,
    "ttft": 7682.425283601249,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.70682149756237,
    "arrivals": 4708,
    "finished_requests": 4698,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8294410896487534. Arrivals time: 0.023903964553028345 Scheduler time: 0.41535630775615573 Scheduler overhead time: 0.1414418602362275 Adapter cache time: 0.04289192333817482 Engine time: 0.1371652507223189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3084908 . Total output tokens: 2787633
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.827539037913084,
    "estimated_duration": 3598.576950805962,
    "input_throughput": 318.60594220257417,
    "output_throughput": 284.908455207655,
    "total_throughput": 603.5143974102291,
    "itl": 21.08385591439895,
    "ttft": 7682.177487303422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.902851282358146,
    "arrivals": 4708,
    "finished_requests": 4698,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8276166506111622. Arrivals time: 0.024035041220486164 Scheduler time: 0.41435879841446877 Scheduler overhead time: 0.14085898781195283 Adapter cache time: 0.042659678030759096 Engine time: 0.1374540152028203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3084908 . Total output tokens: 2787633
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.821579284965992,
    "estimated_duration": 3598.5753665911866,
    "input_throughput": 318.6060824637025,
    "output_throughput": 284.908580634008,
    "total_throughput": 603.5146630977105,
    "itl": 21.088331441414795,
    "ttft": 7682.548729084975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.654420851878851,
    "arrivals": 4708,
    "finished_requests": 4698,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8216266627423465. Arrivals time: 0.024088613223284483 Scheduler time: 0.4114232826977968 Scheduler overhead time: 0.1390929319895804 Adapter cache time: 0.04279960226267576 Engine time: 0.13650565827265382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2580649 . Total output tokens: 2350802
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.7745557660236955,
    "estimated_duration": 3599.5893370514273,
    "input_throughput": 263.3906013224904,
    "output_throughput": 238.32718670700504,
    "total_throughput": 501.71778802949547,
    "itl": 20.823132206296705,
    "ttft": 3702.1523877778295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.007119873361724,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7746214759536088. Arrivals time: 0.022015352733433247 Scheduler time: 0.367664550896734 Scheduler overhead time: 0.13922774512320757 Adapter cache time: 0.03918437613174319 Engine time: 0.13824355928227305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2580649 . Total output tokens: 2350802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.7702410211786628,
    "estimated_duration": 3599.583484012167,
    "input_throughput": 263.39102960413385,
    "output_throughput": 238.32757423472506,
    "total_throughput": 501.71860383885894,
    "itl": 20.826296272935828,
    "ttft": 3702.330417561768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.42810914223083,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7702936860732734. Arrivals time: 0.022027376107871532 Scheduler time: 0.3643736718222499 Scheduler overhead time: 0.13925794186070561 Adapter cache time: 0.039155005011707544 Engine time: 0.13687634281814098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2580649 . Total output tokens: 2350802
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.780453234910965,
    "estimated_duration": 3599.5933627457553,
    "input_throughput": 263.39030675309243,
    "output_throughput": 238.32692016789713,
    "total_throughput": 501.71722692098956,
    "itl": 20.827861985446884,
    "ttft": 3702.4418592029747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.547212766339104,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7805020618252456. Arrivals time: 0.02242889441549778 Scheduler time: 0.36807595286518335 Scheduler overhead time: 0.1381330662406981 Adapter cache time: 0.039172932505607605 Engine time: 0.14450129307806492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2580649 . Total output tokens: 2350802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.7728569889441133,
    "estimated_duration": 3599.580731995687,
    "input_throughput": 263.39123097660143,
    "output_throughput": 238.32775644522698,
    "total_throughput": 501.7189874218284,
    "itl": 20.82444669201014,
    "ttft": 3702.034667544013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.146300284648308,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7729207761585712. Arrivals time: 0.0219437750056386 Scheduler time: 0.36288874270394444 Scheduler overhead time: 0.13955675205215812 Adapter cache time: 0.03873595781624317 Engine time: 0.1418399065732956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2580649 . Total output tokens: 2350802
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.765753336250782,
    "estimated_duration": 3599.58986119749,
    "input_throughput": 263.3905629694691,
    "output_throughput": 238.32715200353567,
    "total_throughput": 501.7177149730048,
    "itl": 20.827639065583746,
    "ttft": 3702.3607903326483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.505167979486321,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7658208669163287. Arrivals time: 0.022107228636741638 Scheduler time: 0.36100267991423607 Scheduler overhead time: 0.1390299703925848 Adapter cache time: 0.03883510688319802 Engine time: 0.13638050528243184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2580649 . Total output tokens: 2350802
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.7736382409930229,
    "estimated_duration": 3599.5985892492627,
    "input_throughput": 263.38992431868263,
    "output_throughput": 238.32657412473336,
    "total_throughput": 501.71649844341596,
    "itl": 20.821445520395425,
    "ttft": 3702.189558986786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.868656089985725,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.773688652087003. Arrivals time: 0.021971698850393295 Scheduler time: 0.36500334134325385 Scheduler overhead time: 0.14114534761756659 Adapter cache time: 0.039342174772173166 Engine time: 0.13751532370224595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2580649 . Total output tokens: 2350802
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.7622203840874135,
    "estimated_duration": 3599.585938919352,
    "input_throughput": 263.39084997221454,
    "output_throughput": 238.3274116960097,
    "total_throughput": 501.7182616682242,
    "itl": 20.826553745671465,
    "ttft": 3702.26480136338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.463744544163381,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.762266464997083. Arrivals time: 0.02218460477888584 Scheduler time: 0.35911562154069543 Scheduler overhead time: 0.13821855932474136 Adapter cache time: 0.038511235266923904 Engine time: 0.136379299685359 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1633565 . Total output tokens: 1492335
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.6601371327415109,
    "estimated_duration": 3599.032884314026,
    "input_throughput": 167.93094684801588,
    "output_throughput": 146.67662590713348,
    "total_throughput": 314.60757275514936,
    "itl": 20.2261625664976,
    "ttft": 10426.282762879102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8418096475629704,
    "arrivals": 2425,
    "finished_requests": 2418,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6601852369494736. Arrivals time: 0.01847107382491231 Scheduler time: 0.26389285176992416 Scheduler overhead time: 0.13759489124640822 Adapter cache time: 0.03260315814986825 Engine time: 0.14022471429780126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1633565 . Total output tokens: 1492335
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6574706453830004,
    "estimated_duration": 3599.0153641054967,
    "input_throughput": 167.93176434527822,
    "output_throughput": 146.6773399371701,
    "total_throughput": 314.60910428244836,
    "itl": 20.228678962873666,
    "ttft": 10426.596407965726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.242134920223622,
    "arrivals": 2425,
    "finished_requests": 2418,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6575639941729605. Arrivals time: 0.01865182863548398 Scheduler time: 0.2659324430860579 Scheduler overhead time: 0.1368112750351429 Adapter cache time: 0.03290906501933932 Engine time: 0.13592858472838998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1633565 . Total output tokens: 1492335
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6576617690734565,
    "estimated_duration": 3599.016850454872,
    "input_throughput": 167.93169499153987,
    "output_throughput": 146.67727936124572,
    "total_throughput": 314.6089743527856,
    "itl": 20.229329538911312,
    "ttft": 10426.621502444617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.355563770365003,
    "arrivals": 2425,
    "finished_requests": 2418,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.657715329900384. Arrivals time: 0.018876751884818077 Scheduler time: 0.26482384465634823 Scheduler overhead time: 0.13740341924130917 Adapter cache time: 0.03292475361377001 Engine time: 0.1358389798551798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1633565 . Total output tokens: 1492335
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.6611665831878781,
    "estimated_duration": 3599.0153641054967,
    "input_throughput": 167.93176434527822,
    "output_throughput": 146.6773399371701,
    "total_throughput": 314.60910428244836,
    "itl": 20.22697645002362,
    "ttft": 10426.42990203891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.972820051400916,
    "arrivals": 2425,
    "finished_requests": 2418,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6612207451835275. Arrivals time: 0.01868650084361434 Scheduler time: 0.26813763892278075 Scheduler overhead time: 0.13743755081668496 Adapter cache time: 0.03279057238250971 Engine time: 0.13638979755342007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1633565 . Total output tokens: 1492335
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6611650250852108,
    "estimated_duration": 3599.016850454872,
    "input_throughput": 167.93169499153987,
    "output_throughput": 146.67727936124572,
    "total_throughput": 314.6089743527856,
    "itl": 20.229118332684923,
    "ttft": 10426.584061422533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.315383038101751,
    "arrivals": 2425,
    "finished_requests": 2418,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6612138268537819. Arrivals time: 0.018572627566754818 Scheduler time: 0.26611614553257823 Scheduler overhead time: 0.13851507101207972 Adapter cache time: 0.033222191501408815 Engine time: 0.13694866839796305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1633565 . Total output tokens: 1492335
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.6607451108284295,
    "estimated_duration": 3599.0309862156887,
    "input_throughput": 167.93103541336922,
    "output_throughput": 146.6767032631387,
    "total_throughput": 314.60773867650795,
    "itl": 20.225438883363275,
    "ttft": 10426.235681009972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7090580664714627,
    "arrivals": 2425,
    "finished_requests": 2418,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6607911516912282. Arrivals time: 0.018971933517605066 Scheduler time: 0.266902188770473 Scheduler overhead time: 0.1373662855476141 Adapter cache time: 0.033108692150563 Engine time: 0.13700934126973152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1633565 . Total output tokens: 1492335
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6603291458450258,
    "estimated_duration": 3599.015814868989,
    "input_throughput": 167.93174331244248,
    "output_throughput": 146.67732156637283,
    "total_throughput": 314.6090648788153,
    "itl": 20.228920933527647,
    "ttft": 10426.604541507177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2760307745449575,
    "arrivals": 2425,
    "finished_requests": 2418,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6603870992548764. Arrivals time: 0.01880426937714219 Scheduler time: 0.2667402448132634 Scheduler overhead time: 0.1382375881075859 Adapter cache time: 0.03271369030699134 Engine time: 0.13617523107677698 
