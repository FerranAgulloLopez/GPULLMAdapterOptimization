INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:51 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.818029916845262,
    "estimated_duration": 3600.0576621498235,
    "input_throughput": 4530.552710719669,
    "output_throughput": 3942.8765681279424,
    "total_throughput": 8473.429278847612,
    "itl": 122.02311103663176,
    "ttft": 1932553.8196803136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1096,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.5201366578042395,
    "arrivals": 236027,
    "finished_requests": 66039,
    "scheduler_time": 94.16177877452579
}
#Debug simulation 
Total elapsed time: 5.818182391114533. Arrivals time: 0.23077269131317735 Scheduler time: 5.45288701960817 Scheduler overhead time: 0.044755406212061644 Adapter cache time: 0.02406466007232666 Engine time: 0.04497157223522663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.792989366222173,
    "estimated_duration": 3600.0212193390216,
    "input_throughput": 4010.288584535264,
    "output_throughput": 3494.1246824954937,
    "total_throughput": 7504.413267030758,
    "itl": 97.97692100202389,
    "ttft": 2031295.1566686889,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.303327654124894,
    "arrivals": 236027,
    "finished_requests": 58406,
    "scheduler_time": 96.72024179177758
}
#Debug simulation 
Total elapsed time: 4.793132137041539. Arrivals time: 0.20730133447796106 Scheduler time: 4.413939257152379 Scheduler overhead time: 0.052601218689233065 Adapter cache time: 0.04123734636232257 Engine time: 0.05321673583239317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.847726262174547,
    "estimated_duration": 3600.0164321562443,
    "input_throughput": 4530.506265003663,
    "output_throughput": 3942.7489478147936,
    "total_throughput": 8473.255212818458,
    "itl": 122.00559110628106,
    "ttft": 1932402.6580048995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1102,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.035080876508692,
    "arrivals": 236027,
    "finished_requests": 66031,
    "scheduler_time": 94.17167139599097
}
#Debug simulation 
Total elapsed time: 5.847818566020578. Arrivals time: 0.22520164400339127 Scheduler time: 5.486508726608008 Scheduler overhead time: 0.04502353863790631 Adapter cache time: 0.02481828024610877 Engine time: 0.04539068462327123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.727217277977616,
    "estimated_duration": 3600.002050177802,
    "input_throughput": 4017.137990042462,
    "output_throughput": 3500.0724511747653,
    "total_throughput": 7517.2104412172275,
    "itl": 98.24724805886814,
    "ttft": 2030765.105625223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.647403968982095,
    "arrivals": 236027,
    "finished_requests": 58514,
    "scheduler_time": 96.66613856858092
}
#Debug simulation 
Total elapsed time: 4.727316014934331. Arrivals time: 0.20815231604501605 Scheduler time: 4.346566950902343 Scheduler overhead time: 0.0526508460752666 Adapter cache time: 0.04224823974072933 Engine time: 0.05309424037113786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156649726 . Total output tokens: 138202524
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.166357803158462,
    "estimated_duration": 3600.1169850331385,
    "input_throughput": 4680.194579800552,
    "output_throughput": 4095.2741428385248,
    "total_throughput": 8775.468722639076,
    "itl": 133.5483899016164,
    "ttft": 1895247.7523586038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.767546912035991,
    "arrivals": 233648,
    "finished_requests": 68143,
    "scheduler_time": 93.21656950680074
}
#Debug simulation 
Total elapsed time: 6.166485233232379. Arrivals time: 0.24840869707986712 Scheduler time: 5.797237238846719 Scheduler overhead time: 0.04189362656325102 Adapter cache time: 0.01790890609845519 Engine time: 0.041729509830474854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156649726 . Total output tokens: 138202524
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.543469733092934,
    "estimated_duration": 3600.1108360847074,
    "input_throughput": 4500.218948153183,
    "output_throughput": 3937.6157139142188,
    "total_throughput": 8437.834662067402,
    "itl": 121.86007007755022,
    "ttft": 1929087.973241967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 957,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.982603332339796,
    "arrivals": 233648,
    "finished_requests": 65512,
    "scheduler_time": 94.13180410401648
}
#Debug simulation 
Total elapsed time: 5.543590770103037. Arrivals time: 0.24673386802896857 Scheduler time: 5.1641782354563475 Scheduler overhead time: 0.044898971915245056 Adapter cache time: 0.022232675459235907 Engine time: 0.04476327262818813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156649726 . Total output tokens: 138202524
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.649058653973043,
    "estimated_duration": 3600.0382703085415,
    "input_throughput": 3985.5984638658515,
    "output_throughput": 3498.9708592515663,
    "total_throughput": 7484.569323117417,
    "itl": 98.36474926591944,
    "ttft": 2026331.8852056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.209608158766974,
    "arrivals": 233648,
    "finished_requests": 58093,
    "scheduler_time": 96.63037827348624
}
#Debug simulation 
Total elapsed time: 4.649153042118996. Arrivals time: 0.22917007841169834 Scheduler time: 4.250586985144764 Scheduler overhead time: 0.0525517575442791 Adapter cache time: 0.038883620873093605 Engine time: 0.05330460565164685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156649726 . Total output tokens: 138202524
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.603479145094752,
    "estimated_duration": 3600.040663611265,
    "input_throughput": 4506.747983153318,
    "output_throughput": 3942.0751947185295,
    "total_throughput": 8448.823177871847,
    "itl": 122.02057684068099,
    "ttft": 1929213.346821918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 943,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.4517741696583,
    "arrivals": 233648,
    "finished_requests": 65597,
    "scheduler_time": 94.12182043284118
}
#Debug simulation 
Total elapsed time: 5.60359034081921. Arrivals time: 0.2547891680151224 Scheduler time: 5.21523368684575 Scheduler overhead time: 0.04512507189065218 Adapter cache time: 0.022311183623969555 Engine time: 0.04519135318696499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156649726 . Total output tokens: 138202524
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.671332668047398,
    "estimated_duration": 3600.0058800072625,
    "input_throughput": 3985.6898789207125,
    "output_throughput": 3499.048729324461,
    "total_throughput": 7484.738608245174,
    "itl": 98.36411728781997,
    "ttft": 2026274.8486501242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.02611131937219,
    "arrivals": 233648,
    "finished_requests": 58095,
    "scheduler_time": 96.63225686591382
}
#Debug simulation 
Total elapsed time: 4.671427785884589. Arrivals time: 0.23021731805056334 Scheduler time: 4.271347938105464 Scheduler overhead time: 0.052474905736744404 Adapter cache time: 0.03886686637997627 Engine time: 0.05357903800904751 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156649726 . Total output tokens: 138202524
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.859671733807772,
    "estimated_duration": 3600.051620134338,
    "input_throughput": 4506.21538571012,
    "output_throughput": 3942.279860828885,
    "total_throughput": 8448.495246539005,
    "itl": 122.02064286517887,
    "ttft": 1928827.8546492099,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 943,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.020037446957983,
    "arrivals": 233648,
    "finished_requests": 65596,
    "scheduler_time": 94.13278189089272
}
#Debug simulation 
Total elapsed time: 5.859739135950804. Arrivals time: 0.4757501953281462 Scheduler time: 5.250028884969652 Scheduler overhead time: 0.04520011320710182 Adapter cache time: 0.022715080063790083 Engine time: 0.04536935314536095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 4320, 135, 135, 135, 8640, 135, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 135, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 135, 4320, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 135, 135, 4320, 135, 4320, 8640, 135, 135, 4320, 135, 135, 135, 135, 135, 8640, 4320, 4320, 8640, 4320, 135, 8640, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 135, 135, 8640, 4320, 8640, 8640, 135, 8640, 135, 4320, 135, 135, 4320, 4320, 8640, 8640, 8640, 135, 8640, 4320, 4320, 135, 135, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 135, 4320, 4320, 8640, 4320, 8640, 135, 135, 135, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 135, 4320, 4320, 135, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 135, 8640, 135, 8640, 4320, 135, 4320, 135, 135, 4320, 4320, 4320, 8640, 4320, 135, 135]
Prompts retrieved: 702675 . Total input tokens: 156649726 . Total output tokens: 138202524
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.6686300449073315,
    "estimated_duration": 3600.0763252174534,
    "input_throughput": 3986.093544595394,
    "output_throughput": 3499.0888698003123,
    "total_throughput": 7485.1824143957065,
    "itl": 98.355685054372,
    "ttft": 2026152.3964074003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.93160839054708,
    "arrivals": 233648,
    "finished_requests": 58099,
    "scheduler_time": 96.63518577430543
}
#Debug simulation 
Total elapsed time: 4.668725281953812. Arrivals time: 0.21149778040125966 Scheduler time: 4.288422402460128 Scheduler overhead time: 0.052605750504881144 Adapter cache time: 0.03825643751770258 Engine time: 0.053316628094762564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155819441 . Total output tokens: 137517244
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.922336287796497,
    "estimated_duration": 3600.097604734143,
    "input_throughput": 4674.323267755598,
    "output_throughput": 4102.099059919952,
    "total_throughput": 8776.422327675551,
    "itl": 134.0899132715439,
    "ttft": 1892605.0541290632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.993895055297824,
    "arrivals": 232444,
    "finished_requests": 68489,
    "scheduler_time": 93.20167825397844
}
#Debug simulation 
Total elapsed time: 5.922434304840863. Arrivals time: 0.2349337195046246 Scheduler time: 5.567421761341393 Scheduler overhead time: 0.04214319959282875 Adapter cache time: 0.01673883432522416 Engine time: 0.041945382952690125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155819441 . Total output tokens: 137517244
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.385702251922339,
    "estimated_duration": 3600.072814304184,
    "input_throughput": 4492.085531088255,
    "output_throughput": 3944.821044611252,
    "total_throughput": 8436.906575699508,
    "itl": 122.39803510243902,
    "ttft": 1925623.0852929975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 809,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.911454924563886,
    "arrivals": 232444,
    "finished_requests": 65778,
    "scheduler_time": 94.11481131362098
}
#Debug simulation 
Total elapsed time: 5.38579621585086. Arrivals time: 0.22916971566155553 Scheduler time: 5.025887274183333 Scheduler overhead time: 0.04479841282591224 Adapter cache time: 0.020213952288031578 Engine time: 0.04501372715458274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155819441 . Total output tokens: 137517244
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.580480597913265,
    "estimated_duration": 3600.0846627527185,
    "input_throughput": 3979.6400202002947,
    "output_throughput": 3499.010767810168,
    "total_throughput": 7478.650788010463,
    "itl": 98.3452174262762,
    "ttft": 2025227.6003037281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.696921867709396,
    "arrivals": 232444,
    "finished_requests": 58341,
    "scheduler_time": 96.6738926107014
}
#Debug simulation 
Total elapsed time: 4.580574340652674. Arrivals time: 0.21850346866995096 Scheduler time: 4.195504573173821 Scheduler overhead time: 0.05250543728470802 Adapter cache time: 0.03579662786796689 Engine time: 0.05362470634281635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155819441 . Total output tokens: 137517244
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.377200343646109,
    "estimated_duration": 3600.132129097487,
    "input_throughput": 4491.857359705839,
    "output_throughput": 3944.590779105667,
    "total_throughput": 8436.448138811505,
    "itl": 122.3398174158926,
    "ttft": 1925090.7289789475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 797,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.447534221722735,
    "arrivals": 232444,
    "finished_requests": 65773,
    "scheduler_time": 94.13273405999855
}
#Debug simulation 
Total elapsed time: 5.377320947591215. Arrivals time: 0.2302407925017178 Scheduler time: 5.016807637177408 Scheduler overhead time: 0.04491271264851093 Adapter cache time: 0.019641384948045015 Engine time: 0.044971848372370005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155819441 . Total output tokens: 137517244
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.5704530528746545,
    "estimated_duration": 3600.0194951299914,
    "input_throughput": 3980.5892771929443,
    "output_throughput": 3499.9691021242747,
    "total_throughput": 7480.558379317219,
    "itl": 98.36691996766592,
    "ttft": 2024958.3361753288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.600251091462335,
    "arrivals": 232444,
    "finished_requests": 58355,
    "scheduler_time": 96.67155427404582
}
#Debug simulation 
Total elapsed time: 4.570551815908402. Arrivals time: 0.20861659245565534 Scheduler time: 4.1964539075270295 Scheduler overhead time: 0.052383077796548605 Adapter cache time: 0.03549444116652012 Engine time: 0.0529434853233397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155819441 . Total output tokens: 137517244
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.363698509056121,
    "estimated_duration": 3600.0374757497993,
    "input_throughput": 4492.5807325468095,
    "output_throughput": 3945.559482555559,
    "total_throughput": 8438.140215102369,
    "itl": 122.36889222366136,
    "ttft": 1925172.66845344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 800,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.107136752456402,
    "arrivals": 232444,
    "finished_requests": 65787,
    "scheduler_time": 94.13190412409037
}
#Debug simulation 
Total elapsed time: 5.363817374221981. Arrivals time: 0.22639276878908277 Scheduler time: 5.007897259667516 Scheduler overhead time: 0.04442200716584921 Adapter cache time: 0.019756607711315155 Engine time: 0.044729814399033785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 4320, 66, 66, 66, 8640, 66, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 66, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 66, 4320, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 66, 66, 4320, 66, 4320, 8640, 66, 66, 4320, 66, 66, 66, 66, 66, 8640, 4320, 4320, 8640, 4320, 66, 8640, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 66, 66, 8640, 4320, 8640, 8640, 66, 8640, 66, 4320, 66, 66, 4320, 4320, 8640, 8640, 8640, 66, 8640, 4320, 4320, 66, 66, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 66, 4320, 4320, 8640, 4320, 8640, 66, 66, 66, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 66, 4320, 4320, 66, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 66, 8640, 66, 8640, 4320, 66, 4320, 66, 66, 4320, 4320, 4320, 8640, 4320, 66, 66]
Prompts retrieved: 699018 . Total input tokens: 155819441 . Total output tokens: 137517244
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.599165929015726,
    "estimated_duration": 3600.057213714101,
    "input_throughput": 3986.2577587189608,
    "output_throughput": 3506.4892724236856,
    "total_throughput": 7492.747031142647,
    "itl": 98.63302837145702,
    "ttft": 2023272.5800837493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1696,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.52132232952842,
    "arrivals": 232444,
    "finished_requests": 58460,
    "scheduler_time": 96.62653509494069
}
#Debug simulation 
Total elapsed time: 4.59926161589101. Arrivals time: 0.20898866187781096 Scheduler time: 4.223704617004842 Scheduler overhead time: 0.05267193540930748 Adapter cache time: 0.036018707789480686 Engine time: 0.053218729328364134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155437084 . Total output tokens: 137184509
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.6638773418962955,
    "estimated_duration": 3600.140938032097,
    "input_throughput": 4726.363576560707,
    "output_throughput": 4098.4753802625855,
    "total_throughput": 8824.838956823292,
    "itl": 133.54358921236647,
    "ttft": 1895343.8143523405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5310264230613133,
    "arrivals": 231825,
    "finished_requests": 68462,
    "scheduler_time": 93.2226725713859
}
#Debug simulation 
Total elapsed time: 5.663986824918538. Arrivals time: 0.24179133214056492 Scheduler time: 5.3036087192595005 Scheduler overhead time: 0.04184784786775708 Adapter cache time: 0.015433543361723423 Engine time: 0.04199285991489887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155437084 . Total output tokens: 137184509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.243923489935696,
    "estimated_duration": 3600.046042094208,
    "input_throughput": 4542.075242595494,
    "output_throughput": 3940.9357086296764,
    "total_throughput": 8483.010951225171,
    "itl": 121.96983906206688,
    "ttft": 1928473.07313131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.44457870348823,
    "arrivals": 231825,
    "finished_requests": 65788,
    "scheduler_time": 94.12766784889735
}
#Debug simulation 
Total elapsed time: 5.244017172604799. Arrivals time: 0.22941678203642368 Scheduler time: 4.884431335143745 Scheduler overhead time: 0.044942501932382584 Adapter cache time: 0.019125187303870916 Engine time: 0.045261540450155735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155437084 . Total output tokens: 137184509
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.544241076800972,
    "estimated_duration": 3600.0863215621216,
    "input_throughput": 4024.4862777938233,
    "output_throughput": 3498.648886434113,
    "total_throughput": 7523.135164227937,
    "itl": 98.24698987896663,
    "ttft": 2027557.7826251031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.94603929449781,
    "arrivals": 231825,
    "finished_requests": 58266,
    "scheduler_time": 96.63346619084008
}
#Debug simulation 
Total elapsed time: 4.544331576675177. Arrivals time: 0.20977372815832496 Scheduler time: 4.167389779817313 Scheduler overhead time: 0.05276851495727897 Adapter cache time: 0.03595999628305435 Engine time: 0.05379979871213436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155437084 . Total output tokens: 137184509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.261021309997886,
    "estimated_duration": 3600.01499899763,
    "input_throughput": 4542.856072697926,
    "output_throughput": 3941.243023695897,
    "total_throughput": 8484.099096393822,
    "itl": 121.96280555302533,
    "ttft": 1928221.7308235406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 739,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.063384597436517,
    "arrivals": 231825,
    "finished_requests": 65796,
    "scheduler_time": 94.13499902989903
}
#Debug simulation 
Total elapsed time: 5.261115893255919. Arrivals time: 0.22773221926763654 Scheduler time: 4.90406839735806 Scheduler overhead time: 0.04469451028853655 Adapter cache time: 0.01880399789661169 Engine time: 0.04503386560827494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155437084 . Total output tokens: 137184509
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.560547322034836,
    "estimated_duration": 3600.0325098160583,
    "input_throughput": 4017.055390630043,
    "output_throughput": 3492.6801260032094,
    "total_throughput": 7509.735516633252,
    "itl": 97.97190024106233,
    "ttft": 2028179.8257033695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.798679733504308,
    "arrivals": 231825,
    "finished_requests": 58159,
    "scheduler_time": 96.68361608592767
}
#Debug simulation 
Total elapsed time: 4.560644854791462. Arrivals time: 0.20929914200678468 Scheduler time: 4.1842902498319745 Scheduler overhead time: 0.05285094305872917 Adapter cache time: 0.03602252062410116 Engine time: 0.05345645919442177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155437084 . Total output tokens: 137184509
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.267809316981584,
    "estimated_duration": 3600.0859601929105,
    "input_throughput": 4539.976872975608,
    "output_throughput": 3939.013167130077,
    "total_throughput": 8478.990040105686,
    "itl": 121.76190171387056,
    "ttft": 1928686.8644472212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 722,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.609190919091903,
    "arrivals": 231825,
    "finished_requests": 65761,
    "scheduler_time": 94.16969783358422
}
#Debug simulation 
Total elapsed time: 5.267904757056385. Arrivals time: 0.2294895937666297 Scheduler time: 4.908633693587035 Scheduler overhead time: 0.04477395210415125 Adapter cache time: 0.01886171568185091 Engine time: 0.04534923145547509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 4320, 33, 33, 33, 8640, 33, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 33, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 33, 4320, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 33, 33, 4320, 33, 4320, 8640, 33, 33, 4320, 33, 33, 33, 33, 33, 8640, 4320, 4320, 8640, 4320, 33, 8640, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 33, 33, 8640, 4320, 8640, 8640, 33, 8640, 33, 4320, 33, 33, 4320, 4320, 8640, 8640, 8640, 33, 8640, 4320, 4320, 33, 33, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 33, 4320, 4320, 8640, 4320, 8640, 33, 33, 33, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 33, 4320, 4320, 33, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 33, 8640, 33, 8640, 4320, 33, 4320, 33, 33, 4320, 4320, 4320, 8640, 4320, 33, 33]
Prompts retrieved: 697269 . Total input tokens: 155437084 . Total output tokens: 137184509
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.5593357952311635,
    "estimated_duration": 3600.0361107540944,
    "input_throughput": 4024.3721324687613,
    "output_throughput": 3499.1443453497236,
    "total_throughput": 7523.516477818484,
    "itl": 98.2459981750628,
    "ttft": 2027488.4513643428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1726,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.784421421363712,
    "arrivals": 231825,
    "finished_requests": 58268,
    "scheduler_time": 96.63447505214786
}
#Debug simulation 
Total elapsed time: 4.559428609907627. Arrivals time: 0.21480342373251915 Scheduler time: 4.176867763046175 Scheduler overhead time: 0.052749281749129295 Adapter cache time: 0.03674420388415456 Engine time: 0.05351361632347107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123099467 . Total output tokens: 108714760
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.538990729954094,
    "estimated_duration": 3600.0125839479115,
    "input_throughput": 4684.406125465923,
    "output_throughput": 4082.297952382002,
    "total_throughput": 8766.704077847924,
    "itl": 133.10131753421732,
    "ttft": 1801601.5543575939,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1958,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.947096884558327,
    "arrivals": 183717,
    "finished_requests": 67890,
    "scheduler_time": 91.68297812760498
}
#Debug simulation 
Total elapsed time: 5.539086332079023. Arrivals time: 0.2335302820429206 Scheduler time: 5.1669165580533445 Scheduler overhead time: 0.042224105447530746 Adapter cache time: 0.03468782966956496 Engine time: 0.0421515335328877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123099467 . Total output tokens: 108714760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.1863164021633565,
    "estimated_duration": 3600.063107551753,
    "input_throughput": 4502.756345019701,
    "output_throughput": 3923.0345630259126,
    "total_throughput": 8425.790908045614,
    "itl": 121.74062705815781,
    "ttft": 1840901.0112542156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2485,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.119902618950814,
    "arrivals": 183717,
    "finished_requests": 65223,
    "scheduler_time": 92.44485183349326
}
#Debug simulation 
Total elapsed time: 5.186412342824042. Arrivals time: 0.2269837474450469 Scheduler time: 4.805606122594327 Scheduler overhead time: 0.044893491081893444 Adapter cache time: 0.04280619928613305 Engine time: 0.04530526790767908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123099467 . Total output tokens: 108714760
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.5285203121602535,
    "estimated_duration": 3600.050144531624,
    "input_throughput": 3991.703843855658,
    "output_throughput": 3484.7047947528386,
    "total_throughput": 7476.408638608496,
    "itl": 97.95418125188117,
    "ttft": 1952134.06454646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.163943234538806,
    "arrivals": 183717,
    "finished_requests": 57850,
    "scheduler_time": 94.9371984074058
}
#Debug simulation 
Total elapsed time: 4.528616033028811. Arrivals time: 0.2088714838027954 Scheduler time: 4.112495371606201 Scheduler overhead time: 0.05248607136309147 Adapter cache time: 0.07655390538275242 Engine time: 0.05350379319861531 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123099467 . Total output tokens: 108714760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.21623025322333,
    "estimated_duration": 3600.072409131704,
    "input_throughput": 4504.120239045667,
    "output_throughput": 3923.9594081962255,
    "total_throughput": 8428.079647241892,
    "itl": 121.70748522760829,
    "ttft": 1840594.7621296013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.065402385476407,
    "arrivals": 183717,
    "finished_requests": 65236,
    "scheduler_time": 92.47083458758907
}
#Debug simulation 
Total elapsed time: 5.216326252091676. Arrivals time: 0.2347889393568039 Scheduler time: 4.827629253733903 Scheduler overhead time: 0.044763035140931606 Adapter cache time: 0.04293719585984945 Engine time: 0.04532811092212796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123099467 . Total output tokens: 108714760
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.5255180252715945,
    "estimated_duration": 3600.01137059305,
    "input_throughput": 3992.521278518139,
    "output_throughput": 3485.084547922739,
    "total_throughput": 7477.6058264408775,
    "itl": 97.93364585868981,
    "ttft": 1952160.6766549477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.822882092722,
    "arrivals": 183717,
    "finished_requests": 57861,
    "scheduler_time": 94.94964715777701
}
#Debug simulation 
Total elapsed time: 4.525636686943471. Arrivals time: 0.2072181380353868 Scheduler time: 4.110166210215539 Scheduler overhead time: 0.052705511916428804 Adapter cache time: 0.07692421041429043 Engine time: 0.05387457553297281 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123099467 . Total output tokens: 108714760
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.23357786424458,
    "estimated_duration": 3600.039003232893,
    "input_throughput": 4505.7209061994845,
    "output_throughput": 3925.4902481082318,
    "total_throughput": 8431.211154307717,
    "itl": 121.66214220235814,
    "ttft": 1840242.171433278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.915114904843355,
    "arrivals": 183717,
    "finished_requests": 65261,
    "scheduler_time": 92.4976462471784
}
#Debug simulation 
Total elapsed time: 5.2336725001223385. Arrivals time: 0.22470960160717368 Scheduler time: 4.8546722759492695 Scheduler overhead time: 0.045082907658070326 Adapter cache time: 0.04275962803512812 Engine time: 0.04553654510527849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 1080, 540, 540, 540, 8640, 540, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 540, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 540, 1080, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 540, 540, 1080, 540, 1080, 8640, 540, 540, 1080, 540, 540, 540, 540, 540, 8640, 1080, 1080, 8640, 1080, 540, 8640, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 540, 540, 8640, 1080, 8640, 8640, 540, 8640, 540, 1080, 540, 540, 1080, 1080, 8640, 8640, 8640, 540, 8640, 1080, 1080, 540, 540, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 540, 1080, 1080, 8640, 1080, 8640, 540, 540, 540, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 540, 1080, 1080, 540, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 540, 8640, 540, 8640, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 8640, 1080, 540, 540]
Prompts retrieved: 552420 . Total input tokens: 123099467 . Total output tokens: 108714760
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.553351824637502,
    "estimated_duration": 3600.008956960586,
    "input_throughput": 3992.9170098888108,
    "output_throughput": 3485.4510502645326,
    "total_throughput": 7478.368060153343,
    "itl": 97.92133530731947,
    "ttft": 1952055.7957058249,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.516499071234215,
    "arrivals": 183717,
    "finished_requests": 57866,
    "scheduler_time": 94.95693873927424
}
#Debug simulation 
Total elapsed time: 4.553459926042706. Arrivals time: 0.21218846132978797 Scheduler time: 4.133062953129411 Scheduler overhead time: 0.05315569741651416 Adapter cache time: 0.07627478148788214 Engine time: 0.053786253090947866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 119919062 . Total output tokens: 105915383
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.304814326576889,
    "estimated_duration": 3600.0428705125446,
    "input_throughput": 4663.001137430901,
    "output_throughput": 4089.967128059147,
    "total_throughput": 8752.968265490048,
    "itl": 134.32611862039036,
    "ttft": 1780278.6556754461,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2288,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.129191865101877,
    "arrivals": 179046,
    "finished_requests": 67986,
    "scheduler_time": 91.31377399643257
}
#Debug simulation 
Total elapsed time: 5.304907459765673. Arrivals time: 0.23115961952134967 Scheduler time: 4.932625703513622 Scheduler overhead time: 0.041668621357530355 Adapter cache time: 0.03839519340544939 Engine time: 0.041804286651313305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 119919062 . Total output tokens: 105915383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.032507986295968,
    "estimated_duration": 3600.0866455242394,
    "input_throughput": 4476.543924306916,
    "output_throughput": 3930.609008422746,
    "total_throughput": 8407.152932729661,
    "itl": 122.8649962694273,
    "ttft": 1819134.4616112683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2893,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.141008654697323,
    "arrivals": 179046,
    "finished_requests": 65331,
    "scheduler_time": 92.05166499606007
}
#Debug simulation 
Total elapsed time: 5.032600212376565. Arrivals time: 0.22101763635873795 Scheduler time: 4.65333154797554 Scheduler overhead time: 0.044851678889244795 Adapter cache time: 0.047523034270852804 Engine time: 0.04514002101495862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 119919062 . Total output tokens: 105915383
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.572924579959363,
    "estimated_duration": 3600.1108090190305,
    "input_throughput": 4059.258665980342,
    "output_throughput": 3569.6590137740027,
    "total_throughput": 7628.917679754345,
    "itl": 96.49701337316473,
    "ttft": 1913016.4853854948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.934496984240784,
    "arrivals": 179046,
    "finished_requests": 59253,
    "scheduler_time": 96.66948097896173
}
#Debug simulation 
Total elapsed time: 4.5730185136199. Arrivals time: 0.20938410516828299 Scheduler time: 4.157268474809825 Scheduler overhead time: 0.05326450988650322 Adapter cache time: 0.0721803093329072 Engine time: 0.05588201666250825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 119919062 . Total output tokens: 105915383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.013422599993646,
    "estimated_duration": 3600.0623164067138,
    "input_throughput": 4479.249963677081,
    "output_throughput": 3932.3449862195835,
    "total_throughput": 8411.594949896664,
    "itl": 122.86732465955487,
    "ttft": 1818664.9546221031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2899,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.91464287365366,
    "arrivals": 179046,
    "finished_requests": 65362,
    "scheduler_time": 92.07420337903028
}
#Debug simulation 
Total elapsed time: 5.013521164190024. Arrivals time: 0.22117151087149978 Scheduler time: 4.634343825280666 Scheduler overhead time: 0.04459783807396889 Adapter cache time: 0.04769649310037494 Engine time: 0.04497513035312295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 119919062 . Total output tokens: 105915383
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.551995757035911,
    "estimated_duration": 3600.050152799434,
    "input_throughput": 4039.8006646354206,
    "output_throughput": 3556.425176478173,
    "total_throughput": 7596.225841113594,
    "itl": 96.01053738617823,
    "ttft": 1915253.2163188325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3829,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.466552598412296,
    "arrivals": 179046,
    "finished_requests": 58987,
    "scheduler_time": 96.73505772491126
}
#Debug simulation 
Total elapsed time: 4.552088620141149. Arrivals time: 0.20986276678740978 Scheduler time: 4.136729136575013 Scheduler overhead time: 0.05348268384113908 Adapter cache time: 0.07219354528933764 Engine time: 0.054673886857926846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 119919062 . Total output tokens: 105915383
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.016588453669101,
    "estimated_duration": 3600.078062952644,
    "input_throughput": 4481.201162279412,
    "output_throughput": 3934.130247271337,
    "total_throughput": 8415.331409550749,
    "itl": 122.82343865201098,
    "ttft": 1818172.6526830113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2901,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.51975464859648,
    "arrivals": 179046,
    "finished_requests": 65386,
    "scheduler_time": 92.10773920481614
}
#Debug simulation 
Total elapsed time: 5.016682632733136. Arrivals time: 0.22445391304790974 Scheduler time: 4.634042737539858 Scheduler overhead time: 0.04465014860033989 Adapter cache time: 0.04792633466422558 Engine time: 0.044845602940768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 1080, 270, 270, 270, 8640, 270, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 270, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 270, 1080, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 270, 270, 1080, 270, 1080, 8640, 270, 270, 1080, 270, 270, 270, 270, 270, 8640, 1080, 1080, 8640, 1080, 270, 8640, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 270, 270, 8640, 1080, 8640, 8640, 270, 8640, 270, 1080, 270, 270, 1080, 1080, 8640, 8640, 8640, 270, 8640, 1080, 1080, 270, 270, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 270, 1080, 1080, 8640, 1080, 8640, 270, 270, 270, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 270, 1080, 1080, 270, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 270, 8640, 270, 8640, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 8640, 1080, 270, 270]
Prompts retrieved: 538110 . Total input tokens: 119919062 . Total output tokens: 105915383
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.568255495745689,
    "estimated_duration": 3600.0970155282666,
    "input_throughput": 4060.4839083357265,
    "output_throughput": 3570.8248818160396,
    "total_throughput": 7631.308790151766,
    "itl": 96.53314407039595,
    "ttft": 1912706.7784299578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.43963469775502,
    "arrivals": 179046,
    "finished_requests": 59273,
    "scheduler_time": 96.66375127049432
}
#Debug simulation 
Total elapsed time: 4.568378238938749. Arrivals time: 0.2112699174322188 Scheduler time: 4.151432593353093 Scheduler overhead time: 0.0530801871791482 Adapter cache time: 0.07310104183852673 Engine time: 0.054425474256277084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118325659 . Total output tokens: 104525493
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.327340765856206,
    "estimated_duration": 3600.102546196507,
    "input_throughput": 4640.693920691467,
    "output_throughput": 4087.7293941384114,
    "total_throughput": 8728.423314829879,
    "itl": 133.9972400371628,
    "ttft": 1771241.1432423869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.060015302431037,
    "arrivals": 176720,
    "finished_requests": 68036,
    "scheduler_time": 91.25921090350283
}
#Debug simulation 
Total elapsed time: 5.32741117104888. Arrivals time: 0.22733310237526894 Scheduler time: 4.954940041527152 Scheduler overhead time: 0.04131751600652933 Adapter cache time: 0.0426792916841805 Engine time: 0.042040363419801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118325659 . Total output tokens: 104525493
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.964451385196298,
    "estimated_duration": 3600.1082066800636,
    "input_throughput": 4485.734337105482,
    "output_throughput": 3956.4958002013263,
    "total_throughput": 8442.230137306808,
    "itl": 121.8513209156104,
    "ttft": 1806096.8242450478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2924,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.32502799412188,
    "arrivals": 176720,
    "finished_requests": 65867,
    "scheduler_time": 92.64051920580594
}
#Debug simulation 
Total elapsed time: 4.964577173348516. Arrivals time: 0.2202687975950539 Scheduler time: 4.582992295734584 Scheduler overhead time: 0.044412096962332726 Adapter cache time: 0.051177837420254946 Engine time: 0.04503957461565733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118325659 . Total output tokens: 104525493
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.632112542167306,
    "estimated_duration": 3600.003286885942,
    "input_throughput": 4132.394282580924,
    "output_throughput": 3653.2536089366863,
    "total_throughput": 7785.647891517609,
    "itl": 94.58946553665434,
    "ttft": 1886820.2227304205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2970,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.265169880432456,
    "arrivals": 176720,
    "finished_requests": 60764,
    "scheduler_time": 98.55530006882026
}
#Debug simulation 
Total elapsed time: 4.632206161040813. Arrivals time: 0.2128273001872003 Scheduler time: 4.219581757672131 Scheduler overhead time: 0.05387949291616678 Adapter cache time: 0.065392239484936 Engine time: 0.05523476283997297 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118325659 . Total output tokens: 104525493
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 4.9896340956911445,
    "estimated_duration": 3600.085900618027,
    "input_throughput": 4487.684584755739,
    "output_throughput": 3957.3850161614832,
    "total_throughput": 8445.069600917222,
    "itl": 121.80424219547962,
    "ttft": 1805926.8122091028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2930,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.075062456531906,
    "arrivals": 176720,
    "finished_requests": 65887,
    "scheduler_time": 92.6694385600481
}
#Debug simulation 
Total elapsed time: 4.989742977079004. Arrivals time: 0.22699878318235278 Scheduler time: 4.60151802143082 Scheduler overhead time: 0.044512322172522545 Adapter cache time: 0.05077691888436675 Engine time: 0.045237228740006685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118325659 . Total output tokens: 104525493
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.64317009691149,
    "estimated_duration": 3600.068992555542,
    "input_throughput": 4130.02807189135,
    "output_throughput": 3651.559741544921,
    "total_throughput": 7781.587813436271,
    "itl": 94.45669463477529,
    "ttft": 1887271.1331092492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2966,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.0285443128323,
    "arrivals": 176720,
    "finished_requests": 60732,
    "scheduler_time": 98.60412729231142
}
#Debug simulation 
Total elapsed time: 4.6432635500095785. Arrivals time: 0.21254052827134728 Scheduler time: 4.231691819150001 Scheduler overhead time: 0.05373147502541542 Adapter cache time: 0.06490628700703382 Engine time: 0.05505430744960904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118325659 . Total output tokens: 104525493
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.961861624848098,
    "estimated_duration": 3600.0909356598513,
    "input_throughput": 4489.264101612965,
    "output_throughput": 3958.7627798040066,
    "total_throughput": 8448.026881416972,
    "itl": 121.75581779566342,
    "ttft": 1805409.0991883536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2934,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.730424039635334,
    "arrivals": 176720,
    "finished_requests": 65912,
    "scheduler_time": 92.70403303330966
}
#Debug simulation 
Total elapsed time: 4.9619533768855035. Arrivals time: 0.22696771891787648 Scheduler time: 4.572619722224772 Scheduler overhead time: 0.044429535046219826 Adapter cache time: 0.051707551814615726 Engine time: 0.04543177084997296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 1080, 135, 135, 135, 8640, 135, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 135, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 135, 1080, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 135, 135, 1080, 135, 1080, 8640, 135, 135, 1080, 135, 135, 135, 135, 135, 8640, 1080, 1080, 8640, 1080, 135, 8640, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 135, 135, 8640, 1080, 8640, 8640, 135, 8640, 135, 1080, 135, 135, 1080, 1080, 8640, 8640, 8640, 135, 8640, 1080, 1080, 135, 135, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 135, 1080, 1080, 8640, 1080, 8640, 135, 135, 135, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 135, 1080, 1080, 135, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 135, 8640, 135, 8640, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 8640, 1080, 135, 135]
Prompts retrieved: 530955 . Total input tokens: 118325659 . Total output tokens: 104525493
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.658043729141355,
    "estimated_duration": 3600.0180923397484,
    "input_throughput": 4132.988673490207,
    "output_throughput": 3653.871914696645,
    "total_throughput": 7786.860588186852,
    "itl": 94.57439519978722,
    "ttft": 1886839.0407075144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.920409333203335,
    "arrivals": 176720,
    "finished_requests": 60776,
    "scheduler_time": 98.56462294353692
}
#Debug simulation 
Total elapsed time: 4.658135432284325. Arrivals time: 0.21545355673879385 Scheduler time: 4.243193211499602 Scheduler overhead time: 0.05394785339012742 Adapter cache time: 0.06491326913237572 Engine time: 0.05526727344840765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117515559 . Total output tokens: 103818053
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.110765933059156,
    "estimated_duration": 3600.076678294817,
    "input_throughput": 4693.24253615699,
    "output_throughput": 4101.3684761274535,
    "total_throughput": 8794.611012284444,
    "itl": 133.34567600208334,
    "ttft": 1769686.1454176009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.201928364453329,
    "arrivals": 175562,
    "finished_requests": 68486,
    "scheduler_time": 91.5774940391598
}
#Debug simulation 
Total elapsed time: 5.11086519388482. Arrivals time: 0.2265326175838709 Scheduler time: 4.742105226498097 Scheduler overhead time: 0.04119135718792677 Adapter cache time: 0.04016161756590009 Engine time: 0.04178194934502244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117515559 . Total output tokens: 103818053
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.993734886404127,
    "estimated_duration": 3600.002702180447,
    "input_throughput": 4559.041022402359,
    "output_throughput": 3984.960619977036,
    "total_throughput": 8544.001642379395,
    "itl": 120.70658840625197,
    "ttft": 1800287.4919103389,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.159329990129542,
    "arrivals": 175562,
    "finished_requests": 66525,
    "scheduler_time": 93.31102397008472
}
#Debug simulation 
Total elapsed time: 4.993831070140004. Arrivals time: 0.22387764556333423 Scheduler time: 4.611953070387244 Scheduler overhead time: 0.04442217806354165 Adapter cache time: 0.04746532114222646 Engine time: 0.045185946859419346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117515559 . Total output tokens: 103818053
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.6603269767947495,
    "estimated_duration": 3600.081460951883,
    "input_throughput": 4195.094795440201,
    "output_throughput": 3668.287549390124,
    "total_throughput": 7863.382344830326,
    "itl": 93.38631627788911,
    "ttft": 1882012.7917634961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.738157860231453,
    "arrivals": 175562,
    "finished_requests": 61153,
    "scheduler_time": 99.28010865502637
}
#Debug simulation 
Total elapsed time: 4.6604195781983435. Arrivals time: 0.21322040352970362 Scheduler time: 4.250366562977433 Scheduler overhead time: 0.054360838141292334 Adapter cache time: 0.06098795589059591 Engine time: 0.05575829604640603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117515559 . Total output tokens: 103818053
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 4.964584122877568,
    "estimated_duration": 3600.04974726189,
    "input_throughput": 4559.792545223913,
    "output_throughput": 3985.627701648592,
    "total_throughput": 8545.420246872505,
    "itl": 120.62294925935602,
    "ttft": 1799744.0270682308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.943257895191586,
    "arrivals": 175562,
    "finished_requests": 66539,
    "scheduler_time": 93.34938875454024
}
#Debug simulation 
Total elapsed time: 4.964677006006241. Arrivals time: 0.22527326503768563 Scheduler time: 4.580989712849259 Scheduler overhead time: 0.044372040778398514 Adapter cache time: 0.04758990602567792 Engine time: 0.04570394288748503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117515559 . Total output tokens: 103818053
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.658363712951541,
    "estimated_duration": 3600.096612801775,
    "input_throughput": 4201.765571015495,
    "output_throughput": 3674.952209047415,
    "total_throughput": 7876.717780062911,
    "itl": 93.27023693235775,
    "ttft": 1881175.0713597648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.65162163950954,
    "arrivals": 175562,
    "finished_requests": 61258,
    "scheduler_time": 99.42739811666591
}
#Debug simulation 
Total elapsed time: 4.658455683849752. Arrivals time: 0.2235617572441697 Scheduler time: 4.239077657926828 Scheduler overhead time: 0.054371911101043224 Adapter cache time: 0.060063470620661974 Engine time: 0.05574837513267994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117515559 . Total output tokens: 103818053
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.980776225682348,
    "estimated_duration": 3600.0559133181387,
    "input_throughput": 4560.805830614618,
    "output_throughput": 3986.6283595500645,
    "total_throughput": 8547.434190164682,
    "itl": 120.63073542831641,
    "ttft": 1799201.228630085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.870427458259355,
    "arrivals": 175562,
    "finished_requests": 66554,
    "scheduler_time": 93.36603100384305
}
#Debug simulation 
Total elapsed time: 4.980867939069867. Arrivals time: 0.22494526440277696 Scheduler time: 4.597848211880773 Scheduler overhead time: 0.04457088327035308 Adapter cache time: 0.04737416002899408 Engine time: 0.04527198849245906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 1080, 66, 66, 66, 8640, 66, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 66, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 66, 1080, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 66, 66, 1080, 66, 1080, 8640, 66, 66, 1080, 66, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 66, 8640, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 1080, 66, 66, 1080, 1080, 8640, 8640, 8640, 66, 8640, 1080, 1080, 66, 66, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 8640, 1080, 8640, 66, 66, 66, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 66, 1080, 1080, 66, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 8640, 1080, 66, 66]
Prompts retrieved: 527298 . Total input tokens: 117515559 . Total output tokens: 103818053
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.679009886924177,
    "estimated_duration": 3600.019426348855,
    "input_throughput": 4202.408156264757,
    "output_throughput": 3675.311556143211,
    "total_throughput": 7877.719712407968,
    "itl": 93.26721860890729,
    "ttft": 1881079.289916753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.53433246947809,
    "arrivals": 175562,
    "finished_requests": 61264,
    "scheduler_time": 99.42805369204625
}
#Debug simulation 
Total elapsed time: 4.679132604971528. Arrivals time: 0.22125240042805672 Scheduler time: 4.261970566119999 Scheduler overhead time: 0.0546138733625412 Adapter cache time: 0.05960666202008724 Engine time: 0.056011846754699945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117133124 . Total output tokens: 103479286
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.14534947834909,
    "estimated_duration": 3600.039325895161,
    "input_throughput": 4747.105921058397,
    "output_throughput": 4136.13342856956,
    "total_throughput": 8883.239349627958,
    "itl": 132.38679042889893,
    "ttft": 1754539.8280301737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2057,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.601725378721392,
    "arrivals": 174997,
    "finished_requests": 68964,
    "scheduler_time": 92.19959164186622
}
#Debug simulation 
Total elapsed time: 5.145474413409829. Arrivals time: 0.22983349673449993 Scheduler time: 4.772643805947155 Scheduler overhead time: 0.041329710744321346 Adapter cache time: 0.040246824733912945 Engine time: 0.04220462264493108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117133124 . Total output tokens: 103479286
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.9818534520454705,
    "estimated_duration": 3600.117777313563,
    "input_throughput": 4624.907303011771,
    "output_throughput": 4026.98492014843,
    "total_throughput": 8651.892223160201,
    "itl": 119.55376352224616,
    "ttft": 1783138.3224176127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2092,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.309777738097779,
    "arrivals": 174997,
    "finished_requests": 67142,
    "scheduler_time": 94.09644322531628
}
#Debug simulation 
Total elapsed time: 4.9819468799978495. Arrivals time: 0.22059846576303244 Scheduler time: 4.604972638189793 Scheduler overhead time: 0.04466952895745635 Adapter cache time: 0.04540696879848838 Engine time: 0.04553188942372799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117133124 . Total output tokens: 103479286
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.713240762241185,
    "estimated_duration": 3600.0249837131237,
    "input_throughput": 4265.944005799654,
    "output_throughput": 3713.7936710123117,
    "total_throughput": 7979.737676811967,
    "itl": 92.75679304456818,
    "ttft": 1864240.545756246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1956,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.689492975193723,
    "arrivals": 174997,
    "finished_requests": 61842,
    "scheduler_time": 100.01709964473976
}
#Debug simulation 
Total elapsed time: 4.7133600153028965. Arrivals time: 0.21512962086126208 Scheduler time: 4.304174873512238 Scheduler overhead time: 0.05492802103981376 Adapter cache time: 0.056985643692314625 Engine time: 0.056271815206855536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117133124 . Total output tokens: 103479286
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 4.988577615935355,
    "estimated_duration": 3600.1127200416977,
    "input_throughput": 4626.097096150674,
    "output_throughput": 4028.0952647038334,
    "total_throughput": 8654.192360854508,
    "itl": 119.52011343952299,
    "ttft": 1782626.9611611234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.359129702183647,
    "arrivals": 174997,
    "finished_requests": 67161,
    "scheduler_time": 94.12033937475927
}
#Debug simulation 
Total elapsed time: 4.988701665773988. Arrivals time: 0.22631526598706841 Scheduler time: 4.605678732506931 Scheduler overhead time: 0.044522731099277735 Adapter cache time: 0.04555317899212241 Engine time: 0.04568032966926694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117133124 . Total output tokens: 103479286
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.7093580779619515,
    "estimated_duration": 3600.0315669200436,
    "input_throughput": 4266.211202458912,
    "output_throughput": 3714.269653318565,
    "total_throughput": 7980.480855777477,
    "itl": 92.74623730736785,
    "ttft": 1864163.0848167203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1950,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.524689268176159,
    "arrivals": 174997,
    "finished_requests": 61852,
    "scheduler_time": 100.02113086333468
}
#Debug simulation 
Total elapsed time: 4.709450109861791. Arrivals time: 0.21519738482311368 Scheduler time: 4.299815118312836 Scheduler overhead time: 0.054961041547358036 Adapter cache time: 0.05722375959157944 Engine time: 0.05629365053027868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117133124 . Total output tokens: 103479286
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.996380882803351,
    "estimated_duration": 3600.0055582554905,
    "input_throughput": 4623.332861759649,
    "output_throughput": 4025.4373959973586,
    "total_throughput": 8648.770257757007,
    "itl": 119.42402404772683,
    "ttft": 1783089.9030180492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2081,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.284939477327944,
    "arrivals": 174997,
    "finished_requests": 67112,
    "scheduler_time": 94.098326111208
}
#Debug simulation 
Total elapsed time: 4.996474077925086. Arrivals time: 0.22756964899599552 Scheduler time: 4.612007719930261 Scheduler overhead time: 0.04490226740017533 Adapter cache time: 0.045335604809224606 Engine time: 0.045740352012217045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 1080, 33, 33, 33, 8640, 33, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 33, 8640, 1080, 8640, 8640, 8640, 1080, 8640, 33, 1080, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 33, 33, 1080, 33, 1080, 8640, 33, 33, 1080, 33, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 33, 8640, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 1080, 33, 33, 1080, 1080, 8640, 8640, 8640, 33, 8640, 1080, 1080, 33, 33, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 8640, 1080, 8640, 33, 33, 33, 1080, 1080, 1080, 8640, 8640, 1080, 8640, 33, 1080, 1080, 33, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 8640, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 8640, 1080, 33, 33]
Prompts retrieved: 525549 . Total input tokens: 117133124 . Total output tokens: 103479286
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.72175762290135,
    "estimated_duration": 3600.0114500883196,
    "input_throughput": 4265.73587692985,
    "output_throughput": 3713.8215212265495,
    "total_throughput": 7979.5573981564,
    "itl": 92.74597712340868,
    "ttft": 1864173.9698569186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1953,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.397980218026511,
    "arrivals": 174997,
    "finished_requests": 61845,
    "scheduler_time": 100.0224540510182
}
#Debug simulation 
Total elapsed time: 4.7218800550326705. Arrivals time: 0.21423256490379572 Scheduler time: 4.311970189679414 Scheduler overhead time: 0.05494187446311116 Adapter cache time: 0.05801501451060176 Engine time: 0.056756493635475636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_160_slots_96_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_160_slots_96_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113581257 . Total output tokens: 100320098
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.122515199705958,
    "estimated_duration": 3600.1463280587723,
    "input_throughput": 4656.053246879679,
    "output_throughput": 4120.329744485274,
    "total_throughput": 8776.382991364953,
    "itl": 132.83402351132696,
    "ttft": 1757453.9723356839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.4837169448045,
    "arrivals": 169522,
    "finished_requests": 68114,
    "scheduler_time": 91.7182699602341
}
#Debug simulation 
Total elapsed time: 5.1226151320151985. Arrivals time: 0.22748924884945154 Scheduler time: 4.739386614412069 Scheduler overhead time: 0.04145165719091892 Adapter cache time: 0.05322273587808013 Engine time: 0.04190630232915282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_160_slots_96_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_160_slots_96_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113581257 . Total output tokens: 100320098
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.070957736112177,
    "estimated_duration": 3600.0167456593267,
    "input_throughput": 4556.48269408141,
    "output_throughput": 4033.6284595088796,
    "total_throughput": 8590.11115359029,
    "itl": 119.46417262537109,
    "ttft": 1781716.689055581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.71686438796523,
    "arrivals": 169522,
    "finished_requests": 66641,
    "scheduler_time": 94.02967161163845
}
#Debug simulation 
Total elapsed time: 5.071087956894189. Arrivals time: 0.22553414897993207 Scheduler time: 4.676229239907116 Scheduler overhead time: 0.04495151853188872 Adapter cache time: 0.05726108932867646 Engine time: 0.04601632757112384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_160_slots_96_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_160_slots_96_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113581257 . Total output tokens: 100320098
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.7760267979465425,
    "estimated_duration": 3600.030996990141,
    "input_throughput": 4231.208845905867,
    "output_throughput": 3751.3763107293003,
    "total_throughput": 7982.585156635167,
    "itl": 91.85387062620973,
    "ttft": 1854465.090709918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.64690096858002,
    "arrivals": 169522,
    "finished_requests": 61891,
    "scheduler_time": 100.7495305935961
}
#Debug simulation 
Total elapsed time: 4.776121785864234. Arrivals time: 0.2248709574341774 Scheduler time: 4.34862992214039 Scheduler overhead time: 0.05544879473745823 Adapter cache time: 0.06402194825932384 Engine time: 0.056938041001558304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_160_slots_96_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_160_slots_96_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113581257 . Total output tokens: 100320098
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.042750541586429,
    "estimated_duration": 3600.0304712093866,
    "input_throughput": 4558.383916813668,
    "output_throughput": 4035.2936221453065,
    "total_throughput": 8593.677538958975,
    "itl": 119.42000662332214,
    "ttft": 1781283.4118575354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.32725519368013,
    "arrivals": 169522,
    "finished_requests": 66668,
    "scheduler_time": 94.06471186464607
}
#Debug simulation 
Total elapsed time: 5.042851511854678. Arrivals time: 0.22556250868365169 Scheduler time: 4.647455512546003 Scheduler overhead time: 0.04477505153045058 Adapter cache time: 0.058071403298527 Engine time: 0.045973294880241156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_160_slots_96_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_160_slots_96_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113581257 . Total output tokens: 100320098
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.77875090809539,
    "estimated_duration": 3600.0315601671614,
    "input_throughput": 4231.4626262033835,
    "output_throughput": 3751.546555712108,
    "total_throughput": 7983.009181915491,
    "itl": 91.85312995066843,
    "ttft": 1854504.3893675953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3022,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.41478196514813,
    "arrivals": 169522,
    "finished_requests": 61893,
    "scheduler_time": 100.75696295392848
}
#Debug simulation 
Total elapsed time: 4.778879152145237. Arrivals time: 0.21281005069613457 Scheduler time: 4.36291307862848 Scheduler overhead time: 0.0553921228274703 Adapter cache time: 0.06451489869505167 Engine time: 0.05707884440198541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_160_slots_96_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_160_slots_96_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113581257 . Total output tokens: 100320098
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.062738358974457,
    "estimated_duration": 3600.0724271050426,
    "input_throughput": 4559.326605881387,
    "output_throughput": 4036.7404529375517,
    "total_throughput": 8596.067058818939,
    "itl": 119.3157222594654,
    "ttft": 1780981.202196659,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.798814424380463,
    "arrivals": 169522,
    "finished_requests": 66691,
    "scheduler_time": 94.11362515471822
}
#Debug simulation 
Total elapsed time: 5.06283012824133. Arrivals time: 0.22388205071911216 Scheduler time: 4.6689277733676136 Scheduler overhead time: 0.04516701865941286 Adapter cache time: 0.057534968946129084 Engine time: 0.046158598735928535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_160_slots_96_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_160_slots_96_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 540, 270, 270, 270, 8640, 270, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 270, 8640, 540, 8640, 8640, 8640, 540, 8640, 270, 540, 540, 540, 8640, 270, 270, 8640, 270, 8640, 270, 270, 540, 270, 540, 8640, 270, 270, 540, 270, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 270, 8640, 8640, 8640, 540, 540, 270, 270, 270, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 270, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 540, 270, 270, 540, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 8640, 540, 8640, 270, 270, 270, 540, 540, 540, 8640, 8640, 540, 8640, 270, 540, 540, 270, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 509490 . Total input tokens: 113581257 . Total output tokens: 100320098
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.775364890228957,
    "estimated_duration": 3600.042197361423,
    "input_throughput": 4231.572066340036,
    "output_throughput": 3751.7657459402344,
    "total_throughput": 7983.337812280271,
    "itl": 91.84529788965564,
    "ttft": 1854320.695988807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3023,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.209579215590317,
    "arrivals": 169522,
    "finished_requests": 61896,
    "scheduler_time": 100.76159260199081
}
#Debug simulation 
Total elapsed time: 4.775482893921435. Arrivals time: 0.21392529923468828 Scheduler time: 4.358353186864406 Scheduler overhead time: 0.05564247444272041 Adapter cache time: 0.06346105737611651 Engine time: 0.05796976946294308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 111955793 . Total output tokens: 98907135
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.249716151040047,
    "estimated_duration": 3600.07124680051,
    "input_throughput": 4917.796839641561,
    "output_throughput": 4263.943668793346,
    "total_throughput": 9181.740508434907,
    "itl": 127.9362406750702,
    "ttft": 1696481.5452813006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.742619668897515,
    "arrivals": 167239,
    "finished_requests": 71344,
    "scheduler_time": 94.58168718784844
}
#Debug simulation 
Total elapsed time: 5.249843209981918. Arrivals time: 0.23305431474000216 Scheduler time: 4.864547296892852 Scheduler overhead time: 0.042274607345461845 Adapter cache time: 0.046792592853307724 Engine time: 0.043382365722209215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 111955793 . Total output tokens: 98907135
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.208063356112689,
    "estimated_duration": 3600.06753900951,
    "input_throughput": 4806.018723959916,
    "output_throughput": 4171.014526058405,
    "total_throughput": 8977.033250018321,
    "itl": 115.03997202976323,
    "ttft": 1719710.5814520172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.13795896928717,
    "arrivals": 167239,
    "finished_requests": 69744,
    "scheduler_time": 96.93871490036011
}
#Debug simulation 
Total elapsed time: 5.208184071816504. Arrivals time: 0.2276232587173581 Scheduler time: 4.814488342963159 Scheduler overhead time: 0.04622675525024533 Adapter cache time: 0.05061934143304825 Engine time: 0.04745705705136061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 111955793 . Total output tokens: 98907135
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.8794381730258465,
    "estimated_duration": 3600.0089592404197,
    "input_throughput": 4448.654762064567,
    "output_throughput": 3860.598725546626,
    "total_throughput": 8309.253487611193,
    "itl": 88.9038112113258,
    "ttft": 1803735.4801236386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.166160526498935,
    "arrivals": 167239,
    "finished_requests": 64575,
    "scheduler_time": 103.36871234285235
}
#Debug simulation 
Total elapsed time: 4.87954488536343. Arrivals time: 0.2328796978108585 Scheduler time: 4.446918917819858 Scheduler overhead time: 0.05681914649903774 Adapter cache time: 0.05735138664022088 Engine time: 0.05854746978729963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 111955793 . Total output tokens: 98907135
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.202337522991002,
    "estimated_duration": 3600.022823111979,
    "input_throughput": 4808.0103517337075,
    "output_throughput": 4172.544102655196,
    "total_throughput": 8980.554454388905,
    "itl": 114.99940324999966,
    "ttft": 1719677.6063379007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.005453985869263,
    "arrivals": 167239,
    "finished_requests": 69765,
    "scheduler_time": 96.96562191050695
}
#Debug simulation 
Total elapsed time: 5.202448130119592. Arrivals time: 0.23209042195230722 Scheduler time: 4.804324237629771 Scheduler overhead time: 0.0462506297044456 Adapter cache time: 0.0509324511513114 Engine time: 0.04716671444475651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 111955793 . Total output tokens: 98907135
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.8965977020561695,
    "estimated_duration": 3600.0838389953324,
    "input_throughput": 4449.63526306943,
    "output_throughput": 3861.2878537515703,
    "total_throughput": 8310.923116821,
    "itl": 88.9459547220975,
    "ttft": 1803497.2501403529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.030701044699878,
    "arrivals": 167239,
    "finished_requests": 64588,
    "scheduler_time": 103.35847897125426
}
#Debug simulation 
Total elapsed time: 4.896691645961255. Arrivals time: 0.22391188284382224 Scheduler time: 4.473967281635851 Scheduler overhead time: 0.0569794662296772 Adapter cache time: 0.056470658630132675 Engine time: 0.05849570408463478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 111955793 . Total output tokens: 98907135
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.205360968597233,
    "estimated_duration": 3600.102276402133,
    "input_throughput": 4810.53388775045,
    "output_throughput": 4174.162244917686,
    "total_throughput": 8984.696132668136,
    "itl": 114.95927603925514,
    "ttft": 1719899.8551641076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.80020432791307,
    "arrivals": 167239,
    "finished_requests": 69795,
    "scheduler_time": 96.99906574161339
}
#Debug simulation 
Total elapsed time: 5.205455022864044. Arrivals time: 0.235859842505306 Scheduler time: 4.803195260930806 Scheduler overhead time: 0.04646905744448304 Adapter cache time: 0.050899761728942394 Engine time: 0.04737012227997184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 540, 135, 135, 135, 8640, 135, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 135, 8640, 540, 8640, 8640, 8640, 540, 8640, 135, 540, 540, 540, 8640, 135, 135, 8640, 135, 8640, 135, 135, 540, 135, 540, 8640, 135, 135, 540, 135, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 135, 8640, 8640, 8640, 540, 540, 135, 135, 135, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 135, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 540, 135, 135, 540, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 8640, 540, 8640, 135, 135, 135, 540, 540, 540, 8640, 8640, 540, 8640, 135, 540, 540, 135, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 502335 . Total input tokens: 111955793 . Total output tokens: 98907135
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.088156516198069,
    "estimated_duration": 3600.0110649921585,
    "input_throughput": 4448.582993462239,
    "output_throughput": 3860.505634315397,
    "total_throughput": 8309.088627777635,
    "itl": 88.8713612496641,
    "ttft": 1803560.7358267407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.84600888168413,
    "arrivals": 167239,
    "finished_requests": 64572,
    "scheduler_time": 103.38445722237628
}
#Debug simulation 
Total elapsed time: 5.088221862912178. Arrivals time: 0.2228138637728989 Scheduler time: 4.666988101322204 Scheduler overhead time: 0.05685066245496273 Adapter cache time: 0.05639504827558994 Engine time: 0.05841445829719305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111152831 . Total output tokens: 98178968
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.3630680199712515,
    "estimated_duration": 3600.0900381783654,
    "input_throughput": 4997.400289772596,
    "output_throughput": 4361.319254099748,
    "total_throughput": 9358.719543872343,
    "itl": 125.40045424522137,
    "ttft": 1670037.4874865569,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1914,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.65615088715252,
    "arrivals": 166072,
    "finished_requests": 72803,
    "scheduler_time": 96.41812533044704
}
#Debug simulation 
Total elapsed time: 5.363161102868617. Arrivals time: 0.24091042717918754 Scheduler time: 4.970372183714062 Scheduler overhead time: 0.04311068216338754 Adapter cache time: 0.04441604483872652 Engine time: 0.04428447317332029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111152831 . Total output tokens: 98178968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.280539625324309,
    "estimated_duration": 3600.111781483823,
    "input_throughput": 4873.597006137527,
    "output_throughput": 4253.243768361253,
    "total_throughput": 9126.84077449878,
    "itl": 112.90615515617453,
    "ttft": 1696987.906901986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1847,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.508331321221556,
    "arrivals": 166072,
    "finished_requests": 70993,
    "scheduler_time": 98.57632937500529
}
#Debug simulation 
Total elapsed time: 5.280634438153356. Arrivals time: 0.23454436473548412 Scheduler time: 4.8815534603782 Scheduler overhead time: 0.0471826926805079 Adapter cache time: 0.047093525528907776 Engine time: 0.04815866705030203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111152831 . Total output tokens: 98178968
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.935343363787979,
    "estimated_duration": 3600.02190660595,
    "input_throughput": 4484.72548746832,
    "output_throughput": 3926.008887352875,
    "total_throughput": 8410.734374821195,
    "itl": 87.64356376535386,
    "ttft": 1784420.5326258633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.722695866222285,
    "arrivals": 166072,
    "finished_requests": 65439,
    "scheduler_time": 104.78450461362068
}
#Debug simulation 
Total elapsed time: 4.935436944942921. Arrivals time: 0.22446863818913698 Scheduler time: 4.516120993997902 Scheduler overhead time: 0.057690059300512075 Adapter cache time: 0.05072524165734649 Engine time: 0.05917414417490363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111152831 . Total output tokens: 98178968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.266562214586884,
    "estimated_duration": 3600.0908439495747,
    "input_throughput": 4879.6565868675225,
    "output_throughput": 4259.146411755039,
    "total_throughput": 9138.802998622561,
    "itl": 112.7883544064609,
    "ttft": 1696295.213587893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.807808480574892,
    "arrivals": 166072,
    "finished_requests": 71093,
    "scheduler_time": 98.69932016537254
}
#Debug simulation 
Total elapsed time: 5.266657473985106. Arrivals time: 0.23238034080713987 Scheduler time: 4.870108613278717 Scheduler overhead time: 0.04704217566177249 Adapter cache time: 0.046839259564876556 Engine time: 0.048170456662774086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111152831 . Total output tokens: 98178968
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.916808082722127,
    "estimated_duration": 3600.0525914112322,
    "input_throughput": 4485.037812647779,
    "output_throughput": 3926.2862530736247,
    "total_throughput": 8411.324065721403,
    "itl": 87.63384691963246,
    "ttft": 1784309.1484510817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.613596983128026,
    "arrivals": 166072,
    "finished_requests": 65444,
    "scheduler_time": 104.7894816922307
}
#Debug simulation 
Total elapsed time: 4.91692932555452. Arrivals time: 0.22196962172165513 Scheduler time: 4.500029567629099 Scheduler overhead time: 0.05749841360375285 Adapter cache time: 0.0511548169888556 Engine time: 0.058974063489586115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111152831 . Total output tokens: 98178968
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.298735603224486,
    "estimated_duration": 3600.0811111210605,
    "input_throughput": 4876.164302457487,
    "output_throughput": 4255.378844847599,
    "total_throughput": 9131.543147305087,
    "itl": 112.8013779321289,
    "ttft": 1696587.1674704247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.848557265699382,
    "arrivals": 166072,
    "finished_requests": 71033,
    "scheduler_time": 98.63353660437167
}
#Debug simulation 
Total elapsed time: 5.298828270286322. Arrivals time: 0.23342554224655032 Scheduler time: 4.902985505759716 Scheduler overhead time: 0.04716643877327442 Adapter cache time: 0.04514659848064184 Engine time: 0.048075669445097446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 540, 66, 66, 66, 8640, 66, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 66, 8640, 540, 8640, 8640, 8640, 540, 8640, 66, 540, 540, 540, 8640, 66, 66, 8640, 66, 8640, 66, 66, 540, 66, 540, 8640, 66, 66, 540, 66, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 66, 8640, 8640, 8640, 540, 540, 66, 66, 66, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 66, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 540, 66, 66, 540, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 8640, 540, 8640, 66, 66, 66, 540, 540, 540, 8640, 8640, 540, 8640, 66, 540, 540, 66, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 498678 . Total input tokens: 111152831 . Total output tokens: 98178968
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.925625609699637,
    "estimated_duration": 3600.0850599032447,
    "input_throughput": 4484.846255392069,
    "output_throughput": 3926.250287091796,
    "total_throughput": 8411.096542483865,
    "itl": 87.63089862085008,
    "ttft": 1784286.9436514366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.46810183547417,
    "arrivals": 166072,
    "finished_requests": 65443,
    "scheduler_time": 104.79479972057912
}
#Debug simulation 
Total elapsed time: 4.9257518127560616. Arrivals time: 0.22276445850729942 Scheduler time: 4.507877495139837 Scheduler overhead time: 0.05749581893905997 Adapter cache time: 0.05097597325220704 Engine time: 0.059358418453484774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110766558 . Total output tokens: 97833648
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.3860215987078846,
    "estimated_duration": 3600.1258470017747,
    "input_throughput": 5004.138678930775,
    "output_throughput": 4391.5775925352555,
    "total_throughput": 9395.71627146603,
    "itl": 124.50502886725198,
    "ttft": 1673432.3667289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.341807725969968,
    "arrivals": 165445,
    "finished_requests": 72947,
    "scheduler_time": 97.14207620653355
}
#Debug simulation 
Total elapsed time: 5.386116378009319. Arrivals time: 0.2384129511192441 Scheduler time: 4.998085746541619 Scheduler overhead time: 0.0431985417380929 Adapter cache time: 0.042034038342535496 Engine time: 0.044170064851641655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110766558 . Total output tokens: 97833648
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.277493722271174,
    "estimated_duration": 3600.018464229825,
    "input_throughput": 4875.326939123034,
    "output_throughput": 4283.48191911261,
    "total_throughput": 9158.808858235643,
    "itl": 112.24678194666222,
    "ttft": 1700164.3643456772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.053477277336537,
    "arrivals": 165445,
    "finished_requests": 71109,
    "scheduler_time": 99.27468602542609
}
#Debug simulation 
Total elapsed time: 5.277584659866989. Arrivals time: 0.23308269726112485 Scheduler time: 4.8836149126291275 Scheduler overhead time: 0.047083568293601274 Adapter cache time: 0.043456879910081625 Engine time: 0.048284368589520454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110766558 . Total output tokens: 97833648
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.024989654310048,
    "estimated_duration": 3600.0951206858035,
    "input_throughput": 4472.7807072310225,
    "output_throughput": 3932.1713803226685,
    "total_throughput": 8404.952087553691,
    "itl": 87.13396957601911,
    "ttft": 1791391.375122028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.229713140167213,
    "arrivals": 165445,
    "finished_requests": 65259,
    "scheduler_time": 105.21162848462775
}
#Debug simulation 
Total elapsed time: 5.025086101144552. Arrivals time: 0.22655716771259904 Scheduler time: 4.602684407029301 Scheduler overhead time: 0.05812590382993221 Adapter cache time: 0.0506283538416028 Engine time: 0.05973716452717781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110766558 . Total output tokens: 97833648
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.277236506808549,
    "estimated_duration": 3600.099838980054,
    "input_throughput": 4876.163380228206,
    "output_throughput": 4284.541176605258,
    "total_throughput": 9160.704556833463,
    "itl": 112.23015926256542,
    "ttft": 1699955.0765064352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.351868501887752,
    "arrivals": 165445,
    "finished_requests": 71121,
    "scheduler_time": 99.29319261999942
}
#Debug simulation 
Total elapsed time: 5.277328850701451. Arrivals time: 0.23582017794251442 Scheduler time: 4.879873509053141 Scheduler overhead time: 0.04721654858440161 Adapter cache time: 0.0440176953561604 Engine time: 0.04829733492806554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110766558 . Total output tokens: 97833648
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.922925237100571,
    "estimated_duration": 3600.0509009160724,
    "input_throughput": 4474.820063210978,
    "output_throughput": 3934.982973822751,
    "total_throughput": 8409.80303703373,
    "itl": 87.31676394697055,
    "ttft": 1790379.1376472441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.15400899846099,
    "arrivals": 165445,
    "finished_requests": 65299,
    "scheduler_time": 105.14400210460997
}
#Debug simulation 
Total elapsed time: 4.923112853895873. Arrivals time: 0.23154439916834235 Scheduler time: 4.496744574047625 Scheduler overhead time: 0.05783196911215782 Adapter cache time: 0.05054080067202449 Engine time: 0.05925116082653403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110766558 . Total output tokens: 97833648
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.341931847855449,
    "estimated_duration": 3600.0954009068655,
    "input_throughput": 4876.888261232554,
    "output_throughput": 4285.234773532354,
    "total_throughput": 9162.123034764909,
    "itl": 112.20849120297179,
    "ttft": 1699789.5847483317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.67802414590511,
    "arrivals": 165445,
    "finished_requests": 71131,
    "scheduler_time": 99.30917933847243
}
#Debug simulation 
Total elapsed time: 5.342023979872465. Arrivals time: 0.23636077949777246 Scheduler time: 4.94313998427242 Scheduler overhead time: 0.04765359405428171 Adapter cache time: 0.043974402360618114 Engine time: 0.048538210801780224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 540, 33, 33, 33, 8640, 33, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 8640, 8640, 540, 540, 540, 8640, 8640, 33, 8640, 540, 8640, 8640, 8640, 540, 8640, 33, 540, 540, 540, 8640, 33, 33, 8640, 33, 8640, 33, 33, 540, 33, 540, 8640, 33, 33, 540, 33, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 33, 8640, 8640, 8640, 540, 540, 33, 33, 33, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 33, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 540, 33, 33, 540, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 8640, 540, 8640, 33, 33, 33, 540, 540, 540, 8640, 8640, 540, 8640, 33, 540, 540, 33, 8640, 8640, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 540, 8640, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 496929 . Total input tokens: 110766558 . Total output tokens: 97833648
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.921028655022383,
    "estimated_duration": 3600.0531474819413,
    "input_throughput": 4474.817270758309,
    "output_throughput": 3934.980518248324,
    "total_throughput": 8409.797789006632,
    "itl": 87.31453357332802,
    "ttft": 1790387.7502360991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.091194638907835,
    "arrivals": 165445,
    "finished_requests": 65299,
    "scheduler_time": 105.14616644064294
}
#Debug simulation 
Total elapsed time: 4.921149739064276. Arrivals time: 0.22121830144897103 Scheduler time: 4.505994848441333 Scheduler overhead time: 0.05736614065244794 Adapter cache time: 0.05011499207466841 Engine time: 0.059135759714990854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108735185 . Total output tokens: 96104825
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.513517439831048,
    "estimated_duration": 3600.052640501778,
    "input_throughput": 5145.683369068183,
    "output_throughput": 4496.985910112557,
    "total_throughput": 9642.66927918074,
    "itl": 121.09777604820158,
    "ttft": 1639392.5702019439,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.966934111654178,
    "arrivals": 162486,
    "finished_requests": 74627,
    "scheduler_time": 99.43695457062509
}
#Debug simulation 
Total elapsed time: 5.513611403759569. Arrivals time: 0.24011116800829768 Scheduler time: 5.121272809803486 Scheduler overhead time: 0.044455057475715876 Adapter cache time: 0.041624114383012056 Engine time: 0.04542948678135872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108735185 . Total output tokens: 96104825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.434462870005518,
    "estimated_duration": 3600.0899796521812,
    "input_throughput": 5011.819177292676,
    "output_throughput": 4384.502356667489,
    "total_throughput": 9396.321533960165,
    "itl": 109.20492242430261,
    "ttft": 1666661.708753828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.920519218095391,
    "arrivals": 162486,
    "finished_requests": 72709,
    "scheduler_time": 101.64144431341613
}
#Debug simulation 
Total elapsed time: 5.434575058054179. Arrivals time: 0.24053415702655911 Scheduler time: 5.030409718398005 Scheduler overhead time: 0.04836488235741854 Adapter cache time: 0.04291045991703868 Engine time: 0.04956001369282603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108735185 . Total output tokens: 96104825
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.028648681938648,
    "estimated_duration": 3600.01412836604,
    "input_throughput": 4579.320639356053,
    "output_throughput": 4003.0559564889354,
    "total_throughput": 8582.37659584499,
    "itl": 84.79572463341879,
    "ttft": 1762568.718459903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.197617291468,
    "arrivals": 162486,
    "finished_requests": 66336,
    "scheduler_time": 107.39577180003937
}
#Debug simulation 
Total elapsed time: 5.0287435771897435. Arrivals time: 0.22274910705164075 Scheduler time: 4.610848360229284 Scheduler overhead time: 0.05922099808230996 Adapter cache time: 0.04687519557774067 Engine time: 0.060911886394023895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108735185 . Total output tokens: 96104825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.442400920204818,
    "estimated_duration": 3600.014666478324,
    "input_throughput": 5012.671522711602,
    "output_throughput": 4385.151301464858,
    "total_throughput": 9397.82282417646,
    "itl": 109.18089413754987,
    "ttft": 1666440.7764419545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.050945182559271,
    "arrivals": 162486,
    "finished_requests": 72719,
    "scheduler_time": 101.66113463262654
}
#Debug simulation 
Total elapsed time: 5.442497066222131. Arrivals time: 0.2393438844010234 Scheduler time: 5.038554066326469 Scheduler overhead time: 0.04854673892259598 Adapter cache time: 0.04345219675451517 Engine time: 0.04978587757796049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108735185 . Total output tokens: 96104825
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.001510486938059,
    "estimated_duration": 3600.070452885315,
    "input_throughput": 4581.648113797468,
    "output_throughput": 4004.7455150343094,
    "total_throughput": 8586.393628831778,
    "itl": 84.95336859890311,
    "ttft": 1760950.7104960403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1760,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.085461664441775,
    "arrivals": 162486,
    "finished_requests": 66369,
    "scheduler_time": 107.36673595446072
}
#Debug simulation 
Total elapsed time: 5.001601506024599. Arrivals time: 0.22879846906289458 Scheduler time: 4.577823955565691 Scheduler overhead time: 0.059007796458899975 Adapter cache time: 0.04610058991238475 Engine time: 0.061814293731004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108735185 . Total output tokens: 96104825
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.433069745078683,
    "estimated_duration": 3600.105706709269,
    "input_throughput": 5013.52945452765,
    "output_throughput": 4386.193430535067,
    "total_throughput": 9399.722885062716,
    "itl": 109.15393007450325,
    "ttft": 1666060.1477214287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.186905075549666,
    "arrivals": 162486,
    "finished_requests": 72735,
    "scheduler_time": 101.68602284980774
}
#Debug simulation 
Total elapsed time: 5.433167059905827. Arrivals time: 0.24019076628610492 Scheduler time: 5.028816503472626 Scheduler overhead time: 0.048671568278223276 Adapter cache time: 0.04276154702529311 Engine time: 0.049835728481411934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [53 53 54]
Adapter prompts. [135, 8640, 135, 135, 270, 135, 135, 135, 8640, 135, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 135, 8640, 270, 8640, 8640, 8640, 270, 8640, 135, 270, 270, 270, 8640, 135, 135, 8640, 135, 8640, 135, 135, 270, 135, 270, 8640, 135, 135, 270, 135, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 135, 8640, 8640, 8640, 270, 270, 135, 135, 135, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 135, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 270, 135, 135, 270, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 8640, 270, 8640, 135, 135, 135, 270, 270, 270, 8640, 8640, 270, 8640, 135, 270, 270, 135, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 488025 . Total input tokens: 108735185 . Total output tokens: 96104825
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.997808181680739,
    "estimated_duration": 3600.038952503584,
    "input_throughput": 4577.453804642852,
    "output_throughput": 4001.459759201219,
    "total_throughput": 8578.913563844071,
    "itl": 84.70382061215977,
    "ttft": 1762690.8991523308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1756,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.933392132632244,
    "arrivals": 162486,
    "finished_requests": 66309,
    "scheduler_time": 107.43295615077214
}
#Debug simulation 
Total elapsed time: 4.997901347000152. Arrivals time: 0.22495209146291018 Scheduler time: 4.578154784627259 Scheduler overhead time: 0.059109268710017204 Adapter cache time: 0.046934373676776886 Engine time: 0.060723372269421816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 107919224 . Total output tokens: 95406418
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.62801529886201,
    "estimated_duration": 3600.025826218346,
    "input_throughput": 5298.120047109677,
    "output_throughput": 4614.626061572152,
    "total_throughput": 9912.74610868183,
    "itl": 117.91308994174716,
    "ttft": 1599809.099793561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.369783598273296,
    "arrivals": 161281,
    "finished_requests": 77087,
    "scheduler_time": 101.62154023807986
}
#Debug simulation 
Total elapsed time: 5.628111673984677. Arrivals time: 0.24517557676881552 Scheduler time: 5.233320266474038 Scheduler overhead time: 0.045490564312785864 Adapter cache time: 0.03638596786186099 Engine time: 0.04647564888000488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 107919224 . Total output tokens: 95406418
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.497559878975153,
    "estimated_duration": 3600.008101629237,
    "input_throughput": 5150.303131709325,
    "output_throughput": 4491.418781163969,
    "total_throughput": 9641.721912873294,
    "itl": 106.5580457300304,
    "ttft": 1631603.7696990068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.124720535152536,
    "arrivals": 161281,
    "finished_requests": 74967,
    "scheduler_time": 103.61138511047108
}
#Debug simulation 
Total elapsed time: 5.497700544074178. Arrivals time: 0.2414029324427247 Scheduler time: 5.0957462238147855 Scheduler overhead time: 0.04939658381044865 Adapter cache time: 0.03723348956555128 Engine time: 0.050714371260255575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 107919224 . Total output tokens: 95406418
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.085587174165994,
    "estimated_duration": 3600.01591790344,
    "input_throughput": 4682.080408637821,
    "output_throughput": 4089.986082221242,
    "total_throughput": 8772.066490859064,
    "itl": 83.38139744448351,
    "ttft": 1733846.516895021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1260,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.43935689474918,
    "arrivals": 161281,
    "finished_requests": 68102,
    "scheduler_time": 108.99312586269951
}
#Debug simulation 
Total elapsed time: 5.085705793928355. Arrivals time: 0.22835990181192756 Scheduler time: 4.667645454406738 Scheduler overhead time: 0.059676318895071745 Adapter cache time: 0.0400595935061574 Engine time: 0.06160788098350167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 107919224 . Total output tokens: 95406418
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.526184725109488,
    "estimated_duration": 3600.0583337961693,
    "input_throughput": 5151.68207856325,
    "output_throughput": 4492.61053582576,
    "total_throughput": 9644.292614389009,
    "itl": 106.53556681088472,
    "ttft": 1631271.5848207597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.458931651888474,
    "arrivals": 161281,
    "finished_requests": 74986,
    "scheduler_time": 103.63139938891324
}
#Debug simulation 
Total elapsed time: 5.526280325837433. Arrivals time: 0.2443110323511064 Scheduler time: 5.120668969117105 Scheduler overhead time: 0.04964420897886157 Adapter cache time: 0.03763337666168809 Engine time: 0.0506927827373147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 107919224 . Total output tokens: 95406418
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.084125901106745,
    "estimated_duration": 3600.0409911878205,
    "input_throughput": 4670.827371454983,
    "output_throughput": 4081.6976906564823,
    "total_throughput": 8752.525062111465,
    "itl": 83.53115744371844,
    "ttft": 1734458.549040178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.304431067910013,
    "arrivals": 161281,
    "finished_requests": 67948,
    "scheduler_time": 108.76862038569921
}
#Debug simulation 
Total elapsed time: 5.084246397949755. Arrivals time: 0.22692465130239725 Scheduler time: 4.667457660194486 Scheduler overhead time: 0.059905752539634705 Adapter cache time: 0.04012966435402632 Engine time: 0.06153212487697601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 107919224 . Total output tokens: 95406418
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.505684249103069,
    "estimated_duration": 3600.0070567343305,
    "input_throughput": 5152.296567114426,
    "output_throughput": 4492.9998039150105,
    "total_throughput": 9645.296371029437,
    "itl": 106.51729052216149,
    "ttft": 1631134.8913506996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.867266186452545,
    "arrivals": 161281,
    "finished_requests": 74992,
    "scheduler_time": 103.64537635800231
}
#Debug simulation 
Total elapsed time: 5.5057999598793685. Arrivals time: 0.24954620469361544 Scheduler time: 5.095616554375738 Scheduler overhead time: 0.049134086817502975 Adapter cache time: 0.037349885795265436 Engine time: 0.05088748689740896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [53 53 54]
Adapter prompts. [66, 8640, 66, 66, 270, 66, 66, 66, 8640, 66, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 66, 8640, 270, 8640, 8640, 8640, 270, 8640, 66, 270, 270, 270, 8640, 66, 66, 8640, 66, 8640, 66, 66, 270, 66, 270, 8640, 66, 66, 270, 66, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 66, 8640, 8640, 8640, 270, 270, 66, 66, 66, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 66, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 270, 66, 66, 270, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 8640, 270, 8640, 66, 66, 66, 270, 270, 270, 8640, 8640, 270, 8640, 66, 270, 270, 66, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 484368 . Total input tokens: 107919224 . Total output tokens: 95406418
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.12244099099189,
    "estimated_duration": 3600.0159029431434,
    "input_throughput": 4682.2804272112735,
    "output_throughput": 4090.102209815863,
    "total_throughput": 8772.382637027136,
    "itl": 83.3775566804422,
    "ttft": 1733747.354527895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.25041715372351,
    "arrivals": 161281,
    "finished_requests": 68106,
    "scheduler_time": 108.9984197120541
}
#Debug simulation 
Total elapsed time: 5.1225500400178134. Arrivals time: 0.23465117625892162 Scheduler time: 4.6978653110563755 Scheduler overhead time: 0.06007139524444938 Adapter cache time: 0.03986745327711105 Engine time: 0.0617621554993093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 270, 33, 33, 33, 8640, 33, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 33, 8640, 270, 8640, 8640, 8640, 270, 8640, 33, 270, 270, 270, 8640, 33, 33, 8640, 33, 8640, 33, 33, 270, 33, 270, 8640, 33, 33, 270, 33, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 33, 8640, 8640, 8640, 270, 270, 33, 33, 33, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 33, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 270, 33, 33, 270, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 8640, 270, 8640, 33, 33, 33, 270, 270, 270, 8640, 8640, 270, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 482619 . Total input tokens: 107531037 . Total output tokens: 95055354
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.947370876092464,
    "estimated_duration": 3600.0917982652854,
    "input_throughput": 5325.132545019431,
    "output_throughput": 4669.012886865664,
    "total_throughput": 9994.145431885096,
    "itl": 117.37149320275498,
    "ttft": 1581196.7153778917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1052,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.956254301611491,
    "arrivals": 160680,
    "finished_requests": 77576,
    "scheduler_time": 102.26219912710071
}
#Debug simulation 
Total elapsed time: 5.947436208836734. Arrivals time: 0.2585064428858459 Scheduler time: 5.542594857048243 Scheduler overhead time: 0.04529612325131893 Adapter cache time: 0.032989641185849905 Engine time: 0.04669704521074891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 270, 33, 33, 33, 8640, 33, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 33, 8640, 270, 8640, 8640, 8640, 270, 8640, 33, 270, 270, 270, 8640, 33, 33, 8640, 33, 8640, 33, 33, 270, 33, 270, 8640, 33, 33, 270, 33, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 33, 8640, 8640, 8640, 270, 270, 33, 33, 33, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 33, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 270, 33, 33, 270, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 8640, 270, 8640, 33, 33, 33, 270, 270, 270, 8640, 8640, 270, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 482619 . Total input tokens: 107531037 . Total output tokens: 95055354
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.630336510017514,
    "estimated_duration": 3600.069103131149,
    "input_throughput": 5169.722987765103,
    "output_throughput": 4538.068723678285,
    "total_throughput": 9707.791711443388,
    "itl": 106.15567312854407,
    "ttft": 1614532.9638416786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1024,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.490842851810168,
    "arrivals": 160680,
    "finished_requests": 75337,
    "scheduler_time": 104.14900258426334
}
#Debug simulation 
Total elapsed time: 5.630431370809674. Arrivals time: 0.2587051698938012 Scheduler time: 5.213307640515268 Scheduler overhead time: 0.049663043580949306 Adapter cache time: 0.03440061258152127 Engine time: 0.05098303547129035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [53 53 54]
Adapter prompts. [33, 8640, 33, 33, 270, 33, 33, 33, 8640, 33, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 8640, 8640, 270, 270, 270, 8640, 8640, 33, 8640, 270, 8640, 8640, 8640, 270, 8640, 33, 270, 270, 270, 8640, 33, 33, 8640, 33, 8640, 33, 33, 270, 33, 270, 8640, 33, 33, 270, 33, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 33, 8640, 8640, 8640, 270, 270, 33, 33, 33, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 33, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 270, 33, 33, 270, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 8640, 270, 8640, 33, 33, 33, 270, 270, 270, 8640, 8640, 270, 8640, 33, 270, 270, 33, 8640, 8640, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 270, 8640, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 482619 . Total input tokens: 107531037 . Total output tokens: 95055354
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.119326529093087,
    "estimated_duration": 3600.093149226984,
    "input_throughput": 4695.01435084515,
    "output_throughput": 4134.346635779664,
    "total_throughput": 8829.360986624813,
    "itl": 83.36571548057654,
    "ttft": 1720680.0372406892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 933,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.993284830544162,
    "arrivals": 160680,
    "finished_requests": 68471,
    "scheduler_time": 109.37026774404652
}
#Debug simulation 
Total elapsed time: 5.119426165241748. Arrivals time: 0.25350541854277253 Scheduler time: 4.67947760829702 Scheduler overhead time: 0.05987068451941013 Adapter cache time: 0.03660590387880802 Engine time: 0.06175502156838775 
