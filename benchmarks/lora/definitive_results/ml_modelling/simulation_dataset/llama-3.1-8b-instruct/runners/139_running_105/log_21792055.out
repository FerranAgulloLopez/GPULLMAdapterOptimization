INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 7.210157067049295,
    "estimated_duration": 3600.094150542222,
    "input_throughput": 5544.206669426634,
    "output_throughput": 4826.837375178864,
    "total_throughput": 10371.044044605498,
    "itl": 106.90961778439107,
    "ttft": 190127.7125097022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 709,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.857984759486274,
    "arrivals": 83337,
    "finished_requests": 80224,
    "scheduler_time": 69.68468247884002
}
#Debug simulation 
Total elapsed time: 7.210293669719249. Arrivals time: 0.18470019241794944 Scheduler time: 6.8844526978209615 Scheduler overhead time: 0.0505058323033154 Adapter cache time: 0.016205241438001394 Engine time: 0.050514857750386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.645114963874221,
    "estimated_duration": 3600.066028833697,
    "input_throughput": 5245.1826851957685,
    "output_throughput": 4568.127603295048,
    "total_throughput": 9813.310288490817,
    "itl": 95.02933378723027,
    "ttft": 460393.825585186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.544284390420676,
    "arrivals": 83337,
    "finished_requests": 75866,
    "scheduler_time": 74.57690592117875
}
#Debug simulation 
Total elapsed time: 6.645219951868057. Arrivals time: 0.19099325919523835 Scheduler time: 6.296230622101575 Scheduler overhead time: 0.055993185844272375 Adapter cache time: 0.01941324071958661 Engine time: 0.05621393723413348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 7.235365136060864,
    "estimated_duration": 3600.068069947581,
    "input_throughput": 5545.56125387115,
    "output_throughput": 4827.415110585131,
    "total_throughput": 10372.97636445628,
    "itl": 106.88686575556093,
    "ttft": 189620.82642573613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.519816025923916,
    "arrivals": 83337,
    "finished_requests": 80236,
    "scheduler_time": 69.68491994079423
}
#Debug simulation 
Total elapsed time: 7.235484207049012. Arrivals time: 0.18480293033644557 Scheduler time: 6.909637452103198 Scheduler overhead time: 0.05045353062450886 Adapter cache time: 0.01625172095373273 Engine time: 0.050386478658765554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.625169203151017,
    "estimated_duration": 3600.0854399959135,
    "input_throughput": 5244.39469970508,
    "output_throughput": 4567.165772604181,
    "total_throughput": 9811.560472309262,
    "itl": 95.0188086957401,
    "ttft": 461337.3095384547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.32394350005316,
    "arrivals": 83337,
    "finished_requests": 75838,
    "scheduler_time": 74.5767640063399
}
#Debug simulation 
Total elapsed time: 6.625284524168819. Arrivals time: 0.19037427101284266 Scheduler time: 6.277207819744945 Scheduler overhead time: 0.056102532893419266 Adapter cache time: 0.019165155477821827 Engine time: 0.056012112647295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 7.340242812409997,
    "estimated_duration": 3600.033597514846,
    "input_throughput": 5586.274531960688,
    "output_throughput": 4855.850515413949,
    "total_throughput": 10442.125047374639,
    "itl": 108.5676947764783,
    "ttft": 51534.55149908787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 790,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.223803135240551,
    "arrivals": 81595,
    "finished_requests": 80642,
    "scheduler_time": 66.02725491421123
}
#Debug simulation 
Total elapsed time: 7.3403650829568505. Arrivals time: 0.180709860753268 Scheduler time: 7.020034822635353 Scheduler overhead time: 0.05022930772975087 Adapter cache time: 0.016396572813391685 Engine time: 0.04962043138220906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.856126398779452,
    "estimated_duration": 3600.011421630022,
    "input_throughput": 5519.191656065245,
    "output_throughput": 4800.786990885326,
    "total_throughput": 10319.978646950573,
    "itl": 105.51067660966584,
    "ttft": 107514.52166864008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.198183660646909,
    "arrivals": 81595,
    "finished_requests": 79710,
    "scheduler_time": 66.3707203115827
}
#Debug simulation 
Total elapsed time: 6.85621426673606. Arrivals time: 0.18148892745375633 Scheduler time: 6.529944706708193 Scheduler overhead time: 0.05152537440881133 Adapter cache time: 0.017571400851011276 Engine time: 0.05154171213507652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.144159873947501,
    "estimated_duration": 3600.083219933237,
    "input_throughput": 5251.92664861526,
    "output_throughput": 4571.5295993366535,
    "total_throughput": 9823.456247951914,
    "itl": 95.05890279846516,
    "ttft": 348267.7613731066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.071571965818306,
    "arrivals": 81595,
    "finished_requests": 75859,
    "scheduler_time": 69.87251775675256
}
#Debug simulation 
Total elapsed time: 6.144254843238741. Arrivals time: 0.18363589188084006 Scheduler time: 5.802622293587774 Scheduler overhead time: 0.055185350589454174 Adapter cache time: 0.021248499397188425 Engine time: 0.055423532612621784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.873983247671276,
    "estimated_duration": 3600.0459217950925,
    "input_throughput": 5519.4845931554155,
    "output_throughput": 4801.076534985315,
    "total_throughput": 10320.561128140731,
    "itl": 105.49132748142605,
    "ttft": 107223.80289870928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.826971476846365,
    "arrivals": 81595,
    "finished_requests": 79715,
    "scheduler_time": 66.36732490458361
}
#Debug simulation 
Total elapsed time: 6.874099113047123. Arrivals time: 0.18275024136528373 Scheduler time: 6.546605549287051 Scheduler overhead time: 0.05170546332374215 Adapter cache time: 0.017802603542804718 Engine time: 0.050979225896298885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.1707556950859725,
    "estimated_duration": 3600.010699853022,
    "input_throughput": 5251.559391412882,
    "output_throughput": 4572.05918878852,
    "total_throughput": 9823.618580201402,
    "itl": 95.05637620454657,
    "ttft": 348190.861662259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1059,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.854958046865662,
    "arrivals": 81595,
    "finished_requests": 75860,
    "scheduler_time": 69.86977616711144
}
#Debug simulation 
Total elapsed time: 6.1708446550183. Arrivals time: 0.18483920814469457 Scheduler time: 5.827630370855331 Scheduler overhead time: 0.05558682745322585 Adapter cache time: 0.021023813169449568 Engine time: 0.05548607977107167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.8532687071710825,
    "estimated_duration": 3600.069293285307,
    "input_throughput": 5520.544850919609,
    "output_throughput": 4800.942313037378,
    "total_throughput": 10321.487163956986,
    "itl": 105.46885958905483,
    "ttft": 106757.59297651214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.426332799484927,
    "arrivals": 81595,
    "finished_requests": 79721,
    "scheduler_time": 66.358102351858
}
#Debug simulation 
Total elapsed time: 6.853359783068299. Arrivals time: 0.1834091618657112 Scheduler time: 6.525747986510396 Scheduler overhead time: 0.051357923075556755 Adapter cache time: 0.017650607507675886 Engine time: 0.05101128853857517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.201685088220984,
    "estimated_duration": 3600.0129825204904,
    "input_throughput": 5251.944115702196,
    "output_throughput": 4571.678791135117,
    "total_throughput": 9823.622906837312,
    "itl": 95.0559272364964,
    "ttft": 348069.0652773577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1078,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.919601323679103,
    "arrivals": 81595,
    "finished_requests": 75862,
    "scheduler_time": 69.86576696745313
}
#Debug simulation 
Total elapsed time: 6.201829115394503. Arrivals time: 0.19096563709899783 Scheduler time: 5.8512752135284245 Scheduler overhead time: 0.055775710847228765 Adapter cache time: 0.021725060418248177 Engine time: 0.055527721997350454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.715369157958776,
    "estimated_duration": 3600.09450672656,
    "input_throughput": 5526.242981351571,
    "output_throughput": 4849.819349846899,
    "total_throughput": 10376.062331198471,
    "itl": 107.92153855843641,
    "ttft": 39428.593387270084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 868,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.739571039732663,
    "arrivals": 81010,
    "finished_requests": 80251,
    "scheduler_time": 65.52923488432677
}
#Debug simulation 
Total elapsed time: 6.7154602645896375. Arrivals time: 0.18127158796414733 Scheduler time: 6.394401353318244 Scheduler overhead time: 0.050046718679368496 Adapter cache time: 0.017050096299499273 Engine time: 0.049559589475393295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.2881141267716885,
    "estimated_duration": 3600.065998761252,
    "input_throughput": 5492.552082879561,
    "output_throughput": 4818.977764843617,
    "total_throughput": 10311.529847723177,
    "itl": 106.42217127689774,
    "ttft": 71028.52372616247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.428297622995461,
    "arrivals": 81010,
    "finished_requests": 79743,
    "scheduler_time": 65.86552211026157
}
#Debug simulation 
Total elapsed time: 6.288241700734943. Arrivals time: 0.18151498213410378 Scheduler time: 5.963962290436029 Scheduler overhead time: 0.05053624836727977 Adapter cache time: 0.018117578700184822 Engine time: 0.05021783569827676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.8462224141694605,
    "estimated_duration": 3600.08494226675,
    "input_throughput": 5213.139217816099,
    "output_throughput": 4571.795739251886,
    "total_throughput": 9784.934957067984,
    "itl": 95.08323182588053,
    "ttft": 333435.242322334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1132,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.511565499384883,
    "arrivals": 81010,
    "finished_requests": 75663,
    "scheduler_time": 69.775486542094
}
#Debug simulation 
Total elapsed time: 5.846329124178737. Arrivals time: 0.18939570290967822 Scheduler time: 5.498009033035487 Scheduler overhead time: 0.055149216670542955 Adapter cache time: 0.021867268718779087 Engine time: 0.05583786312490702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.286633640062064,
    "estimated_duration": 3600.0632875485426,
    "input_throughput": 5492.652606522649,
    "output_throughput": 4818.748064791093,
    "total_throughput": 10311.400671313742,
    "itl": 106.37187299005116,
    "ttft": 71311.3514946378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.032654645601279,
    "arrivals": 81010,
    "finished_requests": 79738,
    "scheduler_time": 65.86536396800024
}
#Debug simulation 
Total elapsed time: 6.286735199857503. Arrivals time: 0.18423695350065827 Scheduler time: 5.959467006847262 Scheduler overhead time: 0.05071786139160395 Adapter cache time: 0.018010715022683144 Engine time: 0.05037495028227568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.85710955504328,
    "estimated_duration": 3600.0908096262883,
    "input_throughput": 5212.7929522833565,
    "output_throughput": 4571.247190764148,
    "total_throughput": 9784.040143047505,
    "itl": 95.08366152557016,
    "ttft": 333766.0603025786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.554621569141736,
    "arrivals": 81010,
    "finished_requests": 75656,
    "scheduler_time": 69.7763577212202
}
#Debug simulation 
Total elapsed time: 5.857201193924993. Arrivals time: 0.18561568157747388 Scheduler time: 5.511727429926395 Scheduler overhead time: 0.05539043014869094 Adapter cache time: 0.022463366854935884 Engine time: 0.05560439545661211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.276231132913381,
    "estimated_duration": 3600.1090405999544,
    "input_throughput": 5491.008126994299,
    "output_throughput": 4817.652966730593,
    "total_throughput": 10308.661093724893,
    "itl": 106.29574774909827,
    "ttft": 72265.28786430226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.7072253208700285,
    "arrivals": 81010,
    "finished_requests": 79726,
    "scheduler_time": 65.87576763846467
}
#Debug simulation 
Total elapsed time: 6.276318182703108. Arrivals time: 0.18233259906992316 Scheduler time: 5.950448846910149 Scheduler overhead time: 0.050835114903748035 Adapter cache time: 0.0182669241912663 Engine time: 0.05049883807078004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.826784370932728,
    "estimated_duration": 3600.0822730114587,
    "input_throughput": 5212.7517031165,
    "output_throughput": 4571.851072234541,
    "total_throughput": 9784.60277535104,
    "itl": 95.07851411545352,
    "ttft": 333463.459074932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.377141962219026,
    "arrivals": 81010,
    "finished_requests": 75662,
    "scheduler_time": 69.77451423701811
}
#Debug simulation 
Total elapsed time: 5.826874852180481. Arrivals time: 0.1834027385339141 Scheduler time: 5.484302739147097 Scheduler overhead time: 0.05541599355638027 Adapter cache time: 0.021774306427687407 Engine time: 0.055757911875844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.768226617947221,
    "estimated_duration": 3600.092385047955,
    "input_throughput": 5408.772863960996,
    "output_throughput": 4789.246262570657,
    "total_throughput": 10198.019126531653,
    "itl": 104.58564745085721,
    "ttft": 25063.341666335768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.25889888090567,
    "arrivals": 79794,
    "finished_requests": 79269,
    "scheduler_time": 64.02422461420902
}
#Debug simulation 
Total elapsed time: 5.768313840031624. Arrivals time: 0.17484759632498026 Scheduler time: 5.448928510770202 Scheduler overhead time: 0.05045001022517681 Adapter cache time: 0.020690991543233395 Engine time: 0.04998155636712909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.751313485670835,
    "estimated_duration": 3600.071811017225,
    "input_throughput": 5408.656277469692,
    "output_throughput": 4789.149746190301,
    "total_throughput": 10197.806023659994,
    "itl": 104.68185831038004,
    "ttft": 26394.78348596695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.107977120773826,
    "arrivals": 79794,
    "finished_requests": 79268,
    "scheduler_time": 64.19322565533386
}
#Debug simulation 
Total elapsed time: 5.751399360597134. Arrivals time: 0.1749237203039229 Scheduler time: 5.43073001364246 Scheduler overhead time: 0.05042293295264244 Adapter cache time: 0.02145821414887905 Engine time: 0.05015991162508726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.407069904264063,
    "estimated_duration": 3600.0819043443403,
    "input_throughput": 5178.267188172537,
    "output_throughput": 4590.384729874564,
    "total_throughput": 9768.6519180471,
    "itl": 95.30076864316052,
    "ttft": 250558.19460518638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.806836893083418,
    "arrivals": 79794,
    "finished_requests": 75920,
    "scheduler_time": 67.7653973289475
}
#Debug simulation 
Total elapsed time: 5.407166606280953. Arrivals time: 0.1816825452260673 Scheduler time: 5.064719131216407 Scheduler overhead time: 0.054453130811452866 Adapter cache time: 0.025387823581695557 Engine time: 0.05499222595244646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.714433972723782,
    "estimated_duration": 3600.0743711261653,
    "input_throughput": 5408.799928182816,
    "output_throughput": 4789.2702268277,
    "total_throughput": 10198.070155010517,
    "itl": 104.62226654834991,
    "ttft": 26313.86312104328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.543528368561535,
    "arrivals": 79794,
    "finished_requests": 79269,
    "scheduler_time": 64.18576255738135
}
#Debug simulation 
Total elapsed time: 5.714534910861403. Arrivals time: 0.17840470327064395 Scheduler time: 5.390639603603631 Scheduler overhead time: 0.050256452057510614 Adapter cache time: 0.021339569706469774 Engine time: 0.05037867231294513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.4351051999256015,
    "estimated_duration": 3600.036910828023,
    "input_throughput": 5178.506349178536,
    "output_throughput": 4590.473211620206,
    "total_throughput": 9768.979560798742,
    "itl": 95.29655278809717,
    "ttft": 250272.5906641243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.73309868866567,
    "arrivals": 79794,
    "finished_requests": 75923,
    "scheduler_time": 67.76705813832349
}
#Debug simulation 
Total elapsed time: 5.435197554063052. Arrivals time: 0.18122677598148584 Scheduler time: 5.092146364971995 Scheduler overhead time: 0.05473939934745431 Adapter cache time: 0.025625566951930523 Engine time: 0.055401879362761974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.710740635171533,
    "estimated_duration": 3600.001362007139,
    "input_throughput": 5408.750175901013,
    "output_throughput": 4789.1881880809715,
    "total_throughput": 10197.938363981984,
    "itl": 104.56907973471566,
    "ttft": 26149.02710389788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.973517254772555,
    "arrivals": 79794,
    "finished_requests": 79267,
    "scheduler_time": 64.179443566489
}
#Debug simulation 
Total elapsed time: 5.710838761180639. Arrivals time: 0.1753153926692903 Scheduler time: 5.390254134312272 Scheduler overhead time: 0.05029960861429572 Adapter cache time: 0.021296711172908545 Engine time: 0.05009586410596967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.441431229934096,
    "estimated_duration": 3600.019732655279,
    "input_throughput": 5178.818002269336,
    "output_throughput": 4590.55372671827,
    "total_throughput": 9769.371728987606,
    "itl": 95.29490129990731,
    "ttft": 249993.83242143304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.638237525261836,
    "arrivals": 79794,
    "finished_requests": 75926,
    "scheduler_time": 67.76227711470145
}
#Debug simulation 
Total elapsed time: 5.4415290779434144. Arrivals time: 0.18330095382407308 Scheduler time: 5.097340130247176 Scheduler overhead time: 0.054581635631620884 Adapter cache time: 0.02537457598373294 Engine time: 0.05491645587608218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_160_slots_64_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_160_slots_64_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 3.0060493289493024,
    "estimated_duration": 3599.79080613668,
    "input_throughput": 2309.0852906868595,
    "output_throughput": 2042.6639757690432,
    "total_throughput": 4351.749266455902,
    "itl": 45.26380239354891,
    "ttft": 20188.28758560223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 82.33771726583272,
    "arrivals": 33938,
    "finished_requests": 33777,
    "scheduler_time": 15.861798244091633
}
#Debug simulation 
Total elapsed time: 3.006142209749669. Arrivals time: 0.09133147308602929 Scheduler time: 2.5813487735576928 Scheduler overhead time: 0.08349809143692255 Adapter cache time: 0.12736576329916716 Engine time: 0.082163589540869 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_160_slots_64_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_160_slots_64_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.9905670010484755,
    "estimated_duration": 3599.8006674866174,
    "input_throughput": 2308.889510208109,
    "output_throughput": 2042.5678194936706,
    "total_throughput": 4351.45732970178,
    "itl": 45.38399103900898,
    "ttft": 20519.988896865136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12132,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 88.75262401572026,
    "arrivals": 33938,
    "finished_requests": 33776,
    "scheduler_time": 15.918804881453122
}
#Debug simulation 
Total elapsed time: 2.990651312749833. Arrivals time: 0.09108073776587844 Scheduler time: 2.5681522767990828 Scheduler overhead time: 0.08547809952870011 Adapter cache time: 0.12299512885510921 Engine time: 0.08248491631820798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_160_slots_64_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_160_slots_64_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 3.0081085129640996,
    "estimated_duration": 3599.826027399959,
    "input_throughput": 2308.9610266536665,
    "output_throughput": 2042.610377288391,
    "total_throughput": 4351.571403942058,
    "itl": 45.42411931487511,
    "ttft": 20431.8538460513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12110,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 90.99336387904097,
    "arrivals": 33938,
    "finished_requests": 33777,
    "scheduler_time": 15.933137068497427
}
#Debug simulation 
Total elapsed time: 3.0082038547843695. Arrivals time: 0.09356583189219236 Scheduler time: 2.5864939275197685 Scheduler overhead time: 0.08329685032367706 Adapter cache time: 0.1237132204696536 Engine time: 0.08066553482785821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_160_slots_64_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_160_slots_64_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.9198797419667244,
    "estimated_duration": 3599.8016954516693,
    "input_throughput": 2309.0783057584676,
    "output_throughput": 2042.657796758828,
    "total_throughput": 4351.736102517296,
    "itl": 45.3063350265153,
    "ttft": 20212.380095762343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 85.00777796961422,
    "arrivals": 33938,
    "finished_requests": 33777,
    "scheduler_time": 15.878883898023362
}
#Debug simulation 
Total elapsed time: 2.9199722507037222. Arrivals time: 0.09002026543021202 Scheduler time: 2.5012989682145417 Scheduler overhead time: 0.08288310235366225 Adapter cache time: 0.12536579836159945 Engine time: 0.0796938855201006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_160_slots_64_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_160_slots_64_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 3.0107263829559088,
    "estimated_duration": 3599.797211669768,
    "input_throughput": 2308.8917267494317,
    "output_throughput": 2042.5697803653175,
    "total_throughput": 4351.461507114749,
    "itl": 45.40756793866558,
    "ttft": 20528.402352184265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12123,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 90.25761234403764,
    "arrivals": 33938,
    "finished_requests": 33776,
    "scheduler_time": 15.92790338802127
}
#Debug simulation 
Total elapsed time: 3.010812676977366. Arrivals time: 0.09138282900676131 Scheduler time: 2.592000259552151 Scheduler overhead time: 0.08301990479230881 Adapter cache time: 0.12380590988323092 Engine time: 0.08016928937286139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_160_slots_64_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_160_slots_64_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.967129162978381,
    "estimated_duration": 3599.837459663267,
    "input_throughput": 2309.118145789159,
    "output_throughput": 2042.7436189543566,
    "total_throughput": 4351.861764743516,
    "itl": 45.210142596731714,
    "ttft": 20057.08426483975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 79.73517254771798,
    "arrivals": 33938,
    "finished_requests": 33778,
    "scheduler_time": 15.845061288885129
}
#Debug simulation 
Total elapsed time: 2.967213314026594. Arrivals time: 0.09134045289829373 Scheduler time: 2.542833949904889 Scheduler overhead time: 0.08336261985823512 Adapter cache time: 0.12741575855761766 Engine time: 0.08159967698156834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_160_slots_64_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_160_slots_64_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.9910037890076637,
    "estimated_duration": 3599.8360508271903,
    "input_throughput": 2308.9545975545343,
    "output_throughput": 2042.6046898192426,
    "total_throughput": 4351.559287373777,
    "itl": 45.396124077386986,
    "ttft": 20418.14673678237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12123,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 89.41262613243106,
    "arrivals": 33938,
    "finished_requests": 33777,
    "scheduler_time": 15.923014838444782
}
#Debug simulation 
Total elapsed time: 2.9910864983685315. Arrivals time: 0.09081936068832874 Scheduler time: 2.572464879602194 Scheduler overhead time: 0.08360711112618446 Adapter cache time: 0.12358167627826333 Engine time: 0.0798393595032394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_160_slots_64_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_160_slots_64_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.620186544023454,
    "estimated_duration": 3599.761563956737,
    "input_throughput": 2153.8532100658826,
    "output_throughput": 1889.3481913075227,
    "total_throughput": 4043.201401373405,
    "itl": 43.08576969649763,
    "ttft": 12034.358181058271,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 88.35500948490251,
    "arrivals": 31534,
    "finished_requests": 31435,
    "scheduler_time": 12.65224178617346
}
#Debug simulation 
Total elapsed time: 2.620278426911682. Arrivals time: 0.08706802455708385 Scheduler time: 2.18700770707801 Scheduler overhead time: 0.08600810496136546 Adapter cache time: 0.13530905963853002 Engine time: 0.08328280365094543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_160_slots_64_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_160_slots_64_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.6216640188358724,
    "estimated_duration": 3599.7497708449278,
    "input_throughput": 2153.8602662873823,
    "output_throughput": 1889.3543809862183,
    "total_throughput": 4043.214647273601,
    "itl": 43.28519955072636,
    "ttft": 12064.876715930315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 97.71963560261212,
    "arrivals": 31534,
    "finished_requests": 31435,
    "scheduler_time": 12.72586105408074
}
#Debug simulation 
Total elapsed time: 2.6217522430233657. Arrivals time: 0.08618017099797726 Scheduler time: 2.192440017592162 Scheduler overhead time: 0.08428971748799086 Adapter cache time: 0.13564307615160942 Engine time: 0.08176020439714193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_160_slots_64_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_160_slots_64_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.6046699681319296,
    "estimated_duration": 3599.78332825567,
    "input_throughput": 2153.8401878640316,
    "output_throughput": 1889.3367683036709,
    "total_throughput": 4043.1769561677024,
    "itl": 43.338515035820706,
    "ttft": 12074.61422305113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 100.30604867163267,
    "arrivals": 31534,
    "finished_requests": 31435,
    "scheduler_time": 12.746385835474639
}
#Debug simulation 
Total elapsed time: 2.60475014988333. Arrivals time: 0.08481211867183447 Scheduler time: 2.17853747215122 Scheduler overhead time: 0.08342816308140755 Adapter cache time: 0.13492685183882713 Engine time: 0.08201138023287058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_160_slots_64_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_160_slots_64_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.6285566850565374,
    "estimated_duration": 3599.7758144140803,
    "input_throughput": 2153.8446835923255,
    "output_throughput": 1889.3407119318074,
    "total_throughput": 4043.1853955241327,
    "itl": 43.14858199838172,
    "ttft": 12045.044721682072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 91.45400873306072,
    "arrivals": 31534,
    "finished_requests": 31435,
    "scheduler_time": 12.677253286834958
}
#Debug simulation 
Total elapsed time: 2.628629453945905. Arrivals time: 0.08520428044721484 Scheduler time: 2.197952615097165 Scheduler overhead time: 0.08441035961732268 Adapter cache time: 0.13609456457197666 Engine time: 0.08349208207800984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_160_slots_64_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_160_slots_64_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.595948664005846,
    "estimated_duration": 3599.7697833444277,
    "input_throughput": 2153.848292152897,
    "output_throughput": 1889.3438773412965,
    "total_throughput": 4043.192169494194,
    "itl": 43.318999956359,
    "ttft": 12070.940923029202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 99.40145338904236,
    "arrivals": 31534,
    "finished_requests": 31435,
    "scheduler_time": 12.739342207855037
}
#Debug simulation 
Total elapsed time: 2.5960273980163038. Arrivals time: 0.08458268642425537 Scheduler time: 2.170705195516348 Scheduler overhead time: 0.08392636245116591 Adapter cache time: 0.13506002631038427 Engine time: 0.08072258858010173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_160_slots_64_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_160_slots_64_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.5736810178495944,
    "estimated_duration": 3599.782256361619,
    "input_throughput": 2153.840829205179,
    "output_throughput": 1889.3373308845987,
    "total_throughput": 4043.178160089778,
    "itl": 43.02395589498061,
    "ttft": 12025.847677602145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 85.41686218482019,
    "arrivals": 31534,
    "finished_requests": 31435,
    "scheduler_time": 12.629386102977934
}
#Debug simulation 
Total elapsed time: 2.573765782173723. Arrivals time: 0.08463191101327538 Scheduler time: 2.1449442449957132 Scheduler overhead time: 0.08374208537861705 Adapter cache time: 0.13604111643508077 Engine time: 0.08310191566124558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_160_slots_64_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_160_slots_64_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.603278767783195,
    "estimated_duration": 3599.7500063864727,
    "input_throughput": 2153.8601253543807,
    "output_throughput": 1889.3542573605641,
    "total_throughput": 4043.2143827149443,
    "itl": 43.299835929646285,
    "ttft": 12068.381634382991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13324,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 98.42925434109846,
    "arrivals": 31534,
    "finished_requests": 31435,
    "scheduler_time": 12.731422744276443
}
#Debug simulation 
Total elapsed time: 2.6033556791953743. Arrivals time: 0.08501245547086 Scheduler time: 2.175612687598914 Scheduler overhead time: 0.08345162170007825 Adapter cache time: 0.13528139563277364 Engine time: 0.08294316800311208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.4830779610201716,
    "estimated_duration": 3599.988192768952,
    "input_throughput": 2067.2140022425974,
    "output_throughput": 1810.2464927773872,
    "total_throughput": 3877.4604950199846,
    "itl": 40.96764422331765,
    "ttft": 9576.127457649396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 81.52439095490351,
    "arrivals": 30357,
    "finished_requests": 30278,
    "scheduler_time": 10.591232187656347
}
#Debug simulation 
Total elapsed time: 2.4831807841546834. Arrivals time: 0.0819233562797308 Scheduler time: 2.0531464936211705 Scheduler overhead time: 0.08682158729061484 Adapter cache time: 0.1327788927592337 Engine time: 0.08557180874049664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.4773622541688383,
    "estimated_duration": 3599.9848207932105,
    "input_throughput": 2067.1323270636262,
    "output_throughput": 1810.2173549065456,
    "total_throughput": 3877.349681970172,
    "itl": 41.15674827885998,
    "ttft": 9703.29692576192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 90.27906151432659,
    "arrivals": 30357,
    "finished_requests": 30277,
    "scheduler_time": 10.665531246426625
}
#Debug simulation 
Total elapsed time: 2.4774427260272205. Arrivals time: 0.0817171516828239 Scheduler time: 2.04923137743026 Scheduler overhead time: 0.08656100369989872 Adapter cache time: 0.13346395641565323 Engine time: 0.08398093702271581 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.466245132032782,
    "estimated_duration": 3599.9983893986664,
    "input_throughput": 2067.208147068944,
    "output_throughput": 1810.2413654380994,
    "total_throughput": 3877.4495125070434,
    "itl": 41.210776268651436,
    "ttft": 9587.101675220621,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 92.73163373959515,
    "arrivals": 30357,
    "finished_requests": 30278,
    "scheduler_time": 10.686354915043408
}
#Debug simulation 
Total elapsed time: 2.4663405041210353. Arrivals time: 0.08402038970962167 Scheduler time: 2.036363708321005 Scheduler overhead time: 0.08596910536289215 Adapter cache time: 0.1322748069651425 Engine time: 0.08515621861442924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.503848931286484,
    "estimated_duration": 3599.9826299909173,
    "input_throughput": 2067.2171965504112,
    "output_throughput": 1810.249290012947,
    "total_throughput": 3877.466486563358,
    "itl": 41.02744887821841,
    "ttft": 9578.946996959276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 84.38048216566109,
    "arrivals": 30357,
    "finished_requests": 30278,
    "scheduler_time": 10.615433187093195
}
#Debug simulation 
Total elapsed time: 2.5039433403871953. Arrivals time: 0.08715332671999931 Scheduler time: 2.065248684026301 Scheduler overhead time: 0.08765784744173288 Adapter cache time: 0.13459011120721698 Engine time: 0.08633004361763597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.4798615481704473,
    "estimated_duration": 3599.9811176334015,
    "input_throughput": 2067.1344534418217,
    "output_throughput": 1810.2192170063554,
    "total_throughput": 3877.353670448177,
    "itl": 41.19329826332047,
    "ttft": 9704.947081555913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 91.85112561505986,
    "arrivals": 30357,
    "finished_requests": 30277,
    "scheduler_time": 10.678849937520747
}
#Debug simulation 
Total elapsed time: 2.479930378962308. Arrivals time: 0.0819279165007174 Scheduler time: 2.0513880904763937 Scheduler overhead time: 0.08665603399276733 Adapter cache time: 0.13285876344889402 Engine time: 0.0843016766011715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.4757766821421683,
    "estimated_duration": 3599.982471013499,
    "input_throughput": 2067.2172878399815,
    "output_throughput": 1810.2493699546583,
    "total_throughput": 3877.4666577946396,
    "itl": 40.90637097542455,
    "ttft": 9573.583846480351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 78.68182559252487,
    "arrivals": 30357,
    "finished_requests": 30278,
    "scheduler_time": 10.567082192158063
}
#Debug simulation 
Total elapsed time: 2.475863022264093. Arrivals time: 0.08305700635537505 Scheduler time: 2.0462421094998717 Scheduler overhead time: 0.08597431378439069 Adapter cache time: 0.13396585499867797 Engine time: 0.08404127042740583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.480152954813093,
    "estimated_duration": 3599.9992683434457,
    "input_throughput": 2067.207642357228,
    "output_throughput": 1810.2409234651768,
    "total_throughput": 3877.448565822405,
    "itl": 41.17209379411057,
    "ttft": 9585.418201237042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 91.00737875473419,
    "arrivals": 30357,
    "finished_requests": 30278,
    "scheduler_time": 10.671690393301665
}
#Debug simulation 
Total elapsed time: 2.480232938658446. Arrivals time: 0.08165466506034136 Scheduler time: 2.0504563841968775 Scheduler overhead time: 0.08682107971981168 Adapter cache time: 0.13319542817771435 Engine time: 0.0854862523265183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.425029600970447,
    "estimated_duration": 3600.01609509657,
    "input_throughput": 2025.919831284631,
    "output_throughput": 1770.4756955618625,
    "total_throughput": 3796.395526846494,
    "itl": 39.706499730128705,
    "ttft": 7258.207994460829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 75.88400605065458,
    "arrivals": 29680,
    "finished_requests": 29621,
    "scheduler_time": 9.447316219950098
}
#Debug simulation 
Total elapsed time: 2.425115347839892. Arrivals time: 0.08242722833529115 Scheduler time: 1.9900445081293583 Scheduler overhead time: 0.0887426994740963 Adapter cache time: 0.1307778460904956 Engine time: 0.08941366709768772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.390170017257333,
    "estimated_duration": 3600.0343647866243,
    "input_throughput": 2025.9092722389275,
    "output_throughput": 1770.3319896997,
    "total_throughput": 3796.2412619386273,
    "itl": 40.33295703628766,
    "ttft": 7408.942571302842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 85.58004177296074,
    "arrivals": 29680,
    "finished_requests": 29620,
    "scheduler_time": 9.714732373682942
}
#Debug simulation 
Total elapsed time: 2.3902509342879057. Arrivals time: 0.07900781510397792 Scheduler time: 1.968437324743718 Scheduler overhead time: 0.08676739502698183 Adapter cache time: 0.1295703463256359 Engine time: 0.08362162206321955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.4137520510703325,
    "estimated_duration": 3600.0303014047718,
    "input_throughput": 2025.9118366737237,
    "output_throughput": 1770.4687089752815,
    "total_throughput": 3796.3805456490054,
    "itl": 39.93154707953431,
    "ttft": 7262.038050095694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 86.48102160342044,
    "arrivals": 29680,
    "finished_requests": 29621,
    "scheduler_time": 9.540413692664343
}
#Debug simulation 
Total elapsed time: 2.4138313308358192. Arrivals time: 0.079283541534096 Scheduler time: 1.984301927499473 Scheduler overhead time: 0.08959846058860421 Adapter cache time: 0.13009112887084484 Engine time: 0.08680607145652175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.4253711607307196,
    "estimated_duration": 3600.0235579022105,
    "input_throughput": 2025.915631577129,
    "output_throughput": 1770.4720253869887,
    "total_throughput": 3796.387656964118,
    "itl": 39.762911264380485,
    "ttft": 7259.093046610404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 78.50602784491866,
    "arrivals": 29680,
    "finished_requests": 29621,
    "scheduler_time": 9.470536461236046
}
#Debug simulation 
Total elapsed time: 2.4255013479851186. Arrivals time: 0.08054932253435254 Scheduler time: 1.9946764786727726 Scheduler overhead time: 0.08974656276404858 Adapter cache time: 0.13035295577719808 Engine time: 0.08627620385959744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.4123106291517615,
    "estimated_duration": 3600.0109334255994,
    "input_throughput": 2025.9149582804257,
    "output_throughput": 1770.3115678972736,
    "total_throughput": 3796.2265261776993,
    "itl": 40.36828426114414,
    "ttft": 7531.086467788174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 87.05341087779064,
    "arrivals": 29680,
    "finished_requests": 29619,
    "scheduler_time": 9.727595665475025
}
#Debug simulation 
Total elapsed time: 2.4123884071595967. Arrivals time: 0.07993785431608558 Scheduler time: 1.985323823057115 Scheduler overhead time: 0.08762550679966807 Adapter cache time: 0.12980927620083094 Engine time: 0.08640287350863218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.42550354776904,
    "estimated_duration": 3600.025442081595,
    "input_throughput": 2026.0479036455333,
    "output_throughput": 1770.485265324838,
    "total_throughput": 3796.533168970371,
    "itl": 39.65362039178129,
    "ttft": 7135.951748449168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 73.28102847680749,
    "arrivals": 29680,
    "finished_requests": 29622,
    "scheduler_time": 9.424682019271893
}
#Debug simulation 
Total elapsed time: 2.4255737038329244. Arrivals time: 0.08021842269226909 Scheduler time: 1.9946299423463643 Scheduler overhead time: 0.08865453582257032 Adapter cache time: 0.13052922300994396 Engine time: 0.08788753673434258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.433325617108494,
    "estimated_duration": 3600.0068576928875,
    "input_throughput": 2025.9172519115752,
    "output_throughput": 1770.3135721481133,
    "total_throughput": 3796.2308240596885,
    "itl": 40.356999099137745,
    "ttft": 7409.346111041491,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11661,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 86.28924439272384,
    "arrivals": 29680,
    "finished_requests": 29619,
    "scheduler_time": 9.720872186428455
}
#Debug simulation 
Total elapsed time: 2.4334094799123704. Arrivals time: 0.080061593092978 Scheduler time: 2.0051796277984977 Scheduler overhead time: 0.08761747926473618 Adapter cache time: 0.13097470672801137 Engine time: 0.08601292641833425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_160_slots_64_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_160_slots_64_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.2005728287622333,
    "estimated_duration": 3599.974878583098,
    "input_throughput": 1803.4606404129484,
    "output_throughput": 1589.9099835532038,
    "total_throughput": 3393.3706239661524,
    "itl": 35.824549776183154,
    "ttft": 9627.882104525208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10176,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.28787430912631,
    "arrivals": 26722,
    "finished_requests": 26651,
    "scheduler_time": 5.159531845809978
}
#Debug simulation 
Total elapsed time: 2.200651534833014. Arrivals time: 0.07283168099820614 Scheduler time: 1.7712328871712089 Scheduler overhead time: 0.09486666647717357 Adapter cache time: 0.12373821204528213 Engine time: 0.09097049804404378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_160_slots_64_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_160_slots_64_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.201198721304536,
    "estimated_duration": 3599.957381362805,
    "input_throughput": 1803.4694059467513,
    "output_throughput": 1589.9177111461393,
    "total_throughput": 3393.3871170928905,
    "itl": 36.14077977944258,
    "ttft": 9629.23203154273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 74.32276986566492,
    "arrivals": 26722,
    "finished_requests": 26651,
    "scheduler_time": 5.306759322906315
}
#Debug simulation 
Total elapsed time: 2.201287870295346. Arrivals time: 0.07378559419885278 Scheduler time: 1.7702857474796474 Scheduler overhead time: 0.09479630459100008 Adapter cache time: 0.12245029583573341 Engine time: 0.09293585829436779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_160_slots_64_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_160_slots_64_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2250662110745907,
    "estimated_duration": 3599.9603117614315,
    "input_throughput": 1803.4679379071583,
    "output_throughput": 1589.916416939461,
    "total_throughput": 3393.3843548466193,
    "itl": 36.18002088941173,
    "ttft": 9629.461920847909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10153,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 76.37610873101312,
    "arrivals": 26722,
    "finished_requests": 26651,
    "scheduler_time": 5.3236291557544435
}
#Debug simulation 
Total elapsed time: 2.2251457599923015. Arrivals time: 0.07389425439760089 Scheduler time: 1.7921633645892143 Scheduler overhead time: 0.0946966796182096 Adapter cache time: 0.12402018858119845 Engine time: 0.09360016277059913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_160_slots_64_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_160_slots_64_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.2360691991634667,
    "estimated_duration": 3599.9716671490855,
    "input_throughput": 1803.4622492297326,
    "output_throughput": 1589.911401867421,
    "total_throughput": 3393.373651097154,
    "itl": 35.86786472674664,
    "ttft": 9628.190124963729,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10187,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 69.72241306944353,
    "arrivals": 26722,
    "finished_requests": 26651,
    "scheduler_time": 5.179649664684344
}
#Debug simulation 
Total elapsed time: 2.2361490419134498. Arrivals time: 0.07394297374412417 Scheduler time: 1.8003868348896503 Scheduler overhead time: 0.09675009734928608 Adapter cache time: 0.12443028064444661 Engine time: 0.09303701249882579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_160_slots_64_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_160_slots_64_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.223152290098369,
    "estimated_duration": 3599.9893568550424,
    "input_throughput": 1803.4533873377293,
    "output_throughput": 1589.903589326214,
    "total_throughput": 3393.356976663943,
    "itl": 36.1605586137166,
    "ttft": 9629.18917879038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 75.64250268447216,
    "arrivals": 26722,
    "finished_requests": 26651,
    "scheduler_time": 5.317600254327384
}
#Debug simulation 
Total elapsed time: 2.223257723264396. Arrivals time: 0.07744174264371395 Scheduler time: 1.7869790201075375 Scheduler overhead time: 0.09528057277202606 Adapter cache time: 0.12363618379458785 Engine time: 0.09294384717941284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_160_slots_64_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_160_slots_64_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.222681060899049,
    "estimated_duration": 3599.985472307434,
    "input_throughput": 1803.4553333457332,
    "output_throughput": 1589.9053049042996,
    "total_throughput": 3393.360638250033,
    "itl": 35.78061548459453,
    "ttft": 9627.861014555276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10179,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.98193125407393,
    "arrivals": 26722,
    "finished_requests": 26651,
    "scheduler_time": 5.140486838982849
}
#Debug simulation 
Total elapsed time: 2.22275870712474. Arrivals time: 0.07357756327837706 Scheduler time: 1.7883083149790764 Scheduler overhead time: 0.09605930559337139 Adapter cache time: 0.12438000459223986 Engine time: 0.09303596848621964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_160_slots_64_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_160_slots_64_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2388721853494644,
    "estimated_duration": 3599.958376318118,
    "input_throughput": 1803.4689075044694,
    "output_throughput": 1589.9172717252047,
    "total_throughput": 3393.386179229674,
    "itl": 36.149750947755706,
    "ttft": 9629.263987053013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 74.88177362563057,
    "arrivals": 26722,
    "finished_requests": 26651,
    "scheduler_time": 5.31128774686383
}
#Debug simulation 
Total elapsed time: 2.2389528593048453. Arrivals time: 0.07410718314349651 Scheduler time: 1.805897078011185 Scheduler overhead time: 0.09477202082052827 Adapter cache time: 0.1234861291013658 Engine time: 0.09377109073102474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.1326563181355596,
    "estimated_duration": 3600.006280128922,
    "input_throughput": 1725.6347674419967,
    "output_throughput": 1513.8281924899404,
    "total_throughput": 3239.4629599319373,
    "itl": 33.95917557287753,
    "ttft": 6266.366828948432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.436911087696735,
    "arrivals": 25517,
    "finished_requests": 25472,
    "scheduler_time": 3.3267821668961215
}
#Debug simulation 
Total elapsed time: 2.132734994869679. Arrivals time: 0.07100270921364427 Scheduler time: 1.6985923992469907 Scheduler overhead time: 0.09919127076864243 Adapter cache time: 0.11718940502032638 Engine time: 0.09747279155999422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.142570846248418,
    "estimated_duration": 3600.0005060597327,
    "input_throughput": 1725.6375352012028,
    "output_throughput": 1513.8306205309113,
    "total_throughput": 3239.468155732114,
    "itl": 34.0596745183141,
    "ttft": 6125.800511670223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8529,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.51541377804481,
    "arrivals": 25517,
    "finished_requests": 25472,
    "scheduler_time": 3.3697499976898153
}
#Debug simulation 
Total elapsed time: 2.1426492161117494. Arrivals time: 0.07028198335319757 Scheduler time: 1.7082902663387358 Scheduler overhead time: 0.10044766264036298 Adapter cache time: 0.11827491875737906 Engine time: 0.09591884352266788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.131815361790359,
    "estimated_duration": 3600.0134969433557,
    "input_throughput": 1725.6313081255505,
    "output_throughput": 1513.825157774332,
    "total_throughput": 3239.4564658998825,
    "itl": 34.08238468190975,
    "ttft": 6266.820423945282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.25928139581308,
    "arrivals": 25517,
    "finished_requests": 25472,
    "scheduler_time": 3.382282637625517
}
#Debug simulation 
Total elapsed time: 2.1318939407356083. Arrivals time: 0.07014203490689397 Scheduler time: 1.697347505018115 Scheduler overhead time: 0.10031464276835322 Adapter cache time: 0.1181148081086576 Engine time: 0.09651064081117511 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.1480238321237266,
    "estimated_duration": 3600.0115950275353,
    "input_throughput": 1725.6322197908044,
    "output_throughput": 1513.8259575406496,
    "total_throughput": 3239.458177331454,
    "itl": 33.9913742615338,
    "ttft": 6266.3962730364665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.36768336291169,
    "arrivals": 25517,
    "finished_requests": 25472,
    "scheduler_time": 3.3403238305260006
}
#Debug simulation 
Total elapsed time: 2.1480990489944816. Arrivals time: 0.07125876331701875 Scheduler time: 1.7123406697064638 Scheduler overhead time: 0.09978730883449316 Adapter cache time: 0.11827882193028927 Engine time: 0.09721582382917404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.145284522790462,
    "estimated_duration": 3600.0103498370117,
    "input_throughput": 1725.6328166615572,
    "output_throughput": 1513.826481150738,
    "total_throughput": 3239.459297812295,
    "itl": 34.079064507928734,
    "ttft": 6266.840004311005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.66106877596072,
    "arrivals": 25517,
    "finished_requests": 25472,
    "scheduler_time": 3.3780730766845997
}
#Debug simulation 
Total elapsed time: 2.1453686910681427. Arrivals time: 0.07118113478645682 Scheduler time: 1.7061105533502996 Scheduler overhead time: 0.09922782378271222 Adapter cache time: 0.11834964528679848 Engine time: 0.10052509140223265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.143957742024213,
    "estimated_duration": 3600.0090111688532,
    "input_throughput": 1725.6334583404246,
    "output_throughput": 1513.8270440691365,
    "total_throughput": 3239.460502409561,
    "itl": 33.929893991468184,
    "ttft": 6266.256470452675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.48038130683509,
    "arrivals": 25517,
    "finished_requests": 25472,
    "scheduler_time": 3.312785754731348
}
#Debug simulation 
Total elapsed time: 2.1440355689264834. Arrivals time: 0.07103622378781438 Scheduler time: 1.7080200682394207 Scheduler overhead time: 0.09932946041226387 Adapter cache time: 0.11835905816406012 Engine time: 0.09787901304662228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.132809294387698,
    "estimated_duration": 3600.0127621495835,
    "input_throughput": 1725.6316603418402,
    "output_throughput": 1513.8254667591527,
    "total_throughput": 3239.457127100993,
    "itl": 34.06783824249095,
    "ttft": 6266.858741728874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.04997571179142,
    "arrivals": 25517,
    "finished_requests": 25472,
    "scheduler_time": 3.373714415227326
}
#Debug simulation 
Total elapsed time: 2.1328912312164903. Arrivals time: 0.07078084954991937 Scheduler time: 1.699199718888849 Scheduler overhead time: 0.09947693720459938 Adapter cache time: 0.11731072748079896 Engine time: 0.09683979908004403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.1383461779914796,
    "estimated_duration": 3599.9432906869024,
    "input_throughput": 1706.9404998397902,
    "output_throughput": 1494.5915992397095,
    "total_throughput": 3201.5320990795,
    "itl": 33.45539080506217,
    "ttft": 9148.459309620772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 50.40639405055658,
    "arrivals": 24947,
    "finished_requests": 24884,
    "scheduler_time": 2.9800300745123964
}
#Debug simulation 
Total elapsed time: 2.1384293977171183. Arrivals time: 0.07033283123746514 Scheduler time: 1.6874784757383168 Scheduler overhead time: 0.10103968530893326 Adapter cache time: 0.11394342314451933 Engine time: 0.11556477705016732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.12706119986251,
    "estimated_duration": 3599.940542413748,
    "input_throughput": 1706.8654128048618,
    "output_throughput": 1494.5066277102003,
    "total_throughput": 3201.372040515062,
    "itl": 33.54226861162904,
    "ttft": 9293.153789226597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.93974774485709,
    "arrivals": 24947,
    "finished_requests": 24883,
    "scheduler_time": 3.0164770067501627
}
#Debug simulation 
Total elapsed time: 2.127134408801794. Arrivals time: 0.069719850551337 Scheduler time: 1.6941327503882349 Scheduler overhead time: 0.1008567176759243 Adapter cache time: 0.1136523550376296 Engine time: 0.09868056792765856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.116827684920281,
    "estimated_duration": 3599.963185217345,
    "input_throughput": 1706.8546770788778,
    "output_throughput": 1494.4972276640597,
    "total_throughput": 3201.351904742937,
    "itl": 33.563898752782215,
    "ttft": 9293.263583995802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7618,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.48903506294896,
    "arrivals": 24947,
    "finished_requests": 24883,
    "scheduler_time": 3.026759200903025
}
#Debug simulation 
Total elapsed time: 2.116909039672464. Arrivals time: 0.0691680135205388 Scheduler time: 1.6849312880076468 Scheduler overhead time: 0.10146956611424685 Adapter cache time: 0.11331767542287707 Engine time: 0.09798434609547257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.1422705119475722,
    "estimated_duration": 3599.9418832364236,
    "input_throughput": 1706.9411671934035,
    "output_throughput": 1494.5921835723823,
    "total_throughput": 3201.5333507657856,
    "itl": 33.484672243431945,
    "ttft": 9148.708578108239,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.21764398460455,
    "arrivals": 24947,
    "finished_requests": 24884,
    "scheduler_time": 2.9914994407593767
}
#Debug simulation 
Total elapsed time: 2.142359693069011. Arrivals time: 0.07026724703609943 Scheduler time: 1.7090646591968834 Scheduler overhead time: 0.10181288840249181 Adapter cache time: 0.11429085955023766 Engine time: 0.0966411167755723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.355002027004957,
    "estimated_duration": 3599.964390442401,
    "input_throughput": 1706.85410564433,
    "output_throughput": 1494.496727324248,
    "total_throughput": 3201.3508329685783,
    "itl": 33.55634872537214,
    "ttft": 9293.328411960389,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.98505662766364,
    "arrivals": 24947,
    "finished_requests": 24883,
    "scheduler_time": 3.0233458415362247
}
#Debug simulation 
Total elapsed time: 2.355139742139727. Arrivals time: 0.0710796881467104 Scheduler time: 1.9162987605668604 Scheduler overhead time: 0.1028523319400847 Adapter cache time: 0.11366295116022229 Engine time: 0.0996275981888175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.1385573856532574,
    "estimated_duration": 3599.9610696260465,
    "input_throughput": 1706.9320698621648,
    "output_throughput": 1494.5842179784752,
    "total_throughput": 3201.51628784064,
    "itl": 33.42946691055059,
    "ttft": 9148.4106972126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.6773971718557,
    "arrivals": 24947,
    "finished_requests": 24884,
    "scheduler_time": 2.968433651244099
}
#Debug simulation 
Total elapsed time: 2.1386390067636967. Arrivals time: 0.07011978467926383 Scheduler time: 1.703908443916589 Scheduler overhead time: 0.10115412017330527 Adapter cache time: 0.11368491733446717 Engine time: 0.09969569789245725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.1103358757682145,
    "estimated_duration": 3599.9491083067046,
    "input_throughput": 1706.861351406776,
    "output_throughput": 1494.5030716088747,
    "total_throughput": 3201.364423015651,
    "itl": 33.54930621524398,
    "ttft": 9293.15979023101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.45680444808297,
    "arrivals": 24947,
    "finished_requests": 24883,
    "scheduler_time": 3.0197854513519062
}
#Debug simulation 
Total elapsed time: 2.110406775958836. Arrivals time: 0.06996359210461378 Scheduler time: 1.6767633706331253 Scheduler overhead time: 0.10037584230303764 Adapter cache time: 0.11325760977342725 Engine time: 0.10026366310194135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.9857478267513216,
    "estimated_duration": 3599.257093584878,
    "input_throughput": 1572.6184189755545,
    "output_throughput": 1380.3720797981493,
    "total_throughput": 2952.9904987737036,
    "itl": 31.31363901045199,
    "ttft": 7827.645129470907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.6113825737296,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.1811361685506276
}
#Debug simulation 
Total elapsed time: 1.985857383813709. Arrivals time: 0.06524793663993478 Scheduler time: 1.5570037998259068 Scheduler overhead time: 0.10505450516939163 Adapter cache time: 0.10412120074033737 Engine time: 0.10167591879144311 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.005730214063078,
    "estimated_duration": 3599.2602897227066,
    "input_throughput": 1572.617022492718,
    "output_throughput": 1380.3708540297785,
    "total_throughput": 2952.987876522496,
    "itl": 31.36913774795519,
    "ttft": 7827.939692615587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.67721637181796,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.196892865777482
}
#Debug simulation 
Total elapsed time: 2.005809562280774. Arrivals time: 0.06607830943539739 Scheduler time: 1.572198226582259 Scheduler overhead time: 0.10542227793484926 Adapter cache time: 0.10474080825224519 Engine time: 0.10465556290000677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9990185401402414,
    "estimated_duration": 3599.2471759401087,
    "input_throughput": 1572.6227522902934,
    "output_throughput": 1380.3758833824177,
    "total_throughput": 2952.9986356727113,
    "itl": 31.38613911867907,
    "ttft": 7828.042416210126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.8071079517148,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.201286945520338
}
#Debug simulation 
Total elapsed time: 1.9991066581569612. Arrivals time: 0.06622615223750472 Scheduler time: 1.5638597551733255 Scheduler overhead time: 0.10786205111071467 Adapter cache time: 0.10435300692915916 Engine time: 0.10355237824842334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_160_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.003961166832596,
    "estimated_duration": 3599.258293130274,
    "input_throughput": 1572.61789486002,
    "output_throughput": 1380.3716197536517,
    "total_throughput": 2952.9895146136714,
    "itl": 31.33113724480808,
    "ttft": 7827.746961777403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.98046020459974,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.1865878614082792
}
#Debug simulation 
Total elapsed time: 2.0040427520871162. Arrivals time: 0.06605150457471609 Scheduler time: 1.5719721531495452 Scheduler overhead time: 0.10681026196107268 Adapter cache time: 0.10437807021662593 Engine time: 0.10203181533142924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_160_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.9935381077229977,
    "estimated_duration": 3599.259100164859,
    "input_throughput": 1572.61754224383,
    "output_throughput": 1380.371310243387,
    "total_throughput": 2952.988852487217,
    "itl": 31.376944933087223,
    "ttft": 7828.005664019997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.404420291394224,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.1996356628634808
}
#Debug simulation 
Total elapsed time: 1.9936176436021924. Arrivals time: 0.06584938056766987 Scheduler time: 1.559171992354095 Scheduler overhead time: 0.10699543822556734 Adapter cache time: 0.104453279171139 Engine time: 0.10415214207023382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_160_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.031854803673923,
    "estimated_duration": 3599.270356258269,
    "input_throughput": 1572.6126241553839,
    "output_throughput": 1380.366993371668,
    "total_throughput": 2952.979617527052,
    "itl": 31.295927815655254,
    "ttft": 7827.583245553613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5689,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.3181262309095,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.176297618543228
}
#Debug simulation 
Total elapsed time: 2.031941297929734. Arrivals time: 0.06631161505356431 Scheduler time: 1.5956874112598598 Scheduler overhead time: 0.10768246185034513 Adapter cache time: 0.10517154261469841 Engine time: 0.10411219066008925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_160_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.0081827910616994,
    "estimated_duration": 3599.249047307318,
    "input_throughput": 1572.6219346323285,
    "output_throughput": 1380.375165679883,
    "total_throughput": 2952.9971003122114,
    "itl": 31.372158895315387,
    "ttft": 7828.05974639502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.98169862346662,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.1981649788404614
}
#Debug simulation 
Total elapsed time: 2.0082961986772716. Arrivals time: 0.06550943152979016 Scheduler time: 1.5731581738218665 Scheduler overhead time: 0.1079417197033763 Adapter cache time: 0.10466980934143066 Engine time: 0.103658402338624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.9634891678579152,
    "estimated_duration": 3600.000149390261,
    "input_throughput": 1527.239658845908,
    "output_throughput": 1347.6666107421481,
    "total_throughput": 2874.906269588056,
    "itl": 30.57783740225336,
    "ttft": 8510.754070828993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.921150869570624,
    "arrivals": 22557,
    "finished_requests": 22503,
    "scheduler_time": 0.7974465044426383
}
#Debug simulation 
Total elapsed time: 1.9635694189928472. Arrivals time: 0.06443963712081313 Scheduler time: 1.5339788408018649 Scheduler overhead time: 0.10645854566246271 Adapter cache time: 0.0988767254166305 Engine time: 0.10632471181452274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9575044140219688,
    "estimated_duration": 3600.001993893652,
    "input_throughput": 1527.2388763466943,
    "output_throughput": 1347.665920249299,
    "total_throughput": 2874.904796595993,
    "itl": 30.621975266783792,
    "ttft": 8510.808774118956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.14047746518991,
    "arrivals": 22557,
    "finished_requests": 22503,
    "scheduler_time": 0.8064457032925555
}
#Debug simulation 
Total elapsed time: 1.9576271921396255. Arrivals time: 0.06422460777685046 Scheduler time: 1.5261559002101421 Scheduler overhead time: 0.10730785131454468 Adapter cache time: 0.0985753508284688 Engine time: 0.10770462732762098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9644368011504412,
    "estimated_duration": 3600.0314006750355,
    "input_throughput": 1527.226401127798,
    "output_throughput": 1347.6549118683479,
    "total_throughput": 2874.881312996146,
    "itl": 30.633838402349777,
    "ttft": 8670.218751644436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4527,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.07919727763732,
    "arrivals": 22557,
    "finished_requests": 22503,
    "scheduler_time": 0.8090727856633906
}
#Debug simulation 
Total elapsed time: 1.9645165400579572. Arrivals time: 0.06418930413201451 Scheduler time: 1.5336068370379508 Scheduler overhead time: 0.10908115794882178 Adapter cache time: 0.09891169145703316 Engine time: 0.1045341407880187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.9578440738841891,
    "estimated_duration": 3600.0090070463407,
    "input_throughput": 1527.2359011431847,
    "output_throughput": 1347.6632948706254,
    "total_throughput": 2874.89919601381,
    "itl": 30.593096435592752,
    "ttft": 8669.95736777922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.025933592031706,
    "arrivals": 22557,
    "finished_requests": 22503,
    "scheduler_time": 0.8005780203346264
}
#Debug simulation 
Total elapsed time: 1.9579378301277757. Arrivals time: 0.06591309141367674 Scheduler time: 1.5265569030307233 Scheduler overhead time: 0.10925918677821755 Adapter cache time: 0.09859848720952868 Engine time: 0.10367702413350344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.9618245558813214,
    "estimated_duration": 3600.0021430717256,
    "input_throughput": 1527.238813060467,
    "output_throughput": 1347.665864404275,
    "total_throughput": 2874.9046774647422,
    "itl": 30.626932729226436,
    "ttft": 8510.917188476828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4521,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.7190298453404,
    "arrivals": 22557,
    "finished_requests": 22503,
    "scheduler_time": 0.8078854884472682
}
#Debug simulation 
Total elapsed time: 1.9619035781361163. Arrivals time: 0.06446314556524158 Scheduler time: 1.532017881050706 Scheduler overhead time: 0.1072714515030384 Adapter cache time: 0.09896935475990176 Engine time: 0.10531407268717885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.983596259728074,
    "estimated_duration": 3600.001298891491,
    "input_throughput": 1527.2391711894545,
    "output_throughput": 1347.6661804244072,
    "total_throughput": 2874.9053516138615,
    "itl": 30.726603246904173,
    "ttft": 8510.707655373672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.70849246974841,
    "arrivals": 22557,
    "finished_requests": 22503,
    "scheduler_time": 0.8258743788030052
}
#Debug simulation 
Total elapsed time: 1.983679513912648. Arrivals time: 0.06533924769610167 Scheduler time: 1.5494853416457772 Scheduler overhead time: 0.10887778457254171 Adapter cache time: 0.09904579352587461 Engine time: 0.10688575403764844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9598968238569796,
    "estimated_duration": 3600.0070734512933,
    "input_throughput": 1527.2367214348437,
    "output_throughput": 1347.664018712279,
    "total_throughput": 2874.9007401471226,
    "itl": 30.62555644113975,
    "ttft": 8670.114193133071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.42957742558913,
    "arrivals": 22557,
    "finished_requests": 22503,
    "scheduler_time": 0.8071376157116151
}
#Debug simulation 
Total elapsed time: 1.959982912056148. Arrivals time: 0.06435756338760257 Scheduler time: 1.5316518982872367 Scheduler overhead time: 0.10739426640793681 Adapter cache time: 0.09880195837467909 Engine time: 0.10380505444481969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_160_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.8596173007972538,
    "estimated_duration": 3599.8698232248043,
    "input_throughput": 1451.8491658451335,
    "output_throughput": 1288.6379863159593,
    "total_throughput": 2740.4871521610926,
    "itl": 29.49599407226803,
    "ttft": 4284.301161610378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.52949634369937,
    "arrivals": 21252,
    "finished_requests": 21227,
    "scheduler_time": 0.409356409186207
}
#Debug simulation 
Total elapsed time: 1.8597075319848955. Arrivals time: 0.06013556197285652 Scheduler time: 1.4324706783518195 Scheduler overhead time: 0.11118556093424559 Adapter cache time: 0.08971787430346012 Engine time: 0.11092974152415991 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_160_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.889976360835135,
    "estimated_duration": 3599.8736440640955,
    "input_throughput": 1451.7592884454443,
    "output_throughput": 1288.5646716097374,
    "total_throughput": 2740.323960055182,
    "itl": 29.67935486454673,
    "ttft": 4454.297759496839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2642,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.340128899430418,
    "arrivals": 21252,
    "finished_requests": 21226,
    "scheduler_time": 0.42990737383619193
}
#Debug simulation 
Total elapsed time: 1.8900542207993567. Arrivals time: 0.06093466095626354 Scheduler time: 1.4650006191805005 Scheduler overhead time: 0.11071056686341763 Adapter cache time: 0.0898333378136158 Engine time: 0.108277955558151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_160_slots_64_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.8901051059365273,
    "estimated_duration": 3599.8780542276727,
    "input_throughput": 1451.7575099141052,
    "output_throughput": 1288.5630930059915,
    "total_throughput": 2740.3206029200965,
    "itl": 29.686633264006847,
    "ttft": 4454.2215639340075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2644,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.876729275044156,
    "arrivals": 21252,
    "finished_requests": 21226,
    "scheduler_time": 0.4309514347988499
}
#Debug simulation 
Total elapsed time: 1.890185363125056. Arrivals time: 0.0611116080544889 Scheduler time: 1.4636232196353376 Scheduler overhead time: 0.10987972421571612 Adapter cache time: 0.09137762291356921 Engine time: 0.10870487801730633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_160_slots_64_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.8755223518237472,
    "estimated_duration": 3599.878341334533,
    "input_throughput": 1451.8457304483418,
    "output_throughput": 1288.6349371129786,
    "total_throughput": 2740.4806675613204,
    "itl": 29.504891007215146,
    "ttft": 4284.433845462994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2650,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.17373047336044,
    "arrivals": 21252,
    "finished_requests": 21227,
    "scheduler_time": 0.4107022046479592
}
#Debug simulation 
Total elapsed time: 1.875592838972807. Arrivals time: 0.0607984010130167 Scheduler time: 1.4528389419429004 Scheduler overhead time: 0.10968551132827997 Adapter cache time: 0.0899396319873631 Engine time: 0.10714743146672845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_160_slots_64_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.8957819733768702,
    "estimated_duration": 3599.8902823672674,
    "input_throughput": 1451.7525785711762,
    "output_throughput": 1288.5587160033213,
    "total_throughput": 2740.3112945744974,
    "itl": 29.681711022241817,
    "ttft": 4454.133400452902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2642,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.68188687385999,
    "arrivals": 21252,
    "finished_requests": 21226,
    "scheduler_time": 0.430528147682529
}
#Debug simulation 
Total elapsed time: 1.8958726902492344. Arrivals time: 0.061873883474618196 Scheduler time: 1.4701824840158224 Scheduler overhead time: 0.10921512637287378 Adapter cache time: 0.08927428210154176 Engine time: 0.11011060047894716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_160_slots_64_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.8806760809384286,
    "estimated_duration": 3599.878510489146,
    "input_throughput": 1451.8456622275944,
    "output_throughput": 1288.6348765613398,
    "total_throughput": 2740.480538788934,
    "itl": 29.4892642813907,
    "ttft": 4284.409748783569,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.95569401815649,
    "arrivals": 21252,
    "finished_requests": 21227,
    "scheduler_time": 0.40841809697462345
}
#Debug simulation 
Total elapsed time: 1.8807532619684935. Arrivals time: 0.06106123235076666 Scheduler time: 1.4567032624036074 Scheduler overhead time: 0.10966628370806575 Adapter cache time: 0.08987465035170317 Engine time: 0.10836280696094036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_160_slots_64_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9080344559624791,
    "estimated_duration": 3599.8664498789194,
    "input_throughput": 1451.7621897267272,
    "output_throughput": 1288.5672467532845,
    "total_throughput": 2740.3294364800117,
    "itl": 29.681911776208903,
    "ttft": 4454.212380478787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2642,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.495326166711806,
    "arrivals": 21252,
    "finished_requests": 21226,
    "scheduler_time": 0.43013625992252497
}
#Debug simulation 
Total elapsed time: 1.90811428707093. Arrivals time: 0.06134932395070791 Scheduler time: 1.4786629602313042 Scheduler overhead time: 0.10971958888694644 Adapter cache time: 0.08987717144191265 Engine time: 0.11340741440653801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_160_slots_64_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_160_slots_64_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.6280554491095245,
    "estimated_duration": 3599.5661337959036,
    "input_throughput": 1183.6529297232184,
    "output_throughput": 1010.0058909505616,
    "total_throughput": 2193.65882067378,
    "itl": 28.114269917872342,
    "ttft": 7809.6823541480635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.27668703475463,
    "arrivals": 17165,
    "finished_requests": 17128,
    "scheduler_time": 0.015276411288345906
}
#Debug simulation 
Total elapsed time: 1.6281344629824162. Arrivals time: 0.05317221023142338 Scheduler time: 1.1835705577395856 Scheduler overhead time: 0.11266858642920852 Adapter cache time: 0.10960127366706729 Engine time: 0.11179828178137541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_160_slots_64_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_160_slots_64_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6233207453042269,
    "estimated_duration": 3599.5700568464913,
    "input_throughput": 1183.651639699619,
    "output_throughput": 1010.0047901790413,
    "total_throughput": 2193.65642987866,
    "itl": 28.188363997426812,
    "ttft": 7810.115266789525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8660,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.425283132845124,
    "arrivals": 17165,
    "finished_requests": 17128,
    "scheduler_time": 0.015830008116013955
}
#Debug simulation 
Total elapsed time: 1.6234083082526922. Arrivals time: 0.052852378226816654 Scheduler time: 1.178081997204572 Scheduler overhead time: 0.11607726477086544 Adapter cache time: 0.10898770485073328 Engine time: 0.10944412834942341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_160_slots_64_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_160_slots_64_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6199423680081964,
    "estimated_duration": 3599.5876516071066,
    "input_throughput": 1183.6458540182387,
    "output_throughput": 1009.9998532823121,
    "total_throughput": 2193.645707300551,
    "itl": 28.20459872945604,
    "ttft": 7810.362142925866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8661,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.16563119724397,
    "arrivals": 17165,
    "finished_requests": 17128,
    "scheduler_time": 0.015958149367327534
}
#Debug simulation 
Total elapsed time: 1.620016518048942. Arrivals time: 0.05261134263128042 Scheduler time: 1.177949771285057 Scheduler overhead time: 0.11301968898624182 Adapter cache time: 0.10886889742687345 Engine time: 0.11024111416190863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_160_slots_64_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_160_slots_64_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.6354887820780277,
    "estimated_duration": 3599.5722579047183,
    "input_throughput": 1183.6509159230163,
    "output_throughput": 1010.0041725836178,
    "total_throughput": 2193.655088506634,
    "itl": 28.139839065288584,
    "ttft": 7809.754059682977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.32836918748192,
    "arrivals": 17165,
    "finished_requests": 17128,
    "scheduler_time": 0.015496874260603076
}
#Debug simulation 
Total elapsed time: 1.6355955176986754. Arrivals time: 0.053126441314816475 Scheduler time: 1.1899712607264519 Scheduler overhead time: 0.11276074731722474 Adapter cache time: 0.10911383666098118 Engine time: 0.11313214944675565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_160_slots_64_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_160_slots_64_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.6312727318145335,
    "estimated_duration": 3599.5770284333585,
    "input_throughput": 1183.6493472274308,
    "output_throughput": 1010.0028340225052,
    "total_throughput": 2193.652181249936,
    "itl": 28.203321158104018,
    "ttft": 7810.18802122333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8665,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.58838963996129,
    "arrivals": 17165,
    "finished_requests": 17128,
    "scheduler_time": 0.015897352124704906
}
#Debug simulation 
Total elapsed time: 1.6313559720292687. Arrivals time: 0.05321232322603464 Scheduler time: 1.1841391916386783 Scheduler overhead time: 0.1134712346829474 Adapter cache time: 0.10926327109336853 Engine time: 0.11359665775671601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_160_slots_64_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_160_slots_64_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.6160626709461212,
    "estimated_duration": 3599.5626964315547,
    "input_throughput": 1183.7810199067396,
    "output_throughput": 1010.0824201796579,
    "total_throughput": 2193.8634400863975,
    "itl": 28.092815604140526,
    "ttft": 7599.753688236552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8659,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.278371424406515,
    "arrivals": 17165,
    "finished_requests": 17129,
    "scheduler_time": 0.015144225228991082
}
#Debug simulation 
Total elapsed time: 1.616141865029931. Arrivals time: 0.05251289578154683 Scheduler time: 1.1736787222325802 Scheduler overhead time: 0.11312583461403847 Adapter cache time: 0.10836155759170651 Engine time: 0.11086441483348608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_160_slots_64_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_160_slots_64_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6130343228578568,
    "estimated_duration": 3599.572014467179,
    "input_throughput": 1183.6509959728294,
    "output_throughput": 1010.0042408897746,
    "total_throughput": 2193.655236862604,
    "itl": 28.194316473678356,
    "ttft": 7810.239334344942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8659,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.93556527835729,
    "arrivals": 17165,
    "finished_requests": 17128,
    "scheduler_time": 0.015867245374394223
}
#Debug simulation 
Total elapsed time: 1.6131297168321908. Arrivals time: 0.054170635528862476 Scheduler time: 1.1717413854785264 Scheduler overhead time: 0.1130807502195239 Adapter cache time: 0.1077686925418675 Engine time: 0.10907399980351329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_160_slots_64_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.5648962263949215,
    "estimated_duration": 3599.6127281757776,
    "input_throughput": 1078.1607059064947,
    "output_throughput": 964.911300822134,
    "total_throughput": 2043.0720067286288,
    "itl": 27.46346217894165,
    "ttft": 6385.388458663283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7179,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.47048444036992,
    "arrivals": 15906,
    "finished_requests": 15878,
    "scheduler_time": 0.0014543806329471189
}
#Debug simulation 
Total elapsed time: 1.5650913291610777. Arrivals time: 0.04945568973198533 Scheduler time: 1.1294656936079264 Scheduler overhead time: 0.1151338005438447 Adapter cache time: 0.09970504371449351 Engine time: 0.11265319725498557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_160_slots_64_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.5780891301110387,
    "estimated_duration": 3599.634355917194,
    "input_throughput": 1078.1542279760588,
    "output_throughput": 964.9055033299331,
    "total_throughput": 2043.0597313059918,
    "itl": 27.524718635523353,
    "ttft": 6385.747822155002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7182,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.70296714042118,
    "arrivals": 15906,
    "finished_requests": 15878,
    "scheduler_time": 0.001533984187765701
}
#Debug simulation 
Total elapsed time: 1.578172082081437. Arrivals time: 0.0498398132622242 Scheduler time: 1.139416455756873 Scheduler overhead time: 0.11570364376530051 Adapter cache time: 0.09999296115711331 Engine time: 0.11463535716757178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_160_slots_64_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.5569089483469725,
    "estimated_duration": 3599.6204696286477,
    "input_throughput": 1078.1583871814066,
    "output_throughput": 964.9092256546484,
    "total_throughput": 2043.0676128360549,
    "itl": 27.54000333957012,
    "ttft": 6385.980658332179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7186,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.19497529450946,
    "arrivals": 15906,
    "finished_requests": 15878,
    "scheduler_time": 0.001549579677929437
}
#Debug simulation 
Total elapsed time: 1.5569861740805209. Arrivals time: 0.049491641111671925 Scheduler time: 1.1226736190728843 Scheduler overhead time: 0.11555464519187808 Adapter cache time: 0.09915352566167712 Engine time: 0.11171531584113836 
