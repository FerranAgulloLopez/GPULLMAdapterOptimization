INFO 05-31 19:31:05 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:05 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 15.28123637707904,
    "estimated_duration": 3600.046700407646,
    "input_throughput": 5070.702276704618,
    "output_throughput": 4430.0989201595885,
    "total_throughput": 9500.801196864206,
    "itl": 98.96536323865183,
    "ttft": 2067946.3561601143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.7962791241192,
    "arrivals": 541365,
    "finished_requests": 74179,
    "scheduler_time": 189.13805123823127
}
#Debug simulation 
Total elapsed time: 15.281413660850376. Arrivals time: 0.3066074005328119 Scheduler time: 14.806640549562871 Scheduler overhead time: 0.0569802294485271 Adapter cache time: 0.02787521667778492 Engine time: 0.05742452619597316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 34.515242115128785,
    "estimated_duration": 3600.061914702805,
    "input_throughput": 5399.811575630859,
    "output_throughput": 4715.115573616825,
    "total_throughput": 10114.927149247684,
    "itl": 111.90917500314211,
    "ttft": 2024557.455971539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.300354901952664,
    "arrivals": 541365,
    "finished_requests": 79020,
    "scheduler_time": 178.7883709373195
}
#Debug simulation 
Total elapsed time: 34.51538946805522. Arrivals time: 0.3391530974768102 Scheduler time: 34.0120011176914 Scheduler overhead time: 0.06091939890757203 Adapter cache time: 0.018196949269622564 Engine time: 0.05978031037375331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 17.43041880009696,
    "estimated_duration": 3600.092786497835,
    "input_throughput": 5088.148024601203,
    "output_throughput": 4447.58564558448,
    "total_throughput": 9535.733670185682,
    "itl": 99.7240930743189,
    "ttft": 2066059.0944885334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.382003107513212,
    "arrivals": 541365,
    "finished_requests": 74474,
    "scheduler_time": 188.4583708087378
}
#Debug simulation 
Total elapsed time: 17.43055810034275. Arrivals time: 0.30880133621394634 Scheduler time: 16.9526252085343 Scheduler overhead time: 0.05803421791642904 Adapter cache time: 0.027000537142157555 Engine time: 0.058140178211033344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 33.4939726209268,
    "estimated_duration": 3600.0744818481508,
    "input_throughput": 5396.6502909756955,
    "output_throughput": 4715.82271022472,
    "total_throughput": 10112.473001200415,
    "itl": 111.98330876740253,
    "ttft": 2025633.2529735786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 641,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.092093322905693,
    "arrivals": 541365,
    "finished_requests": 79020,
    "scheduler_time": 178.74897655974482
}
#Debug simulation 
Total elapsed time: 33.49413291411474. Arrivals time: 0.3297093375585973 Scheduler time: 33.002826544456184 Scheduler overhead time: 0.059469942934811115 Adapter cache time: 0.01787922764196992 Engine time: 0.05907964799553156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 22.613573959097266,
    "estimated_duration": 3600.082529852322,
    "input_throughput": 5086.978936772107,
    "output_throughput": 4440.275706861568,
    "total_throughput": 9527.254643633674,
    "itl": 99.1171363279413,
    "ttft": 2066969.187469847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.685112784225488,
    "arrivals": 541365,
    "finished_requests": 74375,
    "scheduler_time": 189.01517265641243
}
#Debug simulation 
Total elapsed time: 22.61367054702714. Arrivals time: 0.30937802977859974 Scheduler time: 22.131939361337572 Scheduler overhead time: 0.060164709109812975 Adapter cache time: 0.02494141971692443 Engine time: 0.06093161925673485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 65.78069836460054,
    "estimated_duration": 3600.0577772628467,
    "input_throughput": 5563.989591086367,
    "output_throughput": 4841.391743787965,
    "total_throughput": 10405.381334874332,
    "itl": 119.3760161991424,
    "ttft": 2009398.041438771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 614,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.060019145617325,
    "arrivals": 533687,
    "finished_requests": 80882,
    "scheduler_time": 173.86238550116823
}
#Debug simulation 
Total elapsed time: 65.78086496982723. Arrivals time: 0.40333037031814456 Scheduler time: 65.21336811454967 Scheduler overhead time: 0.061306431889534 Adapter cache time: 0.01781534217298031 Engine time: 0.0602660970762372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 61.89232812682167,
    "estimated_duration": 3600.1263272482474,
    "input_throughput": 5400.017452959633,
    "output_throughput": 4696.056877793615,
    "total_throughput": 10096.074330753248,
    "itl": 111.04886530733503,
    "ttft": 2028618.6585268192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.156367506049579,
    "arrivals": 533687,
    "finished_requests": 78484,
    "scheduler_time": 179.52759712879748
}
#Debug simulation 
Total elapsed time: 61.8925868999213. Arrivals time: 0.36255678441375494 Scheduler time: 61.359420667402446 Scheduler overhead time: 0.0639709709212184 Adapter cache time: 0.01753617450594902 Engine time: 0.06286837672814727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 19.16716439696029,
    "estimated_duration": 3600.063689071894,
    "input_throughput": 5091.8110298003485,
    "output_throughput": 4430.471063169426,
    "total_throughput": 9522.282092969774,
    "itl": 98.8366841049,
    "ttft": 2062987.3324158734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.781798464101714,
    "arrivals": 533687,
    "finished_requests": 74034,
    "scheduler_time": 189.27630580034295
}
#Debug simulation 
Total elapsed time: 19.167285174131393. Arrivals time: 0.2963145673274994 Scheduler time: 18.701904052402824 Scheduler overhead time: 0.05953649338334799 Adapter cache time: 0.02440324565395713 Engine time: 0.05879457760602236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 64.7723770160228,
    "estimated_duration": 3600.0454702094116,
    "input_throughput": 5413.3899588958175,
    "output_throughput": 4707.102768625386,
    "total_throughput": 10120.492727521203,
    "itl": 111.61540986077407,
    "ttft": 2025649.952064913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.186275362069714,
    "arrivals": 533687,
    "finished_requests": 78671,
    "scheduler_time": 179.04046444534237
}
#Debug simulation 
Total elapsed time: 64.77254914492369. Arrivals time: 0.36171560641378164 Scheduler time: 64.23944494035095 Scheduler overhead time: 0.06480560824275017 Adapter cache time: 0.01804569037631154 Engine time: 0.06283551687374711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 17.70162599720061,
    "estimated_duration": 3600.079459965298,
    "input_throughput": 5090.7615245183115,
    "output_throughput": 4429.0269637975425,
    "total_throughput": 9519.788488315853,
    "itl": 98.85038749902839,
    "ttft": 2063807.8693643892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.148099020188646,
    "arrivals": 533687,
    "finished_requests": 74072,
    "scheduler_time": 189.24066545501898
}
#Debug simulation 
Total elapsed time: 17.701723675243556. Arrivals time: 0.3383408021181822 Scheduler time: 17.19453068356961 Scheduler overhead time: 0.05926156044006348 Adapter cache time: 0.02460642484948039 Engine time: 0.0588436983525753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 65.11014099419117,
    "estimated_duration": 3600.0832379920794,
    "input_throughput": 5414.0062080539265,
    "output_throughput": 4707.895034519557,
    "total_throughput": 10121.901242573484,
    "itl": 111.59725444152403,
    "ttft": 2025635.0876824125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.817584722461161,
    "arrivals": 533687,
    "finished_requests": 78663,
    "scheduler_time": 179.06725083506012
}
#Debug simulation 
Total elapsed time: 65.11030654096976. Arrivals time: 0.3578792642802 Scheduler time: 64.58031205506995 Scheduler overhead time: 0.06495020631700754 Adapter cache time: 0.017966227140277624 Engine time: 0.0628843167796731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 24.066465585958213,
    "estimated_duration": 3600.07102298031,
    "input_throughput": 5091.082337822046,
    "output_throughput": 4431.091469632723,
    "total_throughput": 9522.173807454768,
    "itl": 98.85443312719063,
    "ttft": 2062386.7651604332,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1099,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.10286967443303,
    "arrivals": 533687,
    "finished_requests": 74065,
    "scheduler_time": 189.2921332556131
}
#Debug simulation 
Total elapsed time: 24.066576038021594. Arrivals time: 0.3236278616823256 Scheduler time: 23.569777752272785 Scheduler overhead time: 0.06116886856034398 Adapter cache time: 0.02368181524798274 Engine time: 0.0614297091960907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 44.10363410785794,
    "estimated_duration": 3600.110187238917,
    "input_throughput": 5581.658603458307,
    "output_throughput": 4845.081703840202,
    "total_throughput": 10426.740307298509,
    "itl": 119.15989323248259,
    "ttft": 2002962.076001546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.648523549460888,
    "arrivals": 529924,
    "finished_requests": 81547,
    "scheduler_time": 173.64318177507533
}
#Debug simulation 
Total elapsed time: 44.103814399801195. Arrivals time: 0.3543865932151675 Scheduler time: 43.59160500811413 Scheduler overhead time: 0.0579501804895699 Adapter cache time: 0.018336832989007235 Engine time: 0.057368002366274595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 27.220560505986214,
    "estimated_duration": 3600.018211039435,
    "input_throughput": 5427.308378631415,
    "output_throughput": 4710.415060679326,
    "total_throughput": 10137.723439310741,
    "itl": 111.62188603277511,
    "ttft": 2021500.2966423694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.431999342371721,
    "arrivals": 529924,
    "finished_requests": 79303,
    "scheduler_time": 178.60499063815422
}
#Debug simulation 
Total elapsed time: 27.220746508799493. Arrivals time: 0.34165372932329774 Scheduler time: 26.715851590503007 Scheduler overhead time: 0.05815501604229212 Adapter cache time: 0.022596283350139856 Engine time: 0.05765414098277688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 18.89885580725968,
    "estimated_duration": 3600.074664153068,
    "input_throughput": 5116.23416686362,
    "output_throughput": 4442.038705261715,
    "total_throughput": 9558.272872125335,
    "itl": 99.18322027523604,
    "ttft": 2054856.1886935844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.549806420924039,
    "arrivals": 529924,
    "finished_requests": 74722,
    "scheduler_time": 188.53206952533563
}
#Debug simulation 
Total elapsed time: 18.898983391933143. Arrivals time: 0.31058704387396574 Scheduler time: 18.41769905621186 Scheduler overhead time: 0.05902573559433222 Adapter cache time: 0.026361506432294846 Engine time: 0.059049442410469055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 40.064339521341026,
    "estimated_duration": 3600.017986457007,
    "input_throughput": 5422.881239327704,
    "output_throughput": 4707.4725914573955,
    "total_throughput": 10130.3538307851,
    "itl": 111.41675818136727,
    "ttft": 2019683.5995409405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 813,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.587158923051313,
    "arrivals": 529924,
    "finished_requests": 79194,
    "scheduler_time": 178.8168597963486
}
#Debug simulation 
Total elapsed time: 40.06448770035058. Arrivals time: 0.33308630296960473 Scheduler time: 39.566771023441106 Scheduler overhead time: 0.060463919304311275 Adapter cache time: 0.019838978070765734 Engine time: 0.059198733884841204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 17.061474120710045,
    "estimated_duration": 3600.0478823009444,
    "input_throughput": 5120.633003419307,
    "output_throughput": 4444.8694915059305,
    "total_throughput": 9565.502494925237,
    "itl": 99.28660227557899,
    "ttft": 2054758.95054411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1447,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.783678169655497,
    "arrivals": 529924,
    "finished_requests": 74834,
    "scheduler_time": 188.44220989079696
}
#Debug simulation 
Total elapsed time: 17.061586569994688. Arrivals time: 0.30779542960226536 Scheduler time: 16.58475015917793 Scheduler overhead time: 0.0582416420802474 Adapter cache time: 0.026711431331932545 Engine time: 0.05806449614465237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 26.298694057855755,
    "estimated_duration": 3600.0478270372796,
    "input_throughput": 5422.896010819535,
    "output_throughput": 4706.783302360981,
    "total_throughput": 10129.679313180515,
    "itl": 111.3677672214227,
    "ttft": 2020702.1607458068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1047,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.683965224777315,
    "arrivals": 529924,
    "finished_requests": 79183,
    "scheduler_time": 178.83005499731712
}
#Debug simulation 
Total elapsed time: 26.298856244888157. Arrivals time: 0.3369657429866493 Scheduler time: 25.800772765185684 Scheduler overhead time: 0.057184315752238035 Adapter cache time: 0.022224875632673502 Engine time: 0.0572446258738637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 14.537561282981187,
    "estimated_duration": 3600.054041069266,
    "input_throughput": 5119.6173140017,
    "output_throughput": 4444.2716185582285,
    "total_throughput": 9563.888932559928,
    "itl": 99.38118662267199,
    "ttft": 2055186.044083705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.57001894747824,
    "arrivals": 529924,
    "finished_requests": 74779,
    "scheduler_time": 188.32018856987264
}
#Debug simulation 
Total elapsed time: 14.537678220309317. Arrivals time: 0.286388399079442 Scheduler time: 14.083949658554047 Scheduler overhead time: 0.056884045246988535 Adapter cache time: 0.028199792839586735 Engine time: 0.05668043904006481 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 52.29695747094229,
    "estimated_duration": 3600.0242121291253,
    "input_throughput": 5563.79202465252,
    "output_throughput": 4851.660147493899,
    "total_throughput": 10415.452172146419,
    "itl": 119.4844279570344,
    "ttft": 1983827.9878727463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6515760218119433,
    "arrivals": 527992,
    "finished_requests": 81136,
    "scheduler_time": 173.569679683911
}
#Debug simulation 
Total elapsed time: 52.2971440050751. Arrivals time: 0.3692121570929885 Scheduler time: 51.765980021096766 Scheduler overhead time: 0.06157742254436016 Adapter cache time: 0.015038984827697277 Engine time: 0.060560598969459534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 32.15547441598028,
    "estimated_duration": 3600.048779526773,
    "input_throughput": 5392.979981385725,
    "output_throughput": 4711.6183804125185,
    "total_throughput": 10104.598361798244,
    "itl": 111.8245788321247,
    "ttft": 2014960.9184950124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 786,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.749354312224322,
    "arrivals": 527992,
    "finished_requests": 78533,
    "scheduler_time": 178.6711124134039
}
#Debug simulation 
Total elapsed time: 32.155595964286476. Arrivals time: 0.4158111601136625 Scheduler time: 31.57743194513023 Scheduler overhead time: 0.05926232133060694 Adapter cache time: 0.019134733825922012 Engine time: 0.05905681103467941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 14.54285664903,
    "estimated_duration": 3600.0227848263685,
    "input_throughput": 5084.98392764559,
    "output_throughput": 4432.951943322131,
    "total_throughput": 9517.93587096772,
    "itl": 98.9293242448899,
    "ttft": 2063862.725332479,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.660523558030777,
    "arrivals": 527992,
    "finished_requests": 74005,
    "scheduler_time": 188.9643487300989
}
#Debug simulation 
Total elapsed time: 14.543009927961975. Arrivals time: 0.3075382588431239 Scheduler time: 14.070565713569522 Scheduler overhead time: 0.05750229861587286 Adapter cache time: 0.024530672002583742 Engine time: 0.05709358211606741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 27.01469115819782,
    "estimated_duration": 3600.046849819302,
    "input_throughput": 5402.56274747542,
    "output_throughput": 4709.668431356949,
    "total_throughput": 10112.23117883237,
    "itl": 111.85229404827638,
    "ttft": 2027517.4805684134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1020,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.986370932254929,
    "arrivals": 527992,
    "finished_requests": 78677,
    "scheduler_time": 178.58205231350126
}
#Debug simulation 
Total elapsed time: 27.014863597229123. Arrivals time: 0.3713069618679583 Scheduler time: 26.48301239591092 Scheduler overhead time: 0.05734206270426512 Adapter cache time: 0.022029542364180088 Engine time: 0.05653933063149452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 15.788741347845644,
    "estimated_duration": 3600.0428495492038,
    "input_throughput": 5100.0665179024445,
    "output_throughput": 4440.167150233117,
    "total_throughput": 9540.233668135561,
    "itl": 99.13519846488275,
    "ttft": 2063217.4087810176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1170,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.697186848800621,
    "arrivals": 527992,
    "finished_requests": 74210,
    "scheduler_time": 188.79213167929146
}
#Debug simulation 
Total elapsed time: 15.788867672905326. Arrivals time: 0.3485331037081778 Scheduler time: 15.275824914686382 Scheduler overhead time: 0.057793437503278255 Adapter cache time: 0.02292213961482048 Engine time: 0.05769830709323287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 38.86736635258421,
    "estimated_duration": 3600.026148794046,
    "input_throughput": 5407.693776480326,
    "output_throughput": 4710.5574512787125,
    "total_throughput": 10118.251227759038,
    "itl": 111.79945840840065,
    "ttft": 2027606.661095072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 940,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.000885684136271,
    "arrivals": 527992,
    "finished_requests": 78676,
    "scheduler_time": 178.64428439458985
}
#Debug simulation 
Total elapsed time: 38.867546578869224. Arrivals time: 0.3905350766144693 Scheduler time: 38.31227706139907 Scheduler overhead time: 0.059140097349882126 Adapter cache time: 0.02100218366831541 Engine time: 0.05966908065602183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 13.093156005255878,
    "estimated_duration": 3600.0771990622666,
    "input_throughput": 5045.426527167602,
    "output_throughput": 4400.184252750524,
    "total_throughput": 9445.610779918126,
    "itl": 97.60251814342978,
    "ttft": 2065402.3360304146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.22568791447199,
    "arrivals": 527992,
    "finished_requests": 73430,
    "scheduler_time": 190.24324631428098
}
#Debug simulation 
Total elapsed time: 13.093273268081248. Arrivals time: 0.3354747537523508 Scheduler time: 12.592994461301714 Scheduler overhead time: 0.056778790429234505 Adapter cache time: 0.02556568756699562 Engine time: 0.05649712309241295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 59.789439724292606,
    "estimated_duration": 3600.094641652801,
    "input_throughput": 5574.989548270779,
    "output_throughput": 4844.417921189189,
    "total_throughput": 10419.407469459968,
    "itl": 119.02084364562964,
    "ttft": 2004728.0685231087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.093081190777076,
    "arrivals": 526966,
    "finished_requests": 81219,
    "scheduler_time": 173.70730587662325
}
#Debug simulation 
Total elapsed time: 59.78961149323732. Arrivals time: 0.3692821185104549 Scheduler time: 59.256547609809786 Scheduler overhead time: 0.0615126546472311 Adapter cache time: 0.017409383319318295 Engine time: 0.0599249005317688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 36.93590237526223,
    "estimated_duration": 3600.096611540552,
    "input_throughput": 5406.928230092788,
    "output_throughput": 4703.0582306386195,
    "total_throughput": 10109.986460731407,
    "itl": 111.00932210312887,
    "ttft": 2018636.33759879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 605,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.4203370003169455,
    "arrivals": 526966,
    "finished_requests": 78811,
    "scheduler_time": 179.14304417786985
}
#Debug simulation 
Total elapsed time: 36.936042729299515. Arrivals time: 0.39141107350587845 Scheduler time: 36.375861627049744 Scheduler overhead time: 0.06319111492484808 Adapter cache time: 0.01767762564122677 Engine time: 0.06217872630804777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 17.044497448951006,
    "estimated_duration": 3600.0733719763207,
    "input_throughput": 5103.281545040922,
    "output_throughput": 4439.906732018998,
    "total_throughput": 9543.18827705992,
    "itl": 98.84506885249789,
    "ttft": 2060576.0135105825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.103571328716363,
    "arrivals": 526966,
    "finished_requests": 74367,
    "scheduler_time": 188.8654686468775
}
#Debug simulation 
Total elapsed time: 17.04464208614081. Arrivals time: 0.30349526880308986 Scheduler time: 16.5756700434722 Scheduler overhead time: 0.05798394698649645 Adapter cache time: 0.022243575658649206 Engine time: 0.059136006981134415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 35.846159665845335,
    "estimated_duration": 3600.0337100332927,
    "input_throughput": 5407.627141308065,
    "output_throughput": 4709.087015699978,
    "total_throughput": 10116.714157008044,
    "itl": 111.35258464122872,
    "ttft": 2019230.5438496987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.448856635363767,
    "arrivals": 526966,
    "finished_requests": 78897,
    "scheduler_time": 178.85911246522468
}
#Debug simulation 
Total elapsed time: 35.84631355199963. Arrivals time: 0.36317066475749016 Scheduler time: 35.318037586286664 Scheduler overhead time: 0.06143101071938872 Adapter cache time: 0.018147090449929237 Engine time: 0.060010616201907396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 13.414216595236212,
    "estimated_duration": 3600.03775654474,
    "input_throughput": 5107.014771324527,
    "output_throughput": 4445.85476107939,
    "total_throughput": 9552.869532403918,
    "itl": 99.11020895779372,
    "ttft": 2060199.1915371427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.365009966902388,
    "arrivals": 526966,
    "finished_requests": 74475,
    "scheduler_time": 188.58560392299154
}
#Debug simulation 
Total elapsed time: 13.414290565997362. Arrivals time: 0.5733256740495563 Scheduler time: 12.679907660931349 Scheduler overhead time: 0.055558030027896166 Adapter cache time: 0.024087219964712858 Engine time: 0.05569753423333168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 37.89491929905489,
    "estimated_duration": 3600.020617524524,
    "input_throughput": 5414.884544023645,
    "output_throughput": 4710.80496523975,
    "total_throughput": 10125.689509263395,
    "itl": 111.4324598934006,
    "ttft": 2017511.5520389325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.970798825034853,
    "arrivals": 526966,
    "finished_requests": 78943,
    "scheduler_time": 178.81897281190479
}
#Debug simulation 
Total elapsed time: 37.89507570909336. Arrivals time: 0.4070143699645996 Scheduler time: 37.323104387149215 Scheduler overhead time: 0.06156783411279321 Adapter cache time: 0.017603935208171606 Engine time: 0.060592832043766975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 13.215413969941437,
    "estimated_duration": 3600.094920466015,
    "input_throughput": 5097.547816218264,
    "output_throughput": 4433.914202999328,
    "total_throughput": 9531.462019217592,
    "itl": 98.69937531387386,
    "ttft": 2060244.6503906227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.560670333951656,
    "arrivals": 526966,
    "finished_requests": 74255,
    "scheduler_time": 188.96042947470139
}
#Debug simulation 
Total elapsed time: 13.215529328212142. Arrivals time: 0.2784785879775882 Scheduler time: 12.774350696243346 Scheduler overhead time: 0.055873995181173086 Adapter cache time: 0.024686861783266068 Engine time: 0.056600880343467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 40.29309673793614,
    "estimated_duration": 3600.0058453738143,
    "input_throughput": 5525.521583683562,
    "output_throughput": 4844.086301251328,
    "total_throughput": 10369.60788493489,
    "itl": 119.48852270804623,
    "ttft": 2007867.5603889634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 816,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.395725770071255,
    "arrivals": 518548,
    "finished_requests": 80860,
    "scheduler_time": 173.53058945799148
}
#Debug simulation 
Total elapsed time: 40.29323417088017. Arrivals time: 0.39772267220541835 Scheduler time: 39.736532448325306 Scheduler overhead time: 0.05820714356377721 Adapter cache time: 0.019500944763422012 Engine time: 0.057081061881035566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 46.23593688895926,
    "estimated_duration": 3600.0881181334357,
    "input_throughput": 5377.450874740632,
    "output_throughput": 4707.189780895216,
    "total_throughput": 10084.640655635849,
    "itl": 111.47785194349723,
    "ttft": 2001373.8204452132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.364269932825125,
    "arrivals": 518548,
    "finished_requests": 78783,
    "scheduler_time": 178.90372100221103
}
#Debug simulation 
Total elapsed time: 46.23612201400101. Arrivals time: 0.346558737102896 Scheduler time: 45.7218050789088 Scheduler overhead time: 0.06212083762511611 Adapter cache time: 0.017723805271089077 Engine time: 0.061957940459251404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 15.070866671856493,
    "estimated_duration": 3600.0589812131134,
    "input_throughput": 5057.904632958038,
    "output_throughput": 4437.221468693035,
    "total_throughput": 9495.126101651073,
    "itl": 99.19495582915127,
    "ttft": 2062214.9380627042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.129879828030122,
    "arrivals": 518548,
    "finished_requests": 73951,
    "scheduler_time": 188.69018481040425
}
#Debug simulation 
Total elapsed time: 15.070961714256555. Arrivals time: 0.284661500249058 Scheduler time: 14.618841863702983 Scheduler overhead time: 0.057641482912003994 Adapter cache time: 0.026757257524877787 Engine time: 0.05716886604204774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 40.79797399882227,
    "estimated_duration": 3600.0473864665832,
    "input_throughput": 5380.520843369127,
    "output_throughput": 4711.371317989022,
    "total_throughput": 10091.892161358148,
    "itl": 111.72726345373017,
    "ttft": 2010475.7208342778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.127233284525567,
    "arrivals": 518548,
    "finished_requests": 78740,
    "scheduler_time": 178.70165257576355
}
#Debug simulation 
Total elapsed time: 40.79812689591199. Arrivals time: 0.35078889038413763 Scheduler time: 40.27991430461407 Scheduler overhead time: 0.06205181451514363 Adapter cache time: 0.019283614121377468 Engine time: 0.06072807731106877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 13.296106407884508,
    "estimated_duration": 3600.0580749012347,
    "input_throughput": 5060.724749697218,
    "output_throughput": 4435.021232383321,
    "total_throughput": 9495.74598208054,
    "itl": 99.08229154680377,
    "ttft": 2062085.8111058965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.295514549277597,
    "arrivals": 518548,
    "finished_requests": 73925,
    "scheduler_time": 188.77680651637542
}
#Debug simulation 
Total elapsed time: 13.296203006058931. Arrivals time: 0.27600462082773447 Scheduler time: 12.854254860430956 Scheduler overhead time: 0.05668844794854522 Adapter cache time: 0.026851657312363386 Engine time: 0.05673462199047208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 24.12237391481176,
    "estimated_duration": 3600.1177222801025,
    "input_throughput": 5371.682120370223,
    "output_throughput": 4703.296754772786,
    "total_throughput": 10074.97887514301,
    "itl": 111.60498105780758,
    "ttft": 2026368.1069403812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.331016827444548,
    "arrivals": 518548,
    "finished_requests": 78501,
    "scheduler_time": 178.72486341309346
}
#Debug simulation 
Total elapsed time: 24.122494590934366. Arrivals time: 0.31552293337881565 Scheduler time: 23.64562193537131 Scheduler overhead time: 0.05644082138314843 Adapter cache time: 0.0243003754876554 Engine time: 0.05621176119893789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 13.385123332031071,
    "estimated_duration": 3600.0024727273226,
    "input_throughput": 5059.087636182159,
    "output_throughput": 4440.296672321416,
    "total_throughput": 9499.384308503575,
    "itl": 99.29777375432522,
    "ttft": 2062306.6505136844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1485,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.96308743877325,
    "arrivals": 518548,
    "finished_requests": 73975,
    "scheduler_time": 188.60376174849145
}
#Debug simulation 
Total elapsed time: 13.385216753929853. Arrivals time: 0.3344607762992382 Scheduler time: 12.885604344308376 Scheduler overhead time: 0.05629404028877616 Adapter cache time: 0.026862250175327063 Engine time: 0.056212757248431444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 72.82964286813512,
    "estimated_duration": 3600.1052629447436,
    "input_throughput": 5565.548931647317,
    "output_throughput": 4841.6842639046845,
    "total_throughput": 10407.233195552,
    "itl": 119.5144056551029,
    "ttft": 1995917.1844665539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.377414779150932,
    "arrivals": 514751,
    "finished_requests": 81063,
    "scheduler_time": 173.5693256184627
}
#Debug simulation 
Total elapsed time: 72.82981489086524. Arrivals time: 0.3869314077310264 Scheduler time: 72.27497593592852 Scheduler overhead time: 0.06322333635762334 Adapter cache time: 0.018025684636086226 Engine time: 0.0614082645624876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 23.060559088829905,
    "estimated_duration": 3600.109364191752,
    "input_throughput": 5400.35260966713,
    "output_throughput": 4700.241378305728,
    "total_throughput": 10100.59398797286,
    "itl": 111.5306882676301,
    "ttft": 2023923.390874179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1041,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.621581043372874,
    "arrivals": 514751,
    "finished_requests": 78542,
    "scheduler_time": 178.7875605625018
}
#Debug simulation 
Total elapsed time: 23.06068011978641. Arrivals time: 0.3139261272735894 Scheduler time: 22.585398235358298 Scheduler overhead time: 0.058611161075532436 Adapter cache time: 0.02144896285608411 Engine time: 0.05663765175268054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 14.091771767940372,
    "estimated_duration": 3600.0027254742645,
    "input_throughput": 5101.2583601810065,
    "output_throughput": 4444.596912879305,
    "total_throughput": 9545.855273060311,
    "itl": 99.50306300347378,
    "ttft": 2059920.3574196794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.197571874675255,
    "arrivals": 514751,
    "finished_requests": 74272,
    "scheduler_time": 188.3768050334372
}
#Debug simulation 
Total elapsed time: 14.091873348224908. Arrivals time: 0.28465851955115795 Scheduler time: 13.644683103077114 Scheduler overhead time: 0.05621766531839967 Adapter cache time: 0.024255070369690657 Engine time: 0.056517322082072496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 44.779070732183754,
    "estimated_duration": 3600.036963456554,
    "input_throughput": 5404.04812436165,
    "output_throughput": 4709.7774750958115,
    "total_throughput": 10113.825599457461,
    "itl": 111.74204986431728,
    "ttft": 2008847.408424563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 764,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.2257590628974055,
    "arrivals": 514751,
    "finished_requests": 78628,
    "scheduler_time": 178.65143387394204
}
#Debug simulation 
Total elapsed time: 44.77922131307423. Arrivals time: 0.35701765259727836 Scheduler time: 44.25176385836676 Scheduler overhead time: 0.06346509838476777 Adapter cache time: 0.019202054478228092 Engine time: 0.062078320886939764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 17.06892479211092,
    "estimated_duration": 3600.0628023800964,
    "input_throughput": 5097.689959149326,
    "output_throughput": 4439.147836375077,
    "total_throughput": 9536.837795524401,
    "itl": 99.1876508323943,
    "ttft": 2058905.2425742599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.491632431005083,
    "arrivals": 514751,
    "finished_requests": 74171,
    "scheduler_time": 188.69529195569785
}
#Debug simulation 
Total elapsed time: 17.069021285045892. Arrivals time: 0.5825643022544682 Scheduler time: 16.318426905199885 Scheduler overhead time: 0.059009469114243984 Adapter cache time: 0.02439497783780098 Engine time: 0.058452803175896406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 27.067787159234285,
    "estimated_duration": 3600.039503858251,
    "input_throughput": 5409.83980290424,
    "output_throughput": 4709.066659360609,
    "total_throughput": 10118.90646226485,
    "itl": 111.89085007671224,
    "ttft": 2017089.7300447442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.466911912797918,
    "arrivals": 514751,
    "finished_requests": 78701,
    "scheduler_time": 178.52813786996498
}
#Debug simulation 
Total elapsed time: 27.06791258510202. Arrivals time: 0.3263458516448736 Scheduler time: 26.58015003055334 Scheduler overhead time: 0.057975202333182096 Adapter cache time: 0.02122762193903327 Engine time: 0.057630662340670824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 18.560460899956524,
    "estimated_duration": 3600.031319232137,
    "input_throughput": 5089.673776479303,
    "output_throughput": 4435.600022337009,
    "total_throughput": 9525.273798816314,
    "itl": 99.08118163587814,
    "ttft": 2062270.25365733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.272600790336647,
    "arrivals": 514751,
    "finished_requests": 74112,
    "scheduler_time": 188.77807385980466
}
#Debug simulation 
Total elapsed time: 18.560576433315873. Arrivals time: 0.3095197924412787 Scheduler time: 18.080578313674778 Scheduler overhead time: 0.05970913404598832 Adapter cache time: 0.02510126680135727 Engine time: 0.059249437879770994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 76.22579551907256,
    "estimated_duration": 3600.0712062989815,
    "input_throughput": 5596.653467505527,
    "output_throughput": 4845.612211635586,
    "total_throughput": 10442.265679141114,
    "itl": 119.5944471597477,
    "ttft": 1995323.873870335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.4832133236621345,
    "arrivals": 512803,
    "finished_requests": 81392,
    "scheduler_time": 173.50111603048367
}
#Debug simulation 
Total elapsed time: 76.2259610388428. Arrivals time: 0.38737137895077467 Scheduler time: 75.66700501926243 Scheduler overhead time: 0.06413639709353447 Adapter cache time: 0.01846949988976121 Engine time: 0.0632561007514596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 37.053316672798246,
    "estimated_duration": 3600.0281869734126,
    "input_throughput": 5430.74747879589,
    "output_throughput": 4706.218707205118,
    "total_throughput": 10136.96618600101,
    "itl": 111.56152085932719,
    "ttft": 2009514.1721095466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 746,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.444021519562237,
    "arrivals": 512803,
    "finished_requests": 78978,
    "scheduler_time": 178.831184895934
}
#Debug simulation 
Total elapsed time: 37.05341407097876. Arrivals time: 0.6255632592365146 Scheduler time: 36.26180378952995 Scheduler overhead time: 0.06166212912648916 Adapter cache time: 0.018426148686558008 Engine time: 0.06065818993374705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 15.193866804707795,
    "estimated_duration": 3600.0168128286487,
    "input_throughput": 5133.726024317784,
    "output_throughput": 4443.763413268661,
    "total_throughput": 9577.489437586444,
    "itl": 99.31474267048686,
    "ttft": 2056482.5565251003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.162154898988,
    "arrivals": 512803,
    "finished_requests": 74607,
    "scheduler_time": 188.47796597003153
}
#Debug simulation 
Total elapsed time: 15.193985254038125. Arrivals time: 0.3036528676748276 Scheduler time: 14.723141344729811 Scheduler overhead time: 0.059607008937746286 Adapter cache time: 0.024477477185428143 Engine time: 0.05728591373190284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 37.861408052966,
    "estimated_duration": 3600.090904667989,
    "input_throughput": 5433.187527192144,
    "output_throughput": 4708.289165149068,
    "total_throughput": 10141.476692341212,
    "itl": 111.63885335990938,
    "ttft": 2009053.7074104429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 764,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.260464587230229,
    "arrivals": 512803,
    "finished_requests": 79030,
    "scheduler_time": 178.75733500574097
}
#Debug simulation 
Total elapsed time: 37.861586729995906. Arrivals time: 0.35644049383699894 Scheduler time: 37.3378783846274 Scheduler overhead time: 0.06185238575562835 Adapter cache time: 0.01870703836902976 Engine time: 0.061049358919262886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 16.56219533830881,
    "estimated_duration": 3600.012160257113,
    "input_throughput": 5127.463791311656,
    "output_throughput": 4442.154161739793,
    "total_throughput": 9569.61795305145,
    "itl": 99.23528404434379,
    "ttft": 2054785.3733072097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.79784221888513,
    "arrivals": 512803,
    "finished_requests": 74503,
    "scheduler_time": 188.5814485149207
}
#Debug simulation 
Total elapsed time: 16.562290518078953. Arrivals time: 0.2912976061925292 Scheduler time: 16.10490190424025 Scheduler overhead time: 0.05793222691863775 Adapter cache time: 0.023916420992463827 Engine time: 0.05832198169082403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 37.350203718058765,
    "estimated_duration": 3600.0548128997175,
    "input_throughput": 5439.433846905008,
    "output_throughput": 4711.119658297393,
    "total_throughput": 10150.5535052024,
    "itl": 111.74478704662594,
    "ttft": 2009310.7075930329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 766,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.890083440477005,
    "arrivals": 512803,
    "finished_requests": 79088,
    "scheduler_time": 178.69360890786652
}
#Debug simulation 
Total elapsed time: 37.3503744979389. Arrivals time: 0.6429292322136462 Scheduler time: 36.54119120258838 Scheduler overhead time: 0.06148489424958825 Adapter cache time: 0.018971951212733984 Engine time: 0.06010476965457201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 14.353221311233938,
    "estimated_duration": 3600.0017678204576,
    "input_throughput": 5135.804700227607,
    "output_throughput": 4446.084205589274,
    "total_throughput": 9581.88890581688,
    "itl": 99.27851453415632,
    "ttft": 2055767.3821434395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.209990842416843,
    "arrivals": 512803,
    "finished_requests": 74597,
    "scheduler_time": 188.57056710521599
}
#Debug simulation 
Total elapsed time: 14.353327821940184. Arrivals time: 0.2835808345116675 Scheduler time: 13.908452581614256 Scheduler overhead time: 0.05626310268417001 Adapter cache time: 0.022669791243970394 Engine time: 0.056731642223894596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 43.44344873400405,
    "estimated_duration": 3600.001311841158,
    "input_throughput": 5533.713539068562,
    "output_throughput": 4840.436847254367,
    "total_throughput": 10374.150386322928,
    "itl": 119.01366214466921,
    "ttft": 2001113.1059854664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 815,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.389113361039305,
    "arrivals": 511802,
    "finished_requests": 80817,
    "scheduler_time": 173.7332203541067
}
#Debug simulation 
Total elapsed time: 43.443612137343735. Arrivals time: 0.35844437638297677 Scheduler time: 42.92521484801546 Scheduler overhead time: 0.058283957187086344 Adapter cache time: 0.019069043453782797 Engine time: 0.058399626053869724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 38.15135017270222,
    "estimated_duration": 3600.087591158954,
    "input_throughput": 5398.95697197269,
    "output_throughput": 4706.184105522207,
    "total_throughput": 10105.141077494896,
    "itl": 111.44041529585616,
    "ttft": 2013434.2509671773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 789,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.785164726725788,
    "arrivals": 511802,
    "finished_requests": 78714,
    "scheduler_time": 178.7789439926562
}
#Debug simulation 
Total elapsed time: 38.15152922505513. Arrivals time: 0.35561192128807306 Scheduler time: 37.629219769034535 Scheduler overhead time: 0.06146042235195637 Adapter cache time: 0.01916796388104558 Engine time: 0.060410572215914726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 15.937771650962532,
    "estimated_duration": 3600.0494168924597,
    "input_throughput": 5079.887768814561,
    "output_throughput": 4443.135676122808,
    "total_throughput": 9523.02344493737,
    "itl": 99.03279734924196,
    "ttft": 2057158.8901006903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.799525611777728,
    "arrivals": 511802,
    "finished_requests": 74166,
    "scheduler_time": 188.74785401345963
}
#Debug simulation 
Total elapsed time: 15.937867681030184. Arrivals time: 0.2904777326621115 Scheduler time: 15.483011531177908 Scheduler overhead time: 0.057523966766893864 Adapter cache time: 0.023892420809715986 Engine time: 0.05740928603336215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 37.81992951594293,
    "estimated_duration": 3600.0142553748487,
    "input_throughput": 5395.190858203316,
    "output_throughput": 4702.535823219195,
    "total_throughput": 10097.72668142251,
    "itl": 111.13008083493334,
    "ttft": 2013588.917007361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 756,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.208004998732353,
    "arrivals": 511802,
    "finished_requests": 78640,
    "scheduler_time": 179.02495944849304
}
#Debug simulation 
Total elapsed time: 37.82009846577421. Arrivals time: 0.3397907139733434 Scheduler time: 37.31275147385895 Scheduler overhead time: 0.061836299020797014 Adapter cache time: 0.01894995616748929 Engine time: 0.061277035623788834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 14.342614232096821,
    "estimated_duration": 3600.0653369579645,
    "input_throughput": 5071.97544793149,
    "output_throughput": 4435.232282059674,
    "total_throughput": 9507.207729991163,
    "itl": 98.85858617255127,
    "ttft": 2057729.8354598752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.751367275547162,
    "arrivals": 511802,
    "finished_requests": 74060,
    "scheduler_time": 188.8416897008234
}
#Debug simulation 
Total elapsed time: 14.342776288744062. Arrivals time: 0.28598306607455015 Scheduler time: 13.893491269554943 Scheduler overhead time: 0.056829416658729315 Adapter cache time: 0.023842372931540012 Engine time: 0.05698182247579098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 50.359424240887165,
    "estimated_duration": 3600.081495246024,
    "input_throughput": 4836.039412716188,
    "output_throughput": 4232.700570840454,
    "total_throughput": 9068.739983556641,
    "itl": 90.81603290257667,
    "ttft": 2066755.336842148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6447760149976237,
    "arrivals": 511802,
    "finished_requests": 70739,
    "scheduler_time": 197.87424717557934
}
#Debug simulation 
Total elapsed time: 50.359601692762226. Arrivals time: 0.3458455973304808 Scheduler time: 49.824872138444334 Scheduler overhead time: 0.07358045969158411 Adapter cache time: 0.013466034084558487 Engine time: 0.07169459853321314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 14.449471657164395,
    "estimated_duration": 3600.062981109293,
    "input_throughput": 4893.536888782883,
    "output_throughput": 4282.624520988051,
    "total_throughput": 9176.161409770933,
    "itl": 92.80649127146805,
    "ttft": 2062317.825107506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.691878178212681,
    "arrivals": 511802,
    "finished_requests": 71477,
    "scheduler_time": 195.4137443903029
}
#Debug simulation 
Total elapsed time: 14.449565189890563. Arrivals time: 0.2782367067411542 Scheduler time: 13.998642691411078 Scheduler overhead time: 0.05967105505988002 Adapter cache time: 0.026168460492044687 Engine time: 0.059910633601248264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 43.85985885094851,
    "estimated_duration": 3600.086974786022,
    "input_throughput": 5576.341666354662,
    "output_throughput": 4857.150152890215,
    "total_throughput": 10433.491819244877,
    "itl": 120.28890694666201,
    "ttft": 1982557.8303128406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.706508994572912,
    "arrivals": 507065,
    "finished_requests": 81621,
    "scheduler_time": 172.8113192788892
}
#Debug simulation 
Total elapsed time: 43.86001246701926. Arrivals time: 0.35254373075440526 Scheduler time: 43.34485350269824 Scheduler overhead time: 0.05963222635909915 Adapter cache time: 0.018926189746707678 Engine time: 0.05975649692118168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 24.955425397958606,
    "estimated_duration": 3600.0748512525333,
    "input_throughput": 5414.995744662791,
    "output_throughput": 4713.37366613262,
    "total_throughput": 10128.36941079541,
    "itl": 111.96866325158757,
    "ttft": 2011718.1650055756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.59335368036291,
    "arrivals": 507065,
    "finished_requests": 79131,
    "scheduler_time": 178.29368759458907
}
#Debug simulation 
Total elapsed time: 24.955578756053. Arrivals time: 0.32129031559452415 Scheduler time: 24.472846501972526 Scheduler overhead time: 0.05736827338114381 Adapter cache time: 0.02184291835874319 Engine time: 0.05771744064986706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 14.600829949136823,
    "estimated_duration": 3600.0217974358097,
    "input_throughput": 5123.292868153492,
    "output_throughput": 4465.614350293847,
    "total_throughput": 9588.907218447339,
    "itl": 99.74859088122552,
    "ttft": 2046348.2774012934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.304879496120758,
    "arrivals": 507065,
    "finished_requests": 74933,
    "scheduler_time": 188.15241382511155
}
#Debug simulation 
Total elapsed time: 14.600947396829724. Arrivals time: 0.2990872599184513 Scheduler time: 14.139264196157455 Scheduler overhead time: 0.05658769328147173 Adapter cache time: 0.02372696530073881 Engine time: 0.056656725239008665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 24.970456326380372,
    "estimated_duration": 3600.015617182446,
    "input_throughput": 5430.460886528213,
    "output_throughput": 4720.424244520375,
    "total_throughput": 10150.885131048588,
    "itl": 112.23388464524477,
    "ttft": 2011622.2478171452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.29649137909525,
    "arrivals": 507065,
    "finished_requests": 79355,
    "scheduler_time": 178.10351502864322
}
#Debug simulation 
Total elapsed time: 24.97058607917279. Arrivals time: 0.32527291821315885 Scheduler time: 24.483687435742468 Scheduler overhead time: 0.057485734578222036 Adapter cache time: 0.02214126056060195 Engine time: 0.057272166945040226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 14.513984190765768,
    "estimated_duration": 3600.035228188637,
    "input_throughput": 5123.325698476623,
    "output_throughput": 4465.7207446520015,
    "total_throughput": 9589.046443128625,
    "itl": 99.74628285199303,
    "ttft": 2046362.8338301098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.213126586880453,
    "arrivals": 507065,
    "finished_requests": 74935,
    "scheduler_time": 188.15787902408957
}
#Debug simulation 
Total elapsed time: 14.514127657748759. Arrivals time: 0.29841877752915025 Scheduler time: 14.053045737557113 Scheduler overhead time: 0.05636477982625365 Adapter cache time: 0.02392972819507122 Engine time: 0.056776552461087704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 25.005822370760143,
    "estimated_duration": 3600.0882380878434,
    "input_throughput": 5442.5454889425155,
    "output_throughput": 4726.006107293877,
    "total_throughput": 10168.551596236392,
    "itl": 112.37178374756795,
    "ttft": 2012007.50847762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.699008654328024,
    "arrivals": 507065,
    "finished_requests": 79526,
    "scheduler_time": 178.03390052604882
}
#Debug simulation 
Total elapsed time: 25.005923129618168. Arrivals time: 0.32983462139964104 Scheduler time: 24.515770636498928 Scheduler overhead time: 0.05679104942828417 Adapter cache time: 0.022214837837964296 Engine time: 0.0569567927159369 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 14.589345545973629,
    "estimated_duration": 3600.044073556382,
    "input_throughput": 5123.490885982101,
    "output_throughput": 4465.800048974931,
    "total_throughput": 9589.290934957031,
    "itl": 99.74248907874976,
    "ttft": 2046462.5221302374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.117024216931235,
    "arrivals": 507065,
    "finished_requests": 74938,
    "scheduler_time": 188.16339171761055
}
#Debug simulation 
Total elapsed time: 14.589507079683244. Arrivals time: 0.30177544988691807 Scheduler time: 14.124357874505222 Scheduler overhead time: 0.05654618889093399 Adapter cache time: 0.024028385989367962 Engine time: 0.05699702864512801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 47.90719538414851,
    "estimated_duration": 3600.0362089618447,
    "input_throughput": 5613.872424307663,
    "output_throughput": 4863.477194038846,
    "total_throughput": 10477.34961834651,
    "itl": 118.42312019050195,
    "ttft": 1998717.2422808437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1002,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.625633850013983,
    "arrivals": 505172,
    "finished_requests": 81465,
    "scheduler_time": 174.4870291593334
}
#Debug simulation 
Total elapsed time: 47.90736259985715. Arrivals time: 0.38523402716964483 Scheduler time: 47.35749091207981 Scheduler overhead time: 0.059829480946063995 Adapter cache time: 0.021101919934153557 Engine time: 0.059102490078657866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 27.345625197980553,
    "estimated_duration": 3600.011309766519,
    "input_throughput": 5428.462945930979,
    "output_throughput": 4712.648528068184,
    "total_throughput": 10141.111473999163,
    "itl": 110.7128191970126,
    "ttft": 2014026.294452174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.979921130775486,
    "arrivals": 505172,
    "finished_requests": 78868,
    "scheduler_time": 179.56972733983412
}
#Debug simulation 
Total elapsed time: 27.34575499407947. Arrivals time: 0.334982855245471 Scheduler time: 26.847484251484275 Scheduler overhead time: 0.058589219115674496 Adapter cache time: 0.021469241939485073 Engine time: 0.05840935045853257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 13.240022610872984,
    "estimated_duration": 3600.038966708415,
    "input_throughput": 5118.867092944049,
    "output_throughput": 4439.62972284531,
    "total_throughput": 9558.49681578936,
    "itl": 98.089673047358,
    "ttft": 2052583.549129557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.072077244082397,
    "arrivals": 505172,
    "finished_requests": 74312,
    "scheduler_time": 189.90480632963883
}
#Debug simulation 
Total elapsed time: 13.240142419934273. Arrivals time: 0.2748397686518729 Scheduler time: 12.802611824125051 Scheduler overhead time: 0.05588051490485668 Adapter cache time: 0.02397133456543088 Engine time: 0.05707659665495157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 27.12836569780484,
    "estimated_duration": 3600.0678114163447,
    "input_throughput": 5443.766902904462,
    "output_throughput": 4724.147124692348,
    "total_throughput": 10167.914027596811,
    "itl": 110.75935571465251,
    "ttft": 2015259.899551178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1092,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.495989195015271,
    "arrivals": 505172,
    "finished_requests": 79087,
    "scheduler_time": 179.6632003709595
}
#Debug simulation 
Total elapsed time: 27.128469966817647. Arrivals time: 0.32632655650377274 Scheduler time: 26.63843849953264 Scheduler overhead time: 0.058614215813577175 Adapter cache time: 0.021513089537620544 Engine time: 0.05862858984619379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 12.985086448024958,
    "estimated_duration": 3600.065624340008,
    "input_throughput": 5141.86765786904,
    "output_throughput": 4452.920494453178,
    "total_throughput": 9594.788152322219,
    "itl": 98.3748244681892,
    "ttft": 2050505.8351914398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1359,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.091676845149987,
    "arrivals": 505172,
    "finished_requests": 74595,
    "scheduler_time": 189.66885513771953
}
#Debug simulation 
Total elapsed time: 12.98522908007726. Arrivals time: 0.3410739512182772 Scheduler time: 12.482218113262206 Scheduler overhead time: 0.05594988400116563 Adapter cache time: 0.023832614067941904 Engine time: 0.05648733349516988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 27.7346325032413,
    "estimated_duration": 3600.0610044882183,
    "input_throughput": 5436.2962115366145,
    "output_throughput": 4715.577313505371,
    "total_throughput": 10151.873525041985,
    "itl": 110.66345282057574,
    "ttft": 2013855.217453081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1078,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.881866773935,
    "arrivals": 505172,
    "finished_requests": 78912,
    "scheduler_time": 179.63471038996482
}
#Debug simulation 
Total elapsed time: 27.73476407211274. Arrivals time: 0.36576025234535336 Scheduler time: 27.206456459593028 Scheduler overhead time: 0.058540355414152145 Adapter cache time: 0.02123386738821864 Engine time: 0.05812652641907334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 12.86578959506005,
    "estimated_duration": 3600.0655815456244,
    "input_throughput": 5141.237174922124,
    "output_throughput": 4456.743811070116,
    "total_throughput": 9597.98098599224,
    "itl": 98.55878948416043,
    "ttft": 2050585.512788975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.128257061671388,
    "arrivals": 505172,
    "finished_requests": 74617,
    "scheduler_time": 189.49360427879222
}
#Debug simulation 
Total elapsed time: 12.865896817296743. Arrivals time: 0.28928351774811745 Scheduler time: 12.414557326119393 Scheduler overhead time: 0.05590945528820157 Adapter cache time: 0.02411112328991294 Engine time: 0.056365275755524635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 336836409 . Total output tokens: 296818738
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 49.170614619739354,
    "estimated_duration": 3600.11109964404,
    "input_throughput": 5582.955482120346,
    "output_throughput": 4846.8526434435,
    "total_throughput": 10429.808125563844,
    "itl": 118.41467629890084,
    "ttft": 1969614.7842801807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5376388320932635,
    "arrivals": 504244,
    "finished_requests": 81284,
    "scheduler_time": 174.26931550891268
}
#Debug simulation 
Total elapsed time: 49.17078989977017. Arrivals time: 0.36609808215871453 Scheduler time: 48.64029260445386 Scheduler overhead time: 0.062239804305136204 Adapter cache time: 0.01600170787423849 Engine time: 0.06146159255877137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 336836409 . Total output tokens: 296818738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 25.06586557906121,
    "estimated_duration": 3600.028318840208,
    "input_throughput": 5452.2021110998985,
    "output_throughput": 4740.144379057991,
    "total_throughput": 10192.346490157888,
    "itl": 110.58308349319763,
    "ttft": 2008065.4668585476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 931,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.802739178151834,
    "arrivals": 504244,
    "finished_requests": 79522,
    "scheduler_time": 180.06830777382908
}
#Debug simulation 
Total elapsed time: 25.06596673792228. Arrivals time: 0.3237464823760092 Scheduler time: 24.581565514672548 Scheduler overhead time: 0.058546672109514475 Adapter cache time: 0.019932181108742952 Engine time: 0.05755017511546612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 336836409 . Total output tokens: 296818738
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 12.679565034806728,
    "estimated_duration": 3600.0101326217846,
    "input_throughput": 5123.205580137647,
    "output_throughput": 4463.797713896123,
    "total_throughput": 9587.003294033771,
    "itl": 98.74229161765543,
    "ttft": 2046794.715006392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.750267059802992,
    "arrivals": 504244,
    "finished_requests": 74808,
    "scheduler_time": 189.30652675936474
}
#Debug simulation 
Total elapsed time: 12.679709948133677. Arrivals time: 0.270385401789099 Scheduler time: 12.249277365393937 Scheduler overhead time: 0.055382213555276394 Adapter cache time: 0.022397037129849195 Engine time: 0.05673293396830559 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 336836409 . Total output tokens: 296818738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 24.65133464615792,
    "estimated_duration": 3600.0840270645103,
    "input_throughput": 5443.601552816987,
    "output_throughput": 4735.303085106164,
    "total_throughput": 10178.904637923151,
    "itl": 110.59593774416231,
    "ttft": 2007740.5968377453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 936,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.444568689353757,
    "arrivals": 504244,
    "finished_requests": 79444,
    "scheduler_time": 180.02271212889002
}
#Debug simulation 
Total elapsed time: 24.65143436891958. Arrivals time: 0.3197067668661475 Scheduler time: 24.171451052185148 Scheduler overhead time: 0.05850417725741863 Adapter cache time: 0.019842085428535938 Engine time: 0.057110187597572803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 336836409 . Total output tokens: 296818738
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 13.018852595705539,
    "estimated_duration": 3600.057600533031,
    "input_throughput": 5122.208599459549,
    "output_throughput": 4456.975354401078,
    "total_throughput": 9579.183953860627,
    "itl": 98.5710049326625,
    "ttft": 2048235.4201834674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.568959316266692,
    "arrivals": 504244,
    "finished_requests": 74751,
    "scheduler_time": 189.4392265652647
}
#Debug simulation 
Total elapsed time: 13.018968835938722. Arrivals time: 0.2915847082622349 Scheduler time: 12.568555479403585 Scheduler overhead time: 0.055977095384150743 Adapter cache time: 0.021956257987767458 Engine time: 0.05564270354807377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 336836409 . Total output tokens: 296818738
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 24.747478636913,
    "estimated_duration": 3600.031991048818,
    "input_throughput": 5443.39857221404,
    "output_throughput": 4734.404872617388,
    "total_throughput": 10177.803444831427,
    "itl": 110.51240779080098,
    "ttft": 2007656.6095377991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 930,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.9370464747305665,
    "arrivals": 504244,
    "finished_requests": 79444,
    "scheduler_time": 180.10430052872508
}
#Debug simulation 
Total elapsed time: 24.74758016085252. Arrivals time: 0.3188135242089629 Scheduler time: 24.269539271481335 Scheduler overhead time: 0.05718424171209335 Adapter cache time: 0.019627952948212624 Engine time: 0.05754869570955634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 336836409 . Total output tokens: 296818738
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 15.294052871875465,
    "estimated_duration": 3600.0106211551147,
    "input_throughput": 5135.335126891403,
    "output_throughput": 4471.9293063736595,
    "total_throughput": 9607.264433265063,
    "itl": 98.06340958977898,
    "ttft": 2049864.2094356678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.383089070301502,
    "arrivals": 504244,
    "finished_requests": 74975,
    "scheduler_time": 190.34477262745455
}
#Debug simulation 
Total elapsed time: 15.294204836711287. Arrivals time: 0.31130585679784417 Scheduler time: 14.8186483993195 Scheduler overhead time: 0.057840559631586075 Adapter cache time: 0.02269759774208069 Engine time: 0.05774253001436591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 334925773 . Total output tokens: 295114829
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 41.95176692912355,
    "estimated_duration": 3600.0080221273206,
    "input_throughput": 5587.663937513464,
    "output_throughput": 4895.9665899812935,
    "total_throughput": 10483.630527494757,
    "itl": 118.58550855777672,
    "ttft": 1973700.7924300511,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.603762922412765,
    "arrivals": 501368,
    "finished_requests": 81739,
    "scheduler_time": 174.9090766497025
}
#Debug simulation 
Total elapsed time: 41.951942465268075. Arrivals time: 0.38300589146092534 Scheduler time: 41.40667925728485 Scheduler overhead time: 0.061062514781951904 Adapter cache time: 0.01612637424841523 Engine time: 0.0603055153042078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 334925773 . Total output tokens: 295114829
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 28.06610561721027,
    "estimated_duration": 3600.102469191295,
    "input_throughput": 5455.34972075719,
    "output_throughput": 4790.288373062318,
    "total_throughput": 10245.638093819507,
    "itl": 110.15377626045749,
    "ttft": 2008195.841896662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 855,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.262032347735959,
    "arrivals": 501368,
    "finished_requests": 79787,
    "scheduler_time": 181.37856976260812
}
#Debug simulation 
Total elapsed time: 28.066228301264346. Arrivals time: 0.35364247439429164 Scheduler time: 27.55038810428232 Scheduler overhead time: 0.05948863597586751 Adapter cache time: 0.019112663809210062 Engine time: 0.058643536642193794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 334925773 . Total output tokens: 295114829
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 16.49406348960474,
    "estimated_duration": 3600.0425013460735,
    "input_throughput": 5151.854455347465,
    "output_throughput": 4527.246829421039,
    "total_throughput": 9679.101284768503,
    "itl": 97.92698738499611,
    "ttft": 2039479.661825084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 978,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.360125745148419,
    "arrivals": 501368,
    "finished_requests": 75409,
    "scheduler_time": 191.5298322832066
}
#Debug simulation 
Total elapsed time: 16.49417417962104. Arrivals time: 0.33426244044676423 Scheduler time: 15.995308403391391 Scheduler overhead time: 0.0590336280874908 Adapter cache time: 0.02032067347317934 Engine time: 0.05900153610855341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 334925773 . Total output tokens: 295114829
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 28.14620619500056,
    "estimated_duration": 3600.0659102403833,
    "input_throughput": 5465.570211931527,
    "output_throughput": 4794.753882394176,
    "total_throughput": 10260.324094325704,
    "itl": 109.94762782366347,
    "ttft": 2009790.9035526703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 883,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.056244924464255,
    "arrivals": 501368,
    "finished_requests": 79965,
    "scheduler_time": 181.6130970575584
}
#Debug simulation 
Total elapsed time: 28.14636190980673. Arrivals time: 0.35563084203749895 Scheduler time: 27.626754426397383 Scheduler overhead time: 0.05989876855164766 Adapter cache time: 0.0196144450455904 Engine time: 0.05921866372227669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 334925773 . Total output tokens: 295114829
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 15.499548907857388,
    "estimated_duration": 3600.066237529927,
    "input_throughput": 5154.233221200767,
    "output_throughput": 4533.356311576567,
    "total_throughput": 9687.589532777334,
    "itl": 97.82648153378508,
    "ttft": 2040567.1914101162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1053,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.8464258639794044,
    "arrivals": 501368,
    "finished_requests": 75478,
    "scheduler_time": 191.70490919548357
}
#Debug simulation 
Total elapsed time: 15.499652511905879. Arrivals time: 0.3191015780903399 Scheduler time: 15.016363690141588 Scheduler overhead time: 0.05825318302959204 Adapter cache time: 0.02105414541438222 Engine time: 0.058880367781966925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 334925773 . Total output tokens: 295114829
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 28.379063387401402,
    "estimated_duration": 3600.0363172514344,
    "input_throughput": 5448.356702961032,
    "output_throughput": 4787.904199022045,
    "total_throughput": 10236.260901983076,
    "itl": 110.0777476456836,
    "ttft": 2008734.5996583735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 882,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.630618269583183,
    "arrivals": 501368,
    "finished_requests": 79756,
    "scheduler_time": 181.45936101564214
}
#Debug simulation 
Total elapsed time: 28.37922928109765. Arrivals time: 0.3260811949148774 Scheduler time: 27.890973197296262 Scheduler overhead time: 0.0589805799536407 Adapter cache time: 0.01977214263752103 Engine time: 0.05849629454314709 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 334925773 . Total output tokens: 295114829
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 16.803145807702094,
    "estimated_duration": 3600.079912618437,
    "input_throughput": 5132.419681917861,
    "output_throughput": 4517.513053806402,
    "total_throughput": 9649.932735724264,
    "itl": 98.21886693548045,
    "ttft": 2037969.5253772703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 917,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.777339581046281,
    "arrivals": 501368,
    "finished_requests": 75215,
    "scheduler_time": 190.96053390874465
}
#Debug simulation 
Total elapsed time: 16.803258234634995. Arrivals time: 0.3251409940421581 Scheduler time: 16.314578196499497 Scheduler overhead time: 0.0586011647246778 Adapter cache time: 0.019424263387918472 Engine time: 0.059319926891475916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334312807 . Total output tokens: 294563923
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 61.11015476612374,
    "estimated_duration": 3600.092074011737,
    "input_throughput": 5711.405591104047,
    "output_throughput": 4983.982251322137,
    "total_throughput": 10695.387842426184,
    "itl": 116.1155876571263,
    "ttft": 2014879.4932001864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.119530826904876,
    "arrivals": 500381,
    "finished_requests": 83088,
    "scheduler_time": 178.57619973530336
}
#Debug simulation 
Total elapsed time: 61.110313727054745. Arrivals time: 0.3848095750436187 Scheduler time: 60.5571229448542 Scheduler overhead time: 0.06300569558516145 Adapter cache time: 0.017884761095046997 Engine time: 0.061658937484025955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334312807 . Total output tokens: 294563923
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 51.56241295207292,
    "estimated_duration": 3600.020605897186,
    "input_throughput": 5463.521227567586,
    "output_throughput": 4750.964195033406,
    "total_throughput": 10214.485422600992,
    "itl": 110.56812745812657,
    "ttft": 1981595.875862841,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4742796598281744,
    "arrivals": 500381,
    "finished_requests": 79350,
    "scheduler_time": 180.42367234881223
}
#Debug simulation 
Total elapsed time: 51.562580570112914. Arrivals time: 0.3535028141923249 Scheduler time: 51.03854513820261 Scheduler overhead time: 0.06572707230225205 Adapter cache time: 0.014446733053773642 Engine time: 0.06397003680467606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334312807 . Total output tokens: 294563923
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 16.262109991163015,
    "estimated_duration": 3600.060304698487,
    "input_throughput": 5193.67077701382,
    "output_throughput": 4540.630605177893,
    "total_throughput": 9734.301382191712,
    "itl": 96.93879799369674,
    "ttft": 2041781.6613079044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 808,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.052127914619655,
    "arrivals": 500381,
    "finished_requests": 75581,
    "scheduler_time": 193.12635920994674
}
#Debug simulation 
Total elapsed time: 16.26222274499014. Arrivals time: 0.29814420687034726 Scheduler time: 15.800200137775391 Scheduler overhead time: 0.05922461440786719 Adapter cache time: 0.018792442977428436 Engine time: 0.05961804278194904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334312807 . Total output tokens: 294563923
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 50.35886087408289,
    "estimated_duration": 3600.1070778442627,
    "input_throughput": 5465.300496501274,
    "output_throughput": 4753.770826796596,
    "total_throughput": 10219.07132329787,
    "itl": 110.77720953387752,
    "ttft": 1980452.2328773905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1913943451270437,
    "arrivals": 500381,
    "finished_requests": 79366,
    "scheduler_time": 180.28409640991552
}
#Debug simulation 
Total elapsed time: 50.35903672687709. Arrivals time: 0.35041511664167047 Scheduler time: 49.838976251892745 Scheduler overhead time: 0.06578626437112689 Adapter cache time: 0.014161833561956882 Engine time: 0.0636076950468123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334312807 . Total output tokens: 294563923
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 16.75407457910478,
    "estimated_duration": 3600.0962086921627,
    "input_throughput": 5180.8318219294715,
    "output_throughput": 4532.384984768955,
    "total_throughput": 9713.216806698427,
    "itl": 96.82717976649772,
    "ttft": 2040893.2097580014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 788,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.845714247552703,
    "arrivals": 500381,
    "finished_requests": 75437,
    "scheduler_time": 193.15237060919966
}
#Debug simulation 
Total elapsed time: 16.754143923986703. Arrivals time: 0.2934490037150681 Scheduler time: 16.297191625460982 Scheduler overhead time: 0.05908541567623615 Adapter cache time: 0.018300931435078382 Engine time: 0.0597771517932415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334312807 . Total output tokens: 294563923
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 51.48955057607964,
    "estimated_duration": 3600.1065927724644,
    "input_throughput": 5466.23481635444,
    "output_throughput": 4753.148152433471,
    "total_throughput": 10219.382968787912,
    "itl": 110.72333200585915,
    "ttft": 1980646.7615805273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1386135150911203,
    "arrivals": 500381,
    "finished_requests": 79345,
    "scheduler_time": 180.32691797622698
}
#Debug simulation 
Total elapsed time: 51.48973507899791. Arrivals time: 0.38316256646066904 Scheduler time: 50.93834122689441 Scheduler overhead time: 0.06454294780269265 Adapter cache time: 0.014026741031557322 Engine time: 0.06361371092498302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334312807 . Total output tokens: 294563923
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 16.191561146173626,
    "estimated_duration": 3600.06258740647,
    "input_throughput": 5181.314643042885,
    "output_throughput": 4530.8978952366,
    "total_throughput": 9712.212538279484,
    "itl": 96.73502413651858,
    "ttft": 2041828.6541274209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 801,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.887066000457876,
    "arrivals": 500381,
    "finished_requests": 75424,
    "scheduler_time": 193.2709075313246
}
#Debug simulation 
Total elapsed time: 16.191714980173856. Arrivals time: 0.29232165729627013 Scheduler time: 15.736211022362113 Scheduler overhead time: 0.05899416981264949 Adapter cache time: 0.018471930641680956 Engine time: 0.0591675853356719 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 332981610 . Total output tokens: 293421440
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 84.72663121530786,
    "estimated_duration": 3600.006541713392,
    "input_throughput": 5670.7496954391045,
    "output_throughput": 4935.767975450149,
    "total_throughput": 10606.517670889252,
    "itl": 117.08879428016279,
    "ttft": 1984594.7779846478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7522883934667313,
    "arrivals": 498436,
    "finished_requests": 82635,
    "scheduler_time": 176.9530414724349
}
#Debug simulation 
Total elapsed time: 84.72679244726896. Arrivals time: 0.38963309908285737 Scheduler time: 84.16515423823148 Scheduler overhead time: 0.06638753274455667 Adapter cache time: 0.014348726719617844 Engine time: 0.06512184580788016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 332981610 . Total output tokens: 293421440
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 25.70887571806088,
    "estimated_duration": 3600.0629188179114,
    "input_throughput": 5565.08412541257,
    "output_throughput": 4852.088808974372,
    "total_throughput": 10417.172934386941,
    "itl": 108.22456001744892,
    "ttft": 2003920.1482091711,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 551,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.033958640326752,
    "arrivals": 498436,
    "finished_requests": 81217,
    "scheduler_time": 184.1307861027271
}
#Debug simulation 
Total elapsed time: 25.709033572115004. Arrivals time: 0.3241986585780978 Scheduler time: 25.226313002873212 Scheduler overhead time: 0.059330195654183626 Adapter cache time: 0.015452697407454252 Engine time: 0.058512983843684196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 332981610 . Total output tokens: 293421440
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 14.38716177130118,
    "estimated_duration": 3600.055908070303,
    "input_throughput": 5204.933056176882,
    "output_throughput": 4537.050650625904,
    "total_throughput": 9741.983706802786,
    "itl": 96.77947846000959,
    "ttft": 2034930.7754079804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.076652968209265,
    "arrivals": 498436,
    "finished_requests": 75944,
    "scheduler_time": 192.96832682764128
}
#Debug simulation 
Total elapsed time: 14.387279433198273. Arrivals time: 0.2985954466275871 Scheduler time: 13.93183370353654 Scheduler overhead time: 0.057130332104861736 Adapter cache time: 0.01651499792933464 Engine time: 0.057158918119966984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 332981610 . Total output tokens: 293421440
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 25.447651472873986,
    "estimated_duration": 3600.0006255246403,
    "input_throughput": 5559.678478412256,
    "output_throughput": 4837.635270538872,
    "total_throughput": 10397.313748951126,
    "itl": 108.18848820449809,
    "ttft": 2002091.0255732075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.72190172981936,
    "arrivals": 498436,
    "finished_requests": 81030,
    "scheduler_time": 183.9694532029734
}
#Debug simulation 
Total elapsed time: 25.447754693217576. Arrivals time: 0.6052218219265342 Scheduler time: 24.68555846437812 Scheduler overhead time: 0.05839755479246378 Adapter cache time: 0.015429585240781307 Engine time: 0.05812347633764148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 332981610 . Total output tokens: 293421440
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 14.316351366229355,
    "estimated_duration": 3600.0146245959536,
    "input_throughput": 5192.400573122108,
    "output_throughput": 4530.326596056665,
    "total_throughput": 9722.727169178774,
    "itl": 96.57862267127008,
    "ttft": 2036467.257656601,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 685,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.0970403621020095,
    "arrivals": 498436,
    "finished_requests": 75827,
    "scheduler_time": 193.10102687182675
}
#Debug simulation 
Total elapsed time: 14.316453524399549. Arrivals time: 0.28951111482456326 Scheduler time: 13.870158655103296 Scheduler overhead time: 0.0568178272806108 Adapter cache time: 0.016494259238243103 Engine time: 0.05747964000329375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 332981610 . Total output tokens: 293421440
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 25.277622968889773,
    "estimated_duration": 3600.046501176961,
    "input_throughput": 5576.229360769922,
    "output_throughput": 4847.88737986974,
    "total_throughput": 10424.116740639662,
    "itl": 108.30282618061808,
    "ttft": 2001687.9099379373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.453701228848643,
    "arrivals": 498436,
    "finished_requests": 81268,
    "scheduler_time": 183.97365816676972
}
#Debug simulation 
Total elapsed time: 25.277785879094154. Arrivals time: 0.32395560340955853 Scheduler time: 24.795929128304124 Scheduler overhead time: 0.0584176373668015 Adapter cache time: 0.015402410179376602 Engine time: 0.059045452158898115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 332981610 . Total output tokens: 293421440
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 12.070221171714365,
    "estimated_duration": 3600.009053825171,
    "input_throughput": 5207.233292950039,
    "output_throughput": 4545.854122953199,
    "total_throughput": 9753.08741590324,
    "itl": 96.81026339685471,
    "ttft": 2038085.7345855073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 895,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.599717477057151,
    "arrivals": 498436,
    "finished_requests": 76029,
    "scheduler_time": 193.01499161546337
}
#Debug simulation 
Total elapsed time: 12.070288602728397. Arrivals time: 0.2826808341778815 Scheduler time: 11.63184561394155 Scheduler overhead time: 0.05591252073645592 Adapter cache time: 0.01805106597021222 Engine time: 0.05606054328382015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_256_slots_64_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_256_slots_64_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267683845 . Total output tokens: 236075847
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 60.323425131849945,
    "estimated_duration": 3600.0635632070166,
    "input_throughput": 5569.191945638734,
    "output_throughput": 4857.362847344383,
    "total_throughput": 10426.554792983117,
    "itl": 118.98887095871392,
    "ttft": 1925709.561459249,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 538,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.557476059189114,
    "arrivals": 401058,
    "finished_requests": 81513,
    "scheduler_time": 172.80614699591425
}
#Debug simulation 
Total elapsed time: 60.3235955350101. Arrivals time: 0.40346375945955515 Scheduler time: 59.75480032712221 Scheduler overhead time: 0.06210806220769882 Adapter cache time: 0.017259931657463312 Engine time: 0.06078722421079874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_256_slots_64_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_256_slots_64_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267683845 . Total output tokens: 236075847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 52.08886006614193,
    "estimated_duration": 3600.082822196731,
    "input_throughput": 5413.183518958237,
    "output_throughput": 4716.957314231486,
    "total_throughput": 10130.140833189724,
    "itl": 111.09290401610814,
    "ttft": 1951274.0132097597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 544,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.972612542063003,
    "arrivals": 401058,
    "finished_requests": 79033,
    "scheduler_time": 178.1131697399028
}
#Debug simulation 
Total elapsed time: 52.08911174722016. Arrivals time: 0.3797874148003757 Scheduler time: 51.54007667256519 Scheduler overhead time: 0.06361751444637775 Adapter cache time: 0.017593463882803917 Engine time: 0.062029910273849964 
