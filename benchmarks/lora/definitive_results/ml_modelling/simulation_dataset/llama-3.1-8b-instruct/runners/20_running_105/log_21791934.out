INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43064457 . Total output tokens: 37937465
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.502705000923015,
    "estimated_duration": 3599.9966698724343,
    "input_throughput": 4457.486901111112,
    "output_throughput": 3876.2383078800112,
    "total_throughput": 8333.725208991124,
    "itl": 35.79548824955815,
    "ttft": 7277.778467528681,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 64833,
    "finished_requests": 64703,
    "scheduler_time": 38.521295233917364
}
#Debug simulation 
Total elapsed time: 4.5028440149035305. Arrivals time: 0.15063184255268425 Scheduler time: 4.080471078050323 Scheduler overhead time: 0.10236400703433901 Adapter cache time: 0.019567634677514434 Engine time: 0.10206974775064737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43064457 . Total output tokens: 37937465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.494043854065239,
    "estimated_duration": 3599.9988752136464,
    "input_throughput": 4457.484170477046,
    "output_throughput": 3876.2359333159116,
    "total_throughput": 8333.720103792957,
    "itl": 35.795757071494755,
    "ttft": 7277.809234442926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 64833,
    "finished_requests": 64703,
    "scheduler_time": 38.5214083246429
}
#Debug simulation 
Total elapsed time: 4.494194281054661. Arrivals time: 0.14906075375620276 Scheduler time: 4.076096141710877 Scheduler overhead time: 0.10194085410330445 Adapter cache time: 0.01954242365900427 Engine time: 0.09978411416523159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43064457 . Total output tokens: 37937465
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.486292777000926,
    "estimated_duration": 3600.0112454424625,
    "input_throughput": 4457.468853830687,
    "output_throughput": 3876.222613933784,
    "total_throughput": 8333.691467764473,
    "itl": 35.7959768731113,
    "ttft": 7277.820129984632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 64833,
    "finished_requests": 64703,
    "scheduler_time": 38.521590259054754
}
#Debug simulation 
Total elapsed time: 4.486393571016379. Arrivals time: 0.14902803918812424 Scheduler time: 4.068557923543267 Scheduler overhead time: 0.10186126234475523 Adapter cache time: 0.019600238068960607 Engine time: 0.09974741307087243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43064457 . Total output tokens: 37937465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.571421166998334,
    "estimated_duration": 3600.011900640354,
    "input_throughput": 4457.468042576649,
    "output_throughput": 3876.221908465871,
    "total_throughput": 8333.689951042521,
    "itl": 35.79564079749071,
    "ttft": 7277.820868715724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 64833,
    "finished_requests": 64703,
    "scheduler_time": 38.52145673941439
}
#Debug simulation 
Total elapsed time: 4.571540449047461. Arrivals time: 0.1526217043865472 Scheduler time: 4.149400161579251 Scheduler overhead time: 0.10224950849078596 Adapter cache time: 0.019511338090524077 Engine time: 0.09985759784467518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43064457 . Total output tokens: 37937465
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.499213794013485,
    "estimated_duration": 3600.0080907337315,
    "input_throughput": 4457.47275993744,
    "output_throughput": 3876.2260106909625,
    "total_throughput": 8333.698770628402,
    "itl": 35.79594328787212,
    "ttft": 7277.876965009002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 64833,
    "finished_requests": 64703,
    "scheduler_time": 38.52156182247376
}
#Debug simulation 
Total elapsed time: 4.499323731986806. Arrivals time: 0.15228750242386013 Scheduler time: 4.077123801922426 Scheduler overhead time: 0.10184195963665843 Adapter cache time: 0.019517587264999747 Engine time: 0.10072943975683302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43064457 . Total output tokens: 37937465
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.475891876034439,
    "estimated_duration": 3599.9864471488845,
    "input_throughput": 4457.499558841075,
    "output_throughput": 3876.2493150638484,
    "total_throughput": 8333.748873904922,
    "itl": 35.79559241733337,
    "ttft": 7277.793786143461,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 64833,
    "finished_requests": 64703,
    "scheduler_time": 38.52117293276569
}
#Debug simulation 
Total elapsed time: 4.4759977160720155. Arrivals time: 0.1507783675333485 Scheduler time: 4.058318384224549 Scheduler overhead time: 0.10096716962289065 Adapter cache time: 0.01939057162962854 Engine time: 0.09926987218204886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43064457 . Total output tokens: 37937465
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.486720155924559,
    "estimated_duration": 3600.0050999420237,
    "input_throughput": 4457.4764630912405,
    "output_throughput": 3876.2292309599034,
    "total_throughput": 8333.705694051145,
    "itl": 35.79589975163805,
    "ttft": 7277.774215608095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 64833,
    "finished_requests": 64703,
    "scheduler_time": 38.52152550115121
}
#Debug simulation 
Total elapsed time: 4.486887171980925. Arrivals time: 0.15091942332219332 Scheduler time: 4.066743632196449 Scheduler overhead time: 0.10138314857613295 Adapter cache time: 0.019527851254679263 Engine time: 0.10058501362800598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42813064 . Total output tokens: 37694590
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.518033114960417,
    "estimated_duration": 3600.026350137985,
    "input_throughput": 4431.522285771191,
    "output_throughput": 3833.168887630803,
    "total_throughput": 8264.691173401994,
    "itl": 35.13182636818027,
    "ttft": 9500.504107743918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 64433,
    "finished_requests": 64264,
    "scheduler_time": 37.581155256709984
}
#Debug simulation 
Total elapsed time: 4.51813757896889. Arrivals time: 0.1517690101172775 Scheduler time: 4.093561899848282 Scheduler overhead time: 0.10343560541514307 Adapter cache time: 0.01871510106138885 Engine time: 0.10224693058989942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42813064 . Total output tokens: 37694590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.485941639984958,
    "estimated_duration": 3600.025446253622,
    "input_throughput": 4431.523398425465,
    "output_throughput": 3833.1698500521725,
    "total_throughput": 8264.693248477637,
    "itl": 35.132178716879125,
    "ttft": 9500.474531119422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113994,
    "arrivals": 64433,
    "finished_requests": 64264,
    "scheduler_time": 37.58126292147989
}
#Debug simulation 
Total elapsed time: 4.48604730097577. Arrivals time: 0.1516080693108961 Scheduler time: 4.060857408330776 Scheduler overhead time: 0.10469608451239765 Adapter cache time: 0.018633188563399017 Engine time: 0.10193766164593399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42813064 . Total output tokens: 37694590
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.478934142040089,
    "estimated_duration": 3600.0009873194217,
    "input_throughput": 4431.499062415252,
    "output_throughput": 3833.0922820870956,
    "total_throughput": 8264.591344502349,
    "itl": 35.132157311193055,
    "ttft": 9556.504913050609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2413462840113789,
    "arrivals": 64433,
    "finished_requests": 64262,
    "scheduler_time": 37.581081575204834
}
#Debug simulation 
Total elapsed time: 4.479038993013091. Arrivals time: 0.1518231708323583 Scheduler time: 4.0546606162097305 Scheduler overhead time: 0.10365554969757795 Adapter cache time: 0.018609967781230807 Engine time: 0.1017913306131959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42813064 . Total output tokens: 37694590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.536645168089308,
    "estimated_duration": 3600.0021776252192,
    "input_throughput": 4431.497597183076,
    "output_throughput": 3833.0910147123163,
    "total_throughput": 8264.588611895393,
    "itl": 35.13183821494464,
    "ttft": 9556.465919379101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 64433,
    "finished_requests": 64262,
    "scheduler_time": 37.580951471261294
}
#Debug simulation 
Total elapsed time: 4.536756628076546. Arrivals time: 0.15293839201331139 Scheduler time: 4.1123618358979 Scheduler overhead time: 0.10264502395875752 Adapter cache time: 0.018682328169234097 Engine time: 0.1017930549569428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42813064 . Total output tokens: 37694590
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.538333437987603,
    "estimated_duration": 3600.0387468226677,
    "input_throughput": 4431.5070258842,
    "output_throughput": 3833.155688165637,
    "total_throughput": 8264.662714049837,
    "itl": 35.1322305682952,
    "ttft": 9500.464235418964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861717,
    "arrivals": 64433,
    "finished_requests": 64264,
    "scheduler_time": 37.58151837349833
}
#Debug simulation 
Total elapsed time: 4.5384741249727085. Arrivals time: 0.1528248287504539 Scheduler time: 4.114636341459118 Scheduler overhead time: 0.10263779340311885 Adapter cache time: 0.01866147352848202 Engine time: 0.10163901757914573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42813064 . Total output tokens: 37694590
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.54317010496743,
    "estimated_duration": 3600.0128394483336,
    "input_throughput": 4431.538917079177,
    "output_throughput": 3833.183273344836,
    "total_throughput": 8264.722190424012,
    "itl": 35.13186744273218,
    "ttft": 9444.758371461698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 64433,
    "finished_requests": 64264,
    "scheduler_time": 37.580953139232655
}
#Debug simulation 
Total elapsed time: 4.543278404977173. Arrivals time: 0.15266047848854214 Scheduler time: 4.117824172368273 Scheduler overhead time: 0.10315484239254147 Adapter cache time: 0.018698959494940937 Engine time: 0.10231287183705717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42813064 . Total output tokens: 37694590
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.523249784018844,
    "estimated_duration": 3600.0312568474396,
    "input_throughput": 4431.516245770216,
    "output_throughput": 3833.1636631633805,
    "total_throughput": 8264.679908933596,
    "itl": 35.132277864237516,
    "ttft": 9500.550007678134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585545,
    "arrivals": 64433,
    "finished_requests": 64264,
    "scheduler_time": 37.58136879755032
}
#Debug simulation 
Total elapsed time: 4.52343187702354. Arrivals time: 0.1525933783268556 Scheduler time: 4.098888799431734 Scheduler overhead time: 0.10295074747409672 Adapter cache time: 0.01866986753884703 Engine time: 0.10186212952248752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42735553 . Total output tokens: 37628459
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.517334094969556,
    "estimated_duration": 3600.0150359635813,
    "input_throughput": 4407.576868842977,
    "output_throughput": 3856.6550031877296,
    "total_throughput": 8264.231872030707,
    "itl": 35.19507056593132,
    "ttft": 8842.791712798899,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 64340,
    "finished_requests": 64182,
    "scheduler_time": 37.922587759762116
}
#Debug simulation 
Total elapsed time: 4.517443487071432. Arrivals time: 0.15199637261684984 Scheduler time: 4.094505911227316 Scheduler overhead time: 0.1031077754450962 Adapter cache time: 0.017999019124545157 Engine time: 0.1014368002070114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42735553 . Total output tokens: 37628459
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.554956797044724,
    "estimated_duration": 3600.0147744220776,
    "input_throughput": 4407.577189053964,
    "output_throughput": 3856.6552833741766,
    "total_throughput": 8264.23247242814,
    "itl": 35.19539884944846,
    "ttft": 8842.795163724764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 64340,
    "finished_requests": 64182,
    "scheduler_time": 37.9227204044415
}
#Debug simulation 
Total elapsed time: 4.55506752000656. Arrivals time: 0.1522403514245525 Scheduler time: 4.132262255996466 Scheduler overhead time: 0.10274244879838079 Adapter cache time: 0.01811415026895702 Engine time: 0.10138743207789958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42735553 . Total output tokens: 37628459
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.544299598084763,
    "estimated_duration": 3600.0243353999854,
    "input_throughput": 4407.565483369723,
    "output_throughput": 3856.645040833425,
    "total_throughput": 8264.210524203147,
    "itl": 35.19542540775905,
    "ttft": 8842.882139725467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 64340,
    "finished_requests": 64182,
    "scheduler_time": 37.922866017530595
}
#Debug simulation 
Total elapsed time: 4.5444077220745385. Arrivals time: 0.15169197309296578 Scheduler time: 4.120516638853587 Scheduler overhead time: 0.10345177061390132 Adapter cache time: 0.017992008361034095 Engine time: 0.10238104173913598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42735553 . Total output tokens: 37628459
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.587498264038004,
    "estimated_duration": 3600.0268379375934,
    "input_throughput": 4407.562419476347,
    "output_throughput": 3856.6423599091736,
    "total_throughput": 8264.20477938552,
    "itl": 35.19517094972165,
    "ttft": 8842.817612294955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 64340,
    "finished_requests": 64182,
    "scheduler_time": 37.92273662464814
}
#Debug simulation 
Total elapsed time: 4.587610127986409. Arrivals time: 0.1527163628488779 Scheduler time: 4.159810588578694 Scheduler overhead time: 0.10464984143618494 Adapter cache time: 0.0181569152045995 Engine time: 0.10324631596449763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42735553 . Total output tokens: 37628459
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.553995591937564,
    "estimated_duration": 3600.021816337653,
    "input_throughput": 4407.568567498862,
    "output_throughput": 3856.647739464085,
    "total_throughput": 8264.216306962948,
    "itl": 35.195527598557604,
    "ttft": 8842.85672336294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 64340,
    "finished_requests": 64182,
    "scheduler_time": 37.92282552847532
}
#Debug simulation 
Total elapsed time: 4.5541051919572055. Arrivals time: 0.15454087511170655 Scheduler time: 4.1277521785814315 Scheduler overhead time: 0.10347013582941145 Adapter cache time: 0.018064654199406505 Engine time: 0.10172237525694072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42735553 . Total output tokens: 37628459
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.584329703939147,
    "estimated_duration": 3600.0073031733177,
    "input_throughput": 4407.586336286965,
    "output_throughput": 3856.66328725544,
    "total_throughput": 8264.249623542406,
    "itl": 35.195105886882885,
    "ttft": 8842.910316586684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 64340,
    "finished_requests": 64182,
    "scheduler_time": 37.92249460625232
}
#Debug simulation 
Total elapsed time: 4.584441073937342. Arrivals time: 0.15301737503614277 Scheduler time: 4.158574808621779 Scheduler overhead time: 0.1032809658208862 Adapter cache time: 0.018188445712439716 Engine time: 0.10283189418260008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42735553 . Total output tokens: 37628459
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.569998673978262,
    "estimated_duration": 3600.0184023250135,
    "input_throughput": 4407.572747337162,
    "output_throughput": 3856.6513968465365,
    "total_throughput": 8264.224144183698,
    "itl": 35.195413555183386,
    "ttft": 8842.785651350423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 64340,
    "finished_requests": 64182,
    "scheduler_time": 37.92276085252167
}
#Debug simulation 
Total elapsed time: 4.57016498001758. Arrivals time: 0.15289367060177028 Scheduler time: 4.14598278212361 Scheduler overhead time: 0.10292653238866478 Adapter cache time: 0.018018825794570148 Engine time: 0.10197894286829978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42569535 . Total output tokens: 37480677
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.518741706036963,
    "estimated_duration": 3600.024414173185,
    "input_throughput": 4423.512778775815,
    "output_throughput": 3829.999859366704,
    "total_throughput": 8253.512638142518,
    "itl": 34.657201237823294,
    "ttft": 8766.309705427539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 64071,
    "finished_requests": 63916,
    "scheduler_time": 37.28915022605931
}
#Debug simulation 
Total elapsed time: 4.518849063082598. Arrivals time: 0.15405857667792588 Scheduler time: 4.089524282957427 Scheduler overhead time: 0.10480308067053556 Adapter cache time: 0.017609084607101977 Engine time: 0.10389608808327466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42569535 . Total output tokens: 37480677
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.521490121958777,
    "estimated_duration": 3600.0257505200134,
    "input_throughput": 4423.511136746651,
    "output_throughput": 3829.9984376523835,
    "total_throughput": 8253.509574399035,
    "itl": 34.65746215923621,
    "ttft": 8766.349801561808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2348263315111399,
    "arrivals": 64071,
    "finished_requests": 63916,
    "scheduler_time": 37.28927961894161
}
#Debug simulation 
Total elapsed time: 4.521598921041004. Arrivals time: 0.15185771300457418 Scheduler time: 4.096392838051543 Scheduler overhead time: 0.10406906879507005 Adapter cache time: 0.017392660840414464 Engine time: 0.10301891202107072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42569535 . Total output tokens: 37480677
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.573170531075448,
    "estimated_duration": 3599.996801677905,
    "input_throughput": 4423.414485417857,
    "output_throughput": 3829.848680302682,
    "total_throughput": 8253.263165720538,
    "itl": 34.65701090524302,
    "ttft": 8878.814570429575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2413462840113789,
    "arrivals": 64071,
    "finished_requests": 63914,
    "scheduler_time": 37.28897951013503
}
#Debug simulation 
Total elapsed time: 4.573280314099975. Arrivals time: 0.154833514126949 Scheduler time: 4.144282244495116 Scheduler overhead time: 0.10424466291442513 Adapter cache time: 0.017466188757680357 Engine time: 0.10347378219012171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42569535 . Total output tokens: 37480677
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.559363431995735,
    "estimated_duration": 3599.99821414332,
    "input_throughput": 4423.412749883669,
    "output_throughput": 3829.847177655046,
    "total_throughput": 8253.259927538715,
    "itl": 34.65680386880281,
    "ttft": 8878.867534355128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 64071,
    "finished_requests": 63914,
    "scheduler_time": 37.2888468654559
}
#Debug simulation 
Total elapsed time: 4.5595078519545496. Arrivals time: 0.15579415671527386 Scheduler time: 4.127681962330826 Scheduler overhead time: 0.10377995984163135 Adapter cache time: 0.01756343722809106 Engine time: 0.10586282575968653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42569535 . Total output tokens: 37480677
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.5332136559300125,
    "estimated_duration": 3599.9927362950984,
    "input_throughput": 4423.41948067049,
    "output_throughput": 3829.853005256124,
    "total_throughput": 8253.272485926615,
    "itl": 34.657147367545704,
    "ttft": 8878.713192970457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 64071,
    "finished_requests": 63914,
    "scheduler_time": 37.28893497627188
}
#Debug simulation 
Total elapsed time: 4.533314470900223. Arrivals time: 0.1515670180087909 Scheduler time: 4.106109793996438 Scheduler overhead time: 0.10461710230447352 Adapter cache time: 0.0177011702908203 Engine time: 0.10414372489321977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42569535 . Total output tokens: 37480677
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.54750680399593,
    "estimated_duration": 3600.0131479239076,
    "input_throughput": 4423.435233613927,
    "output_throughput": 3829.9326789823795,
    "total_throughput": 8253.367912596306,
    "itl": 34.65708275948472,
    "ttft": 8822.652993536194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 64071,
    "finished_requests": 63915,
    "scheduler_time": 37.28899251952014
}
#Debug simulation 
Total elapsed time: 4.547616046038456. Arrivals time: 0.1526367348851636 Scheduler time: 4.121005588909611 Scheduler overhead time: 0.10423686529975384 Adapter cache time: 0.017527390969917178 Engine time: 0.10322023008484393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42569535 . Total output tokens: 37480677
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.53886064409744,
    "estimated_duration": 3599.98884146938,
    "input_throughput": 4423.424266365311,
    "output_throughput": 3829.85714877174,
    "total_throughput": 8253.281415137051,
    "itl": 34.65733913924673,
    "ttft": 8878.755938489072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 64071,
    "finished_requests": 63914,
    "scheduler_time": 37.28888243474248
}
#Debug simulation 
Total elapsed time: 4.539064259035513. Arrivals time: 0.1544486794155091 Scheduler time: 4.110372867435217 Scheduler overhead time: 0.10457231814507395 Adapter cache time: 0.01759331568609923 Engine time: 0.10286749282386154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34137255 . Total output tokens: 30078100
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.760940617066808,
    "estimated_duration": 3600.027755742557,
    "input_throughput": 3529.3427890194866,
    "output_throughput": 3093.726703143913,
    "total_throughput": 6623.069492163399,
    "itl": 37.50627296766401,
    "ttft": 10021.70504758452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 51326,
    "finished_requests": 51184,
    "scheduler_time": 27.932275985002544
}
#Debug simulation 
Total elapsed time: 3.7610515609849244. Arrivals time: 0.12831311812624335 Scheduler time: 3.3709451953181997 Scheduler overhead time: 0.09627653518691659 Adapter cache time: 0.02435589872766286 Engine time: 0.09612589527387172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34137255 . Total output tokens: 30078100
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.7470298630651087,
    "estimated_duration": 3600.0259292993937,
    "input_throughput": 3529.344579602148,
    "output_throughput": 3093.7282727203815,
    "total_throughput": 6623.072852322529,
    "itl": 37.50641934413011,
    "ttft": 10021.751470017984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 51326,
    "finished_requests": 51184,
    "scheduler_time": 27.932316433082804
}
#Debug simulation 
Total elapsed time: 3.7471378659829497. Arrivals time: 0.12808618927374482 Scheduler time: 3.3606476897839457 Scheduler overhead time: 0.09538939408957958 Adapter cache time: 0.024323238991200924 Engine time: 0.09373395482543856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34137255 . Total output tokens: 30078100
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.8309088950045407,
    "estimated_duration": 3600.008639656824,
    "input_throughput": 3529.3615298687705,
    "output_throughput": 3093.7431308669575,
    "total_throughput": 6623.104660735728,
    "itl": 37.5065834810927,
    "ttft": 9951.808340855272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 51326,
    "finished_requests": 51184,
    "scheduler_time": 27.93223478488601
}
#Debug simulation 
Total elapsed time: 3.8310217489488423. Arrivals time: 0.12882976373657584 Scheduler time: 3.443066010484472 Scheduler overhead time: 0.09541709558106959 Adapter cache time: 0.024265015381388366 Engine time: 0.09456400235649198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34137255 . Total output tokens: 30078100
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 3.7992170460056514,
    "estimated_duration": 3600.0425470935334,
    "input_throughput": 3529.3282881497817,
    "output_throughput": 3093.713992072615,
    "total_throughput": 6623.042280222397,
    "itl": 37.50652132547863,
    "ttft": 10021.788770209767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 51326,
    "finished_requests": 51184,
    "scheduler_time": 27.93239336638563
}
#Debug simulation 
Total elapsed time: 3.799328278983012. Arrivals time: 0.1279960866086185 Scheduler time: 3.411633391981013 Scheduler overhead time: 0.09615428245160729 Adapter cache time: 0.02427692455239594 Engine time: 0.09433701238594949 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34137255 . Total output tokens: 30078100
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 3.7492028600536287,
    "estimated_duration": 3600.008642677988,
    "input_throughput": 3529.361526906894,
    "output_throughput": 3093.7431282706566,
    "total_throughput": 6623.104655177551,
    "itl": 37.50656772232475,
    "ttft": 9951.777663665003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 51326,
    "finished_requests": 51184,
    "scheduler_time": 27.932238829694047
}
#Debug simulation 
Total elapsed time: 3.7493104189634323. Arrivals time: 0.12768420355860144 Scheduler time: 3.3616244898876175 Scheduler overhead time: 0.096278116106987 Adapter cache time: 0.024211930809542537 Engine time: 0.09439893835224211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34137255 . Total output tokens: 30078100
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.733624037937261,
    "estimated_duration": 3600.016298986261,
    "input_throughput": 3529.35402086314,
    "output_throughput": 3093.7365486751382,
    "total_throughput": 6623.090569538278,
    "itl": 37.50648474906722,
    "ttft": 10021.760279319458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 51326,
    "finished_requests": 51184,
    "scheduler_time": 27.932110229822484
}
#Debug simulation 
Total elapsed time: 3.733737714937888. Arrivals time: 0.12691332248505205 Scheduler time: 3.3483698706841096 Scheduler overhead time: 0.09545935853384435 Adapter cache time: 0.024156183819286525 Engine time: 0.09382691455539316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34137255 . Total output tokens: 30078100
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.7786329879891127,
    "estimated_duration": 3600.026732847594,
    "input_throughput": 3529.343791830641,
    "output_throughput": 3093.7275821811245,
    "total_throughput": 6623.071374011765,
    "itl": 37.50642819433366,
    "ttft": 10021.75821714881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 51326,
    "finished_requests": 51184,
    "scheduler_time": 27.932324522698913
}
#Debug simulation 
Total elapsed time: 3.7787986299954355. Arrivals time: 0.12720744404941797 Scheduler time: 3.390284875058569 Scheduler overhead time: 0.09635525790508837 Adapter cache time: 0.02423041476868093 Engine time: 0.09576102497521788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32972365 . Total output tokens: 29026215
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.6675771569134668,
    "estimated_duration": 3599.9873330111295,
    "input_throughput": 3402.7933619849014,
    "output_throughput": 2975.2549132002423,
    "total_throughput": 6378.048275185143,
    "itl": 35.61843602270997,
    "ttft": 8405.836246251512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 49599,
    "finished_requests": 49484,
    "scheduler_time": 25.304626549771143
}
#Debug simulation 
Total elapsed time: 3.6676906630164012. Arrivals time: 0.124640071997419 Scheduler time: 3.272696718457155 Scheduler overhead time: 0.10036338411737233 Adapter cache time: 0.023919355822727084 Engine time: 0.09915397595614195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32972365 . Total output tokens: 29026215
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.6214907719986513,
    "estimated_duration": 3599.9907137620253,
    "input_throughput": 3402.7901664220176,
    "output_throughput": 2975.2521191386704,
    "total_throughput": 6378.042285560688,
    "itl": 35.6185863826762,
    "ttft": 8405.913487797383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 49599,
    "finished_requests": 49484,
    "scheduler_time": 25.30469527053302
}
#Debug simulation 
Total elapsed time: 3.621626652078703. Arrivals time: 0.12334373034536839 Scheduler time: 3.2314574994379655 Scheduler overhead time: 0.09882696066051722 Adapter cache time: 0.023945969878695905 Engine time: 0.09742910729255527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32972365 . Total output tokens: 29026215
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.6113727260380983,
    "estimated_duration": 3599.993251268622,
    "input_throughput": 3402.7877679168287,
    "output_throughput": 2975.2500219897724,
    "total_throughput": 6378.037789906601,
    "itl": 35.61870137219804,
    "ttft": 8405.889205236199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 49599,
    "finished_requests": 49484,
    "scheduler_time": 25.304683970094988
}
#Debug simulation 
Total elapsed time: 3.6114862299291417. Arrivals time: 0.12301348510663956 Scheduler time: 3.2215898087015375 Scheduler overhead time: 0.09948098787572235 Adapter cache time: 0.02393985167145729 Engine time: 0.09666444244794548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32972365 . Total output tokens: 29026215
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 3.652551389997825,
    "estimated_duration": 3599.994144872356,
    "input_throughput": 3402.7869232643834,
    "output_throughput": 2975.249283462313,
    "total_throughput": 6378.036206726696,
    "itl": 35.618544758665315,
    "ttft": 8405.891322786136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 49599,
    "finished_requests": 49484,
    "scheduler_time": 25.304630553604515
}
#Debug simulation 
Total elapsed time: 3.6526617310009897. Arrivals time: 0.1235713860951364 Scheduler time: 3.260950360330753 Scheduler overhead time: 0.09938223380595446 Adapter cache time: 0.023919680970720947 Engine time: 0.09800690959673375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32972365 . Total output tokens: 29026215
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 3.678663717932068,
    "estimated_duration": 3599.990891595369,
    "input_throughput": 3402.78999833005,
    "output_throughput": 2975.2519721663452,
    "total_throughput": 6378.041970496395,
    "itl": 35.61871834204804,
    "ttft": 8405.847232311293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 49599,
    "finished_requests": 49484,
    "scheduler_time": 25.304671042659724
}
#Debug simulation 
Total elapsed time: 3.678777582012117. Arrivals time: 0.12555525021161884 Scheduler time: 3.2841046566609293 Scheduler overhead time: 0.09937130636535585 Adapter cache time: 0.024014252121560276 Engine time: 0.09893627720884979 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32972365 . Total output tokens: 29026215
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.618000531103462,
    "estimated_duration": 3599.968769109853,
    "input_throughput": 3402.810909114915,
    "output_throughput": 2975.2702556495865,
    "total_throughput": 6378.081164764501,
    "itl": 35.61822174367624,
    "ttft": 8405.839213995458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 49599,
    "finished_requests": 49484,
    "scheduler_time": 25.30442831320226
}
#Debug simulation 
Total elapsed time: 3.61811060202308. Arrivals time: 0.12347586220130324 Scheduler time: 3.2273724562255666 Scheduler overhead time: 0.09964778029825538 Adapter cache time: 0.023924586712382734 Engine time: 0.09695934830233455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32972365 . Total output tokens: 29026215
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.6228276579640806,
    "estimated_duration": 3599.9902914771747,
    "input_throughput": 3402.7905655749655,
    "output_throughput": 2975.252468140694,
    "total_throughput": 6378.0430337156595,
    "itl": 35.618669068124284,
    "ttft": 8405.908678641988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 49599,
    "finished_requests": 49484,
    "scheduler_time": 25.30466699785161
}
#Debug simulation 
Total elapsed time: 3.6229896009899676. Arrivals time: 0.12438393558841199 Scheduler time: 3.2307388947810978 Scheduler overhead time: 0.09900005056988448 Adapter cache time: 0.023772089392878115 Engine time: 0.09839344467036426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32371057 . Total output tokens: 28510179
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.573814556002617,
    "estimated_duration": 3600.0201492081987,
    "input_throughput": 3354.9323335471995,
    "output_throughput": 2933.436359327794,
    "total_throughput": 6288.368692874994,
    "itl": 34.72556444341144,
    "ttft": 7666.882012258206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 48729,
    "finished_requests": 48626,
    "scheduler_time": 24.210340107666823
}
#Debug simulation 
Total elapsed time: 3.573924159980379. Arrivals time: 0.12199000606779009 Scheduler time: 3.1823050880338997 Scheduler overhead time: 0.10097885271534324 Adapter cache time: 0.021966461441479623 Engine time: 0.09927749843336642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32371057 . Total output tokens: 28510179
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.5703306040959433,
    "estimated_duration": 3600.0162544369764,
    "input_throughput": 3354.9359631680077,
    "output_throughput": 2933.4395329422186,
    "total_throughput": 6288.375496110226,
    "itl": 34.72568956546277,
    "ttft": 7666.834866043682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 48729,
    "finished_requests": 48626,
    "scheduler_time": 24.210389479349367
}
#Debug simulation 
Total elapsed time: 3.570439472096041. Arrivals time: 0.12206444062758237 Scheduler time: 3.177433048025705 Scheduler overhead time: 0.10114189703017473 Adapter cache time: 0.022027783910743892 Engine time: 0.1000044762622565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32371057 . Total output tokens: 28510179
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.559973684954457,
    "estimated_duration": 3600.036325194536,
    "input_throughput": 3354.9172588827555,
    "output_throughput": 2933.4231785645507,
    "total_throughput": 6288.340437447306,
    "itl": 34.72560077487229,
    "ttft": 7666.896135591757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 48729,
    "finished_requests": 48626,
    "scheduler_time": 24.210551230696023
}
#Debug simulation 
Total elapsed time: 3.560082030016929. Arrivals time: 0.12178180716000497 Scheduler time: 3.1706867857137695 Scheduler overhead time: 0.10064412141218781 Adapter cache time: 0.02195666206534952 Engine time: 0.09742363565601408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32371057 . Total output tokens: 28510179
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 3.603505344945006,
    "estimated_duration": 3600.0375860918953,
    "input_throughput": 3354.9160838377143,
    "output_throughput": 2933.422151145961,
    "total_throughput": 6288.338234983676,
    "itl": 34.72574302427341,
    "ttft": 7666.859423816325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 48729,
    "finished_requests": 48626,
    "scheduler_time": 24.210490558575483
}
#Debug simulation 
Total elapsed time: 3.6036285229492933. Arrivals time: 0.1250461710151285 Scheduler time: 3.2065847124904394 Scheduler overhead time: 0.10173514357302338 Adapter cache time: 0.02201708371285349 Engine time: 0.10057654278352857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32371057 . Total output tokens: 28510179
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 3.573551398003474,
    "estimated_duration": 3600.03182319301,
    "input_throughput": 3354.9214543575067,
    "output_throughput": 2933.426846942019,
    "total_throughput": 6288.348301299526,
    "itl": 34.72582480889764,
    "ttft": 7666.817452718989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 48729,
    "finished_requests": 48626,
    "scheduler_time": 24.210547226862843
}
#Debug simulation 
Total elapsed time: 3.5736616170033813. Arrivals time: 0.12457655149046332 Scheduler time: 3.1799887464148924 Scheduler overhead time: 0.10111506388057023 Adapter cache time: 0.021977747906930745 Engine time: 0.09862038330174983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32371057 . Total output tokens: 28510179
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.5628449090290815,
    "estimated_duration": 3600.0003032819736,
    "input_throughput": 3354.9502729177943,
    "output_throughput": 2933.2739195530266,
    "total_throughput": 6288.224192470821,
    "itl": 34.72518994271536,
    "ttft": 7740.868799925292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 48729,
    "finished_requests": 48624,
    "scheduler_time": 24.210174229562238
}
#Debug simulation 
Total elapsed time: 3.5629554770421237. Arrivals time: 0.1189556960016489 Scheduler time: 3.173781110555865 Scheduler overhead time: 0.10095305915456265 Adapter cache time: 0.021925469860434532 Engine time: 0.09964518586639315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32371057 . Total output tokens: 28510179
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.589614744996652,
    "estimated_duration": 3600.0203969648633,
    "input_throughput": 3354.9321026577177,
    "output_throughput": 2933.4361574460468,
    "total_throughput": 6288.368260103764,
    "itl": 34.728386728485845,
    "ttft": 7666.89642100881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 48729,
    "finished_requests": 48626,
    "scheduler_time": 24.212004734510717
}
#Debug simulation 
Total elapsed time: 3.589783499017358. Arrivals time: 0.12197729025501758 Scheduler time: 3.1957632412668318 Scheduler overhead time: 0.10160767997149378 Adapter cache time: 0.02212496509309858 Engine time: 0.10044268914498389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32086836 . Total output tokens: 28257754
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.5301478570327163,
    "estimated_duration": 3599.9937079138053,
    "input_throughput": 3342.538619872529,
    "output_throughput": 2882.9475388206693,
    "total_throughput": 6225.486158693198,
    "itl": 33.977070598699555,
    "ttft": 7745.839466254035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 48221,
    "finished_requests": 48118,
    "scheduler_time": 23.076651437278024
}
#Debug simulation 
Total elapsed time: 3.530283770058304. Arrivals time: 0.11973958439193666 Scheduler time: 3.136911239125766 Scheduler overhead time: 0.10368062695488334 Adapter cache time: 0.021296026068739593 Engine time: 0.09975955123081803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32086836 . Total output tokens: 28257754
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.529607717995532,
    "estimated_duration": 3599.99369004326,
    "input_throughput": 3342.538636465055,
    "output_throughput": 2882.947553131762,
    "total_throughput": 6225.486189596817,
    "itl": 33.977151055490985,
    "ttft": 7745.8341888185205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 48221,
    "finished_requests": 48118,
    "scheduler_time": 23.07677599234129
}
#Debug simulation 
Total elapsed time: 3.5297225879039615. Arrivals time: 0.12095010338816792 Scheduler time: 3.1346719964640215 Scheduler overhead time: 0.1031317807501182 Adapter cache time: 0.021252449369058013 Engine time: 0.10122082417365164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32086836 . Total output tokens: 28257754
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.5212249029427767,
    "estimated_duration": 3599.977874201771,
    "input_throughput": 3342.5533212945434,
    "output_throughput": 2882.960218832251,
    "total_throughput": 6225.513540126794,
    "itl": 33.97738694539214,
    "ttft": 7745.759815186797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 48221,
    "finished_requests": 48118,
    "scheduler_time": 23.07673554426091
}
#Debug simulation 
Total elapsed time: 3.521334782941267. Arrivals time: 0.1212795611936599 Scheduler time: 3.128557695192285 Scheduler overhead time: 0.10260517650749534 Adapter cache time: 0.02106702304445207 Engine time: 0.09939870971720666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32086836 . Total output tokens: 28257754
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 3.500034762895666,
    "estimated_duration": 3599.978033701224,
    "input_throughput": 3342.553173200466,
    "output_throughput": 2882.9600911007556,
    "total_throughput": 6225.513264301222,
    "itl": 33.97729446317533,
    "ttft": 7745.770356911107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 48221,
    "finished_requests": 48118,
    "scheduler_time": 23.076642513675957
}
#Debug simulation 
Total elapsed time: 3.500139400945045. Arrivals time: 0.11986504273954779 Scheduler time: 3.1076402025064453 Scheduler overhead time: 0.1023592222481966 Adapter cache time: 0.021201803465373814 Engine time: 0.10053695784881711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32086836 . Total output tokens: 28257754
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 3.539119033026509,
    "estimated_duration": 3599.99370365758,
    "input_throughput": 3342.5386238243686,
    "output_throughput": 2882.9475422291403,
    "total_throughput": 6225.486166053509,
    "itl": 33.97711175208304,
    "ttft": 7745.846795063362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 48221,
    "finished_requests": 48118,
    "scheduler_time": 23.07673637824686
}
#Debug simulation 
Total elapsed time: 3.539227767032571. Arrivals time: 0.12146234966348857 Scheduler time: 3.1454632396344095 Scheduler overhead time: 0.10248554206918925 Adapter cache time: 0.021169024985283613 Engine time: 0.10019468935206532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32086836 . Total output tokens: 28257754
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.535297993919812,
    "estimated_duration": 3599.9849440749313,
    "input_throughput": 3342.546756981531,
    "output_throughput": 2882.954557096608,
    "total_throughput": 6225.501314078139,
    "itl": 33.9771656291916,
    "ttft": 7745.766338105858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 48221,
    "finished_requests": 48118,
    "scheduler_time": 23.076582675541296
}
#Debug simulation 
Total elapsed time: 3.5354102660203353. Arrivals time: 0.12124678352847695 Scheduler time: 3.1392411610577255 Scheduler overhead time: 0.1028233808465302 Adapter cache time: 0.021391372079961002 Engine time: 0.10211510269436985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32086836 . Total output tokens: 28257754
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.5385393850738183,
    "estimated_duration": 3599.993937122562,
    "input_throughput": 3342.5384070557484,
    "output_throughput": 2882.9473552656877,
    "total_throughput": 6225.485762321436,
    "itl": 33.977117617156935,
    "ttft": 7745.843042555055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 48221,
    "finished_requests": 48118,
    "scheduler_time": 23.076764691903147
}
#Debug simulation 
Total elapsed time: 3.538738599047065. Arrivals time: 0.12078940856736153 Scheduler time: 3.144131614593789 Scheduler overhead time: 0.10278873634524643 Adapter cache time: 0.021155254915356636 Engine time: 0.10135992348659784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31933121 . Total output tokens: 28124683
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.550449586007744,
    "estimated_duration": 3599.993603078436,
    "input_throughput": 3277.4622126857507,
    "output_throughput": 2907.07988787834,
    "total_throughput": 6184.542100564091,
    "itl": 34.03217050716186,
    "ttft": 10099.413696196469,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 48032,
    "finished_requests": 47898,
    "scheduler_time": 23.451801546094686
}
#Debug simulation 
Total elapsed time: 3.5505857180105522. Arrivals time: 0.11843414150644094 Scheduler time: 3.1621700022369623 Scheduler overhead time: 0.10242586792446673 Adapter cache time: 0.019962424645200372 Engine time: 0.09925765136722475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31933121 . Total output tokens: 28124683
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.5547508579911664,
    "estimated_duration": 3600.007546371698,
    "input_throughput": 3277.4495186521417,
    "output_throughput": 2907.068628383216,
    "total_throughput": 6184.518147035358,
    "itl": 34.032410141664286,
    "ttft": 10099.470811455403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 48032,
    "finished_requests": 47898,
    "scheduler_time": 23.452069132536664
}
#Debug simulation 
Total elapsed time: 3.5548630320699885. Arrivals time: 0.11937281570862979 Scheduler time: 3.1642064553452656 Scheduler overhead time: 0.10225996642839164 Adapter cache time: 0.02000909054186195 Engine time: 0.10062259365804493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31933121 . Total output tokens: 28124683
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.5534715319518,
    "estimated_duration": 3599.9866254348344,
    "input_throughput": 3277.46856519914,
    "output_throughput": 2907.085522501323,
    "total_throughput": 6184.554087700462,
    "itl": 34.03237907142074,
    "ttft": 10099.501406696892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 48032,
    "finished_requests": 47898,
    "scheduler_time": 23.45197551381527
}
#Debug simulation 
Total elapsed time: 3.5535912320483476. Arrivals time: 0.1206528574693948 Scheduler time: 3.159941517515108 Scheduler overhead time: 0.10254258278291672 Adapter cache time: 0.02003621100448072 Engine time: 0.1019731987034902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31933121 . Total output tokens: 28124683
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 3.562520548934117,
    "estimated_duration": 3600.010266396808,
    "input_throughput": 3277.4470423411517,
    "output_throughput": 2907.0664319173507,
    "total_throughput": 6184.513474258502,
    "itl": 34.03216164457801,
    "ttft": 10099.484270419453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 48032,
    "finished_requests": 47898,
    "scheduler_time": 23.451944700397913
}
#Debug simulation 
Total elapsed time: 3.5626302139135078. Arrivals time: 0.12108798243571073 Scheduler time: 3.1677807780215517 Scheduler overhead time: 0.10406658507417887 Adapter cache time: 0.020008327555842698 Engine time: 0.10089635266922414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31933121 . Total output tokens: 28124683
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 3.541842974955216,
    "estimated_duration": 3600.0097975426283,
    "input_throughput": 3277.447469185752,
    "output_throughput": 2907.0668105247223,
    "total_throughput": 6184.5142797104745,
    "itl": 34.03223055978109,
    "ttft": 10099.490216066622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 48032,
    "finished_requests": 47898,
    "scheduler_time": 23.452077263127453
}
#Debug simulation 
Total elapsed time: 3.5419551669619977. Arrivals time: 0.12051028560381383 Scheduler time: 3.1524246535263956 Scheduler overhead time: 0.10200323071330786 Adapter cache time: 0.019927777000702918 Engine time: 0.09891541872639209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31933121 . Total output tokens: 28124683
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.546033716062084,
    "estimated_duration": 3599.9866593297616,
    "input_throughput": 3277.468534340815,
    "output_throughput": 2907.0854951302626,
    "total_throughput": 6184.554029471077,
    "itl": 34.032124199495335,
    "ttft": 10099.448822457121,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 48032,
    "finished_requests": 47898,
    "scheduler_time": 23.451724735716752
}
#Debug simulation 
Total elapsed time: 3.546175142051652. Arrivals time: 0.11982428561896086 Scheduler time: 3.1535680406959727 Scheduler overhead time: 0.10237617639359087 Adapter cache time: 0.020044823177158833 Engine time: 0.10210144217126071 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31933121 . Total output tokens: 28124683
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.5465070789214224,
    "estimated_duration": 3600.008714764287,
    "input_throughput": 3277.4484549470144,
    "output_throughput": 2907.067684886211,
    "total_throughput": 6184.516139833226,
    "itl": 34.032366510700115,
    "ttft": 10099.462041781208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 48032,
    "finished_requests": 47898,
    "scheduler_time": 23.452073218319455
}
#Debug simulation 
Total elapsed time: 3.5467000589706004. Arrivals time: 0.11941982933785766 Scheduler time: 3.154816821217537 Scheduler overhead time: 0.10260140162426978 Adapter cache time: 0.01995067938696593 Engine time: 0.10146886121947318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31858323 . Total output tokens: 28054971
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.5323585550067946,
    "estimated_duration": 3599.977864128435,
    "input_throughput": 3283.8940810715585,
    "output_throughput": 2889.19248744273,
    "total_throughput": 6173.086568514289,
    "itl": 33.81345386469255,
    "ttft": 8247.867980127729,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 47900,
    "finished_requests": 47791,
    "scheduler_time": 23.046058931742664
}
#Debug simulation 
Total elapsed time: 3.5324920769780874. Arrivals time: 0.120756950462237 Scheduler time: 3.1395966600393876 Scheduler overhead time: 0.10279806051403284 Adapter cache time: 0.019512630067765713 Engine time: 0.10135823849122971 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31858323 . Total output tokens: 28054971
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.5399604099802673,
    "estimated_duration": 3599.97324987305,
    "input_throughput": 3283.898290193376,
    "output_throughput": 2889.196190656912,
    "total_throughput": 6173.094480850288,
    "itl": 33.801706694662585,
    "ttft": 8247.883626324376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 47900,
    "finished_requests": 47791,
    "scheduler_time": 23.039010541166796
}
#Debug simulation 
Total elapsed time: 3.540074558928609. Arrivals time: 0.12038132990710437 Scheduler time: 3.1484815591247752 Scheduler overhead time: 0.10315024934243411 Adapter cache time: 0.01968683290760964 Engine time: 0.09992010821588337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31858323 . Total output tokens: 28054971
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.5420621670782566,
    "estimated_duration": 3599.9876212088784,
    "input_throughput": 3283.885180702422,
    "output_throughput": 2889.1846568370497,
    "total_throughput": 6173.069837539471,
    "itl": 33.80166975383296,
    "ttft": 8247.858845211973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 47900,
    "finished_requests": 47791,
    "scheduler_time": 23.03915206847329
}
#Debug simulation 
Total elapsed time: 3.5421698500867933. Arrivals time: 0.11986873706337065 Scheduler time: 3.145510681089945 Scheduler overhead time: 0.10427766793873161 Adapter cache time: 0.01969502796418965 Engine time: 0.10383974784053862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31858323 . Total output tokens: 28054971
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 3.5423309890320525,
    "estimated_duration": 3599.9658492493163,
    "input_throughput": 3283.9050410617574,
    "output_throughput": 2889.2021301171167,
    "total_throughput": 6173.1071711788745,
    "itl": 33.80131566670499,
    "ttft": 8247.854185196746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 47900,
    "finished_requests": 47791,
    "scheduler_time": 23.038775942300358
}
#Debug simulation 
Total elapsed time: 3.5424387850798666. Arrivals time: 0.12024817883502692 Scheduler time: 3.1475999729009345 Scheduler overhead time: 0.10293784271925688 Adapter cache time: 0.01958494691643864 Engine time: 0.10356964007951319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31858323 . Total output tokens: 28054971
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 3.543284178012982,
    "estimated_duration": 3599.9790726282386,
    "input_throughput": 3283.8929786803305,
    "output_throughput": 2889.1915175513827,
    "total_throughput": 6173.084496231713,
    "itl": 33.801730078906814,
    "ttft": 8247.911608686962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 47900,
    "finished_requests": 47791,
    "scheduler_time": 23.03904694443917
}
#Debug simulation 
Total elapsed time: 3.5433901919750497. Arrivals time: 0.12044397077988833 Scheduler time: 3.1491652105469257 Scheduler overhead time: 0.10296651208773255 Adapter cache time: 0.019887337926775217 Engine time: 0.10217026667669415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31858323 . Total output tokens: 28054971
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.5147833719383925,
    "estimated_duration": 3599.969021259082,
    "input_throughput": 3283.90214754273,
    "output_throughput": 2889.1995843792733,
    "total_throughput": 6173.101731922004,
    "itl": 33.813496908048734,
    "ttft": 8247.83749752075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 47900,
    "finished_requests": 47791,
    "scheduler_time": 23.045998259622078
}
#Debug simulation 
Total elapsed time: 3.514890211983584. Arrivals time: 0.11876908631529659 Scheduler time: 3.125079855439253 Scheduler overhead time: 0.10302467586006969 Adapter cache time: 0.019398674136027694 Engine time: 0.1001555691473186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31858323 . Total output tokens: 28054971
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.534044138970785,
    "estimated_duration": 3599.979053486538,
    "input_throughput": 3283.892996141348,
    "output_throughput": 2889.191532913705,
    "total_throughput": 6173.084529055053,
    "itl": 33.80174032528404,
    "ttft": 8247.864942325083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 47900,
    "finished_requests": 47791,
    "scheduler_time": 23.039055034055245
}
#Debug simulation 
Total elapsed time: 3.534224872943014. Arrivals time: 0.1187900947406888 Scheduler time: 3.143226256361231 Scheduler overhead time: 0.10316122963558882 Adapter cache time: 0.019617015379481018 Engine time: 0.10061772959306836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25050381 . Total output tokens: 22051341
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.868434541975148,
    "estimated_duration": 3599.979480621132,
    "input_throughput": 2579.1005337613865,
    "output_throughput": 2279.060768030934,
    "total_throughput": 4858.16130179232,
    "itl": 30.13689858675346,
    "ttft": 9883.754460539187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 37706,
    "finished_requests": 37603,
    "scheduler_time": 11.810364191485677
}
#Debug simulation 
Total elapsed time: 2.8685699969064444. Arrivals time: 0.09644096263218671 Scheduler time: 2.4680622154846787 Scheduler overhead time: 0.11147961183451116 Adapter cache time: 0.030678673181682825 Engine time: 0.10926272568758577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25050381 . Total output tokens: 22051341
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.864443550002761,
    "estimated_duration": 3599.9741299878965,
    "input_throughput": 2579.1043670725535,
    "output_throughput": 2279.0641553936903,
    "total_throughput": 4858.168522466243,
    "itl": 30.27101416574035,
    "ttft": 9883.984828874141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 37706,
    "finished_requests": 37603,
    "scheduler_time": 11.906153166600236
}
#Debug simulation 
Total elapsed time: 2.8645565090700984. Arrivals time: 0.09695442917291075 Scheduler time: 2.464658169192262 Scheduler overhead time: 0.11096091009676456 Adapter cache time: 0.030001964303664863 Engine time: 0.10939100326504558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25050381 . Total output tokens: 22051341
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8683067680103704,
    "estimated_duration": 3599.978827058971,
    "input_throughput": 2579.101001987062,
    "output_throughput": 2279.0611817855565,
    "total_throughput": 4858.162183772618,
    "itl": 30.27069543224879,
    "ttft": 9883.931925725326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 37706,
    "finished_requests": 37603,
    "scheduler_time": 11.90623643959716
}
#Debug simulation 
Total elapsed time: 2.8684171530185267. Arrivals time: 0.09868285804986954 Scheduler time: 2.4696977069834247 Scheduler overhead time: 0.1109485257184133 Adapter cache time: 0.030145291122607887 Engine time: 0.10641758819110692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25050381 . Total output tokens: 22051341
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8751870709238574,
    "estimated_duration": 3599.9953286870896,
    "input_throughput": 2579.0891799257174,
    "output_throughput": 2279.050735044201,
    "total_throughput": 4858.139914969918,
    "itl": 30.135830302267603,
    "ttft": 9883.697927457833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 37706,
    "finished_requests": 37603,
    "scheduler_time": 11.809480962432492
}
#Debug simulation 
Total elapsed time: 2.8752918218960986. Arrivals time: 0.09613742784131318 Scheduler time: 2.474196045775898 Scheduler overhead time: 0.11210853338707238 Adapter cache time: 0.030847245478071272 Engine time: 0.10920976276975125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25050381 . Total output tokens: 22051341
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8714190559694543,
    "estimated_duration": 3599.9748505614484,
    "input_throughput": 2579.1038508371707,
    "output_throughput": 2279.063699214572,
    "total_throughput": 4858.167550051742,
    "itl": 30.270923641074702,
    "ttft": 9883.981699640457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 37706,
    "finished_requests": 37603,
    "scheduler_time": 11.90616279906636
}
#Debug simulation 
Total elapsed time: 2.871530691976659. Arrivals time: 0.09634997078683227 Scheduler time: 2.4726165818283334 Scheduler overhead time: 0.1114470997126773 Adapter cache time: 0.030242158682085574 Engine time: 0.1080995942465961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25050381 . Total output tokens: 22051341
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.8761070061009377,
    "estimated_duration": 3599.9735875813503,
    "input_throughput": 2579.1047556651524,
    "output_throughput": 2279.064498779353,
    "total_throughput": 4858.169254444505,
    "itl": 30.135911946669516,
    "ttft": 9883.659961601494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 37706,
    "finished_requests": 37603,
    "scheduler_time": 11.809324258173941
}
#Debug simulation 
Total elapsed time: 2.8762205260572955. Arrivals time: 0.09696813218761235 Scheduler time: 2.474460469209589 Scheduler overhead time: 0.11152183497324586 Adapter cache time: 0.03066735970787704 Engine time: 0.10956121678464115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25050381 . Total output tokens: 22051341
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8660617179702967,
    "estimated_duration": 3599.9740539818313,
    "input_throughput": 2579.10442152505,
    "output_throughput": 2279.0642035114533,
    "total_throughput": 4858.168625036504,
    "itl": 30.271009385025604,
    "ttft": 9883.98450530034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 37706,
    "finished_requests": 37603,
    "scheduler_time": 11.906149121792188
}
#Debug simulation 
Total elapsed time: 2.866220913012512. Arrivals time: 0.09840272541623563 Scheduler time: 2.4674741708440706 Scheduler overhead time: 0.11007820803206414 Adapter cache time: 0.029973489698022604 Engine time: 0.10793890699278563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24434728 . Total output tokens: 21511302
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.7861664629308507,
    "estimated_duration": 3600.0283829782247,
    "input_throughput": 2521.688174160962,
    "output_throughput": 2195.085471371351,
    "total_throughput": 4716.773645532313,
    "itl": 29.23991150594976,
    "ttft": 7199.116102632172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 36751,
    "finished_requests": 36678,
    "scheduler_time": 9.961640943858825
}
#Debug simulation 
Total elapsed time: 2.7862963730003685. Arrivals time: 0.0939286109060049 Scheduler time: 2.3837822464993224 Scheduler overhead time: 0.11410790216177702 Adapter cache time: 0.029376209480687976 Engine time: 0.11118662520311773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24434728 . Total output tokens: 21511302
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.786468358943239,
    "estimated_duration": 3600.028593819156,
    "input_throughput": 2521.688026474612,
    "output_throughput": 2195.0853428129653,
    "total_throughput": 4716.773369287577,
    "itl": 29.23830895353707,
    "ttft": 7199.137154918716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 36751,
    "finished_requests": 36678,
    "scheduler_time": 9.960451895416725
}
#Debug simulation 
Total elapsed time: 2.786575375008397. Arrivals time: 0.09417928743641824 Scheduler time: 2.3869057142874226 Scheduler overhead time: 0.11298379930667579 Adapter cache time: 0.029503556084819138 Engine time: 0.10911372734699398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24434728 . Total output tokens: 21511302
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7981256779748946,
    "estimated_duration": 3600.028502361782,
    "input_throughput": 2521.6880905371504,
    "output_throughput": 2195.085398578285,
    "total_throughput": 4716.773489115436,
    "itl": 29.239902282014818,
    "ttft": 7199.143786685292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 36751,
    "finished_requests": 36678,
    "scheduler_time": 9.961476065837141
}
#Debug simulation 
Total elapsed time: 2.7982337690191343. Arrivals time: 0.0951237385161221 Scheduler time: 2.3901440746849403 Scheduler overhead time: 0.11448416905477643 Adapter cache time: 0.029331964789889753 Engine time: 0.11471651017200202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24434728 . Total output tokens: 21511302
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.797109168022871,
    "estimated_duration": 3600.0084409749174,
    "input_throughput": 2521.702142882073,
    "output_throughput": 2195.0976308988766,
    "total_throughput": 4716.79977378095,
    "itl": 29.240097887333473,
    "ttft": 7101.473755785343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 36751,
    "finished_requests": 36678,
    "scheduler_time": 9.961617634118651
}
#Debug simulation 
Total elapsed time: 2.797242376022041. Arrivals time: 0.0950524810468778 Scheduler time: 2.3932387231616303 Scheduler overhead time: 0.1136179807363078 Adapter cache time: 0.02937208057846874 Engine time: 0.11219208897091448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24434728 . Total output tokens: 21511302
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.78508520394098,
    "estimated_duration": 3600.0284582658373,
    "input_throughput": 2521.688121424745,
    "output_throughput": 2195.0854254653964,
    "total_throughput": 4716.773546890141,
    "itl": 29.23985217006315,
    "ttft": 7199.144996369395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861723,
    "arrivals": 36751,
    "finished_requests": 36678,
    "scheduler_time": 9.96148736627525
}
#Debug simulation 
Total elapsed time: 2.785221383906901. Arrivals time: 0.09414391708560288 Scheduler time: 2.384713916108012 Scheduler overhead time: 0.11340954795014113 Adapter cache time: 0.02930290694348514 Engine time: 0.10977536311838776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24434728 . Total output tokens: 21511302
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.797271890914999,
    "estimated_duration": 3600.0227799388,
    "input_throughput": 2521.692098891199,
    "output_throughput": 2195.08888778041,
    "total_throughput": 4716.780986671609,
    "itl": 29.239854926868983,
    "ttft": 7199.11309884764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 36751,
    "finished_requests": 36678,
    "scheduler_time": 9.961581230846273
}
#Debug simulation 
Total elapsed time: 2.7974092569202185. Arrivals time: 0.09504029608797282 Scheduler time: 2.3936418228549883 Scheduler overhead time: 0.11404923896770924 Adapter cache time: 0.029239673749543726 Engine time: 0.11152690090239048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24434728 . Total output tokens: 21511302
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.77814272895921,
    "estimated_duration": 3600.02857477047,
    "input_throughput": 2521.688039817518,
    "output_throughput": 2195.085354427732,
    "total_throughput": 4716.77339424525,
    "itl": 29.238242653076124,
    "ttft": 7199.115119093802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2367897061258555,
    "arrivals": 36751,
    "finished_requests": 36678,
    "scheduler_time": 9.960412281322323
}
#Debug simulation 
Total elapsed time: 2.7783055409090593. Arrivals time: 0.09410335472784936 Scheduler time: 2.3765420938143507 Scheduler overhead time: 0.11351092264521867 Adapter cache time: 0.02935284178238362 Engine time: 0.1110363737680018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24129533 . Total output tokens: 21261534
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.763989617000334,
    "estimated_duration": 3599.91980731603,
    "input_throughput": 2501.587113606896,
    "output_throughput": 2159.056427924944,
    "total_throughput": 4660.643541531839,
    "itl": 28.837237666829846,
    "ttft": 6489.16877679204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 36327,
    "finished_requests": 36262,
    "scheduler_time": 9.132506632471701
}
#Debug simulation 
Total elapsed time: 2.7641237389761955. Arrivals time: 0.09491561353206635 Scheduler time: 2.358257165760733 Scheduler overhead time: 0.11509306833613664 Adapter cache time: 0.02847731683868915 Engine time: 0.11285030073486269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24129533 . Total output tokens: 21261534
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.764611328020692,
    "estimated_duration": 3599.919951692924,
    "input_throughput": 2501.5870132792825,
    "output_throughput": 2159.056341334724,
    "total_throughput": 4660.643354614006,
    "itl": 28.8374613434671,
    "ttft": 6489.1929250014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 36327,
    "finished_requests": 36262,
    "scheduler_time": 9.132614174316803
}
#Debug simulation 
Total elapsed time: 2.764720765990205. Arrivals time: 0.09401101234834641 Scheduler time: 2.3596521177096292 Scheduler overhead time: 0.1148483941797167 Adapter cache time: 0.02843937440775335 Engine time: 0.11327500641345978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24129533 . Total output tokens: 21261534
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7486852139700204,
    "estimated_duration": 3599.9316080066096,
    "input_throughput": 2501.578913324585,
    "output_throughput": 2159.049350469141,
    "total_throughput": 4660.628263793726,
    "itl": 28.837537341566332,
    "ttft": 6489.069122277383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 36327,
    "finished_requests": 36262,
    "scheduler_time": 9.13272242502583
}
#Debug simulation 
Total elapsed time: 2.7487919400446117. Arrivals time: 0.09305678668897599 Scheduler time: 2.346128383418545 Scheduler overhead time: 0.11519994062837213 Adapter cache time: 0.028425143216736615 Engine time: 0.11130706453695893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24129533 . Total output tokens: 21261534
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.756977265002206,
    "estimated_duration": 3599.9103655409845,
    "input_throughput": 2501.5936747210308,
    "output_throughput": 2159.0620906562435,
    "total_throughput": 4660.655765377274,
    "itl": 28.837639838195148,
    "ttft": 6489.203686961577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 36327,
    "finished_requests": 36262,
    "scheduler_time": 9.132687564603481
}
#Debug simulation 
Total elapsed time: 2.7570892228977755. Arrivals time: 0.09379753726534545 Scheduler time: 2.35283084877301 Scheduler overhead time: 0.11539461673237383 Adapter cache time: 0.028251228155568242 Engine time: 0.1121979943709448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24129533 . Total output tokens: 21261534
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7556465310044587,
    "estimated_duration": 3599.9315340232683,
    "input_throughput": 2501.5789647353313,
    "output_throughput": 2159.049394840453,
    "total_throughput": 4660.628359575784,
    "itl": 28.837547259489554,
    "ttft": 6489.093676876034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 36327,
    "finished_requests": 36262,
    "scheduler_time": 9.132721591039815
}
#Debug simulation 
Total elapsed time: 2.7557567780604586. Arrivals time: 0.09313047002069652 Scheduler time: 2.3487424462800846 Scheduler overhead time: 0.11500474286731333 Adapter cache time: 0.02844854851718992 Engine time: 0.11609274079091847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24129533 . Total output tokens: 21261534
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.757232272066176,
    "estimated_duration": 3599.9160070495295,
    "input_throughput": 2501.5897544178724,
    "output_throughput": 2159.0587071419586,
    "total_throughput": 4660.648461559831,
    "itl": 28.83724424354746,
    "ttft": 6489.176031165596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 36327,
    "finished_requests": 36262,
    "scheduler_time": 9.132547789416147
}
#Debug simulation 
Total elapsed time: 2.7573400180554017. Arrivals time: 0.0945030574221164 Scheduler time: 2.349875494488515 Scheduler overhead time: 0.1162318647839129 Adapter cache time: 0.0281728848349303 Engine time: 0.11387276195455343 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24129533 . Total output tokens: 21261534
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7618737869197503,
    "estimated_duration": 3599.9272986432607,
    "input_throughput": 2501.5819078885274,
    "output_throughput": 2159.0519350013737,
    "total_throughput": 4660.633842889901,
    "itl": 28.83744973922275,
    "ttft": 6489.143665588716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 36327,
    "finished_requests": 36262,
    "scheduler_time": 9.132728012683925
}
#Debug simulation 
Total elapsed time: 2.7620628479635343. Arrivals time: 0.09384296939242631 Scheduler time: 2.356379473232664 Scheduler overhead time: 0.1158720130333677 Adapter cache time: 0.02877978258766234 Engine time: 0.11220324703026563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 23981417 . Total output tokens: 21123930
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.754475921043195,
    "estimated_duration": 3600.0024814937306,
    "input_throughput": 2469.900519710374,
    "output_throughput": 2168.9510049338,
    "total_throughput": 4638.851524644174,
    "itl": 28.798009475480058,
    "ttft": 6632.121209687795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 36084,
    "finished_requests": 36018,
    "scheduler_time": 9.215021131336778
}
#Debug simulation 
Total elapsed time: 2.7545831489842385. Arrivals time: 0.09424042340833694 Scheduler time: 2.3506774328416213 Scheduler overhead time: 0.11501605669036508 Adapter cache time: 0.02727490570396185 Engine time: 0.11287387018091977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 23981417 . Total output tokens: 21123930
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7848594390088692,
    "estimated_duration": 3600.0024526249204,
    "input_throughput": 2469.9005395167737,
    "output_throughput": 2168.951022326853,
    "total_throughput": 4638.851561843627,
    "itl": 28.798104435787998,
    "ttft": 6632.115660245985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 36084,
    "finished_requests": 36018,
    "scheduler_time": 9.215094646745545
}
#Debug simulation 
Total elapsed time: 2.7849737360375. Arrivals time: 0.09377386164851487 Scheduler time: 2.3774145980132744 Scheduler overhead time: 0.11708211898803711 Adapter cache time: 0.027546194498427212 Engine time: 0.11403944052290171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 23981417 . Total output tokens: 21123930
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7496245409129187,
    "estimated_duration": 3599.9882339687892,
    "input_throughput": 2469.910294733782,
    "output_throughput": 2168.9595889017273,
    "total_throughput": 4638.86988363551,
    "itl": 28.79813248985208,
    "ttft": 6632.213278269511,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 36084,
    "finished_requests": 36018,
    "scheduler_time": 9.215132592867821
}
#Debug simulation 
Total elapsed time: 2.749732026946731. Arrivals time: 0.09384573949500918 Scheduler time: 2.3465611445717514 Scheduler overhead time: 0.11543024948332459 Adapter cache time: 0.02737505652476102 Engine time: 0.11197001463733613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 23981417 . Total output tokens: 21123930
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.7388200350105762,
    "estimated_duration": 3599.9882834153664,
    "input_throughput": 2469.910260809058,
    "output_throughput": 2168.9595591106226,
    "total_throughput": 4638.869819919681,
    "itl": 28.7979748479479,
    "ttft": 6632.214869600143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 36084,
    "finished_requests": 36018,
    "scheduler_time": 9.215041939118892
}
#Debug simulation 
Total elapsed time: 2.738925455021672. Arrivals time: 0.09154318156652153 Scheduler time: 2.338500730576925 Scheduler overhead time: 0.11493663699366152 Adapter cache time: 0.02730619302019477 Engine time: 0.11206157971173525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 23981417 . Total output tokens: 21123930
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.759241933003068,
    "estimated_duration": 3600.0111011076838,
    "input_throughput": 2469.894605953892,
    "output_throughput": 2168.9458117497174,
    "total_throughput": 4638.84041770361,
    "itl": 28.798087086363953,
    "ttft": 6632.1581875080765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 36084,
    "finished_requests": 36018,
    "scheduler_time": 9.21511724762173
}
#Debug simulation 
Total elapsed time: 2.759340585093014. Arrivals time: 0.09442686557304114 Scheduler time: 2.3537836355390027 Scheduler overhead time: 0.11548056500032544 Adapter cache time: 0.027565385564230382 Engine time: 0.1132676653796807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 23981417 . Total output tokens: 21123930
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.8239039529580623,
    "estimated_duration": 3599.9994902841813,
    "input_throughput": 2469.9025719301144,
    "output_throughput": 2168.9528070970987,
    "total_throughput": 4638.8553790272135,
    "itl": 28.79802628058399,
    "ttft": 6632.166822691476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 36084,
    "finished_requests": 36018,
    "scheduler_time": 9.214962836052207
}
#Debug simulation 
Total elapsed time: 2.8240144689334556. Arrivals time: 0.09429530391935259 Scheduler time: 2.41698622435797 Scheduler overhead time: 0.11690951441414654 Adapter cache time: 0.027506765793077648 Engine time: 0.11314641335047781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 23981417 . Total output tokens: 21123930
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.763569639995694,
    "estimated_duration": 3600.011055631469,
    "input_throughput": 2469.894637154201,
    "output_throughput": 2168.9458391483686,
    "total_throughput": 4638.84047630257,
    "itl": 28.798118659442846,
    "ttft": 6632.159983952083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 36084,
    "finished_requests": 36018,
    "scheduler_time": 9.21513984849798
}
#Debug simulation 
Total elapsed time: 2.763736850931309. Arrivals time: 0.09416915208566934 Scheduler time: 2.3524846306536347 Scheduler overhead time: 0.12041679816320539 Adapter cache time: 0.02769730193540454 Engine time: 0.11405574134550989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23904447 . Total output tokens: 21060636
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.7787186910863966,
    "estimated_duration": 3599.6308835947243,
    "input_throughput": 2487.358090188023,
    "output_throughput": 2143.66146128131,
    "total_throughput": 4631.019551469333,
    "itl": 28.52790270801074,
    "ttft": 8348.75230941793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 35993,
    "finished_requests": 35910,
    "scheduler_time": 8.690355741833272
}
#Debug simulation 
Total elapsed time: 2.7788615870522335. Arrivals time: 0.09630993194878101 Scheduler time: 2.3712509006727487 Scheduler overhead time: 0.11659414344467223 Adapter cache time: 0.026992806349880993 Engine time: 0.11235035373829305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23904447 . Total output tokens: 21060636
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.741655818070285,
    "estimated_duration": 3599.662870256972,
    "input_throughput": 2487.335987483968,
    "output_throughput": 2143.6424126710353,
    "total_throughput": 4630.978400155003,
    "itl": 28.5280677497531,
    "ttft": 8348.768366711121,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 35993,
    "finished_requests": 35910,
    "scheduler_time": 8.690523830676993
}
#Debug simulation 
Total elapsed time: 2.7417935769772157. Arrivals time: 0.09481068002060056 Scheduler time: 2.3352675035130233 Scheduler overhead time: 0.11597914667800069 Adapter cache time: 0.02690622629597783 Engine time: 0.11397631501313299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23904447 . Total output tokens: 21060636
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.740833471994847,
    "estimated_duration": 3599.641166224303,
    "input_throughput": 2487.350984873718,
    "output_throughput": 2143.655337760734,
    "total_throughput": 4631.006322634452,
    "itl": 28.52815701422688,
    "ttft": 8348.734230575408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 35993,
    "finished_requests": 35910,
    "scheduler_time": 8.690578664895483
}
#Debug simulation 
Total elapsed time: 2.740942656993866. Arrivals time: 0.0920177762163803 Scheduler time: 2.336786760482937 Scheduler overhead time: 0.11601958924438804 Adapter cache time: 0.026877799769863486 Engine time: 0.11430521018337458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23904447 . Total output tokens: 21060636
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.7561845369637012,
    "estimated_duration": 3599.641137978394,
    "input_throughput": 2487.351004391633,
    "output_throughput": 2143.655354581714,
    "total_throughput": 4631.006358973347,
    "itl": 28.527953383155637,
    "ttft": 8348.724193794482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469847,
    "arrivals": 35993,
    "finished_requests": 35910,
    "scheduler_time": 8.69050335639272
}
#Debug simulation 
Total elapsed time: 2.756287216907367. Arrivals time: 0.09345415991265327 Scheduler time: 2.348585296771489 Scheduler overhead time: 0.11728231003507972 Adapter cache time: 0.026868965942412615 Engine time: 0.1147652342915535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23904447 . Total output tokens: 21060636
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.73782381194178,
    "estimated_duration": 3599.6370856965123,
    "input_throughput": 2487.3538045204155,
    "output_throughput": 2143.657767796032,
    "total_throughput": 4631.011572316447,
    "itl": 28.5281086754786,
    "ttft": 8348.754149513325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861723,
    "arrivals": 35993,
    "finished_requests": 35910,
    "scheduler_time": 8.690516449924894
}
#Debug simulation 
Total elapsed time: 2.7379344649380073. Arrivals time: 0.09300702007021755 Scheduler time: 2.3360456288792193 Scheduler overhead time: 0.11545922385994345 Adapter cache time: 0.026761596905998886 Engine time: 0.11178175231907517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23904447 . Total output tokens: 21060636
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.7599331490928307,
    "estimated_duration": 3599.655120014091,
    "input_throughput": 2487.341342846464,
    "output_throughput": 2143.6470280435624,
    "total_throughput": 4630.988370890027,
    "itl": 28.527861269524497,
    "ttft": 8348.904866528148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 35993,
    "finished_requests": 35910,
    "scheduler_time": 8.690466244256454
}
#Debug simulation 
Total elapsed time: 2.7600432510953397. Arrivals time: 0.09368620079476386 Scheduler time: 2.351506121805869 Scheduler overhead time: 0.11751359910704195 Adapter cache time: 0.026972667430527508 Engine time: 0.11504353280179203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23904447 . Total output tokens: 21060636
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7651609630556777,
    "estimated_duration": 3599.630879904015,
    "input_throughput": 2487.358092738317,
    "output_throughput": 2143.661463479211,
    "total_throughput": 4631.019556217528,
    "itl": 28.528058893061225,
    "ttft": 8348.708809668662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2367897061258555,
    "arrivals": 35993,
    "finished_requests": 35910,
    "scheduler_time": 8.690448772418202
}
#Debug simulation 
Total elapsed time: 2.765336337964982. Arrivals time: 0.09363075636792928 Scheduler time: 2.358759167836979 Scheduler overhead time: 0.1162490964634344 Adapter cache time: 0.026885510073043406 Engine time: 0.11465920764021575 
