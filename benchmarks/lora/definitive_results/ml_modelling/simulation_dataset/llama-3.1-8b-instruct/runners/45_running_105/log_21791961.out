INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_64_slots_64_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_64_slots_64_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 8640, 8640, 270, 8640, 270, 540, 270, 8640, 540, 8640, 270, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 8640, 270, 270, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 8640, 540]
Prompts retrieved: 207090 . Total input tokens: 46129286 . Total output tokens: 40647886
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.866990508046001,
    "estimated_duration": 3600.0262248180047,
    "input_throughput": 4769.305534952871,
    "output_throughput": 4136.257924274643,
    "total_throughput": 8905.563459227515,
    "itl": 53.52034148258085,
    "ttft": 13011.36170880191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 69367,
    "finished_requests": 69117,
    "scheduler_time": 48.322535427148374
}
#Debug simulation 
Total elapsed time: 4.867086669430137. Arrivals time: 0.1570217781700194 Scheduler time: 4.4771673190407455 Scheduler overhead time: 0.07794230338186026 Adapter cache time: 0.03669499047100544 Engine time: 0.08140234230086207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_64_slots_64_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_64_slots_64_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 8640, 8640, 270, 8640, 270, 540, 270, 8640, 540, 8640, 270, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 8640, 270, 270, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 8640, 540]
Prompts retrieved: 207090 . Total input tokens: 46129286 . Total output tokens: 40647886
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.830000000074506,
    "estimated_duration": 3600.0263545189136,
    "input_throughput": 4769.305363125445,
    "output_throughput": 4136.2577752545085,
    "total_throughput": 8905.563138379954,
    "itl": 53.520789152740576,
    "ttft": 13011.38829865116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489668,
    "arrivals": 69367,
    "finished_requests": 69117,
    "scheduler_time": 48.32280476131514
}
#Debug simulation 
Total elapsed time: 4.830103729851544. Arrivals time: 0.1576260863803327 Scheduler time: 4.4435229897499084 Scheduler overhead time: 0.07743516098707914 Adapter cache time: 0.03644705656915903 Engine time: 0.07856429740786552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_64_slots_64_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_64_slots_64_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 8640, 8640, 270, 8640, 270, 540, 270, 8640, 540, 8640, 270, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 8640, 270, 270, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 8640, 540]
Prompts retrieved: 207090 . Total input tokens: 46129286 . Total output tokens: 40647886
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.816369520034641,
    "estimated_duration": 3600.006580773169,
    "input_throughput": 4769.331559475233,
    "output_throughput": 4136.28049446564,
    "total_throughput": 8905.612053940873,
    "itl": 53.52095729400668,
    "ttft": 13011.23674568231,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 69367,
    "finished_requests": 69117,
    "scheduler_time": 48.322573633608066
}
#Debug simulation 
Total elapsed time: 4.816457697190344. Arrivals time: 0.15604219865053892 Scheduler time: 4.430899726692587 Scheduler overhead time: 0.07758087385445833 Adapter cache time: 0.03659878671169281 Engine time: 0.07867328962311149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_64_slots_64_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_64_slots_64_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 8640, 8640, 270, 8640, 270, 540, 270, 8640, 540, 8640, 270, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 8640, 270, 270, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 8640, 540]
Prompts retrieved: 207090 . Total input tokens: 46129286 . Total output tokens: 40647886
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.86554796108976,
    "estimated_duration": 3600.017002715293,
    "input_throughput": 4769.317752402254,
    "output_throughput": 4136.26852005666,
    "total_throughput": 8905.586272458915,
    "itl": 53.520576806792626,
    "ttft": 13011.192162693482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4391118016093971,
    "arrivals": 69367,
    "finished_requests": 69117,
    "scheduler_time": 48.32252180313996
}
#Debug simulation 
Total elapsed time: 4.8656370169483125. Arrivals time: 0.15714291669428349 Scheduler time: 4.47761005628854 Scheduler overhead time: 0.07771563483402133 Adapter cache time: 0.036544132977724075 Engine time: 0.07979475473985076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_64_slots_64_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_64_slots_64_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 8640, 8640, 270, 8640, 270, 540, 270, 8640, 540, 8640, 270, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 8640, 270, 270, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 8640, 540]
Prompts retrieved: 207090 . Total input tokens: 46129286 . Total output tokens: 40647886
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.83605117816478,
    "estimated_duration": 3600.046753093587,
    "input_throughput": 4769.278339300961,
    "output_throughput": 4136.234338402466,
    "total_throughput": 8905.512677703427,
    "itl": 53.520840751468974,
    "ttft": 13011.453869397525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 69367,
    "finished_requests": 69117,
    "scheduler_time": 48.32311267291253
}
#Debug simulation 
Total elapsed time: 4.836140723899007. Arrivals time: 0.1569793107919395 Scheduler time: 4.448685316834599 Scheduler overhead time: 0.0780786364339292 Adapter cache time: 0.03642671974375844 Engine time: 0.07914641825482249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_64_slots_64_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_64_slots_64_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 8640, 8640, 270, 8640, 270, 540, 270, 8640, 540, 8640, 270, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 8640, 270, 270, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 8640, 540]
Prompts retrieved: 207090 . Total input tokens: 46129286 . Total output tokens: 40647886
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.848359546158463,
    "estimated_duration": 3600.042460908335,
    "input_throughput": 4769.284025518936,
    "output_throughput": 4136.239269867641,
    "total_throughput": 8905.523295386578,
    "itl": 53.51992561122552,
    "ttft": 13011.510351429353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 69367,
    "finished_requests": 69117,
    "scheduler_time": 48.3226526446313
}
#Debug simulation 
Total elapsed time: 4.84844900527969. Arrivals time: 0.15689153410494328 Scheduler time: 4.461109196767211 Scheduler overhead time: 0.07760080462321639 Adapter cache time: 0.03655008412897587 Engine time: 0.07966365152969956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_64_slots_64_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_64_slots_64_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 8640, 8640, 270, 8640, 270, 540, 270, 8640, 540, 8640, 270, 540, 8640, 8640, 8640, 270, 8640, 540, 540, 270, 270, 270, 8640, 270, 270, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 8640, 540]
Prompts retrieved: 207090 . Total input tokens: 46129286 . Total output tokens: 40647886
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.873222711961716,
    "estimated_duration": 3600.026383679021,
    "input_throughput": 4769.305324494213,
    "output_throughput": 4136.257741750943,
    "total_throughput": 8905.563066245155,
    "itl": 53.52087582387128,
    "ttft": 13011.384211144925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 69367,
    "finished_requests": 69117,
    "scheduler_time": 48.32278528931113
}
#Debug simulation 
Total elapsed time: 4.873312841635197. Arrivals time: 0.16083085350692272 Scheduler time: 4.48391780955717 Scheduler overhead time: 0.07674954924732447 Adapter cache time: 0.03650814387947321 Engine time: 0.0787810836918652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 8640, 8640, 135, 8640, 135, 540, 135, 8640, 540, 8640, 135, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 8640, 135, 135, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 8640, 540]
Prompts retrieved: 204255 . Total input tokens: 45485399 . Total output tokens: 40094334
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.844581535086036,
    "estimated_duration": 3600.0181942656823,
    "input_throughput": 4728.084159994618,
    "output_throughput": 4100.748719413417,
    "total_throughput": 8828.832879408035,
    "itl": 50.6733919553284,
    "ttft": 11820.11569461083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 68405,
    "finished_requests": 68181,
    "scheduler_time": 47.131114253941384
}
#Debug simulation 
Total elapsed time: 4.8447011429816484. Arrivals time: 0.1578101785853505 Scheduler time: 4.457832539919764 Scheduler overhead time: 0.07854726817458868 Adapter cache time: 0.03216562606394291 Engine time: 0.08105680160224438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 8640, 8640, 135, 8640, 135, 540, 135, 8640, 540, 8640, 135, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 8640, 135, 135, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 8640, 540]
Prompts retrieved: 204255 . Total input tokens: 45485399 . Total output tokens: 40094334
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.84577850298956,
    "estimated_duration": 3600.0175299539737,
    "input_throughput": 4728.08503246861,
    "output_throughput": 4100.749476125118,
    "total_throughput": 8828.834508593729,
    "itl": 50.67408464952902,
    "ttft": 11820.089691938438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 68405,
    "finished_requests": 68181,
    "scheduler_time": 47.13140802085632
}
#Debug simulation 
Total elapsed time: 4.845880855806172. Arrivals time: 0.15635476354509592 Scheduler time: 4.4586884486489 Scheduler overhead time: 0.0793869374319911 Adapter cache time: 0.03245607949793339 Engine time: 0.08145618718117476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 8640, 8640, 135, 8640, 135, 540, 135, 8640, 540, 8640, 135, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 8640, 135, 135, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 8640, 540]
Prompts retrieved: 204255 . Total input tokens: 45485399 . Total output tokens: 40094334
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.834554004017264,
    "estimated_duration": 3600.0280341900598,
    "input_throughput": 4728.0712367645365,
    "output_throughput": 4100.737510873676,
    "total_throughput": 8828.808747638213,
    "itl": 50.67408770231817,
    "ttft": 11819.924587712754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48098376162815837,
    "arrivals": 68405,
    "finished_requests": 68181,
    "scheduler_time": 47.13156164161179
}
#Debug simulation 
Total elapsed time: 4.834690855350345. Arrivals time: 0.15720140747725964 Scheduler time: 4.44795790174976 Scheduler overhead time: 0.07883124565705657 Adapter cache time: 0.03221518732607365 Engine time: 0.08101539453491569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 8640, 8640, 135, 8640, 135, 540, 135, 8640, 540, 8640, 135, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 8640, 135, 135, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 8640, 540]
Prompts retrieved: 204255 . Total input tokens: 45485399 . Total output tokens: 40094334
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.868829760234803,
    "estimated_duration": 3600.012971000518,
    "input_throughput": 4728.091019980258,
    "output_throughput": 4100.754669196962,
    "total_throughput": 8828.84568917722,
    "itl": 50.67370382879101,
    "ttft": 11820.057093419306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 68405,
    "finished_requests": 68181,
    "scheduler_time": 47.13121862593954
}
#Debug simulation 
Total elapsed time: 4.868920059874654. Arrivals time: 0.15741812624037266 Scheduler time: 4.481268269009888 Scheduler overhead time: 0.07891618646681309 Adapter cache time: 0.03232937818393111 Engine time: 0.0816449555568397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 8640, 8640, 135, 8640, 135, 540, 135, 8640, 540, 8640, 135, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 8640, 135, 135, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 8640, 540]
Prompts retrieved: 204255 . Total input tokens: 45485399 . Total output tokens: 40094334
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.8445763676427305,
    "estimated_duration": 3600.019716654887,
    "input_throughput": 4728.08216056549,
    "output_throughput": 4100.746985274142,
    "total_throughput": 8828.829145839632,
    "itl": 50.67396227802612,
    "ttft": 11819.887421749232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924963,
    "arrivals": 68405,
    "finished_requests": 68181,
    "scheduler_time": 47.13143224872906
}
#Debug simulation 
Total elapsed time: 4.844676794018596. Arrivals time: 0.15691928146407008 Scheduler time: 4.458630184642971 Scheduler overhead time: 0.07894389750435948 Adapter cache time: 0.032188596203923225 Engine time: 0.08079019235447049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 8640, 8640, 135, 8640, 135, 540, 135, 8640, 540, 8640, 135, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 8640, 135, 135, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 8640, 540]
Prompts retrieved: 204255 . Total input tokens: 45485399 . Total output tokens: 40094334
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.8700772961601615,
    "estimated_duration": 3600.0503087823736,
    "input_throughput": 4728.143648013939,
    "output_throughput": 4100.91074671492,
    "total_throughput": 8829.054394728859,
    "itl": 50.6733898077953,
    "ttft": 11819.746801898775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 68405,
    "finished_requests": 68182,
    "scheduler_time": 47.13152290247823
}
#Debug simulation 
Total elapsed time: 4.870167807210237. Arrivals time: 0.15810752799734473 Scheduler time: 4.481853070668876 Scheduler overhead time: 0.07930491445586085 Adapter cache time: 0.032284319400787354 Engine time: 0.08108307188376784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 8640, 8640, 135, 8640, 135, 540, 135, 8640, 540, 8640, 135, 540, 8640, 8640, 8640, 135, 8640, 540, 540, 135, 135, 135, 8640, 135, 135, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 8640, 540]
Prompts retrieved: 204255 . Total input tokens: 45485399 . Total output tokens: 40094334
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.8638550587929785,
    "estimated_duration": 3600.0181601886347,
    "input_throughput": 4728.084204749712,
    "output_throughput": 4100.748758230279,
    "total_throughput": 8828.832962979992,
    "itl": 50.674088959373215,
    "ttft": 11820.115363386965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 68405,
    "finished_requests": 68181,
    "scheduler_time": 47.13141594657247
}
#Debug simulation 
Total elapsed time: 4.863944824784994. Arrivals time: 0.15740146674215794 Scheduler time: 4.475409392733127 Scheduler overhead time: 0.07971247006207705 Adapter cache time: 0.032365333288908005 Engine time: 0.08147107623517513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 8640, 8640, 66, 8640, 66, 540, 66, 8640, 540, 8640, 66, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 8640, 66, 66, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 8640, 540]
Prompts retrieved: 202806 . Total input tokens: 45162460 . Total output tokens: 39809499
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.838505420833826,
    "estimated_duration": 3600.0518759866973,
    "input_throughput": 4652.162684575128,
    "output_throughput": 4087.370823223763,
    "total_throughput": 8739.533507798891,
    "itl": 49.216533484725375,
    "ttft": 11418.514247124533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 67954,
    "finished_requests": 67740,
    "scheduler_time": 46.52861954390461
}
#Debug simulation 
Total elapsed time: 4.838592989835888. Arrivals time: 0.15645116893574595 Scheduler time: 4.450352699030191 Scheduler overhead time: 0.08021274395287037 Adapter cache time: 0.03015602706000209 Engine time: 0.08333368878811598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 8640, 8640, 66, 8640, 66, 540, 66, 8640, 540, 8640, 66, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 8640, 66, 66, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 8640, 540]
Prompts retrieved: 202806 . Total input tokens: 45162460 . Total output tokens: 39809499
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.833619039040059,
    "estimated_duration": 3600.0466908113117,
    "input_throughput": 4652.105219286946,
    "output_throughput": 4087.363377135499,
    "total_throughput": 8739.468596422445,
    "itl": 49.217318779336885,
    "ttft": 11471.378161428756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489669,
    "arrivals": 67954,
    "finished_requests": 67739,
    "scheduler_time": 46.52886452727357
}
#Debug simulation 
Total elapsed time: 4.833711434621364. Arrivals time: 0.15696583734825253 Scheduler time: 4.445306391920894 Scheduler overhead time: 0.08048972999677062 Adapter cache time: 0.03031767951324582 Engine time: 0.0825833547860384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 8640, 8640, 66, 8640, 66, 540, 66, 8640, 540, 8640, 66, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 8640, 66, 66, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 8640, 540]
Prompts retrieved: 202806 . Total input tokens: 45162460 . Total output tokens: 39809499
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.850099134724587,
    "estimated_duration": 3600.0269504052485,
    "input_throughput": 4652.130728664331,
    "output_throughput": 4087.3857898045994,
    "total_throughput": 8739.51651846893,
    "itl": 49.217184454829585,
    "ttft": 11418.541181450108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 67954,
    "finished_requests": 67739,
    "scheduler_time": 46.52880343091608
}
#Debug simulation 
Total elapsed time: 4.8501890120096505. Arrivals time: 0.15719584887847304 Scheduler time: 4.460633770097047 Scheduler overhead time: 0.08135422691702843 Adapter cache time: 0.030124958604574203 Engine time: 0.08278727065771818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 8640, 8640, 66, 8640, 66, 540, 66, 8640, 540, 8640, 66, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 8640, 66, 66, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 8640, 540]
Prompts retrieved: 202806 . Total input tokens: 45162460 . Total output tokens: 39809499
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.831086993217468,
    "estimated_duration": 3600.031401635379,
    "input_throughput": 4652.124976574374,
    "output_throughput": 4087.38073598902,
    "total_throughput": 8739.505712563394,
    "itl": 49.21658785389921,
    "ttft": 11418.502476057498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4391118016093973,
    "arrivals": 67954,
    "finished_requests": 67739,
    "scheduler_time": 46.5284855590529
}
#Debug simulation 
Total elapsed time: 4.831179074011743. Arrivals time: 0.15999314980581403 Scheduler time: 4.43996902089566 Scheduler overhead time: 0.08022254379466176 Adapter cache time: 0.029970428440719843 Engine time: 0.08313877740874887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 8640, 8640, 66, 8640, 66, 540, 66, 8640, 540, 8640, 66, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 8640, 66, 66, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 8640, 540]
Prompts retrieved: 202806 . Total input tokens: 45162460 . Total output tokens: 39809499
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.861338625662029,
    "estimated_duration": 3600.0518686010787,
    "input_throughput": 4652.162694119185,
    "output_throughput": 4087.370831609132,
    "total_throughput": 8739.533525728317,
    "itl": 49.21716528932389,
    "ttft": 11418.464005367194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 67954,
    "finished_requests": 67740,
    "scheduler_time": 46.528921154585866
}
#Debug simulation 
Total elapsed time: 4.861434815917164. Arrivals time: 0.15813161432743073 Scheduler time: 4.471723487135023 Scheduler overhead time: 0.08066016621887684 Adapter cache time: 0.03018109081313014 Engine time: 0.08243743935599923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 8640, 8640, 66, 8640, 66, 540, 66, 8640, 540, 8640, 66, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 8640, 66, 66, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 8640, 540]
Prompts retrieved: 202806 . Total input tokens: 45162460 . Total output tokens: 39809499
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.824250851292163,
    "estimated_duration": 3600.0168870493762,
    "input_throughput": 4652.143733060854,
    "output_throughput": 4087.3972155337224,
    "total_throughput": 8739.540948594577,
    "itl": 49.215981230096965,
    "ttft": 11418.462289943664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 67954,
    "finished_requests": 67739,
    "scheduler_time": 46.52810518319706
}
#Debug simulation 
Total elapsed time: 4.824342736043036. Arrivals time: 0.1566329812631011 Scheduler time: 4.4361913916654885 Scheduler overhead time: 0.08071253960952163 Adapter cache time: 0.03024230245500803 Engine time: 0.08246204582974315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 8640, 8640, 66, 8640, 66, 540, 66, 8640, 540, 8640, 66, 540, 8640, 8640, 8640, 66, 8640, 540, 540, 66, 66, 66, 8640, 66, 66, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 8640, 540]
Prompts retrieved: 202806 . Total input tokens: 45162460 . Total output tokens: 39809499
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.830042032059282,
    "estimated_duration": 3600.052045376457,
    "input_throughput": 4652.1624656814265,
    "output_throughput": 4087.370630904665,
    "total_throughput": 8739.533096586092,
    "itl": 49.217355664025135,
    "ttft": 11418.476026187504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 67954,
    "finished_requests": 67740,
    "scheduler_time": 46.528925240368785
}
#Debug simulation 
Total elapsed time: 4.830130566377193. Arrivals time: 0.15659652231261134 Scheduler time: 4.442797394003719 Scheduler overhead time: 0.0804303134791553 Adapter cache time: 0.030146703589707613 Engine time: 0.08231571363285184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 8640, 8640, 33, 8640, 33, 540, 33, 8640, 540, 8640, 33, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 8640, 33, 33, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 8640, 540]
Prompts retrieved: 202113 . Total input tokens: 45006848 . Total output tokens: 39671291
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.789488181006163,
    "estimated_duration": 3600.030205025432,
    "input_throughput": 4677.574087154371,
    "output_throughput": 4032.386444906911,
    "total_throughput": 8709.960532061283,
    "itl": 48.064449608809866,
    "ttft": 13904.814853176855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 67703,
    "finished_requests": 67442,
    "scheduler_time": 45.48423468240151
}
#Debug simulation 
Total elapsed time: 4.789577660616487. Arrivals time: 0.15760661102831364 Scheduler time: 4.398219091352075 Scheduler overhead time: 0.08172644209116697 Adapter cache time: 0.028760173358023167 Engine time: 0.08449606411159039 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 8640, 8640, 33, 8640, 33, 540, 33, 8640, 540, 8640, 33, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 8640, 33, 33, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 8640, 540]
Prompts retrieved: 202113 . Total input tokens: 45006848 . Total output tokens: 39671291
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.808879823889583,
    "estimated_duration": 3600.025011422787,
    "input_throughput": 4677.580835291141,
    "output_throughput": 4032.3922622589685,
    "total_throughput": 8709.97309755011,
    "itl": 48.065193694996736,
    "ttft": 13904.674474701973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489667,
    "arrivals": 67703,
    "finished_requests": 67442,
    "scheduler_time": 45.4844644024734
}
#Debug simulation 
Total elapsed time: 4.809150000102818. Arrivals time: 0.1572556970641017 Scheduler time: 4.41907916450873 Scheduler overhead time: 0.0813972121104598 Adapter cache time: 0.02869272604584694 Engine time: 0.08404440386220813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 8640, 8640, 33, 8640, 33, 540, 33, 8640, 540, 8640, 33, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 8640, 33, 33, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 8640, 540]
Prompts retrieved: 202113 . Total input tokens: 45006848 . Total output tokens: 39671291
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.795711577869952,
    "estimated_duration": 3600.0608947134056,
    "input_throughput": 4677.596433084939,
    "output_throughput": 4032.399846713055,
    "total_throughput": 8709.996279797993,
    "itl": 48.06589031811649,
    "ttft": 13904.62315199605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 67703,
    "finished_requests": 67443,
    "scheduler_time": 45.484978216019414
}
#Debug simulation 
Total elapsed time: 4.795806318987161. Arrivals time: 0.15652693016454577 Scheduler time: 4.405497127212584 Scheduler overhead time: 0.08175784489139915 Adapter cache time: 0.028940402437001467 Engine time: 0.08422736125066876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 8640, 8640, 33, 8640, 33, 540, 33, 8640, 540, 8640, 33, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 8640, 33, 33, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 8640, 540]
Prompts retrieved: 202113 . Total input tokens: 45006848 . Total output tokens: 39671291
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.764259935356677,
    "estimated_duration": 3600.0145114557895,
    "input_throughput": 4677.594478137369,
    "output_throughput": 4032.4040233186915,
    "total_throughput": 8709.99850145606,
    "itl": 48.064859781507856,
    "ttft": 13798.803167706454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 67703,
    "finished_requests": 67442,
    "scheduler_time": 45.48405992166917
}
#Debug simulation 
Total elapsed time: 4.764351584017277. Arrivals time: 0.15700616408139467 Scheduler time: 4.374413937795907 Scheduler overhead time: 0.0818940494209528 Adapter cache time: 0.028930217493325472 Engine time: 0.0834573283791542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 8640, 8640, 33, 8640, 33, 540, 33, 8640, 540, 8640, 33, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 8640, 33, 33, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 8640, 540]
Prompts retrieved: 202113 . Total input tokens: 45006848 . Total output tokens: 39671291
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.78397627081722,
    "estimated_duration": 3600.0569675053553,
    "input_throughput": 4677.6015357526285,
    "output_throughput": 4032.404245552652,
    "total_throughput": 8710.00578130528,
    "itl": 48.065865000149856,
    "ttft": 13904.707101251952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 67703,
    "finished_requests": 67443,
    "scheduler_time": 45.48496575379605
}
#Debug simulation 
Total elapsed time: 4.784070978872478. Arrivals time: 0.16111478116363287 Scheduler time: 4.3905021930113435 Scheduler overhead time: 0.08175551053136587 Adapter cache time: 0.028847229201346636 Engine time: 0.08306771190837026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 8640, 8640, 33, 8640, 33, 540, 33, 8640, 540, 8640, 33, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 8640, 33, 33, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 8640, 540]
Prompts retrieved: 202113 . Total input tokens: 45006848 . Total output tokens: 39671291
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.78868673555553,
    "estimated_duration": 3600.0607975321363,
    "input_throughput": 4677.596559353573,
    "output_throughput": 4032.399955565032,
    "total_throughput": 8709.996514918605,
    "itl": 48.06448100308659,
    "ttft": 13904.600889199992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 67703,
    "finished_requests": 67443,
    "scheduler_time": 45.48452282068269
}
#Debug simulation 
Total elapsed time: 4.788802343886346. Arrivals time: 0.1568610556423664 Scheduler time: 4.400062067434192 Scheduler overhead time: 0.08144394541159272 Adapter cache time: 0.028649105690419674 Engine time: 0.0830966611392796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 8640, 8640, 33, 8640, 33, 540, 33, 8640, 540, 8640, 33, 540, 8640, 8640, 8640, 33, 8640, 540, 540, 33, 33, 33, 8640, 33, 33, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 8640, 540]
Prompts retrieved: 202113 . Total input tokens: 45006848 . Total output tokens: 39671291
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.815439885947853,
    "estimated_duration": 3600.048558851218,
    "input_throughput": 4677.612461253455,
    "output_throughput": 4032.413664062455,
    "total_throughput": 8710.02612531591,
    "itl": 48.06561735797692,
    "ttft": 13904.680587943498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 67703,
    "finished_requests": 67443,
    "scheduler_time": 45.484860629761776
}
#Debug simulation 
Total elapsed time: 4.815540399868041. Arrivals time: 0.1586745730601251 Scheduler time: 4.423644790891558 Scheduler overhead time: 0.08181627048179507 Adapter cache time: 0.02885558921843767 Engine time: 0.08392975060269237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 8640, 8640, 135, 8640, 135, 270, 135, 8640, 270, 8640, 135, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 8640, 135, 135, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 8640, 270]
Prompts retrieved: 198585 . Total input tokens: 44258747 . Total output tokens: 38968819
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.752652132883668,
    "estimated_duration": 3600.0095066378426,
    "input_throughput": 4571.458205778451,
    "output_throughput": 3992.8611225875975,
    "total_throughput": 8564.31932836605,
    "itl": 46.32163108067513,
    "ttft": 11168.964961723339,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 66533,
    "finished_requests": 66327,
    "scheduler_time": 44.34832362178552
}
#Debug simulation 
Total elapsed time: 4.7527393149212. Arrivals time: 0.15478292247280478 Scheduler time: 4.360208006110042 Scheduler overhead time: 0.08409585105255246 Adapter cache time: 0.028906099498271942 Engine time: 0.08513724524527788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 8640, 8640, 135, 8640, 135, 270, 135, 8640, 270, 8640, 135, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 8640, 135, 135, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 8640, 270]
Prompts retrieved: 198585 . Total input tokens: 44258747 . Total output tokens: 38968819
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.769400034099817,
    "estimated_duration": 3600.0026643242977,
    "input_throughput": 4571.420783403481,
    "output_throughput": 3992.8217671744305,
    "total_throughput": 8564.242550577912,
    "itl": 46.322116663391945,
    "ttft": 11223.141042591784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489668,
    "arrivals": 66533,
    "finished_requests": 66326,
    "scheduler_time": 44.34851189589167
}
#Debug simulation 
Total elapsed time: 4.769489195197821. Arrivals time: 0.1550720459781587 Scheduler time: 4.374662634916604 Scheduler overhead time: 0.08429637039080262 Adapter cache time: 0.028743830043822527 Engine time: 0.08695554081350565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 8640, 8640, 135, 8640, 135, 270, 135, 8640, 270, 8640, 135, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 8640, 135, 135, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 8640, 270]
Prompts retrieved: 198585 . Total input tokens: 44258747 . Total output tokens: 38968819
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.765670977998525,
    "estimated_duration": 3600.03836237799,
    "input_throughput": 4571.421563721673,
    "output_throughput": 3992.8291182166995,
    "total_throughput": 8564.250681938373,
    "itl": 46.322323567501215,
    "ttft": 11168.852713136297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 66533,
    "finished_requests": 66327,
    "scheduler_time": 44.349082459674584
}
#Debug simulation 
Total elapsed time: 4.765761012211442. Arrivals time: 0.15578205231577158 Scheduler time: 4.37244977010414 Scheduler overhead time: 0.08327533071860671 Adapter cache time: 0.02880525030195713 Engine time: 0.08591655781492591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 8640, 8640, 135, 8640, 135, 270, 135, 8640, 270, 8640, 135, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 8640, 135, 135, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 8640, 270]
Prompts retrieved: 198585 . Total input tokens: 44258747 . Total output tokens: 38968819
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.7569668386131525,
    "estimated_duration": 3600.0473141652687,
    "input_throughput": 4571.410196539569,
    "output_throughput": 3992.8191897480465,
    "total_throughput": 8564.229386287616,
    "itl": 46.32180100545556,
    "ttft": 11222.939512771914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 66533,
    "finished_requests": 66327,
    "scheduler_time": 44.34889001783592
}
#Debug simulation 
Total elapsed time: 4.7570823966525495. Arrivals time: 0.1542793926782906 Scheduler time: 4.365805687382817 Scheduler overhead time: 0.08356469357386231 Adapter cache time: 0.028625070117413998 Engine time: 0.08522515790537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 8640, 8640, 135, 8640, 135, 270, 135, 8640, 270, 8640, 135, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 8640, 135, 135, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 8640, 270]
Prompts retrieved: 198585 . Total input tokens: 44258747 . Total output tokens: 38968819
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.738591345958412,
    "estimated_duration": 3600.0386763709603,
    "input_throughput": 4571.421165005335,
    "output_throughput": 3992.828769964809,
    "total_throughput": 8564.249934970145,
    "itl": 46.32250704254702,
    "ttft": 11168.960846327273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 66533,
    "finished_requests": 66327,
    "scheduler_time": 44.34909050831572
}
#Debug simulation 
Total elapsed time: 4.738713414873928. Arrivals time: 0.15391284693032503 Scheduler time: 4.3473608288913965 Scheduler overhead time: 0.08370068203657866 Adapter cache time: 0.02862652065232396 Engine time: 0.08551349537447095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 8640, 8640, 135, 8640, 135, 270, 135, 8640, 270, 8640, 135, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 8640, 135, 135, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 8640, 270]
Prompts retrieved: 198585 . Total input tokens: 44258747 . Total output tokens: 38968819
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.746149597223848,
    "estimated_duration": 3600.0385140856415,
    "input_throughput": 4571.421371079392,
    "output_throughput": 3992.8289499566304,
    "total_throughput": 8564.250321036023,
    "itl": 46.3215138750966,
    "ttft": 11168.865285083783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 66533,
    "finished_requests": 66327,
    "scheduler_time": 44.34862706433801
}
#Debug simulation 
Total elapsed time: 4.746239076368511. Arrivals time: 0.15404949057847261 Scheduler time: 4.3544270298443735 Scheduler overhead time: 0.08344049425795674 Adapter cache time: 0.02875326108187437 Engine time: 0.08599043404683471 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 8640, 8640, 135, 8640, 135, 270, 135, 8640, 270, 8640, 135, 270, 8640, 8640, 8640, 135, 8640, 270, 270, 135, 135, 135, 8640, 135, 135, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 8640, 270]
Prompts retrieved: 198585 . Total input tokens: 44258747 . Total output tokens: 38968819
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.775278714019805,
    "estimated_duration": 3600.011608939445,
    "input_throughput": 4571.455536180418,
    "output_throughput": 3992.8587908733566,
    "total_throughput": 8564.314327053775,
    "itl": 46.322405588722916,
    "ttft": 11169.02599635251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 66533,
    "finished_requests": 66327,
    "scheduler_time": 44.3486455794317
}
#Debug simulation 
Total elapsed time: 4.775367060210556. Arrivals time: 0.1544657340273261 Scheduler time: 4.3819575174711645 Scheduler overhead time: 0.08394489018246531 Adapter cache time: 0.028807825408875942 Engine time: 0.08639189042150974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 8640, 8640, 66, 8640, 66, 270, 66, 8640, 270, 8640, 66, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 8640, 66, 66, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 8640, 270]
Prompts retrieved: 197136 . Total input tokens: 43922378 . Total output tokens: 38702961
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.760455023963004,
    "estimated_duration": 3600.0144913032486,
    "input_throughput": 4564.947457767244,
    "output_throughput": 3960.5301685434174,
    "total_throughput": 8525.47762631066,
    "itl": 44.73439105369813,
    "ttft": 10315.323297356714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 66085,
    "finished_requests": 65897,
    "scheduler_time": 43.367204361497635
}
#Debug simulation 
Total elapsed time: 4.76059057796374. Arrivals time: 0.15405760053545237 Scheduler time: 4.367342407815158 Scheduler overhead time: 0.08534254226833582 Adapter cache time: 0.026221370324492455 Engine time: 0.08716330537572503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 8640, 8640, 66, 8640, 66, 270, 66, 8640, 270, 8640, 66, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 8640, 66, 66, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 8640, 270]
Prompts retrieved: 197136 . Total input tokens: 43922378 . Total output tokens: 38702961
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.7168701202608645,
    "estimated_duration": 3600.047069076532,
    "input_throughput": 4564.906148356428,
    "output_throughput": 3960.4943286637053,
    "total_throughput": 8525.400477020134,
    "itl": 44.734829028578545,
    "ttft": 10315.362149930404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489666,
    "arrivals": 66085,
    "finished_requests": 65897,
    "scheduler_time": 43.36779890730443
}
#Debug simulation 
Total elapsed time: 4.716956535354257. Arrivals time: 0.15410698344931006 Scheduler time: 4.321654478553683 Scheduler overhead time: 0.08662982890382409 Adapter cache time: 0.02632935531437397 Engine time: 0.08750489540398121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 8640, 8640, 66, 8640, 66, 270, 66, 8640, 270, 8640, 66, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 8640, 66, 66, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 8640, 270]
Prompts retrieved: 197136 . Total input tokens: 43922378 . Total output tokens: 38702961
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.7168821059167385,
    "estimated_duration": 3600.03495783314,
    "input_throughput": 4564.9215056210305,
    "output_throughput": 3960.507652565092,
    "total_throughput": 8525.429158186122,
    "itl": 44.7353293592389,
    "ttft": 10315.348191969902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 66085,
    "finished_requests": 65897,
    "scheduler_time": 43.36781837930898
}
#Debug simulation 
Total elapsed time: 4.71697243116796. Arrivals time: 0.15327761601656675 Scheduler time: 4.321102465502918 Scheduler overhead time: 0.08680095570161939 Adapter cache time: 0.02631486812606454 Engine time: 0.08849844103679061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 8640, 8640, 66, 8640, 66, 270, 66, 8640, 270, 8640, 66, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 8640, 66, 66, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 8640, 270]
Prompts retrieved: 197136 . Total input tokens: 43922378 . Total output tokens: 38702961
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.7272829920984805,
    "estimated_duration": 3600.0348425296243,
    "input_throughput": 4564.921651828365,
    "output_throughput": 3960.507779413991,
    "total_throughput": 8525.429431242355,
    "itl": 44.73429823225432,
    "ttft": 10315.382149634816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 66085,
    "finished_requests": 65897,
    "scheduler_time": 43.367464186123016
}
#Debug simulation 
Total elapsed time: 4.7273727767169476. Arrivals time: 0.15368280746042728 Scheduler time: 4.333423936739564 Scheduler overhead time: 0.08594674384221435 Adapter cache time: 0.026137287262827158 Engine time: 0.0874184868298471 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 8640, 8640, 66, 8640, 66, 270, 66, 8640, 270, 8640, 66, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 8640, 66, 66, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 8640, 270]
Prompts retrieved: 197136 . Total input tokens: 43922378 . Total output tokens: 38702961
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.728210081811994,
    "estimated_duration": 3600.032382285773,
    "input_throughput": 4564.924771472643,
    "output_throughput": 3960.5104860048987,
    "total_throughput": 8525.435257477542,
    "itl": 44.7355478464045,
    "ttft": 10315.470415176082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 66085,
    "finished_requests": 65897,
    "scheduler_time": 43.367765714854905
}
#Debug simulation 
Total elapsed time: 4.728309263940901. Arrivals time: 0.15677168127149343 Scheduler time: 4.330694923643023 Scheduler overhead time: 0.08611287036910653 Adapter cache time: 0.026283636689186096 Engine time: 0.08763154176995158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 8640, 8640, 66, 8640, 66, 270, 66, 8640, 270, 8640, 66, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 8640, 66, 66, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 8640, 270]
Prompts retrieved: 197136 . Total input tokens: 43922378 . Total output tokens: 38702961
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.691301683429629,
    "estimated_duration": 3600.0338840961244,
    "input_throughput": 4564.922867142991,
    "output_throughput": 3960.5088338161036,
    "total_throughput": 8525.431700959096,
    "itl": 44.73426035506419,
    "ttft": 10315.343835928186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 66085,
    "finished_requests": 65897,
    "scheduler_time": 43.367350726623414
}
#Debug simulation 
Total elapsed time: 4.6914308234117925. Arrivals time: 0.1536713852547109 Scheduler time: 4.2987075336277485 Scheduler overhead time: 0.08521210821345448 Adapter cache time: 0.02603213395923376 Engine time: 0.08747417386621237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 8640, 8640, 66, 8640, 66, 270, 66, 8640, 270, 8640, 66, 270, 8640, 8640, 8640, 66, 8640, 270, 270, 66, 66, 66, 8640, 66, 66, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 8640, 270]
Prompts retrieved: 197136 . Total input tokens: 43922378 . Total output tokens: 38702961
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.695688142906874,
    "estimated_duration": 3600.0296295164503,
    "input_throughput": 4564.928262050824,
    "output_throughput": 3960.5135144165756,
    "total_throughput": 8525.4417764674,
    "itl": 44.73534026714418,
    "ttft": 10315.368508980577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 66085,
    "finished_requests": 65897,
    "scheduler_time": 43.36777380447081
}
#Debug simulation 
Total elapsed time: 4.695811269804835. Arrivals time: 0.15379415452480316 Scheduler time: 4.3019674750976264 Scheduler overhead time: 0.08531003119423985 Adapter cache time: 0.026173343416303396 Engine time: 0.08808313123881817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 8640, 8640, 33, 8640, 33, 270, 33, 8640, 270, 8640, 33, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 8640, 33, 33, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 8640, 270]
Prompts retrieved: 196443 . Total input tokens: 43777438 . Total output tokens: 38558919
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.680414657108486,
    "estimated_duration": 3600.0388432088075,
    "input_throughput": 4562.318829138076,
    "output_throughput": 3948.3362872080984,
    "total_throughput": 8510.655116346174,
    "itl": 44.06740347941848,
    "ttft": 8766.037234443984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 65845,
    "finished_requests": 65686,
    "scheduler_time": 42.94055542768139
}
#Debug simulation 
Total elapsed time: 4.680503754876554. Arrivals time: 0.1536013586446643 Scheduler time: 4.28219676669687 Scheduler overhead time: 0.08863534824922681 Adapter cache time: 0.0247420622035861 Engine time: 0.09014645917341113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 8640, 8640, 33, 8640, 33, 270, 33, 8640, 270, 8640, 33, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 8640, 33, 33, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 8640, 270]
Prompts retrieved: 196443 . Total input tokens: 43777438 . Total output tokens: 38558919
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.699226271361113,
    "estimated_duration": 3600.0391122214887,
    "input_throughput": 4562.318488219107,
    "output_throughput": 3948.335992168934,
    "total_throughput": 8510.65448038804,
    "itl": 44.06832783108217,
    "ttft": 8766.119531230976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489666,
    "arrivals": 65845,
    "finished_requests": 65686,
    "scheduler_time": 42.94092980393232
}
#Debug simulation 
Total elapsed time: 4.699315153993666. Arrivals time: 0.15373255079612136 Scheduler time: 4.303135781083256 Scheduler overhead time: 0.08714772993698716 Adapter cache time: 0.02482849219813943 Engine time: 0.08919683657586575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 8640, 8640, 33, 8640, 33, 270, 33, 8640, 270, 8640, 33, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 8640, 33, 33, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 8640, 270]
Prompts retrieved: 196443 . Total input tokens: 43777438 . Total output tokens: 38558919
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.6603856440633535,
    "estimated_duration": 3600.0105749573877,
    "input_throughput": 4562.354653692763,
    "output_throughput": 3948.3672906067086,
    "total_throughput": 8510.721944299472,
    "itl": 44.0680965322799,
    "ttft": 8765.963924257596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 65845,
    "finished_requests": 65686,
    "scheduler_time": 42.940605180428335
}
#Debug simulation 
Total elapsed time: 4.660476298071444. Arrivals time: 0.15280930418521166 Scheduler time: 4.265879340469837 Scheduler overhead time: 0.08725642831996083 Adapter cache time: 0.024677817709743977 Engine time: 0.08860476035624743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 8640, 8640, 33, 8640, 33, 270, 33, 8640, 270, 8640, 33, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 8640, 33, 33, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 8640, 270]
Prompts retrieved: 196443 . Total input tokens: 43777438 . Total output tokens: 38558919
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.655627285130322,
    "estimated_duration": 3600.01374001286,
    "input_throughput": 4562.350642567639,
    "output_throughput": 3948.363819286207,
    "total_throughput": 8510.714461853846,
    "itl": 44.067370583057595,
    "ttft": 8766.070199511,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.439111801609397,
    "arrivals": 65845,
    "finished_requests": 65686,
    "scheduler_time": 42.94029956591382
}
#Debug simulation 
Total elapsed time: 4.655715839006007. Arrivals time: 0.15234757959842682 Scheduler time: 4.261547305621207 Scheduler overhead time: 0.08687795605510473 Adapter cache time: 0.02474175952374935 Engine time: 0.08886551298201084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 8640, 8640, 33, 8640, 33, 270, 33, 8640, 270, 8640, 33, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 8640, 33, 33, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 8640, 270]
Prompts retrieved: 196443 . Total input tokens: 43777438 . Total output tokens: 38558919
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.702785557601601,
    "estimated_duration": 3600.0046128364334,
    "input_throughput": 4562.362209602605,
    "output_throughput": 3948.3738296659294,
    "total_throughput": 8510.736039268535,
    "itl": 44.06837473218886,
    "ttft": 8711.572185306308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 65845,
    "finished_requests": 65686,
    "scheduler_time": 42.940564896247686
}
#Debug simulation 
Total elapsed time: 4.702876309864223. Arrivals time: 0.15353676490485668 Scheduler time: 4.306634550448507 Scheduler overhead time: 0.08719611587002873 Adapter cache time: 0.024716461542993784 Engine time: 0.08934466075152159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 8640, 8640, 33, 8640, 33, 270, 33, 8640, 270, 8640, 33, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 8640, 33, 33, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 8640, 270]
Prompts retrieved: 196443 . Total input tokens: 43777438 . Total output tokens: 38558919
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.704738147556782,
    "estimated_duration": 3600.010489574612,
    "input_throughput": 4562.354761899811,
    "output_throughput": 3948.367384251591,
    "total_throughput": 8510.722146151402,
    "itl": 44.06713071628463,
    "ttft": 8766.071561538794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 65845,
    "finished_requests": 65686,
    "scheduler_time": 42.94015803860739
}
#Debug simulation 
Total elapsed time: 4.704829107969999. Arrivals time: 0.1548991622403264 Scheduler time: 4.307356178294867 Scheduler overhead time: 0.08714288473129272 Adapter cache time: 0.024665487464517355 Engine time: 0.08933539036661386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 8640, 8640, 33, 8640, 33, 270, 33, 8640, 270, 8640, 33, 270, 8640, 8640, 8640, 33, 8640, 270, 270, 33, 33, 33, 8640, 33, 33, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 8640, 270]
Prompts retrieved: 196443 . Total input tokens: 43777438 . Total output tokens: 38558919
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.684118548873812,
    "estimated_duration": 3600.0385373727204,
    "input_throughput": 4562.319216723299,
    "output_throughput": 3948.3366226333187,
    "total_throughput": 8510.655839356617,
    "itl": 44.06815411803535,
    "ttft": 8766.013878879286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 65845,
    "finished_requests": 65686,
    "scheduler_time": 42.94089752741785
}
#Debug simulation 
Total elapsed time: 4.684292962774634. Arrivals time: 0.15504411747679114 Scheduler time: 4.288745703175664 Scheduler overhead time: 0.08620134554803371 Adapter cache time: 0.024755849968641996 Engine time: 0.08853451302275062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 8640, 8640, 66, 8640, 66, 135, 66, 8640, 135, 8640, 66, 135, 8640, 8640, 8640, 66, 8640, 135, 135, 66, 66, 66, 8640, 66, 66, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 8640, 135]
Prompts retrieved: 194301 . Total input tokens: 43289625 . Total output tokens: 38134959
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.647197731770575,
    "estimated_duration": 3599.9426377004206,
    "input_throughput": 4474.811301518455,
    "output_throughput": 3925.1467098448506,
    "total_throughput": 8399.958011363306,
    "itl": 43.073907852436236,
    "ttft": 9240.803167425222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 65172,
    "finished_requests": 65006,
    "scheduler_time": 42.25814461664967
}
#Debug simulation 
Total elapsed time: 4.647324109915644. Arrivals time: 0.1538794985972345 Scheduler time: 4.250565288588405 Scheduler overhead time: 0.08798596914857626 Adapter cache time: 0.023119491059333086 Engine time: 0.08969132602214813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 8640, 8640, 66, 8640, 66, 135, 66, 8640, 135, 8640, 66, 135, 8640, 8640, 8640, 66, 8640, 135, 135, 66, 66, 66, 8640, 66, 66, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 8640, 135]
Prompts retrieved: 194301 . Total input tokens: 43289625 . Total output tokens: 38134959
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.677599688060582,
    "estimated_duration": 3599.941117541724,
    "input_throughput": 4474.813191111394,
    "output_throughput": 3925.1483673291573,
    "total_throughput": 8399.961558440551,
    "itl": 43.07466121615498,
    "ttft": 9240.826965620128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489666,
    "arrivals": 65172,
    "finished_requests": 65006,
    "scheduler_time": 42.25840193931724
}
#Debug simulation 
Total elapsed time: 4.677690534852445. Arrivals time: 0.15391764184460044 Scheduler time: 4.277955787722021 Scheduler overhead time: 0.08924407884478569 Adapter cache time: 0.023087030742317438 Engine time: 0.09122322592884302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.8-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.8-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 8640, 8640, 66, 8640, 66, 135, 66, 8640, 135, 8640, 66, 135, 8640, 8640, 8640, 66, 8640, 135, 135, 66, 66, 66, 8640, 66, 66, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 8640, 135]
Prompts retrieved: 194301 . Total input tokens: 43289625 . Total output tokens: 38134959
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.660403419286013,
    "estimated_duration": 3599.967060465844,
    "input_throughput": 4474.780943666593,
    "output_throughput": 3925.120081007493,
    "total_throughput": 8399.901024674085,
    "itl": 43.074531070722976,
    "ttft": 9240.74387458402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 65172,
    "finished_requests": 65006,
    "scheduler_time": 42.258795119683235
}
#Debug simulation 
Total elapsed time: 4.660498300101608. Arrivals time: 0.15303525840863585 Scheduler time: 4.263281207531691 Scheduler overhead time: 0.08808651752769947 Adapter cache time: 0.022997960448265076 Engine time: 0.0913209761492908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 8640, 8640, 66, 8640, 66, 135, 66, 8640, 135, 8640, 66, 135, 8640, 8640, 8640, 66, 8640, 135, 135, 66, 66, 66, 8640, 66, 66, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 8640, 135]
Prompts retrieved: 194301 . Total input tokens: 43289625 . Total output tokens: 38134959
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.679129377938807,
    "estimated_duration": 3599.936474157788,
    "input_throughput": 4474.818962956491,
    "output_throughput": 3925.1534301881848,
    "total_throughput": 8399.972393144675,
    "itl": 43.07425046591147,
    "ttft": 9240.738060372103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 65172,
    "finished_requests": 65006,
    "scheduler_time": 42.25816071393186
}
#Debug simulation 
Total elapsed time: 4.679221850819886. Arrivals time: 0.15404458018019795 Scheduler time: 4.280022455845028 Scheduler overhead time: 0.08879201160743833 Adapter cache time: 0.0234146686270833 Engine time: 0.09088235767558217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.8-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.8-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 8640, 8640, 66, 8640, 66, 135, 66, 8640, 135, 8640, 66, 135, 8640, 8640, 8640, 66, 8640, 135, 135, 66, 66, 66, 8640, 66, 66, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 8640, 135]
Prompts retrieved: 194301 . Total input tokens: 43289625 . Total output tokens: 38134959
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.666925625875592,
    "estimated_duration": 3599.957262949048,
    "input_throughput": 4474.793122072682,
    "output_throughput": 3925.1307634759532,
    "total_throughput": 8399.923885548636,
    "itl": 43.0747739638903,
    "ttft": 9240.743436818539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 65172,
    "finished_requests": 65006,
    "scheduler_time": 42.25868198798274
}
#Debug simulation 
Total elapsed time: 4.667020129039884. Arrivals time: 0.15147187979891896 Scheduler time: 4.271497772075236 Scheduler overhead time: 0.08892162190750241 Adapter cache time: 0.023253781255334616 Engine time: 0.08995131170377135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 8640, 8640, 66, 8640, 66, 135, 66, 8640, 135, 8640, 66, 135, 8640, 8640, 8640, 66, 8640, 135, 135, 66, 66, 66, 8640, 66, 66, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 8640, 135]
Prompts retrieved: 194301 . Total input tokens: 43289625 . Total output tokens: 38134959
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.675473162904382,
    "estimated_duration": 3599.965444874654,
    "input_throughput": 4474.782951857166,
    "output_throughput": 3925.121842521463,
    "total_throughput": 8399.904794378628,
    "itl": 43.07374208212655,
    "ttft": 9240.694123869238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 65172,
    "finished_requests": 65006,
    "scheduler_time": 42.258350983809784
}
#Debug simulation 
Total elapsed time: 4.675561260897666. Arrivals time: 0.15258699236437678 Scheduler time: 4.278125514276326 Scheduler overhead time: 0.08845257572829723 Adapter cache time: 0.023005893919616938 Engine time: 0.09138525743037462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.8-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.8-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 8640, 8640, 66, 8640, 66, 135, 66, 8640, 135, 8640, 66, 135, 8640, 8640, 8640, 66, 8640, 135, 135, 66, 66, 66, 8640, 66, 66, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 8640, 135]
Prompts retrieved: 194301 . Total input tokens: 43289625 . Total output tokens: 38134959
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.627777287736535,
    "estimated_duration": 3599.947444281454,
    "input_throughput": 4474.805326835918,
    "output_throughput": 3925.1414690639726,
    "total_throughput": 8399.94679589989,
    "itl": 43.07463557391301,
    "ttft": 9240.817195300426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 65172,
    "finished_requests": 65006,
    "scheduler_time": 42.25853237105995
}
#Debug simulation 
Total elapsed time: 4.627863404806703. Arrivals time: 0.15195517474785447 Scheduler time: 4.23330164514482 Scheduler overhead time: 0.08805101970210671 Adapter cache time: 0.022983419708907604 Engine time: 0.0895017758011818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 8640, 8640, 33, 8640, 33, 135, 33, 8640, 135, 8640, 33, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 8640, 33, 33, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 8640, 135]
Prompts retrieved: 193608 . Total input tokens: 43139668 . Total output tokens: 38003095
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.651681208051741,
    "estimated_duration": 3599.990551854121,
    "input_throughput": 4458.580034809606,
    "output_throughput": 3901.780795720596,
    "total_throughput": 8360.360830530202,
    "itl": 42.321435916430694,
    "ttft": 10000.566455980776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 64890,
    "finished_requests": 64711,
    "scheduler_time": 41.67211986068412
}
#Debug simulation 
Total elapsed time: 4.6517966943793. Arrivals time: 0.15206693299114704 Scheduler time: 4.254199758172035 Scheduler overhead time: 0.08917568530887365 Adapter cache time: 0.021170809399336576 Engine time: 0.09271903475746512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 8640, 8640, 33, 8640, 33, 135, 33, 8640, 135, 8640, 33, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 8640, 33, 33, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 8640, 135]
Prompts retrieved: 193608 . Total input tokens: 43139668 . Total output tokens: 38003095
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.616887635085732,
    "estimated_duration": 3600.0236380878064,
    "input_throughput": 4458.539335737692,
    "output_throughput": 3901.745491721519,
    "total_throughput": 8360.284827459212,
    "itl": 42.32190131642402,
    "ttft": 9945.051521259593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489667,
    "arrivals": 64890,
    "finished_requests": 64712,
    "scheduler_time": 41.67276302613806
}
#Debug simulation 
Total elapsed time: 4.617007473949343. Arrivals time: 0.15087306266650558 Scheduler time: 4.224102198611945 Scheduler overhead time: 0.08827211381867528 Adapter cache time: 0.021020502783358097 Engine time: 0.09071987122297287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 8640, 8640, 33, 8640, 33, 135, 33, 8640, 135, 8640, 33, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 8640, 33, 33, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 8640, 135]
Prompts retrieved: 193608 . Total input tokens: 43139668 . Total output tokens: 38003095
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.632776492275298,
    "estimated_duration": 3600.005822345471,
    "input_throughput": 4458.561122421344,
    "output_throughput": 3901.764245161283,
    "total_throughput": 8360.325367582627,
    "itl": 42.32218337749887,
    "ttft": 10000.604044074627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48098376162815837,
    "arrivals": 64890,
    "finished_requests": 64711,
    "scheduler_time": 41.672725665954445
}
#Debug simulation 
Total elapsed time: 4.632863390259445. Arrivals time: 0.15087330294772983 Scheduler time: 4.235333727207035 Scheduler overhead time: 0.08924977201968431 Adapter cache time: 0.02109018387272954 Engine time: 0.0941448351368308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 8640, 8640, 33, 8640, 33, 135, 33, 8640, 135, 8640, 33, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 8640, 33, 33, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 8640, 135]
Prompts retrieved: 193608 . Total input tokens: 43139668 . Total output tokens: 38003095
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.603118586353958,
    "estimated_duration": 3600.015127940157,
    "input_throughput": 4458.54987536786,
    "output_throughput": 3901.7547151356007,
    "total_throughput": 8360.304590503461,
    "itl": 42.3211666442598,
    "ttft": 9945.050924909932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4391118016093971,
    "arrivals": 64890,
    "finished_requests": 64712,
    "scheduler_time": 41.67251204316462
}
#Debug simulation 
Total elapsed time: 4.603219817392528. Arrivals time: 0.15120567474514246 Scheduler time: 4.209913798607886 Scheduler overhead time: 0.08899891003966331 Adapter cache time: 0.021133845206350088 Engine time: 0.08976858761161566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 8640, 8640, 33, 8640, 33, 135, 33, 8640, 135, 8640, 33, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 8640, 33, 33, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 8640, 135]
Prompts retrieved: 193608 . Total input tokens: 43139668 . Total output tokens: 38003095
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.6290811179205775,
    "estimated_duration": 3599.9974498778397,
    "input_throughput": 4458.5714916394345,
    "output_throughput": 3901.7733194440575,
    "total_throughput": 8360.344811083492,
    "itl": 42.322262589965746,
    "ttft": 10000.57687456437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924963,
    "arrivals": 64890,
    "finished_requests": 64711,
    "scheduler_time": 41.67259218728928
}
#Debug simulation 
Total elapsed time: 4.629166527185589. Arrivals time: 0.1533652702346444 Scheduler time: 4.2303160964511335 Scheduler overhead time: 0.08967783581465483 Adapter cache time: 0.0211714212782681 Engine time: 0.09215743094682693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 8640, 8640, 33, 8640, 33, 135, 33, 8640, 135, 8640, 33, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 8640, 33, 33, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 8640, 135]
Prompts retrieved: 193608 . Total input tokens: 43139668 . Total output tokens: 38003095
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.61459356918931,
    "estimated_duration": 3600.001730363389,
    "input_throughput": 4458.566190294527,
    "output_throughput": 3901.76868014509,
    "total_throughput": 8360.334870439618,
    "itl": 42.321067880739974,
    "ttft": 10000.586026876914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 64890,
    "finished_requests": 64711,
    "scheduler_time": 41.67216101982599
}
#Debug simulation 
Total elapsed time: 4.614735355135053. Arrivals time: 0.152829026337713 Scheduler time: 4.217636874411255 Scheduler overhead time: 0.08927472354844213 Adapter cache time: 0.02113901823759079 Engine time: 0.09110492980107665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 8640, 8640, 33, 8640, 33, 135, 33, 8640, 135, 8640, 33, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 8640, 33, 33, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 8640, 135]
Prompts retrieved: 193608 . Total input tokens: 43139668 . Total output tokens: 38003095
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.6213066428899765,
    "estimated_duration": 3599.983981163992,
    "input_throughput": 4458.588172609101,
    "output_throughput": 3901.7879172502176,
    "total_throughput": 8360.37608985932,
    "itl": 42.322195611062824,
    "ttft": 10000.565740181108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 64890,
    "finished_requests": 64711,
    "scheduler_time": 41.67233752828242
}
#Debug simulation 
Total elapsed time: 4.621395601890981. Arrivals time: 0.15130878193303943 Scheduler time: 4.226223933510482 Scheduler overhead time: 0.08948098495602608 Adapter cache time: 0.021113816183060408 Engine time: 0.09077265486121178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 8640, 8640, 33, 8640, 33, 66, 33, 8640, 66, 8640, 33, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 8640, 33, 33, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 8640, 66]
Prompts retrieved: 192159 . Total input tokens: 42825638 . Total output tokens: 37707665
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.577307828236371,
    "estimated_duration": 3600.0366304585687,
    "input_throughput": 4402.632980426394,
    "output_throughput": 3870.2061757147303,
    "total_throughput": 8272.839156141124,
    "itl": 41.44944613272512,
    "ttft": 10463.112205117584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 64419,
    "finished_requests": 64233,
    "scheduler_time": 40.9455202248274
}
#Debug simulation 
Total elapsed time: 4.577396787237376. Arrivals time: 0.150418764911592 Scheduler time: 4.1823654202744365 Scheduler overhead time: 0.09011129243299365 Adapter cache time: 0.01942307548597455 Engine time: 0.09229041449725628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 8640, 8640, 33, 8640, 33, 66, 33, 8640, 66, 8640, 33, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 8640, 33, 33, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 8640, 66]
Prompts retrieved: 192159 . Total input tokens: 42825638 . Total output tokens: 37707665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.612938770093024,
    "estimated_duration": 3600.026951269385,
    "input_throughput": 4402.644817537088,
    "output_throughput": 3870.216581319539,
    "total_throughput": 8272.861398856627,
    "itl": 41.450161901745204,
    "ttft": 10463.03642228404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489668,
    "arrivals": 64419,
    "finished_requests": 64233,
    "scheduler_time": 40.94562042909252
}
#Debug simulation 
Total elapsed time: 4.613055945839733. Arrivals time: 0.15038828179240227 Scheduler time: 4.214248796924949 Scheduler overhead time: 0.092137451749295 Adapter cache time: 0.01958639919757843 Engine time: 0.09357449319213629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 8640, 8640, 33, 8640, 33, 66, 33, 8640, 66, 8640, 33, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 8640, 33, 33, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 8640, 66]
Prompts retrieved: 192159 . Total input tokens: 42825638 . Total output tokens: 37707665
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.629845327232033,
    "estimated_duration": 3600.0019543417825,
    "input_throughput": 4402.675387685426,
    "output_throughput": 3870.2434545059746,
    "total_throughput": 8272.9188421914,
    "itl": 41.45032811964176,
    "ttft": 10463.100529292393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 64419,
    "finished_requests": 64233,
    "scheduler_time": 40.945425526270085
}
#Debug simulation 
Total elapsed time: 4.6299361190758646. Arrivals time: 0.15115006547421217 Scheduler time: 4.230810225009918 Scheduler overhead time: 0.09190962556749582 Adapter cache time: 0.019807465840131044 Engine time: 0.09270433895289898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 8640, 8640, 33, 8640, 33, 66, 33, 8640, 66, 8640, 33, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 8640, 33, 33, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 8640, 66]
Prompts retrieved: 192159 . Total input tokens: 42825638 . Total output tokens: 37707665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.5939469314180315,
    "estimated_duration": 3600.018878389607,
    "input_throughput": 4402.654690269293,
    "output_throughput": 3870.2252601054647,
    "total_throughput": 8272.879950374758,
    "itl": 41.449740974630195,
    "ttft": 10463.071284783802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 64419,
    "finished_requests": 64233,
    "scheduler_time": 40.945334081707614
}
#Debug simulation 
Total elapsed time: 4.594037208240479. Arrivals time: 0.14939408283680677 Scheduler time: 4.201235567685217 Scheduler overhead time: 0.08963651116937399 Adapter cache time: 0.019542249850928783 Engine time: 0.0915425424464047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 8640, 8640, 33, 8640, 33, 66, 33, 8640, 66, 8640, 33, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 8640, 33, 33, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 8640, 66]
Prompts retrieved: 192159 . Total input tokens: 42825638 . Total output tokens: 37707665
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.604812056291848,
    "estimated_duration": 3600.0425868276457,
    "input_throughput": 4402.625696149525,
    "output_throughput": 3870.1997723525947,
    "total_throughput": 8272.82546850212,
    "itl": 41.45010142909807,
    "ttft": 10463.084719158078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 64419,
    "finished_requests": 64233,
    "scheduler_time": 40.945911737221124
}
#Debug simulation 
Total elapsed time: 4.604903783183545. Arrivals time: 0.15383462188765407 Scheduler time: 4.204216815531254 Scheduler overhead time: 0.09066875791177154 Adapter cache time: 0.019715539645403624 Engine time: 0.0927367121912539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 8640, 8640, 33, 8640, 33, 66, 33, 8640, 66, 8640, 33, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 8640, 33, 33, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 8640, 66]
Prompts retrieved: 192159 . Total input tokens: 42825638 . Total output tokens: 37707665
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.595559753011912,
    "estimated_duration": 3600.006395979251,
    "input_throughput": 4402.669955726198,
    "output_throughput": 3870.2386794538083,
    "total_throughput": 8272.908635180007,
    "itl": 41.44931318355877,
    "ttft": 10463.045281678309,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 64419,
    "finished_requests": 64233,
    "scheduler_time": 40.94505102709445
}
#Debug simulation 
Total elapsed time: 4.595648345071822. Arrivals time: 0.14966527512297034 Scheduler time: 4.202307902276516 Scheduler overhead time: 0.08995393384248018 Adapter cache time: 0.019579251762479544 Engine time: 0.09139402257278562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 8640, 8640, 33, 8640, 33, 66, 33, 8640, 66, 8640, 33, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 8640, 33, 33, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 8640, 66]
Prompts retrieved: 192159 . Total input tokens: 42825638 . Total output tokens: 37707665
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.587231100071222,
    "estimated_duration": 3600.036382720272,
    "input_throughput": 4402.633283395775,
    "output_throughput": 3870.206442044896,
    "total_throughput": 8272.839725440672,
    "itl": 41.450090128465895,
    "ttft": 10463.104700436648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 64419,
    "finished_requests": 64233,
    "scheduler_time": 40.94582275144447
}
#Debug simulation 
Total elapsed time: 4.587322248145938. Arrivals time: 0.15208647632971406 Scheduler time: 4.1896329540759325 Scheduler overhead time: 0.09093188494443893 Adapter cache time: 0.01955156261101365 Engine time: 0.09219836536794901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 4320, 1080, 4320, 540, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 540, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 4320, 1080]
Prompts retrieved: 129060 . Total input tokens: 28806885 . Total output tokens: 25260878
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.247975226957351,
    "estimated_duration": 3600.040041124843,
    "input_throughput": 2989.9148001245053,
    "output_throughput": 2570.8258503447714,
    "total_throughput": 5560.740650469276,
    "itl": 40.14970972700451,
    "ttft": 9804.907875918203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 43251,
    "finished_requests": 43134,
    "scheduler_time": 21.41688043935288
}
#Debug simulation 
Total elapsed time: 3.24806651705876. Arrivals time: 0.1097288322634995 Scheduler time: 2.8607032313011587 Scheduler overhead time: 0.08917340962216258 Adapter cache time: 0.0550862648524344 Engine time: 0.09065811662003398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 4320, 1080, 4320, 540, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 540, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 4320, 1080]
Prompts retrieved: 129060 . Total input tokens: 28806885 . Total output tokens: 25260878
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.232291513122618,
    "estimated_duration": 3600.017809934955,
    "input_throughput": 2989.9332637452926,
    "output_throughput": 2570.841725965578,
    "total_throughput": 5560.774989710871,
    "itl": 39.99095725264228,
    "ttft": 9721.53350051073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489667,
    "arrivals": 43251,
    "finished_requests": 43134,
    "scheduler_time": 21.351723588064058
}
#Debug simulation 
Total elapsed time: 3.2323746900074184. Arrivals time: 0.10879254899919033 Scheduler time: 2.846168305259198 Scheduler overhead time: 0.08913352899253368 Adapter cache time: 0.05578465526923537 Engine time: 0.08989570522680879 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 4320, 1080, 4320, 540, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 540, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 4320, 1080]
Prompts retrieved: 129060 . Total input tokens: 28806885 . Total output tokens: 25260878
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.2515079909935594,
    "estimated_duration": 3600.0389472912857,
    "input_throughput": 2989.915708578327,
    "output_throughput": 2570.8266314628722,
    "total_throughput": 5560.742340041199,
    "itl": 39.990643647470726,
    "ttft": 9804.708881658564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 43251,
    "finished_requests": 43134,
    "scheduler_time": 21.35192586944087
}
#Debug simulation 
Total elapsed time: 3.251595928799361. Arrivals time: 0.1086243987083435 Scheduler time: 2.8652934739366174 Scheduler overhead time: 0.08883695537224412 Adapter cache time: 0.05583031475543976 Engine time: 0.0904195299372077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 4320, 1080, 4320, 540, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 540, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 4320, 1080]
Prompts retrieved: 129060 . Total input tokens: 28806885 . Total output tokens: 25260878
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.2568631200119853,
    "estimated_duration": 3600.0176994790104,
    "input_throughput": 2989.933355482592,
    "output_throughput": 2570.8418048442877,
    "total_throughput": 5560.77516032688,
    "itl": 40.19985841673158,
    "ttft": 9721.888246487924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4391118016093971,
    "arrivals": 43251,
    "finished_requests": 43134,
    "scheduler_time": 21.43577861602612
}
#Debug simulation 
Total elapsed time: 3.2569514107890427. Arrivals time: 0.1093605081550777 Scheduler time: 2.8717583464458585 Scheduler overhead time: 0.08842345280572772 Adapter cache time: 0.05512752803042531 Engine time: 0.08975479379296303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 4320, 1080, 4320, 540, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 540, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 4320, 1080]
Prompts retrieved: 129060 . Total input tokens: 28806885 . Total output tokens: 25260878
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.246109291911125,
    "estimated_duration": 3600.037443973006,
    "input_throughput": 2989.916957119491,
    "output_throughput": 2570.8277049991143,
    "total_throughput": 5560.744662118605,
    "itl": 39.990724871281714,
    "ttft": 9804.654262740894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 43251,
    "finished_requests": 43134,
    "scheduler_time": 21.351913735016748
}
#Debug simulation 
Total elapsed time: 3.246239345986396. Arrivals time: 0.10869315825402737 Scheduler time: 2.858287291135639 Scheduler overhead time: 0.08898013504222035 Adapter cache time: 0.05547177325934172 Engine time: 0.09221363766118884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 4320, 1080, 4320, 540, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 540, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 4320, 1080]
Prompts retrieved: 129060 . Total input tokens: 28806885 . Total output tokens: 25260878
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.229679764714092,
    "estimated_duration": 3600.0164369464856,
    "input_throughput": 2989.7999602272366,
    "output_throughput": 2570.7715956569045,
    "total_throughput": 5560.571555884141,
    "itl": 40.149573077868276,
    "ttft": 9805.049099695825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 43251,
    "finished_requests": 43133,
    "scheduler_time": 21.416712893276372
}
#Debug simulation 
Total elapsed time: 3.229792019817978. Arrivals time: 0.10952697927132249 Scheduler time: 2.842427557334304 Scheduler overhead time: 0.08900063438341022 Adapter cache time: 0.055100835394114256 Engine time: 0.09105338342487812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 4320, 1080, 4320, 540, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 540, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 4320, 1080]
Prompts retrieved: 129060 . Total input tokens: 28806885 . Total output tokens: 25260878
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.262294930871576,
    "estimated_duration": 3600.0177803378388,
    "input_throughput": 2989.9332883266716,
    "output_throughput": 2570.8417471014463,
    "total_throughput": 5560.775035428118,
    "itl": 39.99085395697367,
    "ttft": 9721.545859443306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 43251,
    "finished_requests": 43134,
    "scheduler_time": 21.351703364023848
}
#Debug simulation 
Total elapsed time: 3.2624130439944565. Arrivals time: 0.10932251252233982 Scheduler time: 2.8742587324231863 Scheduler overhead time: 0.08934362651780248 Adapter cache time: 0.05595225375145674 Engine time: 0.09076970117166638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 4320, 1080, 4320, 270, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 270, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 4320, 1080]
Prompts retrieved: 123390 . Total input tokens: 27525434 . Total output tokens: 24151462
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.1098345979116857,
    "estimated_duration": 3599.9799221697654,
    "input_throughput": 2852.1164623083723,
    "output_throughput": 2461.1109482688357,
    "total_throughput": 5313.227410577208,
    "itl": 37.536099194210635,
    "ttft": 7899.386652335266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 41341,
    "finished_requests": 41251,
    "scheduler_time": 18.709281711244696
}
#Debug simulation 
Total elapsed time: 3.1099300729110837. Arrivals time: 0.10444301273673773 Scheduler time: 2.723355473484844 Scheduler overhead time: 0.09306334517896175 Adapter cache time: 0.05120778689160943 Engine time: 0.09309580409899354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 4320, 1080, 4320, 270, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 270, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 4320, 1080]
Prompts retrieved: 123390 . Total input tokens: 27525434 . Total output tokens: 24151462
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.113229064270854,
    "estimated_duration": 3599.979662043112,
    "input_throughput": 2852.116668396067,
    "output_throughput": 2461.1111261033275,
    "total_throughput": 5313.227794499395,
    "itl": 37.53638475497828,
    "ttft": 7899.379755431665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489667,
    "arrivals": 41341,
    "finished_requests": 41251,
    "scheduler_time": 18.7095559242055
}
#Debug simulation 
Total elapsed time: 3.1133134779520333. Arrivals time: 0.10382868023589253 Scheduler time: 2.725711656268686 Scheduler overhead time: 0.09380395291373134 Adapter cache time: 0.0514012617059052 Engine time: 0.09393251640722156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 4320, 1080, 4320, 270, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 270, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 4320, 1080]
Prompts retrieved: 123390 . Total input tokens: 27525434 . Total output tokens: 24151462
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.1348792226053774,
    "estimated_duration": 3599.9616425767686,
    "input_throughput": 2852.13094455382,
    "output_throughput": 2461.1234450982247,
    "total_throughput": 5313.254389652045,
    "itl": 37.52528585859169,
    "ttft": 7899.32635190636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 41341,
    "finished_requests": 41251,
    "scheduler_time": 18.704004737321767
}
#Debug simulation 
Total elapsed time: 3.134965069591999. Arrivals time: 0.10492747370153666 Scheduler time: 2.7441618596203625 Scheduler overhead time: 0.09393348218873143 Adapter cache time: 0.051693474408239126 Engine time: 0.09532609349116683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 4320, 1080, 4320, 270, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 270, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 4320, 1080]
Prompts retrieved: 123390 . Total input tokens: 27525434 . Total output tokens: 24151462
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.1346370177343488,
    "estimated_duration": 3599.96163879371,
    "input_throughput": 2852.1309475510125,
    "output_throughput": 2461.123447684523,
    "total_throughput": 5313.254395235535,
    "itl": 37.52456961673604,
    "ttft": 7899.347265823538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.439111801609397,
    "arrivals": 41341,
    "finished_requests": 41251,
    "scheduler_time": 18.703730524360996
}
#Debug simulation 
Total elapsed time: 3.134757755789906. Arrivals time: 0.10514938412234187 Scheduler time: 2.747961009852588 Scheduler overhead time: 0.09229861618950963 Adapter cache time: 0.05193303991109133 Engine time: 0.09295594645664096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 4320, 1080, 4320, 270, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 270, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 4320, 1080]
Prompts retrieved: 123390 . Total input tokens: 27525434 . Total output tokens: 24151462
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.13246686803177,
    "estimated_duration": 3599.9998097393004,
    "input_throughput": 2852.100706289632,
    "output_throughput": 2461.0973522916956,
    "total_throughput": 5313.198058581328,
    "itl": 37.52500805977463,
    "ttft": 7899.275031118841,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 41341,
    "finished_requests": 41251,
    "scheduler_time": 18.704179498053595
}
#Debug simulation 
Total elapsed time: 3.132595523260534. Arrivals time: 0.10473746480420232 Scheduler time: 2.7432279768399894 Scheduler overhead time: 0.09382888162508607 Adapter cache time: 0.051600512117147446 Engine time: 0.09449296304956079 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 4320, 1080, 4320, 270, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 270, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 4320, 1080]
Prompts retrieved: 123390 . Total input tokens: 27525434 . Total output tokens: 24151462
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.107783277053386,
    "estimated_duration": 3599.961581707031,
    "input_throughput": 2852.130992778907,
    "output_throughput": 2461.1234867119847,
    "total_throughput": 5313.254479490892,
    "itl": 37.52434764474453,
    "ttft": 7899.328730725187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 41341,
    "finished_requests": 41251,
    "scheduler_time": 18.70362214852984
}
#Debug simulation 
Total elapsed time: 3.1078728730790317. Arrivals time: 0.10449669044464827 Scheduler time: 2.720246125012636 Scheduler overhead time: 0.0930160079151392 Adapter cache time: 0.05156149575486779 Engine time: 0.09366541262716055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 4320, 1080, 4320, 270, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 270, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 4320, 1080]
Prompts retrieved: 123390 . Total input tokens: 27525434 . Total output tokens: 24151462
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.112209330778569,
    "estimated_duration": 3599.9799244357214,
    "input_throughput": 2852.116460513148,
    "output_throughput": 2461.1109467197243,
    "total_throughput": 5313.227407232873,
    "itl": 37.536413920078544,
    "ttft": 7899.394998411511,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 41341,
    "finished_requests": 41251,
    "scheduler_time": 18.709551879397424
}
#Debug simulation 
Total elapsed time: 3.1123069738969207. Arrivals time: 0.10493862209841609 Scheduler time: 2.723860217258334 Scheduler overhead time: 0.09294119849801064 Adapter cache time: 0.05133621487766504 Engine time: 0.09438434801995754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26870685 . Total output tokens: 23614535
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.102881441358477,
    "estimated_duration": 3600.007690535231,
    "input_throughput": 2777.220178247326,
    "output_throughput": 2410.301239859277,
    "total_throughput": 5187.521418106603,
    "itl": 36.29934025331978,
    "ttft": 7191.426190050468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 40385,
    "finished_requests": 40305,
    "scheduler_time": 17.37092137959092
}
#Debug simulation 
Total elapsed time: 3.102975926361978. Arrivals time: 0.10357019398361444 Scheduler time: 2.7105776187963784 Scheduler overhead time: 0.09572607325389981 Adapter cache time: 0.049329149536788464 Engine time: 0.09771756269037724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26870685 . Total output tokens: 23614535
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.0868851142004132,
    "estimated_duration": 3600.03382877022,
    "input_throughput": 2777.20001409413,
    "output_throughput": 2410.283739740334,
    "total_throughput": 5187.483753834464,
    "itl": 36.286019251922546,
    "ttft": 7191.380529408393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489667,
    "arrivals": 40385,
    "finished_requests": 40305,
    "scheduler_time": 17.364100332251255
}
#Debug simulation 
Total elapsed time: 3.0869722752831876. Arrivals time: 0.10234240395948291 Scheduler time: 2.696556180715561 Scheduler overhead time: 0.0974051970988512 Adapter cache time: 0.0496451728977263 Engine time: 0.09540107334032655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26870685 . Total output tokens: 23614535
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.0682346438989043,
    "estimated_duration": 3600.033714312766,
    "input_throughput": 2777.2001023908706,
    "output_throughput": 2410.2838163715446,
    "total_throughput": 5187.483918762416,
    "itl": 36.285926671321306,
    "ttft": 7191.479090985356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 40385,
    "finished_requests": 40305,
    "scheduler_time": 17.364067139800923
}
#Debug simulation 
Total elapsed time: 3.068344933912158. Arrivals time: 0.10221899906173348 Scheduler time: 2.677430875133723 Scheduler overhead time: 0.09600967634469271 Adapter cache time: 0.0492865932174027 Engine time: 0.09736370155587792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26870685 . Total output tokens: 23614535
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.071238054893911,
    "estimated_duration": 3600.034117827823,
    "input_throughput": 2777.19979110436,
    "output_throughput": 2410.2835462113794,
    "total_throughput": 5187.48333731574,
    "itl": 36.28557711304509,
    "ttft": 7191.461918328803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939695,
    "arrivals": 40385,
    "finished_requests": 40305,
    "scheduler_time": 17.363816361702387
}
#Debug simulation 
Total elapsed time: 3.0714068287052214. Arrivals time: 0.10203537158668041 Scheduler time: 2.6800980479456484 Scheduler overhead time: 0.09718434745445848 Adapter cache time: 0.0493181087076664 Engine time: 0.09668379696086049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26870685 . Total output tokens: 23614535
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.0852631530724466,
    "estimated_duration": 3600.0336495120655,
    "input_throughput": 2777.2001523805457,
    "output_throughput": 2410.2838597567165,
    "total_throughput": 5187.484012137263,
    "itl": 36.28601702494496,
    "ttft": 7191.534979587969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 40385,
    "finished_requests": 40305,
    "scheduler_time": 17.364072018594936
}
#Debug simulation 
Total elapsed time: 3.0853605079464614. Arrivals time: 0.10446615563705564 Scheduler time: 2.6912559759803116 Scheduler overhead time: 0.09562681801617146 Adapter cache time: 0.05004879413172603 Engine time: 0.09797400049865246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26870685 . Total output tokens: 23614535
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.076192159205675,
    "estimated_duration": 3600.033714909929,
    "input_throughput": 2777.2001019301965,
    "output_throughput": 2410.2838159717335,
    "total_throughput": 5187.48391790193,
    "itl": 36.285064020210996,
    "ttft": 7191.496763770473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 40385,
    "finished_requests": 40305,
    "scheduler_time": 17.363692640625104
}
#Debug simulation 
Total elapsed time: 3.076279310975224. Arrivals time: 0.10215473501011729 Scheduler time: 2.6861323951743543 Scheduler overhead time: 0.09550881432369351 Adapter cache time: 0.049423505552113056 Engine time: 0.09709213254973292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26870685 . Total output tokens: 23614535
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.0538057326339185,
    "estimated_duration": 3600.0341161330675,
    "input_throughput": 2777.1997924117577,
    "output_throughput": 2410.283547346047,
    "total_throughput": 5187.483339757804,
    "itl": 36.2860331552029,
    "ttft": 7191.437823624439,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 40385,
    "finished_requests": 40305,
    "scheduler_time": 17.364088197827126
}
#Debug simulation 
Total elapsed time: 3.0538989305496216. Arrivals time: 0.10173370828852057 Scheduler time: 2.6672504637390375 Scheduler overhead time: 0.09446770139038563 Adapter cache time: 0.04914175532758236 Engine time: 0.09577290480956435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26551989 . Total output tokens: 23338899
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.059501607902348,
    "estimated_duration": 3600.0136910799947,
    "input_throughput": 2723.9076963227308,
    "output_throughput": 2404.108634765657,
    "total_throughput": 5128.016331088388,
    "itl": 35.86544383665026,
    "ttft": 9524.110723236596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 39938,
    "finished_requests": 39832,
    "scheduler_time": 17.03409950404808
}
#Debug simulation 
Total elapsed time: 3.0596205359324813. Arrivals time: 0.10052511841058731 Scheduler time: 2.672712987754494 Scheduler overhead time: 0.09813176700845361 Adapter cache time: 0.04593307198956609 Engine time: 0.09599848557263613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26551989 . Total output tokens: 23338899
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.0485078329220414,
    "estimated_duration": 3600.021118071426,
    "input_throughput": 2723.9020767892735,
    "output_throughput": 2404.103674990799,
    "total_throughput": 5128.005751780072,
    "itl": 35.86616929303896,
    "ttft": 9524.149488964533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489667,
    "arrivals": 39938,
    "finished_requests": 39832,
    "scheduler_time": 17.03445544715571
}
#Debug simulation 
Total elapsed time: 3.048624952789396. Arrivals time: 0.10277173388749361 Scheduler time: 2.6597412950359285 Scheduler overhead time: 0.09601076925173402 Adapter cache time: 0.04600539896637201 Engine time: 0.09774079825729132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26551989 . Total output tokens: 23338899
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.071384161245078,
    "estimated_duration": 3600.02077671192,
    "input_throughput": 2723.902335073857,
    "output_throughput": 2404.1039029516064,
    "total_throughput": 5128.006238025463,
    "itl": 35.86567995223507,
    "ttft": 9524.087200319578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 39938,
    "finished_requests": 39832,
    "scheduler_time": 17.03440203066512
}
#Debug simulation 
Total elapsed time: 3.071469428949058. Arrivals time: 0.10272225271910429 Scheduler time: 2.6786558777093887 Scheduler overhead time: 0.0979185332544148 Adapter cache time: 0.04619409563019872 Engine time: 0.09972437471151352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26551989 . Total output tokens: 23338899
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.0306910569779575,
    "estimated_duration": 3600.02108462717,
    "input_throughput": 2723.9021020943696,
    "output_throughput": 2404.1036973249625,
    "total_throughput": 5128.005799419332,
    "itl": 35.8651530290822,
    "ttft": 9524.159168688208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 39938,
    "finished_requests": 39832,
    "scheduler_time": 17.034156131360604
}
#Debug simulation 
Total elapsed time: 3.030785609036684. Arrivals time: 0.10126971220597625 Scheduler time: 2.645385481417179 Scheduler overhead time: 0.0974667239934206 Adapter cache time: 0.045891469810158014 Engine time: 0.09479421144351363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26551989 . Total output tokens: 23338899
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.067368672695011,
    "estimated_duration": 3600.0208334569984,
    "input_throughput": 2723.902292138536,
    "output_throughput": 2404.1038650570854,
    "total_throughput": 5128.006157195621,
    "itl": 35.86574143673025,
    "ttft": 9524.13767322533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 39938,
    "finished_requests": 39832,
    "scheduler_time": 17.03443034432145
}
#Debug simulation 
Total elapsed time: 3.0674534128047526. Arrivals time: 0.10161091387271881 Scheduler time: 2.677601892501116 Scheduler overhead time: 0.09657055465504527 Adapter cache time: 0.046194533817470074 Engine time: 0.0991633664816618 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26551989 . Total output tokens: 23338899
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.0986108002252877,
    "estimated_duration": 3600.020836545821,
    "input_throughput": 2723.902289801424,
    "output_throughput": 2404.103862994361,
    "total_throughput": 5128.006152795785,
    "itl": 35.865040392210986,
    "ttft": 9524.091701499781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 39938,
    "finished_requests": 39832,
    "scheduler_time": 17.034035621105424
}
#Debug simulation 
Total elapsed time: 3.0986983068287373. Arrivals time: 0.10183801967650652 Scheduler time: 2.707490131724626 Scheduler overhead time: 0.09661998646333814 Adapter cache time: 0.0464152074418962 Engine time: 0.09984500892460346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26551989 . Total output tokens: 23338899
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.0701440507546067,
    "estimated_duration": 3600.0136911336126,
    "input_throughput": 2723.9076962821614,
    "output_throughput": 2404.1086347298506,
    "total_throughput": 5128.016331012012,
    "itl": 35.86582279122045,
    "ttft": 9524.04637974629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 39938,
    "finished_requests": 39832,
    "scheduler_time": 17.034357537776717
}
#Debug simulation 
Total elapsed time: 3.070234175771475. Arrivals time: 0.10172594711184502 Scheduler time: 2.6819672542624176 Scheduler overhead time: 0.09601652203127742 Adapter cache time: 0.0461401934735477 Engine time: 0.09840681590139866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26390488 . Total output tokens: 23203918
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.9746364410966635,
    "estimated_duration": 3599.7787461167313,
    "input_throughput": 2740.9640135921964,
    "output_throughput": 2351.8862122104047,
    "total_throughput": 5092.850225802601,
    "itl": 35.16726462745787,
    "ttft": 9393.754673710095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 39719,
    "finished_requests": 39616,
    "scheduler_time": 15.971621219665783
}
#Debug simulation 
Total elapsed time: 2.974761700257659. Arrivals time: 0.10412826528772712 Scheduler time: 2.5842157434672117 Scheduler overhead time: 0.09744654502719641 Adapter cache time: 0.04538653278723359 Engine time: 0.09687620354816318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26390488 . Total output tokens: 23203918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.000790175050497,
    "estimated_duration": 3599.802389020717,
    "input_throughput": 2740.982957868473,
    "output_throughput": 2351.871320998581,
    "total_throughput": 5092.854278867054,
    "itl": 35.16727525695691,
    "ttft": 9303.042344288702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 39719,
    "finished_requests": 39617,
    "scheduler_time": 15.971917324638886
}
#Debug simulation 
Total elapsed time: 3.0008846540004015. Arrivals time: 0.10633316915482283 Scheduler time: 2.605621268041432 Scheduler overhead time: 0.09787593828514218 Adapter cache time: 0.045430203434079885 Engine time: 0.0989833902567625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26390488 . Total output tokens: 23203918
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.0320487921126187,
    "estimated_duration": 3599.7824131349357,
    "input_throughput": 2740.9612214331764,
    "output_throughput": 2351.883816396279,
    "total_throughput": 5092.845037829456,
    "itl": 35.167716459683,
    "ttft": 9393.741151254044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 39719,
    "finished_requests": 39616,
    "scheduler_time": 15.971848521927162
}
#Debug simulation 
Total elapsed time: 3.032210821751505. Arrivals time: 0.10465543810278177 Scheduler time: 2.632569359149784 Scheduler overhead time: 0.10126272961497307 Adapter cache time: 0.04574668686836958 Engine time: 0.10031597875058651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26390488 . Total output tokens: 23203918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.032504328060895,
    "estimated_duration": 3599.782431917387,
    "input_throughput": 2740.9612071317647,
    "output_throughput": 2351.8838041249423,
    "total_throughput": 5092.845011256707,
    "itl": 35.167132688157345,
    "ttft": 9393.738159239945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.439111801609397,
    "arrivals": 39719,
    "finished_requests": 39616,
    "scheduler_time": 15.971585650379405
}
#Debug simulation 
Total elapsed time: 3.0325983678922057. Arrivals time: 0.10098408162593842 Scheduler time: 2.6424251338467 Scheduler overhead time: 0.09754645125940442 Adapter cache time: 0.04541334230452776 Engine time: 0.09938920056447387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26390488 . Total output tokens: 23203918
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.998355786781758,
    "estimated_duration": 3599.7823428257025,
    "input_throughput": 2740.9612749683247,
    "output_throughput": 2351.883862332153,
    "total_throughput": 5092.845137300477,
    "itl": 35.16752480189415,
    "ttft": 9393.752649136215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 39719,
    "finished_requests": 39616,
    "scheduler_time": 15.97186791198135
}
#Debug simulation 
Total elapsed time: 2.998432094696909. Arrivals time: 0.10023362562060356 Scheduler time: 2.6109203416854143 Scheduler overhead time: 0.09704327816143632 Adapter cache time: 0.045243152882903814 Engine time: 0.0981627251021564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26390488 . Total output tokens: 23203918
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.995224584825337,
    "estimated_duration": 3599.778796693368,
    "input_throughput": 2740.9639750818465,
    "output_throughput": 2351.8861791665704,
    "total_throughput": 5092.850154248417,
    "itl": 35.16678189871466,
    "ttft": 9393.762126186728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 39719,
    "finished_requests": 39616,
    "scheduler_time": 15.971454507575142
}
#Debug simulation 
Total elapsed time: 2.9953162809833884. Arrivals time: 0.10099839232861996 Scheduler time: 2.60728362435475 Scheduler overhead time: 0.09787046629935503 Adapter cache time: 0.04538894258439541 Engine time: 0.09686685632914305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26390488 . Total output tokens: 23203918
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.0122886658646166,
    "estimated_duration": 3599.7784273584,
    "input_throughput": 2740.9642563029997,
    "output_throughput": 2351.8864204685906,
    "total_throughput": 5092.850676771591,
    "itl": 35.167668463561334,
    "ttft": 9393.741162734192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 39719,
    "finished_requests": 39616,
    "scheduler_time": 15.971839639299965
}
#Debug simulation 
Total elapsed time: 3.012388959992677. Arrivals time: 0.10165236704051495 Scheduler time: 2.6221780511550605 Scheduler overhead time: 0.09716167114675045 Adapter cache time: 0.04552735900506377 Engine time: 0.0989125152118504 
