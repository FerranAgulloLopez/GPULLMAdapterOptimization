INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:53 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_192_slots_128_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_192_slots_128_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 540, 540, 8640, 540, 270, 8640, 270, 540, 540, 270, 8640, 8640, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 270, 540, 540, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 8640, 8640, 270, 540, 8640, 270, 540, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 540, 270, 270, 270, 270, 270, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 270, 540, 540, 8640, 270, 270, 270, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 270, 8640, 540, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 540, 270, 8640, 540, 270, 540, 540, 270, 540, 8640, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 604800 . Total input tokens: 134878818 . Total output tokens: 118830674
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.643837213050574,
    "estimated_duration": 3600.0207195499474,
    "input_throughput": 4487.878059218443,
    "output_throughput": 3871.1085534369377,
    "total_throughput": 8358.98661265538,
    "itl": 133.41617100577972,
    "ttft": 1882003.0847462658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.89979124948848,
    "arrivals": 200999,
    "finished_requests": 65052,
    "scheduler_time": 79.26629730473995
}
#Debug simulation 
Total elapsed time: 4.643966828007251. Arrivals time: 0.2152502303943038 Scheduler time: 4.267200123984367 Scheduler overhead time: 0.03865851601585746 Adapter cache time: 0.06455078488215804 Engine time: 0.03974968893453479 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_192_slots_128_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_192_slots_128_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 540, 540, 8640, 540, 270, 8640, 270, 540, 540, 270, 8640, 8640, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 270, 540, 540, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 8640, 8640, 270, 540, 8640, 270, 540, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 540, 270, 270, 270, 270, 270, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 270, 540, 540, 8640, 270, 270, 270, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 270, 8640, 540, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 540, 270, 8640, 540, 270, 540, 540, 270, 540, 8640, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 604800 . Total input tokens: 134878818 . Total output tokens: 118830674
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.786209949757904,
    "estimated_duration": 3600.1255292085475,
    "input_throughput": 4357.381394822824,
    "output_throughput": 3761.0477440703826,
    "total_throughput": 8118.429138893207,
    "itl": 115.22863198226808,
    "ttft": 1908606.697793207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.426453497530446,
    "arrivals": 200999,
    "finished_requests": 63167,
    "scheduler_time": 81.22697818136642
}
#Debug simulation 
Total elapsed time: 4.7863300908356905. Arrivals time: 0.2101676557213068 Scheduler time: 4.397132793441415 Scheduler overhead time: 0.043768460396677256 Adapter cache time: 0.06943828472867608 Engine time: 0.04483590740710497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_192_slots_128_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_192_slots_128_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 540, 540, 8640, 540, 270, 8640, 270, 540, 540, 270, 8640, 8640, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 270, 540, 540, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 8640, 8640, 270, 540, 8640, 270, 540, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 540, 270, 270, 270, 270, 270, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 270, 540, 540, 8640, 270, 270, 270, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 270, 8640, 540, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 540, 270, 8640, 540, 270, 540, 540, 270, 540, 8640, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 604800 . Total input tokens: 134878818 . Total output tokens: 118830674
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.586701852269471,
    "estimated_duration": 3600.100282595682,
    "input_throughput": 4352.296816771676,
    "output_throughput": 3757.4381095425724,
    "total_throughput": 8109.734926314249,
    "itl": 114.6504865903157,
    "ttft": 1908230.5568079932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.10792690368877,
    "arrivals": 200999,
    "finished_requests": 63099,
    "scheduler_time": 81.32863928250319
}
#Debug simulation 
Total elapsed time: 4.586796393152326. Arrivals time: 0.21125895902514458 Scheduler time: 4.194498902652413 Scheduler overhead time: 0.04436022508889437 Adapter cache time: 0.07012522127479315 Engine time: 0.045303700491786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_192_slots_128_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_192_slots_128_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [64 64 64]
Adapter prompts. [8640, 270, 8640, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 540, 540, 8640, 540, 270, 8640, 270, 540, 540, 270, 8640, 8640, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 270, 540, 540, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 8640, 8640, 270, 540, 8640, 270, 540, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 8640, 540, 270, 270, 270, 270, 270, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 270, 540, 540, 8640, 270, 270, 270, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 270, 8640, 540, 540, 540, 8640, 540, 270, 540, 8640, 8640, 540, 8640, 540, 270, 8640, 540, 270, 540, 540, 270, 540, 8640, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 540, 270, 8640, 8640, 540, 8640, 270, 8640, 8640, 8640, 270, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 540, 540, 8640, 540, 270, 270]
Prompts retrieved: 604800 . Total input tokens: 134878818 . Total output tokens: 118830674
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.593064704909921,
    "estimated_duration": 3600.097111803393,
    "input_throughput": 4356.921636522954,
    "output_throughput": 3760.9818789631126,
    "total_throughput": 8117.903515486067,
    "itl": 114.81358865520595,
    "ttft": 1908237.9976671115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.904622650631918,
    "arrivals": 200999,
    "finished_requests": 63162,
    "scheduler_time": 81.32630783696807
}
#Debug simulation 
Total elapsed time: 4.593159766867757. Arrivals time: 0.2098058662377298 Scheduler time: 4.202910895459354 Scheduler overhead time: 0.04446532530710101 Adapter cache time: 0.06950539303943515 Engine time: 0.045247234869748354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_192_slots_128_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_192_slots_128_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 540, 540, 8640, 540, 135, 8640, 135, 540, 540, 135, 8640, 8640, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 135, 540, 540, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 8640, 8640, 135, 540, 8640, 135, 540, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 540, 135, 135, 135, 135, 135, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 135, 540, 540, 8640, 135, 135, 135, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 135, 8640, 540, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 540, 135, 8640, 540, 135, 540, 540, 135, 540, 8640, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 596160 . Total input tokens: 132966205 . Total output tokens: 117144044
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.744213978294283,
    "estimated_duration": 3600.0625348364088,
    "input_throughput": 4581.296808153767,
    "output_throughput": 4001.001610560781,
    "total_throughput": 8582.298418714548,
    "itl": 129.5464735633442,
    "ttft": 1845277.3201332923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1869,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.358592480714764,
    "arrivals": 198139,
    "finished_requests": 66948,
    "scheduler_time": 81.66233809333974
}
#Debug simulation 
Total elapsed time: 4.744345388375223. Arrivals time: 0.21605953061953187 Scheduler time: 4.37196237500757 Scheduler overhead time: 0.0399670097976923 Adapter cache time: 0.05617368733510375 Engine time: 0.04102236870676279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_192_slots_128_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_192_slots_128_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 540, 540, 8640, 540, 135, 8640, 135, 540, 540, 135, 8640, 8640, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 135, 540, 540, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 8640, 8640, 135, 540, 8640, 135, 540, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 540, 135, 135, 135, 135, 135, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 135, 540, 540, 8640, 135, 135, 135, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 135, 8640, 540, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 540, 135, 8640, 540, 135, 540, 540, 135, 540, 8640, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 596160 . Total input tokens: 132966205 . Total output tokens: 117144044
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.683289554901421,
    "estimated_duration": 3600.0206376845904,
    "input_throughput": 4429.546551226499,
    "output_throughput": 3873.159740819695,
    "total_throughput": 8302.706292046194,
    "itl": 112.16527168521642,
    "ttft": 1875828.8712837184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1810,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.226314954301154,
    "arrivals": 198139,
    "finished_requests": 64714,
    "scheduler_time": 83.38473655274842
}
#Debug simulation 
Total elapsed time: 4.683383826166391. Arrivals time: 0.21524443058297038 Scheduler time: 4.295577319804579 Scheduler overhead time: 0.045378298964351416 Adapter cache time: 0.05917920498177409 Engine time: 0.04636782454326749 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_192_slots_128_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_192_slots_128_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 540, 540, 8640, 540, 135, 8640, 135, 540, 540, 135, 8640, 8640, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 135, 540, 540, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 8640, 8640, 135, 540, 8640, 135, 540, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 540, 135, 135, 135, 135, 135, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 135, 540, 540, 8640, 135, 135, 135, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 135, 8640, 540, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 540, 135, 8640, 540, 135, 540, 540, 135, 540, 8640, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 596160 . Total input tokens: 132966205 . Total output tokens: 117144044
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.695742750074714,
    "estimated_duration": 3600.0811453295896,
    "input_throughput": 4430.721241017938,
    "output_throughput": 3873.8799035384545,
    "total_throughput": 8304.601144556393,
    "itl": 112.13678503614055,
    "ttft": 1875773.1266099338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1807,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.335360420239333,
    "arrivals": 198139,
    "finished_requests": 64731,
    "scheduler_time": 83.40434033904847
}
#Debug simulation 
Total elapsed time: 4.695838475134224. Arrivals time: 0.21480187168344855 Scheduler time: 4.30707570631057 Scheduler overhead time: 0.04548448929563165 Adapter cache time: 0.060537333600223064 Engine time: 0.046324837021529675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_192_slots_128_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_192_slots_128_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 540, 540, 8640, 540, 135, 8640, 135, 540, 540, 135, 8640, 8640, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 135, 540, 540, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 8640, 8640, 135, 540, 8640, 135, 540, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 540, 135, 135, 135, 135, 135, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 135, 540, 540, 8640, 135, 135, 135, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 135, 8640, 540, 540, 540, 8640, 540, 135, 540, 8640, 8640, 540, 8640, 540, 135, 8640, 540, 135, 540, 540, 135, 540, 8640, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 540, 135, 8640, 8640, 540, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 540, 540, 8640, 540, 135, 135]
Prompts retrieved: 596160 . Total input tokens: 132966205 . Total output tokens: 117144044
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.654645786155015,
    "estimated_duration": 3600.0170999045445,
    "input_throughput": 4431.483672792279,
    "output_throughput": 3874.39270784848,
    "total_throughput": 8305.876380640759,
    "itl": 112.10862349649898,
    "ttft": 1875329.2569657543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1807,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.535745139611384,
    "arrivals": 198139,
    "finished_requests": 64737,
    "scheduler_time": 83.42065080311484
}
#Debug simulation 
Total elapsed time: 4.654777725227177. Arrivals time: 0.2152569000609219 Scheduler time: 4.266694625839591 Scheduler overhead time: 0.044851836282759905 Adapter cache time: 0.06051788339391351 Engine time: 0.04595913738012314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_192_slots_128_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_192_slots_128_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 540, 540, 8640, 540, 66, 8640, 66, 540, 540, 66, 8640, 8640, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 66, 540, 540, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 8640, 8640, 66, 540, 8640, 66, 540, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 540, 66, 66, 66, 66, 66, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 66, 540, 540, 8640, 66, 66, 66, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 66, 8640, 540, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 540, 66, 8640, 540, 66, 540, 540, 66, 540, 8640, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 591744 . Total input tokens: 131978401 . Total output tokens: 116287950
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.868199869059026,
    "estimated_duration": 3600.01435252536,
    "input_throughput": 4688.7738067375085,
    "output_throughput": 4086.6120407769577,
    "total_throughput": 8775.385847514466,
    "itl": 125.76294122418003,
    "ttft": 1829943.265610781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.391147061544673,
    "arrivals": 196768,
    "finished_requests": 67948,
    "scheduler_time": 83.58440300553715
}
#Debug simulation 
Total elapsed time: 4.868292203173041. Arrivals time: 0.22270403010770679 Scheduler time: 4.4939169222489 Scheduler overhead time: 0.04119016695767641 Adapter cache time: 0.04918175935745239 Engine time: 0.04168263543397188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_192_slots_128_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_192_slots_128_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 540, 540, 8640, 540, 66, 8640, 66, 540, 540, 66, 8640, 8640, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 66, 540, 540, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 8640, 8640, 66, 540, 8640, 66, 540, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 540, 66, 66, 66, 66, 66, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 66, 540, 540, 8640, 66, 66, 66, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 66, 8640, 540, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 540, 66, 8640, 540, 66, 540, 540, 66, 540, 8640, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 591744 . Total input tokens: 131978401 . Total output tokens: 116287950
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.7374332351610065,
    "estimated_duration": 3600.021740474576,
    "input_throughput": 4526.277387939313,
    "output_throughput": 3944.0356263315944,
    "total_throughput": 8470.313014270907,
    "itl": 108.95248740065097,
    "ttft": 1864983.5430900229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.932825335748474,
    "arrivals": 196768,
    "finished_requests": 65553,
    "scheduler_time": 85.14833082544186
}
#Debug simulation 
Total elapsed time: 4.737563380040228. Arrivals time: 0.22143228258937597 Scheduler time: 4.347424668259919 Scheduler overhead time: 0.04604728240519762 Adapter cache time: 0.05349066760390997 Engine time: 0.047065101098269224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_192_slots_128_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_192_slots_128_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 540, 540, 8640, 540, 66, 8640, 66, 540, 540, 66, 8640, 8640, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 66, 540, 540, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 8640, 8640, 66, 540, 8640, 66, 540, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 540, 66, 66, 66, 66, 66, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 66, 540, 540, 8640, 66, 66, 66, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 66, 8640, 540, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 540, 66, 8640, 540, 66, 540, 540, 66, 540, 8640, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 591744 . Total input tokens: 131978401 . Total output tokens: 116287950
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.765680498909205,
    "estimated_duration": 3600.1044591949244,
    "input_throughput": 4526.34338383727,
    "output_throughput": 3944.2094419603,
    "total_throughput": 8470.55282579757,
    "itl": 108.85107452976455,
    "ttft": 1864535.6869333736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1228,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.394743304345765,
    "arrivals": 196768,
    "finished_requests": 65554,
    "scheduler_time": 85.17622339560249
}
#Debug simulation 
Total elapsed time: 4.765800280962139. Arrivals time: 0.22036124020814896 Scheduler time: 4.3760667708702385 Scheduler overhead time: 0.046321173664182425 Adapter cache time: 0.05324903829023242 Engine time: 0.04762945044785738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_192_slots_128_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_192_slots_128_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 540, 540, 8640, 540, 66, 8640, 66, 540, 540, 66, 8640, 8640, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 66, 540, 540, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 8640, 8640, 66, 540, 8640, 66, 540, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 540, 66, 66, 66, 66, 66, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 66, 540, 540, 8640, 66, 66, 66, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 66, 8640, 540, 540, 540, 8640, 540, 66, 540, 8640, 8640, 540, 8640, 540, 66, 8640, 540, 66, 540, 540, 66, 540, 8640, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 540, 66, 8640, 8640, 540, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 540, 540, 8640, 540, 66, 66]
Prompts retrieved: 591744 . Total input tokens: 131978401 . Total output tokens: 116287950
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.772532794158906,
    "estimated_duration": 3600.067555240871,
    "input_throughput": 4527.351153806194,
    "output_throughput": 3945.1765229582534,
    "total_throughput": 8472.527676764446,
    "itl": 108.91563008389768,
    "ttft": 1864118.502707262,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1230,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.852222756901716,
    "arrivals": 196768,
    "finished_requests": 65572,
    "scheduler_time": 85.17576747245238
}
#Debug simulation 
Total elapsed time: 4.772639223374426. Arrivals time: 0.23983214469626546 Scheduler time: 4.363449152559042 Scheduler overhead time: 0.04647181835025549 Adapter cache time: 0.05310314567759633 Engine time: 0.04758035019040108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 540, 540, 8640, 540, 33, 8640, 33, 540, 540, 33, 8640, 8640, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 33, 540, 540, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 8640, 8640, 33, 540, 8640, 33, 540, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 540, 33, 33, 33, 33, 33, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 33, 540, 540, 8640, 33, 33, 33, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 33, 8640, 540, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 540, 33, 8640, 540, 33, 540, 540, 33, 540, 8640, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 589632 . Total input tokens: 131502555 . Total output tokens: 115896970
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.885886086151004,
    "estimated_duration": 3600.0495617255683,
    "input_throughput": 4727.112143379228,
    "output_throughput": 4112.408661647358,
    "total_throughput": 8839.520805026585,
    "itl": 125.70804393494068,
    "ttft": 1813961.0939547052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.62054767715756,
    "arrivals": 196098,
    "finished_requests": 68859,
    "scheduler_time": 83.82372069297293
}
#Debug simulation 
Total elapsed time: 4.886011016089469. Arrivals time: 0.2221798193641007 Scheduler time: 4.514309307094663 Scheduler overhead time: 0.041358903516083956 Adapter cache time: 0.04642566340044141 Engine time: 0.04190699430182576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 540, 540, 8640, 540, 33, 8640, 33, 540, 540, 33, 8640, 8640, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 33, 540, 540, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 8640, 8640, 33, 540, 8640, 33, 540, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 540, 33, 33, 33, 33, 33, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 33, 540, 540, 8640, 33, 33, 33, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 33, 8640, 540, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 540, 33, 8640, 540, 33, 540, 540, 33, 540, 8640, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 589632 . Total input tokens: 131502555 . Total output tokens: 115896970
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.768498316872865,
    "estimated_duration": 3600.097250904858,
    "input_throughput": 4554.866120874511,
    "output_throughput": 3961.478261848461,
    "total_throughput": 8516.344382722971,
    "itl": 109.23466992888255,
    "ttft": 1848986.839917702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 814,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.94476275024005,
    "arrivals": 196098,
    "finished_requests": 66361,
    "scheduler_time": 85.27322761610914
}
#Debug simulation 
Total elapsed time: 4.7685937862843275. Arrivals time: 0.22034461284056306 Scheduler time: 4.382546158041805 Scheduler overhead time: 0.04627246828749776 Adapter cache time: 0.04991127224639058 Engine time: 0.04738107603043318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 540, 540, 8640, 540, 33, 8640, 33, 540, 540, 33, 8640, 8640, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 33, 540, 540, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 8640, 8640, 33, 540, 8640, 33, 540, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 540, 33, 33, 33, 33, 33, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 33, 540, 540, 8640, 33, 33, 33, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 33, 8640, 540, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 540, 33, 8640, 540, 33, 540, 540, 33, 540, 8640, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 589632 . Total input tokens: 131502555 . Total output tokens: 115896970
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.765939996112138,
    "estimated_duration": 3600.02074504249,
    "input_throughput": 4554.992362913858,
    "output_throughput": 3961.663837532044,
    "total_throughput": 8516.656200445903,
    "itl": 109.22361543407793,
    "ttft": 1848886.0439544707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 815,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.5596683567063785,
    "arrivals": 196098,
    "finished_requests": 66362,
    "scheduler_time": 85.27905726876018
}
#Debug simulation 
Total elapsed time: 4.7660336210392416. Arrivals time: 0.2398867243900895 Scheduler time: 4.360808743629605 Scheduler overhead time: 0.04594299662858248 Adapter cache time: 0.050151357892900705 Engine time: 0.04725295025855303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 540, 540, 8640, 540, 33, 8640, 33, 540, 540, 33, 8640, 8640, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 33, 540, 540, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 8640, 8640, 33, 540, 8640, 33, 540, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 540, 33, 33, 33, 33, 33, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 33, 540, 540, 8640, 33, 33, 33, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 33, 8640, 540, 540, 540, 8640, 540, 33, 540, 8640, 8640, 540, 8640, 540, 33, 8640, 540, 33, 540, 540, 33, 540, 8640, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 540, 33, 8640, 8640, 540, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 540, 540, 540, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 540, 540, 8640, 540, 33, 33]
Prompts retrieved: 589632 . Total input tokens: 131502555 . Total output tokens: 115896970
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.754481280222535,
    "estimated_duration": 3600.0283771034856,
    "input_throughput": 4555.612423587449,
    "output_throughput": 3962.2318231493114,
    "total_throughput": 8517.84424673676,
    "itl": 109.21127671753246,
    "ttft": 1848700.6210322462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 814,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.196511645624389,
    "arrivals": 196098,
    "finished_requests": 66371,
    "scheduler_time": 85.28790732714447
}
#Debug simulation 
Total elapsed time: 4.754632060881704. Arrivals time: 0.23196065099909902 Scheduler time: 4.3580152830109 Scheduler overhead time: 0.04606979480013251 Adapter cache time: 0.04927546251565218 Engine time: 0.04714927123859525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_192_slots_128_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_192_slots_128_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 270, 270, 8640, 270, 135, 8640, 135, 270, 270, 135, 8640, 8640, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 135, 270, 270, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 8640, 8640, 135, 270, 8640, 135, 270, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 270, 135, 135, 135, 135, 135, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 135, 270, 270, 8640, 135, 135, 135, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 135, 8640, 270, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 270, 135, 8640, 270, 135, 270, 270, 135, 270, 8640, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 578880 . Total input tokens: 129049741 . Total output tokens: 113783534
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.964193501975387,
    "estimated_duration": 3600.018896376339,
    "input_throughput": 4820.336364752769,
    "output_throughput": 4218.689522793089,
    "total_throughput": 9039.025887545858,
    "itl": 123.11459256739577,
    "ttft": 1789688.9431586273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.249233999522666,
    "arrivals": 192525,
    "finished_requests": 70241,
    "scheduler_time": 85.87894161354396
}
#Debug simulation 
Total elapsed time: 4.964285179041326. Arrivals time: 0.22636968735605478 Scheduler time: 4.588345597032458 Scheduler overhead time: 0.04180424567312002 Adapter cache time: 0.045173089019954205 Engine time: 0.0425441088154912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_192_slots_128_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_192_slots_128_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 270, 270, 8640, 270, 135, 8640, 135, 270, 270, 135, 8640, 8640, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 135, 270, 270, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 8640, 8640, 135, 270, 8640, 135, 270, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 270, 135, 135, 135, 135, 135, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 135, 270, 270, 8640, 135, 135, 135, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 135, 8640, 270, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 270, 135, 8640, 270, 135, 270, 270, 135, 270, 8640, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 578880 . Total input tokens: 129049741 . Total output tokens: 113783534
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.911781705915928,
    "estimated_duration": 3600.069500063807,
    "input_throughput": 4640.532634079398,
    "output_throughput": 4065.382904341319,
    "total_throughput": 8705.915538420717,
    "itl": 106.96974311698598,
    "ttft": 1826069.5352874158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.031832403372865,
    "arrivals": 192525,
    "finished_requests": 67602,
    "scheduler_time": 87.36074278801922
}
#Debug simulation 
Total elapsed time: 4.911878993269056. Arrivals time: 0.22497059404850006 Scheduler time: 4.519364341162145 Scheduler overhead time: 0.04781439481303096 Adapter cache time: 0.048391840886324644 Engine time: 0.048603632021695375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_192_slots_128_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_192_slots_128_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 270, 270, 8640, 270, 135, 8640, 135, 270, 270, 135, 8640, 8640, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 135, 270, 270, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 8640, 8640, 135, 270, 8640, 135, 270, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 270, 135, 135, 135, 135, 135, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 135, 270, 270, 8640, 135, 135, 135, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 135, 8640, 270, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 270, 135, 8640, 270, 135, 270, 270, 135, 270, 8640, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 578880 . Total input tokens: 129049741 . Total output tokens: 113783534
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.125367482192814,
    "estimated_duration": 3600.0131759715755,
    "input_throughput": 4641.543289765986,
    "output_throughput": 4066.528449871315,
    "total_throughput": 8708.0717396373,
    "itl": 106.94081622400405,
    "ttft": 1825660.2362250057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.284695666609418,
    "arrivals": 192525,
    "finished_requests": 67612,
    "scheduler_time": 87.37735621077344
}
#Debug simulation 
Total elapsed time: 5.125431048218161. Arrivals time: 0.22876467369496822 Scheduler time: 4.7298901518806815 Scheduler overhead time: 0.047203832771629095 Adapter cache time: 0.048232346307486296 Engine time: 0.04861629568040371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_192_slots_128_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_192_slots_128_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [64 64 64]
Adapter prompts. [8640, 135, 8640, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 270, 270, 8640, 270, 135, 8640, 135, 270, 270, 135, 8640, 8640, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 135, 270, 270, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 8640, 8640, 135, 270, 8640, 135, 270, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 8640, 270, 135, 135, 135, 135, 135, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 135, 270, 270, 8640, 135, 135, 135, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 135, 8640, 270, 270, 270, 8640, 270, 135, 270, 8640, 8640, 270, 8640, 270, 135, 8640, 270, 135, 270, 270, 135, 270, 8640, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 270, 135, 8640, 8640, 270, 8640, 135, 8640, 8640, 8640, 135, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 270, 270, 8640, 270, 135, 135]
Prompts retrieved: 578880 . Total input tokens: 129049741 . Total output tokens: 113783534
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.879605288151652,
    "estimated_duration": 3600.055643335892,
    "input_throughput": 4642.160748525057,
    "output_throughput": 4067.3515774972175,
    "total_throughput": 8709.512326022274,
    "itl": 106.9202120092231,
    "ttft": 1825746.4273912918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.607801015558826,
    "arrivals": 192525,
    "finished_requests": 67627,
    "scheduler_time": 87.3929975529952
}
#Debug simulation 
Total elapsed time: 4.8797029703855515. Arrivals time: 0.22455936390906572 Scheduler time: 4.488977546803653 Scheduler overhead time: 0.04738149791955948 Adapter cache time: 0.04762584576383233 Engine time: 0.04843492526561022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_192_slots_128_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_192_slots_128_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 270, 270, 8640, 270, 66, 8640, 66, 270, 270, 66, 8640, 8640, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 66, 270, 270, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 8640, 8640, 66, 270, 8640, 66, 270, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 270, 66, 66, 66, 66, 66, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 66, 270, 270, 8640, 66, 66, 66, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 66, 8640, 270, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 270, 66, 8640, 270, 66, 270, 270, 66, 270, 8640, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 574464 . Total input tokens: 128071976 . Total output tokens: 112909201
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.332556299865246,
    "estimated_duration": 3600.011719094171,
    "input_throughput": 4944.3605712702365,
    "output_throughput": 4322.021763838872,
    "total_throughput": 9266.382335109109,
    "itl": 119.87771061360618,
    "ttft": 1756430.26764858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1085,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.174463799665846,
    "arrivals": 191098,
    "finished_requests": 72200,
    "scheduler_time": 87.87867158286255
}
#Debug simulation 
Total elapsed time: 5.332651793956757. Arrivals time: 0.23614437691867352 Scheduler time: 4.947482050862163 Scheduler overhead time: 0.04299317253753543 Adapter cache time: 0.041324739810079336 Engine time: 0.044103854801505804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_192_slots_128_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_192_slots_128_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 270, 270, 8640, 270, 66, 8640, 66, 270, 270, 66, 8640, 8640, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 66, 270, 270, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 8640, 8640, 66, 270, 8640, 66, 270, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 270, 66, 66, 66, 66, 66, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 66, 270, 270, 8640, 66, 66, 66, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 66, 8640, 270, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 270, 66, 8640, 270, 66, 270, 270, 66, 270, 8640, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 574464 . Total input tokens: 128071976 . Total output tokens: 112909201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.194152025971562,
    "estimated_duration": 3600.0435043717944,
    "input_throughput": 4743.271013048424,
    "output_throughput": 4148.547366681376,
    "total_throughput": 8891.8183797298,
    "itl": 104.35003501871937,
    "ttft": 1798044.3474141844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.607982164444413,
    "arrivals": 191098,
    "finished_requests": 69308,
    "scheduler_time": 89.12031790435695
}
#Debug simulation 
Total elapsed time: 5.194242589175701. Arrivals time: 0.2283943109214306 Scheduler time: 4.802422470413148 Scheduler overhead time: 0.048024714924395084 Adapter cache time: 0.043019179720431566 Engine time: 0.04935911204665899 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_192_slots_128_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_192_slots_128_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 270, 270, 8640, 270, 66, 8640, 66, 270, 270, 66, 8640, 8640, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 66, 270, 270, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 8640, 8640, 66, 270, 8640, 66, 270, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 270, 66, 66, 66, 66, 66, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 66, 270, 270, 8640, 66, 66, 66, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 66, 8640, 270, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 270, 66, 8640, 270, 66, 270, 270, 66, 270, 8640, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 574464 . Total input tokens: 128071976 . Total output tokens: 112909201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.953119496814907,
    "estimated_duration": 3600.008110709027,
    "input_throughput": 4747.396526457816,
    "output_throughput": 4152.640088651263,
    "total_throughput": 8900.03661510908,
    "itl": 104.50833888130816,
    "ttft": 1797818.4739368812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.0976740301912535,
    "arrivals": 191098,
    "finished_requests": 69372,
    "scheduler_time": 89.11369096486516
}
#Debug simulation 
Total elapsed time: 4.953222461044788. Arrivals time: 0.22683704132214189 Scheduler time: 4.564349969383329 Scheduler overhead time: 0.04798066336661577 Adapter cache time: 0.041765376925468445 Engine time: 0.04901563562452793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_192_slots_128_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_192_slots_128_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 270, 270, 8640, 270, 66, 8640, 66, 270, 270, 66, 8640, 8640, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 66, 270, 270, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 8640, 8640, 66, 270, 8640, 66, 270, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 270, 66, 66, 66, 66, 66, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 66, 270, 270, 8640, 66, 66, 66, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 66, 8640, 270, 270, 270, 8640, 270, 66, 270, 8640, 8640, 270, 8640, 270, 66, 8640, 270, 66, 270, 270, 66, 270, 8640, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 270, 66, 8640, 8640, 270, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 270, 270, 8640, 270, 66, 66]
Prompts retrieved: 574464 . Total input tokens: 128071976 . Total output tokens: 112909201
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.94955708226189,
    "estimated_duration": 3600.105624983348,
    "input_throughput": 4748.334849225172,
    "output_throughput": 4153.311751809826,
    "total_throughput": 8901.646601034998,
    "itl": 104.49231510647228,
    "ttft": 1797668.7496791566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.62650993631218,
    "arrivals": 191098,
    "finished_requests": 69386,
    "scheduler_time": 89.12767854390958
}
#Debug simulation 
Total elapsed time: 4.949701138306409. Arrivals time: 0.2294771419838071 Scheduler time: 4.558750320225954 Scheduler overhead time: 0.048057555221021175 Adapter cache time: 0.04118981258943677 Engine time: 0.0492190788500011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 270, 270, 8640, 270, 33, 8640, 33, 270, 270, 33, 8640, 8640, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 33, 270, 270, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 8640, 8640, 33, 270, 8640, 33, 270, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 270, 33, 33, 33, 33, 33, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 33, 270, 270, 8640, 33, 33, 33, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 33, 8640, 270, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 270, 33, 8640, 270, 33, 270, 270, 33, 270, 8640, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 572352 . Total input tokens: 127579584 . Total output tokens: 112490969
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.16742798499763,
    "estimated_duration": 3600.0013353618165,
    "input_throughput": 5003.886477222518,
    "output_throughput": 4372.709211347524,
    "total_throughput": 9376.595688570042,
    "itl": 119.07703649325626,
    "ttft": 1746991.6297799135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.582399459141387,
    "arrivals": 190328,
    "finished_requests": 73088,
    "scheduler_time": 88.73895716555472
}
#Debug simulation 
Total elapsed time: 5.16752259619534. Arrivals time: 0.2354233441874385 Scheduler time: 4.787627863232046 Scheduler overhead time: 0.043355632573366165 Adapter cache time: 0.03628104645758867 Engine time: 0.044060653541237116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 270, 270, 8640, 270, 33, 8640, 33, 270, 270, 33, 8640, 8640, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 33, 270, 270, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 8640, 8640, 33, 270, 8640, 33, 270, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 270, 33, 33, 33, 33, 33, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 33, 270, 270, 8640, 33, 33, 33, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 33, 8640, 270, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 270, 33, 8640, 270, 33, 270, 270, 33, 270, 8640, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 572352 . Total input tokens: 127579584 . Total output tokens: 112490969
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.02000140119344,
    "estimated_duration": 3600.058889887439,
    "input_throughput": 4801.187849607768,
    "output_throughput": 4194.6749933505,
    "total_throughput": 8995.862842958268,
    "itl": 104.02010774961518,
    "ttft": 1790016.0235007666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.883048558472662,
    "arrivals": 190328,
    "finished_requests": 70107,
    "scheduler_time": 89.79509479962732
}
#Debug simulation 
Total elapsed time: 5.020129240117967. Arrivals time: 0.22796634957194328 Scheduler time: 4.63175806729123 Scheduler overhead time: 0.04864457855001092 Adapter cache time: 0.03853968437761068 Engine time: 0.04984169593080878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 270, 270, 8640, 270, 33, 8640, 33, 270, 270, 33, 8640, 8640, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 33, 270, 270, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 8640, 8640, 33, 270, 8640, 33, 270, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 270, 33, 33, 33, 33, 33, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 33, 270, 270, 8640, 33, 33, 33, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 33, 8640, 270, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 270, 33, 8640, 270, 33, 270, 270, 33, 270, 8640, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 572352 . Total input tokens: 127579584 . Total output tokens: 112490969
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.993572952691466,
    "estimated_duration": 3600.0382870513686,
    "input_throughput": 4801.813931306486,
    "output_throughput": 4195.292604060156,
    "total_throughput": 8997.106535366642,
    "itl": 104.01135528098084,
    "ttft": 1789992.141109642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 670,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.572918097497888,
    "arrivals": 190328,
    "finished_requests": 70117,
    "scheduler_time": 89.80194744924225
}
#Debug simulation 
Total elapsed time: 4.9936948996037245. Arrivals time: 0.22747612744569778 Scheduler time: 4.606664594262838 Scheduler overhead time: 0.04827070329338312 Adapter cache time: 0.038448979146778584 Engine time: 0.04954554373398423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 270, 270, 8640, 270, 33, 8640, 33, 270, 270, 33, 8640, 8640, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 33, 270, 270, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 8640, 8640, 33, 270, 8640, 33, 270, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 270, 33, 33, 33, 33, 33, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 33, 270, 270, 8640, 33, 33, 33, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 33, 8640, 270, 270, 270, 8640, 270, 33, 270, 8640, 8640, 270, 8640, 270, 33, 8640, 270, 33, 270, 270, 33, 270, 8640, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 270, 33, 8640, 8640, 270, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 270, 270, 270, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 270, 270, 8640, 270, 33, 33]
Prompts retrieved: 572352 . Total input tokens: 127579584 . Total output tokens: 112490969
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.064285803120583,
    "estimated_duration": 3600.041208400618,
    "input_throughput": 4802.347250819606,
    "output_throughput": 4195.472253138503,
    "total_throughput": 8997.81950395811,
    "itl": 104.00580175143554,
    "ttft": 1789846.0931508709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2708431092416665,
    "arrivals": 190328,
    "finished_requests": 70124,
    "scheduler_time": 89.80618243520273
}
#Debug simulation 
Total elapsed time: 5.064394754823297. Arrivals time: 0.2360034054145217 Scheduler time: 4.665359086822718 Scheduler overhead time: 0.0487342975102365 Adapter cache time: 0.038836201187223196 Engine time: 0.050072194542735815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_192_slots_128_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_192_slots_128_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 135, 135, 8640, 135, 66, 8640, 66, 135, 135, 66, 8640, 8640, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 66, 135, 135, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 8640, 8640, 66, 135, 8640, 66, 135, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 135, 66, 66, 66, 66, 66, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 66, 135, 135, 8640, 66, 66, 66, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 66, 8640, 135, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 135, 66, 8640, 135, 66, 135, 135, 66, 135, 8640, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 565824 . Total input tokens: 126152122 . Total output tokens: 111199696
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.221889015752822,
    "estimated_duration": 3600.091578326774,
    "input_throughput": 5122.067202682209,
    "output_throughput": 4469.6962979699565,
    "total_throughput": 9591.763500652165,
    "itl": 115.93959207057407,
    "ttft": 1716709.0413037785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.891656447467517,
    "arrivals": 188114,
    "finished_requests": 74741,
    "scheduler_time": 90.71430849733869
}
#Debug simulation 
Total elapsed time: 5.221984297968447. Arrivals time: 0.2350184042006731 Scheduler time: 4.845693360082805 Scheduler overhead time: 0.04390030913054943 Adapter cache time: 0.03151426604017615 Engine time: 0.04485416552051902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_192_slots_128_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_192_slots_128_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 135, 135, 8640, 135, 66, 8640, 66, 135, 135, 66, 8640, 8640, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 66, 135, 135, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 8640, 8640, 66, 135, 8640, 66, 135, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 135, 66, 66, 66, 66, 66, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 66, 135, 135, 8640, 66, 66, 66, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 66, 8640, 135, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 135, 66, 8640, 135, 66, 135, 135, 66, 135, 8640, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 565824 . Total input tokens: 126152122 . Total output tokens: 111199696
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.098179322201759,
    "estimated_duration": 3600.088449433336,
    "input_throughput": 4896.203314886472,
    "output_throughput": 4276.9488073059965,
    "total_throughput": 9173.152122192469,
    "itl": 101.40027897869412,
    "ttft": 1763653.0266178611,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.236770517095001,
    "arrivals": 188114,
    "finished_requests": 71423,
    "scheduler_time": 91.61977907859105
}
#Debug simulation 
Total elapsed time: 5.098281804006547. Arrivals time: 0.2328400225378573 Scheduler time: 4.708119023125619 Scheduler overhead time: 0.0496814651414752 Adapter cache time: 0.03293143352493644 Engine time: 0.050946689676493406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_192_slots_128_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_192_slots_128_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 135, 135, 8640, 135, 66, 8640, 66, 135, 135, 66, 8640, 8640, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 66, 135, 135, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 8640, 8640, 66, 135, 8640, 66, 135, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 135, 66, 66, 66, 66, 66, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 66, 135, 135, 8640, 66, 66, 66, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 66, 8640, 135, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 135, 66, 8640, 135, 66, 135, 135, 66, 135, 8640, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 565824 . Total input tokens: 126152122 . Total output tokens: 111199696
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.077259419020265,
    "estimated_duration": 3600.105279223615,
    "input_throughput": 4896.4329187066205,
    "output_throughput": 4277.163250992683,
    "total_throughput": 9173.596169699304,
    "itl": 101.37809069585026,
    "ttft": 1763669.006155271,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.8369628767808805,
    "arrivals": 188114,
    "finished_requests": 71426,
    "scheduler_time": 91.62839411280794
}
#Debug simulation 
Total elapsed time: 5.077356901019812. Arrivals time: 0.23189663933590055 Scheduler time: 4.688609393779188 Scheduler overhead time: 0.049443325493484735 Adapter cache time: 0.033236742950975895 Engine time: 0.050394277554005384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_192_slots_128_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_192_slots_128_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [64 64 64]
Adapter prompts. [8640, 66, 8640, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 135, 135, 8640, 135, 66, 8640, 66, 135, 135, 66, 8640, 8640, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 66, 135, 135, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 8640, 8640, 66, 135, 8640, 66, 135, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 8640, 135, 66, 66, 66, 66, 66, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 66, 135, 135, 8640, 66, 66, 66, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 66, 8640, 135, 135, 135, 8640, 135, 66, 135, 8640, 8640, 135, 8640, 135, 66, 8640, 135, 66, 135, 135, 66, 135, 8640, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 135, 66, 8640, 8640, 135, 8640, 66, 8640, 8640, 8640, 66, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 135, 135, 8640, 135, 66, 66]
Prompts retrieved: 565824 . Total input tokens: 126152122 . Total output tokens: 111199696
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.095146032050252,
    "estimated_duration": 3600.1065927076943,
    "input_throughput": 4896.969449657462,
    "output_throughput": 4278.010832011631,
    "total_throughput": 9174.980281669094,
    "itl": 101.37715802362939,
    "ttft": 1763454.4081264024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.445484562306638,
    "arrivals": 188114,
    "finished_requests": 71437,
    "scheduler_time": 91.6361865582135
}
#Debug simulation 
Total elapsed time: 5.095301143825054. Arrivals time: 0.2370881987735629 Scheduler time: 4.700761297252029 Scheduler overhead time: 0.04960025427863002 Adapter cache time: 0.033090333454310894 Engine time: 0.05081844422966242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 135, 135, 8640, 135, 33, 8640, 33, 135, 135, 33, 8640, 8640, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 33, 135, 135, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 8640, 8640, 33, 135, 8640, 33, 135, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 135, 33, 33, 33, 33, 33, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 33, 135, 135, 8640, 33, 33, 33, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 33, 8640, 135, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 135, 33, 8640, 135, 33, 135, 135, 33, 135, 8640, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 563712 . Total input tokens: 125677331 . Total output tokens: 110772764
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.282761016860604,
    "estimated_duration": 3600.120145799873,
    "input_throughput": 5195.429108615017,
    "output_throughput": 4531.391547871651,
    "total_throughput": 9726.820656486667,
    "itl": 114.30458930127092,
    "ttft": 1702949.1212997085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.139368054000727,
    "arrivals": 187444,
    "finished_requests": 75617,
    "scheduler_time": 91.88273323475596
}
#Debug simulation 
Total elapsed time: 5.282866909168661. Arrivals time: 0.23392166662961245 Scheduler time: 4.909023986663669 Scheduler overhead time: 0.044727650471031666 Adapter cache time: 0.02823132136836648 Engine time: 0.04552514711394906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 135, 135, 8640, 135, 33, 8640, 33, 135, 135, 33, 8640, 8640, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 33, 135, 135, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 8640, 8640, 33, 135, 8640, 33, 135, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 135, 33, 33, 33, 33, 33, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 33, 135, 135, 8640, 33, 33, 33, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 33, 8640, 135, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 135, 33, 8640, 135, 33, 135, 135, 33, 135, 8640, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 563712 . Total input tokens: 125677331 . Total output tokens: 110772764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.143108611926436,
    "estimated_duration": 3600.0836423683377,
    "input_throughput": 4962.751084373843,
    "output_throughput": 4325.589221520293,
    "total_throughput": 9288.340305894135,
    "itl": 100.33029330626104,
    "ttft": 1751253.2283617426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.363155564973137,
    "arrivals": 187444,
    "finished_requests": 72178,
    "scheduler_time": 92.52698466161725
}
#Debug simulation 
Total elapsed time: 5.143231715075672. Arrivals time: 0.23135958658531308 Scheduler time: 4.756437400821596 Scheduler overhead time: 0.05021833395585418 Adapter cache time: 0.02958990028128028 Engine time: 0.051462565548717976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 135, 135, 8640, 135, 33, 8640, 33, 135, 135, 33, 8640, 8640, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 33, 135, 135, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 8640, 8640, 33, 135, 8640, 33, 135, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 135, 33, 33, 33, 33, 33, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 33, 135, 135, 8640, 33, 33, 33, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 33, 8640, 135, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 135, 33, 8640, 135, 33, 135, 135, 33, 135, 8640, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 563712 . Total input tokens: 125677331 . Total output tokens: 110772764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.0992987980134785,
    "estimated_duration": 3600.0124071282244,
    "input_throughput": 4962.84928480349,
    "output_throughput": 4325.6748141105345,
    "total_throughput": 9288.524098914026,
    "itl": 100.32005608413371,
    "ttft": 1751289.954540485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.070240939604111,
    "arrivals": 187444,
    "finished_requests": 72178,
    "scheduler_time": 92.5318940062632
}
#Debug simulation 
Total elapsed time: 5.099394048098475. Arrivals time: 0.23088433407247066 Scheduler time: 4.715044499374926 Scheduler overhead time: 0.0496829766780138 Adapter cache time: 0.02921456703916192 Engine time: 0.050833932124078274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 135, 135, 8640, 135, 33, 8640, 33, 135, 135, 33, 8640, 8640, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 33, 135, 135, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 8640, 8640, 33, 135, 8640, 33, 135, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 135, 33, 33, 33, 33, 33, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 33, 135, 135, 8640, 33, 33, 33, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 33, 8640, 135, 135, 135, 8640, 135, 33, 135, 8640, 8640, 135, 8640, 135, 33, 8640, 135, 33, 135, 135, 33, 135, 8640, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 135, 33, 8640, 8640, 135, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 135, 135, 135, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 135, 135, 8640, 135, 33, 33]
Prompts retrieved: 563712 . Total input tokens: 125677331 . Total output tokens: 110772764
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.139658049214631,
    "estimated_duration": 3600.072394698306,
    "input_throughput": 4962.76658944722,
    "output_throughput": 4325.602735915261,
    "total_throughput": 9288.369325362482,
    "itl": 100.2978393213368,
    "ttft": 1751218.5665823596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8112008015205907,
    "arrivals": 187444,
    "finished_requests": 72178,
    "scheduler_time": 92.53996451747192
}
#Debug simulation 
Total elapsed time: 5.139780547004193. Arrivals time: 0.2346176584251225 Scheduler time: 4.749994362704456 Scheduler overhead time: 0.05013175634667277 Adapter cache time: 0.02920376416295767 Engine time: 0.0518120895139873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 66, 66, 8640, 66, 33, 8640, 33, 66, 66, 33, 8640, 8640, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 33, 66, 66, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 8640, 8640, 33, 66, 8640, 33, 66, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 66, 33, 33, 33, 33, 33, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 33, 66, 66, 8640, 33, 33, 33, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 33, 8640, 66, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 66, 33, 8640, 66, 33, 66, 66, 33, 66, 8640, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 66, 66, 66, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 559296 . Total input tokens: 124679125 . Total output tokens: 109880185
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.3995048720389605,
    "estimated_duration": 3600.1104941099243,
    "input_throughput": 5311.951127968931,
    "output_throughput": 4633.998325133242,
    "total_throughput": 9945.949453102174,
    "itl": 111.97089992960082,
    "ttft": 1677043.444611509,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2202431985596562,
    "arrivals": 185958,
    "finished_requests": 77389,
    "scheduler_time": 93.84419845670173
}
#Debug simulation 
Total elapsed time: 5.399602116085589. Arrivals time: 0.24599292920902371 Scheduler time: 5.017580257263035 Scheduler overhead time: 0.04565710434690118 Adapter cache time: 0.021821309812366962 Engine time: 0.04676512163132429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 66, 66, 8640, 66, 33, 8640, 33, 66, 66, 33, 8640, 8640, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 33, 66, 66, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 8640, 8640, 33, 66, 8640, 33, 66, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 66, 33, 33, 33, 33, 33, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 33, 66, 66, 8640, 33, 33, 33, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 33, 8640, 66, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 66, 33, 8640, 66, 33, 66, 66, 33, 66, 8640, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 66, 66, 66, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 559296 . Total input tokens: 124679125 . Total output tokens: 109880185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.218874878715724,
    "estimated_duration": 3600.073184702517,
    "input_throughput": 5048.825417559377,
    "output_throughput": 4409.546469070396,
    "total_throughput": 9458.371886629771,
    "itl": 98.57276452916882,
    "ttft": 1728725.9797148947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4760359743051277,
    "arrivals": 185958,
    "finished_requests": 73576,
    "scheduler_time": 94.23340564369228
}
#Debug simulation 
Total elapsed time: 5.218999141827226. Arrivals time: 0.23486309219151735 Scheduler time: 4.8342394400388 Scheduler overhead time: 0.050754317082464695 Adapter cache time: 0.02274788450449705 Engine time: 0.052017517387866974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 66, 66, 8640, 66, 33, 8640, 33, 66, 66, 33, 8640, 8640, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 33, 66, 66, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 8640, 8640, 33, 66, 8640, 33, 66, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 66, 33, 33, 33, 33, 33, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 33, 66, 66, 8640, 33, 33, 33, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 33, 8640, 66, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 66, 33, 8640, 66, 33, 66, 66, 33, 66, 8640, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 66, 66, 66, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 559296 . Total input tokens: 124679125 . Total output tokens: 109880185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.269887235946953,
    "estimated_duration": 3600.013856425039,
    "input_throughput": 5047.956681490734,
    "output_throughput": 4408.511920495845,
    "total_throughput": 9456.468601986579,
    "itl": 98.52151152652519,
    "ttft": 1728719.3842699714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.259473502468313,
    "arrivals": 185958,
    "finished_requests": 73561,
    "scheduler_time": 94.23909227766907
}
#Debug simulation 
Total elapsed time: 5.270023699849844. Arrivals time: 0.2396266614086926 Scheduler time: 4.879030636977404 Scheduler overhead time: 0.05110526969656348 Adapter cache time: 0.022908596321940422 Engine time: 0.05228227563202381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [64 64 64]
Adapter prompts. [8640, 33, 8640, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 66, 66, 8640, 66, 33, 8640, 33, 66, 66, 33, 8640, 8640, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 33, 66, 66, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 8640, 8640, 33, 66, 8640, 33, 66, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 8640, 66, 33, 33, 33, 33, 33, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 33, 66, 66, 8640, 33, 33, 33, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 33, 8640, 66, 66, 66, 8640, 66, 33, 66, 8640, 8640, 66, 8640, 66, 33, 8640, 66, 33, 66, 66, 33, 66, 8640, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 66, 33, 8640, 8640, 66, 8640, 33, 8640, 8640, 8640, 33, 8640, 8640, 8640, 66, 66, 66, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 66, 66, 8640, 66, 33, 33]
Prompts retrieved: 559296 . Total input tokens: 124679125 . Total output tokens: 109880185
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.446428314317018,
    "estimated_duration": 3600.0756808219558,
    "input_throughput": 5049.599400601893,
    "output_throughput": 4410.166731932435,
    "total_throughput": 9459.766132534329,
    "itl": 98.58276587803677,
    "ttft": 1728777.3639874842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0387463677115605,
    "arrivals": 185958,
    "finished_requests": 73586,
    "scheduler_time": 94.24183272091209
}
#Debug simulation 
Total elapsed time: 5.44653677335009. Arrivals time: 0.23904531681910157 Scheduler time: 5.058048111852258 Scheduler overhead time: 0.05045691318809986 Adapter cache time: 0.022771854884922504 Engine time: 0.05193498497828841 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_192_slots_128_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_192_slots_128_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [64 64 64]
Adapter prompts. [4320, 540, 4320, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 4320, 4320, 540, 1080, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 4320, 1080, 540, 540, 540, 540, 540, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 540, 1080, 1080, 4320, 540, 540, 540, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 1080, 540, 4320, 1080, 540, 1080, 1080, 540, 1080, 4320, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 540, 4320, 4320, 4320, 540, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 380160 . Total input tokens: 84741070 . Total output tokens: 74690164
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.630074247252196,
    "estimated_duration": 3600.1473788939434,
    "input_throughput": 3981.3611753871064,
    "output_throughput": 3474.6402531562885,
    "total_throughput": 7456.0014285433945,
    "itl": 147.49374683806255,
    "ttft": 1766808.3076526127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.334176545092332,
    "arrivals": 126417,
    "finished_requests": 57834,
    "scheduler_time": 68.64390879718562
}
#Debug simulation 
Total elapsed time: 4.630165518261492. Arrivals time: 0.20451244851574302 Scheduler time: 4.286441837437451 Scheduler overhead time: 0.036864187102764845 Adapter cache time: 0.04819277813658118 Engine time: 0.03686715755611658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_192_slots_128_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_192_slots_128_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [64 64 64]
Adapter prompts. [4320, 540, 4320, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 4320, 4320, 540, 1080, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 4320, 1080, 540, 540, 540, 540, 540, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 540, 1080, 1080, 4320, 540, 540, 540, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 1080, 540, 4320, 1080, 540, 1080, 1080, 540, 1080, 4320, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 540, 4320, 4320, 4320, 540, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 380160 . Total input tokens: 84741070 . Total output tokens: 74690164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.311433132737875,
    "estimated_duration": 3600.063994689667,
    "input_throughput": 3754.6929776633606,
    "output_throughput": 3280.558906014132,
    "total_throughput": 7035.2518836774925,
    "itl": 130.7644313432085,
    "ttft": 1832050.6707349475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.31783138184278,
    "arrivals": 126417,
    "finished_requests": 54522,
    "scheduler_time": 68.30308515790034
}
#Debug simulation 
Total elapsed time: 4.311529899947345. Arrivals time: 0.20038096979260445 Scheduler time: 3.9451538426801562 Scheduler overhead time: 0.04065379826352 Adapter cache time: 0.06521333660930395 Engine time: 0.04099280247464776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_192_slots_128_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_192_slots_128_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [64 64 64]
Adapter prompts. [4320, 540, 4320, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 4320, 4320, 540, 1080, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 4320, 1080, 540, 540, 540, 540, 540, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 540, 1080, 1080, 4320, 540, 540, 540, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 1080, 540, 4320, 1080, 540, 1080, 1080, 540, 1080, 4320, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 540, 4320, 4320, 4320, 540, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 380160 . Total input tokens: 84741070 . Total output tokens: 74690164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.3096683053299785,
    "estimated_duration": 3600.0132134406667,
    "input_throughput": 3757.0481545742023,
    "output_throughput": 3282.033231402397,
    "total_throughput": 7039.081385976599,
    "itl": 130.66657833742977,
    "ttft": 1831537.0710916293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3230,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.072143776128677,
    "arrivals": 126417,
    "finished_requests": 54549,
    "scheduler_time": 68.34174364210435
}
#Debug simulation 
Total elapsed time: 4.309767500963062. Arrivals time: 0.19973167357966304 Scheduler time: 3.946225767955184 Scheduler overhead time: 0.04036313481628895 Adapter cache time: 0.06381575996056199 Engine time: 0.04049570998176932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_192_slots_128_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_192_slots_128_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [64 64 64]
Adapter prompts. [4320, 540, 4320, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 4320, 4320, 540, 1080, 4320, 540, 1080, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 4320, 1080, 540, 540, 540, 540, 540, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 540, 1080, 1080, 4320, 540, 540, 540, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 1080, 4320, 4320, 1080, 4320, 1080, 540, 4320, 1080, 540, 1080, 1080, 540, 1080, 4320, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 1080, 540, 4320, 4320, 1080, 4320, 540, 4320, 4320, 4320, 540, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 380160 . Total input tokens: 84741070 . Total output tokens: 74690164
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.266816745046526,
    "estimated_duration": 3600.0206505861433,
    "input_throughput": 3759.6445447601277,
    "output_throughput": 3284.736157853615,
    "total_throughput": 7044.380702613743,
    "itl": 130.85144483659099,
    "ttft": 1830428.2005497783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.271224573982746,
    "arrivals": 126417,
    "finished_requests": 54584,
    "scheduler_time": 68.35249462765033
}
#Debug simulation 
Total elapsed time: 4.266909615136683. Arrivals time: 0.18776346184313297 Scheduler time: 3.913066269364208 Scheduler overhead time: 0.04041728051379323 Adapter cache time: 0.0661810408346355 Engine time: 0.040488823782652617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_192_slots_128_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_192_slots_128_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 4320, 4320, 270, 1080, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 1080, 270, 270, 270, 270, 270, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 270, 1080, 1080, 4320, 270, 270, 270, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 1080, 270, 4320, 1080, 270, 1080, 1080, 270, 1080, 4320, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 362880 . Total input tokens: 80964191 . Total output tokens: 71252854
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.380065881181508,
    "estimated_duration": 3600.163381790248,
    "input_throughput": 4033.536664877406,
    "output_throughput": 3482.267239151207,
    "total_throughput": 7515.803904028613,
    "itl": 148.19611814288317,
    "ttft": 1732613.8351803394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.812303695897356,
    "arrivals": 120741,
    "finished_requests": 58622,
    "scheduler_time": 68.14745514107823
}
#Debug simulation 
Total elapsed time: 4.380156902130693. Arrivals time: 0.20167153188958764 Scheduler time: 4.03490144899115 Scheduler overhead time: 0.03640670329332352 Adapter cache time: 0.05328920250758529 Engine time: 0.03677005087956786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_192_slots_128_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_192_slots_128_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 4320, 4320, 270, 1080, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 1080, 270, 270, 270, 270, 270, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 270, 1080, 1080, 4320, 270, 270, 270, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 1080, 270, 4320, 1080, 270, 1080, 1080, 270, 1080, 4320, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 362880 . Total input tokens: 80964191 . Total output tokens: 71252854
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.110858159139752,
    "estimated_duration": 3600.10256039652,
    "input_throughput": 3796.3135134946506,
    "output_throughput": 3288.8979692556,
    "total_throughput": 7085.21148275025,
    "itl": 131.52946865409555,
    "ttft": 1798251.735337132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.326612954227368,
    "arrivals": 120741,
    "finished_requests": 55238,
    "scheduler_time": 67.8289028016136
}
#Debug simulation 
Total elapsed time: 4.110953401308507. Arrivals time: 0.19243285292759538 Scheduler time: 3.7425983515568078 Scheduler overhead time: 0.04016344714909792 Adapter cache time: 0.0764797143638134 Engine time: 0.040288598742336035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_192_slots_128_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_192_slots_128_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 4320, 4320, 270, 1080, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 1080, 270, 270, 270, 270, 270, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 270, 1080, 1080, 4320, 270, 270, 270, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 1080, 270, 4320, 1080, 270, 1080, 1080, 270, 1080, 4320, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 362880 . Total input tokens: 80964191 . Total output tokens: 71252854
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.119681915268302,
    "estimated_duration": 3600.100011710819,
    "input_throughput": 3797.8597693186166,
    "output_throughput": 3289.9683235109514,
    "total_throughput": 7087.828092829568,
    "itl": 131.4610563423321,
    "ttft": 1797416.1327886374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4029,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.583810015745325,
    "arrivals": 120741,
    "finished_requests": 55264,
    "scheduler_time": 67.85965954365673
}
#Debug simulation 
Total elapsed time: 4.119776027277112. Arrivals time: 0.19573110388591886 Scheduler time: 3.748468412552029 Scheduler overhead time: 0.040049190167337656 Adapter cache time: 0.07616145350039005 Engine time: 0.04038504045456648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_192_slots_128_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_192_slots_128_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 4320, 4320, 270, 1080, 4320, 270, 1080, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 1080, 270, 270, 270, 270, 270, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 270, 1080, 1080, 4320, 270, 270, 270, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 1080, 4320, 4320, 1080, 4320, 1080, 270, 4320, 1080, 270, 1080, 1080, 270, 1080, 4320, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 1080, 270, 4320, 4320, 1080, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 362880 . Total input tokens: 80964191 . Total output tokens: 71252854
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.106711443979293,
    "estimated_duration": 3600.1405938265957,
    "input_throughput": 3799.535780201493,
    "output_throughput": 3291.747000192516,
    "total_throughput": 7091.282780394009,
    "itl": 131.4000119378335,
    "ttft": 1797061.5840710604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.765504916145,
    "arrivals": 120741,
    "finished_requests": 55294,
    "scheduler_time": 67.88845427742817
}
#Debug simulation 
Total elapsed time: 4.106894026044756. Arrivals time: 0.19320586835965514 Scheduler time: 3.7386098452843726 Scheduler overhead time: 0.040062430780380964 Adapter cache time: 0.07561093149706721 Engine time: 0.040365566965192556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 4320, 4320, 135, 1080, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 1080, 135, 135, 135, 135, 135, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 135, 1080, 1080, 4320, 135, 135, 135, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 1080, 135, 4320, 1080, 135, 1080, 1080, 135, 1080, 4320, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 354240 . Total input tokens: 79040718 . Total output tokens: 69581508
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.320475175976753,
    "estimated_duration": 3600.024306066378,
    "input_throughput": 3989.0347339602704,
    "output_throughput": 3488.873666445855,
    "total_throughput": 7477.908400406125,
    "itl": 148.59250717660566,
    "ttft": 1719491.7582708513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2879,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.0371256029836,
    "arrivals": 117840,
    "finished_requests": 58296,
    "scheduler_time": 68.01738080816634
}
#Debug simulation 
Total elapsed time: 4.320567201357335. Arrivals time: 0.20234381686896086 Scheduler time: 3.9725426328368485 Scheduler overhead time: 0.036340602207928896 Adapter cache time: 0.05586980702355504 Engine time: 0.03641034150496125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 4320, 4320, 135, 1080, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 1080, 135, 135, 135, 135, 135, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 135, 1080, 1080, 4320, 135, 135, 135, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 1080, 135, 4320, 1080, 135, 1080, 1080, 135, 1080, 4320, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 354240 . Total input tokens: 79040718 . Total output tokens: 69581508
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.122757405042648,
    "estimated_duration": 3600.0216645070004,
    "input_throughput": 3819.925067557398,
    "output_throughput": 3346.7170819512085,
    "total_throughput": 7166.642149508606,
    "itl": 130.02624810650153,
    "ttft": 1770238.627868874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.610944038866396,
    "arrivals": 117840,
    "finished_requests": 55843,
    "scheduler_time": 68.5750390235131
}
#Debug simulation 
Total elapsed time: 4.122853264212608. Arrivals time: 0.20726284803822637 Scheduler time: 3.7428049272857606 Scheduler overhead time: 0.03964164201170206 Adapter cache time: 0.07368555990979075 Engine time: 0.040483975782990456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 4320, 4320, 135, 1080, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 1080, 135, 135, 135, 135, 135, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 135, 1080, 1080, 4320, 135, 135, 135, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 1080, 135, 4320, 1080, 135, 1080, 1080, 135, 1080, 4320, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 354240 . Total input tokens: 79040718 . Total output tokens: 69581508
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.128486618865281,
    "estimated_duration": 3600.1178189714237,
    "input_throughput": 3822.239352136388,
    "output_throughput": 3348.340139446887,
    "total_throughput": 7170.579491583275,
    "itl": 129.96069245250905,
    "ttft": 1769752.6076458518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.96090648552471,
    "arrivals": 117840,
    "finished_requests": 55877,
    "scheduler_time": 68.60344093396287
}
#Debug simulation 
Total elapsed time: 4.128580598626286. Arrivals time: 0.19863720098510385 Scheduler time: 3.7569627412594855 Scheduler overhead time: 0.039696937426924706 Adapter cache time: 0.07341925892978907 Engine time: 0.04061153810471296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 4320, 4320, 135, 1080, 4320, 135, 1080, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 1080, 135, 135, 135, 135, 135, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 135, 1080, 1080, 4320, 135, 135, 135, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 1080, 4320, 4320, 1080, 4320, 1080, 135, 4320, 1080, 135, 1080, 1080, 135, 1080, 4320, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 1080, 135, 4320, 4320, 1080, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 354240 . Total input tokens: 79040718 . Total output tokens: 69581508
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.117850954178721,
    "estimated_duration": 3600.0117230635437,
    "input_throughput": 3823.0547728016577,
    "output_throughput": 3349.392704126805,
    "total_throughput": 7172.4474769284625,
    "itl": 129.91070183601101,
    "ttft": 1769019.253124151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3360,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.449974360318745,
    "arrivals": 117840,
    "finished_requests": 55890,
    "scheduler_time": 68.62664054723051
}
#Debug simulation 
Total elapsed time: 4.117975014261901. Arrivals time: 0.19219115190207958 Scheduler time: 3.7533066826872528 Scheduler overhead time: 0.03960975166410208 Adapter cache time: 0.07343538012355566 Engine time: 0.040461492259055376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_192_slots_128_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_192_slots_128_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 4320, 4320, 66, 1080, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 1080, 66, 66, 66, 66, 66, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 66, 1080, 1080, 4320, 66, 66, 66, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 1080, 66, 4320, 1080, 66, 1080, 1080, 66, 1080, 4320, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 349824 . Total input tokens: 78056991 . Total output tokens: 68700290
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.266147532034665,
    "estimated_duration": 3600.035105369717,
    "input_throughput": 4049.209680832526,
    "output_throughput": 3543.107671637567,
    "total_throughput": 7592.317352470093,
    "itl": 145.55038547173595,
    "ttft": 1693590.462719113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.150555328373255,
    "arrivals": 116430,
    "finished_requests": 59080,
    "scheduler_time": 68.82947823712668
}
#Debug simulation 
Total elapsed time: 4.266245693899691. Arrivals time: 0.19757803389802575 Scheduler time: 3.926539481151849 Scheduler overhead time: 0.03593995561823249 Adapter cache time: 0.0524495062418282 Engine time: 0.036508990451693535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_192_slots_128_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_192_slots_128_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 4320, 4320, 66, 1080, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 1080, 66, 66, 66, 66, 66, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 66, 1080, 1080, 4320, 66, 66, 66, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 1080, 66, 4320, 1080, 66, 1080, 1080, 66, 1080, 4320, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 349824 . Total input tokens: 78056991 . Total output tokens: 68700290
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.166731937788427,
    "estimated_duration": 3600.0096963844117,
    "input_throughput": 3904.793927115843,
    "output_throughput": 3423.939388935412,
    "total_throughput": 7328.733316051254,
    "itl": 126.21047826809387,
    "ttft": 1737194.7600821545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.356127258776425,
    "arrivals": 116430,
    "finished_requests": 57003,
    "scheduler_time": 69.90599924372445
}
#Debug simulation 
Total elapsed time: 4.16682696621865. Arrivals time: 0.19626369327306747 Scheduler time: 3.8059748839586973 Scheduler overhead time: 0.0402220799587667 Adapter cache time: 0.0636576502583921 Engine time: 0.041283536702394485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_192_slots_128_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_192_slots_128_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 4320, 4320, 66, 1080, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 1080, 66, 66, 66, 66, 66, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 66, 1080, 1080, 4320, 66, 66, 66, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 1080, 66, 4320, 1080, 66, 1080, 1080, 66, 1080, 4320, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 349824 . Total input tokens: 78056991 . Total output tokens: 68700290
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.170447051059455,
    "estimated_duration": 3600.0683411915707,
    "input_throughput": 3904.8417051291603,
    "output_throughput": 3423.9197236795117,
    "total_throughput": 7328.761428808672,
    "itl": 126.24199410221054,
    "ttft": 1736908.625169993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2103,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.342999801379902,
    "arrivals": 116430,
    "finished_requests": 57004,
    "scheduler_time": 69.89592465055706
}
#Debug simulation 
Total elapsed time: 4.170541959814727. Arrivals time: 0.19517387356609106 Scheduler time: 3.8102166489697993 Scheduler overhead time: 0.04042393248528242 Adapter cache time: 0.0639501428231597 Engine time: 0.04134071385487914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_192_slots_128_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_192_slots_128_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 4320, 4320, 66, 1080, 4320, 66, 1080, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 1080, 66, 66, 66, 66, 66, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 66, 1080, 1080, 4320, 66, 66, 66, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 1080, 4320, 4320, 1080, 4320, 1080, 66, 4320, 1080, 66, 1080, 1080, 66, 1080, 4320, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 1080, 66, 4320, 4320, 1080, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 349824 . Total input tokens: 78056991 . Total output tokens: 68700290
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.19049875671044,
    "estimated_duration": 3600.0681848775203,
    "input_throughput": 3905.56963867015,
    "output_throughput": 3424.631247760505,
    "total_throughput": 7330.200886430655,
    "itl": 126.00772487229655,
    "ttft": 1736677.6201659506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2105,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.438153579901657,
    "arrivals": 116430,
    "finished_requests": 57017,
    "scheduler_time": 69.95173885485418
}
#Debug simulation 
Total elapsed time: 4.190641436725855. Arrivals time: 0.19428858533501625 Scheduler time: 3.8311752565205097 Scheduler overhead time: 0.04047838971018791 Adapter cache time: 0.06375928083434701 Engine time: 0.041379193775355816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 4320, 4320, 33, 1080, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 1080, 33, 33, 33, 33, 33, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 33, 1080, 1080, 4320, 33, 33, 33, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 1080, 33, 4320, 1080, 33, 1080, 1080, 33, 1080, 4320, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 347712 . Total input tokens: 77591074 . Total output tokens: 68289176
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.305634457152337,
    "estimated_duration": 3600.1243904294233,
    "input_throughput": 4124.447210622316,
    "output_throughput": 3600.240879025286,
    "total_throughput": 7724.688089647602,
    "itl": 143.66012172138656,
    "ttft": 1668218.7721238686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.53509382407205,
    "arrivals": 115680,
    "finished_requests": 60162,
    "scheduler_time": 69.73319049530835
}
#Debug simulation 
Total elapsed time: 4.3057362120598555. Arrivals time: 0.1982392193749547 Scheduler time: 3.9689068095758557 Scheduler overhead time: 0.03609728952869773 Adapter cache time: 0.0482415733858943 Engine time: 0.036934477277100086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 4320, 4320, 33, 1080, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 1080, 33, 33, 33, 33, 33, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 33, 1080, 1080, 4320, 33, 33, 33, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 1080, 33, 4320, 1080, 33, 1080, 1080, 33, 1080, 4320, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 347712 . Total input tokens: 77591074 . Total output tokens: 68289176
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.228597100824118,
    "estimated_duration": 3600.1001402795337,
    "input_throughput": 3976.3960562742745,
    "output_throughput": 3471.661207465622,
    "total_throughput": 7448.057263739896,
    "itl": 124.78528205669438,
    "ttft": 1714801.2145953728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.013407959532863,
    "arrivals": 115680,
    "finished_requests": 58014,
    "scheduler_time": 70.70067599195069
}
#Debug simulation 
Total elapsed time: 4.228707010857761. Arrivals time: 0.19799310434609652 Scheduler time: 3.868851682636887 Scheduler overhead time: 0.040645943488925695 Adapter cache time: 0.05974066723138094 Engine time: 0.041852741967886686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 4320, 4320, 33, 1080, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 1080, 33, 33, 33, 33, 33, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 33, 1080, 1080, 4320, 33, 33, 33, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 1080, 33, 4320, 1080, 33, 1080, 1080, 33, 1080, 4320, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 347712 . Total input tokens: 77591074 . Total output tokens: 68289176
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.2127021523192525,
    "estimated_duration": 3600.1340729344615,
    "input_throughput": 3977.060217740577,
    "output_throughput": 3472.134022445213,
    "total_throughput": 7449.1942401857905,
    "itl": 124.75934347291319,
    "ttft": 1714557.7380302278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.402581253591972,
    "arrivals": 115680,
    "finished_requests": 58024,
    "scheduler_time": 70.71204995072104
}
#Debug simulation 
Total elapsed time: 4.212791797239333. Arrivals time: 0.19801829056814313 Scheduler time: 3.8525030873715878 Scheduler overhead time: 0.04088951041921973 Adapter cache time: 0.05991617729887366 Engine time: 0.04177886014804244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 4320, 4320, 33, 1080, 4320, 33, 1080, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 1080, 33, 33, 33, 33, 33, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 33, 1080, 1080, 4320, 33, 33, 33, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 1080, 4320, 4320, 1080, 4320, 1080, 33, 4320, 1080, 33, 1080, 1080, 33, 1080, 4320, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 1080, 33, 4320, 4320, 1080, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 347712 . Total input tokens: 77591074 . Total output tokens: 68289176
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.2277107909321785,
    "estimated_duration": 3600.028409967831,
    "input_throughput": 3977.44777801016,
    "output_throughput": 3472.4884296431724,
    "total_throughput": 7449.9362076533325,
    "itl": 124.73940518458065,
    "ttft": 1714340.267127805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.79704305610626,
    "arrivals": 115680,
    "finished_requests": 58028,
    "scheduler_time": 70.71812568354503
}
#Debug simulation 
Total elapsed time: 4.227804782800376. Arrivals time: 0.19877206161618233 Scheduler time: 3.8674198486842215 Scheduler overhead time: 0.040981451980769634 Adapter cache time: 0.059141323901712894 Engine time: 0.04187977546826005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_192_slots_128_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_192_slots_128_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73215613 . Total output tokens: 64502526
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.270869086030871,
    "estimated_duration": 3600.071634376039,
    "input_throughput": 4026.4640463223327,
    "output_throughput": 3485.0662081824225,
    "total_throughput": 7511.530254504755,
    "itl": 147.646060261244,
    "ttft": 1668437.8360924476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.183613530343997,
    "arrivals": 109355,
    "finished_requests": 58349,
    "scheduler_time": 66.94813402275534
}
#Debug simulation 
Total elapsed time: 4.270969186909497. Arrivals time: 0.20592026878148317 Scheduler time: 3.8994899801909924 Scheduler overhead time: 0.036207256838679314 Adapter cache time: 0.0757121960632503 Engine time: 0.03653833502903581 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_192_slots_128_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_192_slots_128_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73215613 . Total output tokens: 64502526
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.1387859978713095,
    "estimated_duration": 3600.0155859791935,
    "input_throughput": 3900.0622815862293,
    "output_throughput": 3377.848431367953,
    "total_throughput": 7277.910712954183,
    "itl": 127.75124992734644,
    "ttft": 1709556.9129608828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.602160027850427,
    "arrivals": 109355,
    "finished_requests": 56516,
    "scheduler_time": 68.18580771866982
}
#Debug simulation 
Total elapsed time: 4.138902622740716. Arrivals time: 0.19493734883144498 Scheduler time: 3.7550608525052667 Scheduler overhead time: 0.04012938728556037 Adapter cache time: 0.08859236305579543 Engine time: 0.04099969379603863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_192_slots_128_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_192_slots_128_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73215613 . Total output tokens: 64502526
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.148202063981444,
    "estimated_duration": 3600.1357331760205,
    "input_throughput": 3903.4686582781987,
    "output_throughput": 3380.558651677079,
    "total_throughput": 7284.027309955278,
    "itl": 127.69417995847799,
    "ttft": 1709009.2675013347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.624200038636108,
    "arrivals": 109355,
    "finished_requests": 56571,
    "scheduler_time": 68.21998829101507
}
#Debug simulation 
Total elapsed time: 4.148295640945435. Arrivals time: 0.19168450869619846 Scheduler time: 3.7670015739277005 Scheduler overhead time: 0.04016279615461826 Adapter cache time: 0.08932859310880303 Engine time: 0.040888368617743254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_192_slots_128_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_192_slots_128_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73215613 . Total output tokens: 64502526
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.252363500185311,
    "estimated_duration": 3600.0663388178546,
    "input_throughput": 3905.301368589956,
    "output_throughput": 3382.2954506994906,
    "total_throughput": 7287.596819289447,
    "itl": 127.62312642148618,
    "ttft": 1708458.4710790191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.667913356435275,
    "arrivals": 109355,
    "finished_requests": 56600,
    "scheduler_time": 68.24876273706495
}
#Debug simulation 
Total elapsed time: 4.252540376037359. Arrivals time: 0.19491199310868979 Scheduler time: 3.8646791595965624 Scheduler overhead time: 0.04105649562552571 Adapter cache time: 0.09029538044705987 Engine time: 0.04174929531291127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71299708 . Total output tokens: 62786742
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.374167136847973,
    "estimated_duration": 3600.057798639892,
    "input_throughput": 4181.520364947285,
    "output_throughput": 3644.825370569705,
    "total_throughput": 7826.345735516989,
    "itl": 141.86858471987117,
    "ttft": 1592977.9160051008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3106,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.53814245323588,
    "arrivals": 106484,
    "finished_requests": 61078,
    "scheduler_time": 68.93437166118494
}
#Debug simulation 
Total elapsed time: 4.374275885056704. Arrivals time: 0.2086474522948265 Scheduler time: 4.005001031793654 Scheduler overhead time: 0.03648706246167421 Adapter cache time: 0.06861436273902655 Engine time: 0.03800168540328741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71299708 . Total output tokens: 62786742
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.3631655178032815,
    "estimated_duration": 3600.010511593289,
    "input_throughput": 4072.523386469584,
    "output_throughput": 3551.060186860992,
    "total_throughput": 7623.583573330576,
    "itl": 122.08894168799758,
    "ttft": 1628978.6305281124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3007,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.9520689003211,
    "arrivals": 106484,
    "finished_requests": 59452,
    "scheduler_time": 70.4283393308091
}
#Debug simulation 
Total elapsed time: 4.363259241916239. Arrivals time: 0.20351779367774725 Scheduler time: 3.976231615524739 Scheduler overhead time: 0.042090010829269886 Adapter cache time: 0.07787350798025727 Engine time: 0.043220401741564274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71299708 . Total output tokens: 62786742
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.32903467817232,
    "estimated_duration": 3600.087033290605,
    "input_throughput": 4074.1184489069656,
    "output_throughput": 3552.4102283467355,
    "total_throughput": 7626.528677253701,
    "itl": 122.03320834273565,
    "ttft": 1628429.5032387953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3007,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.52636596072986,
    "arrivals": 106484,
    "finished_requests": 59480,
    "scheduler_time": 70.45045048133493
}
#Debug simulation 
Total elapsed time: 4.329133776016533. Arrivals time: 0.20038134325295687 Scheduler time: 3.947386087849736 Scheduler overhead time: 0.04199433093890548 Adapter cache time: 0.07626264542341232 Engine time: 0.04294137516990304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71299708 . Total output tokens: 62786742
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.311746322084218,
    "estimated_duration": 3600.056052904854,
    "input_throughput": 4072.6285325945437,
    "output_throughput": 3551.404981509576,
    "total_throughput": 7624.03351410412,
    "itl": 121.63529729372904,
    "ttft": 1628636.1813686513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.17091458453476,
    "arrivals": 106484,
    "finished_requests": 59456,
    "scheduler_time": 70.51663512696094
}
#Debug simulation 
Total elapsed time: 4.3118388610892. Arrivals time: 0.19751667883247137 Scheduler time: 3.9317463603802025 Scheduler overhead time: 0.04195481166243553 Adapter cache time: 0.07743345154449344 Engine time: 0.04315244313329458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_192_slots_128_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_192_slots_128_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70303492 . Total output tokens: 61942623
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.449246354866773,
    "estimated_duration": 3600.039066805271,
    "input_throughput": 4309.961562103035,
    "output_throughput": 3729.6175821544953,
    "total_throughput": 8039.579144257531,
    "itl": 137.54491471656516,
    "ttft": 1556655.0148583092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2145,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.183617373533005,
    "arrivals": 105023,
    "finished_requests": 62317,
    "scheduler_time": 70.25077751633187
}
#Debug simulation 
Total elapsed time: 4.449339170008898. Arrivals time: 0.20053214207291603 Scheduler time: 4.09295039717108 Scheduler overhead time: 0.03747338708490133 Adapter cache time: 0.061566999182105064 Engine time: 0.03869279567152262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_192_slots_128_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_192_slots_128_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70303492 . Total output tokens: 61942623
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.39152971887961,
    "estimated_duration": 3600.0975806434853,
    "input_throughput": 4181.215831741274,
    "output_throughput": 3621.474337278834,
    "total_throughput": 7802.690169020108,
    "itl": 118.56668175009231,
    "ttft": 1598933.4579812963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2076,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.143776838276304,
    "arrivals": 105023,
    "finished_requests": 60471,
    "scheduler_time": 71.64534303233664
}
#Debug simulation 
Total elapsed time: 4.391621379181743. Arrivals time: 0.20289031183347106 Scheduler time: 4.013054016977549 Scheduler overhead time: 0.042948462534695864 Adapter cache time: 0.0677903899922967 Engine time: 0.044127232395112514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_192_slots_128_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_192_slots_128_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70303492 . Total output tokens: 61942623
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.392690629698336,
    "estimated_duration": 3600.0113161087456,
    "input_throughput": 4181.316023270328,
    "output_throughput": 3621.561116116828,
    "total_throughput": 7802.877139387156,
    "itl": 118.36748620049708,
    "ttft": 1598997.4789902717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2076,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.159528168198008,
    "arrivals": 105023,
    "finished_requests": 60471,
    "scheduler_time": 71.67282228189214
}
#Debug simulation 
Total elapsed time: 4.392787252552807. Arrivals time: 0.20074742985889316 Scheduler time: 4.016264176927507 Scheduler overhead time: 0.04285397753119469 Adapter cache time: 0.06833734456449747 Engine time: 0.04399274569004774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_192_slots_128_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_192_slots_128_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70303492 . Total output tokens: 61942623
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.360506949946284,
    "estimated_duration": 3600.119461142976,
    "input_throughput": 4176.186974425209,
    "output_throughput": 3617.314964283295,
    "total_throughput": 7793.501938708505,
    "itl": 118.80213472909026,
    "ttft": 1600179.2839439865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2064,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.17641282133823,
    "arrivals": 105023,
    "finished_requests": 60407,
    "scheduler_time": 71.54746899373208
}
#Debug simulation 
Total elapsed time: 4.360834512859583. Arrivals time: 0.19885038770735264 Scheduler time: 3.9876088676974177 Scheduler overhead time: 0.042680265847593546 Adapter cache time: 0.06726789521053433 Engine time: 0.043689105194061995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69842118 . Total output tokens: 61543311
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.522673524916172,
    "estimated_duration": 3600.1088691029217,
    "input_throughput": 4391.4935838980655,
    "output_throughput": 3808.6978751330653,
    "total_throughput": 8200.19145903113,
    "itl": 135.21281351395493,
    "ttft": 1517930.9463498995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.508644187944249,
    "arrivals": 104293,
    "finished_requests": 63905,
    "scheduler_time": 71.12063278390985
}
#Debug simulation 
Total elapsed time: 4.522770210169256. Arrivals time: 0.2048355508595705 Scheduler time: 4.1665178569965065 Scheduler overhead time: 0.03822474880144 Adapter cache time: 0.05568634159862995 Engine time: 0.03915858129039407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69842118 . Total output tokens: 61543311
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.466381883248687,
    "estimated_duration": 3600.0293620196267,
    "input_throughput": 4251.051161264547,
    "output_throughput": 3688.3468618575143,
    "total_throughput": 7939.398023122061,
    "itl": 117.12773482842206,
    "ttft": 1562632.385144741,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.351227018507114,
    "arrivals": 104293,
    "finished_requests": 61881,
    "scheduler_time": 72.27077052422915
}
#Debug simulation 
Total elapsed time: 4.466476968023926. Arrivals time: 0.20353540172800422 Scheduler time: 4.091581855900586 Scheduler overhead time: 0.043317270930856466 Adapter cache time: 0.06291947001591325 Engine time: 0.044322080444544554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69842118 . Total output tokens: 61543311
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.454531440045685,
    "estimated_duration": 3600.1261124626867,
    "input_throughput": 4251.411067800096,
    "output_throughput": 3688.6521708307614,
    "total_throughput": 7940.063238630858,
    "itl": 117.06540502793601,
    "ttft": 1562283.9151626788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.654056759099545,
    "arrivals": 104293,
    "finished_requests": 61889,
    "scheduler_time": 72.28830400646669
}
#Debug simulation 
Total elapsed time: 4.454622847959399. Arrivals time: 0.20617060316726565 Scheduler time: 4.077081827446818 Scheduler overhead time: 0.0433832136914134 Adapter cache time: 0.06282063806429505 Engine time: 0.04432707652449608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69842118 . Total output tokens: 61543311
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.471246046945453,
    "estimated_duration": 3600.050579034129,
    "input_throughput": 4254.9946629110345,
    "output_throughput": 3691.0192532808937,
    "total_throughput": 7946.013916191929,
    "itl": 117.12550910105504,
    "ttft": 1562160.9000476168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.084319498431972,
    "arrivals": 104293,
    "finished_requests": 61933,
    "scheduler_time": 72.31034657788578
}
#Debug simulation 
Total elapsed time: 4.471341773867607. Arrivals time: 0.20703905168920755 Scheduler time: 4.093269711360335 Scheduler overhead time: 0.043398757465183735 Adapter cache time: 0.06225890526548028 Engine time: 0.04451351799070835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67401241 . Total output tokens: 59475787
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.6057285270653665,
    "estimated_duration": 3600.128208269836,
    "input_throughput": 4476.449745034217,
    "output_throughput": 3869.509971339295,
    "total_throughput": 8345.959716373512,
    "itl": 132.8510803698465,
    "ttft": 1479255.895268247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.542721161763268,
    "arrivals": 100777,
    "finished_requests": 64637,
    "scheduler_time": 71.23885792123059
}
#Debug simulation 
Total elapsed time: 4.605821486096829. Arrivals time: 0.20734084118157625 Scheduler time: 4.236707793083042 Scheduler overhead time: 0.03899960685521364 Adapter cache time: 0.06405149167403579 Engine time: 0.04009671416133642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67401241 . Total output tokens: 59475787
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.527869577053934,
    "estimated_duration": 3600.016443286487,
    "input_throughput": 4345.850427760107,
    "output_throughput": 3759.328940077011,
    "total_throughput": 8105.179367837118,
    "itl": 114.49938118997864,
    "ttft": 1521378.7543775996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.78220623340882,
    "arrivals": 100777,
    "finished_requests": 62763,
    "scheduler_time": 72.61924691202877
}
#Debug simulation 
Total elapsed time: 4.52796888910234. Arrivals time: 0.2130942279472947 Scheduler time: 4.136276982259005 Scheduler overhead time: 0.04413129761815071 Adapter cache time: 0.06788373598828912 Engine time: 0.04535601381212473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67401241 . Total output tokens: 59475787
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.590257789939642,
    "estimated_duration": 3600.033511161665,
    "input_throughput": 4347.048423710418,
    "output_throughput": 3760.1791644522586,
    "total_throughput": 8107.227588162677,
    "itl": 114.4475881120474,
    "ttft": 1520743.8776481838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.59054597669789,
    "arrivals": 100777,
    "finished_requests": 62780,
    "scheduler_time": 72.63689753310713
}
#Debug simulation 
Total elapsed time: 4.590352893806994. Arrivals time: 0.2201729970984161 Scheduler time: 4.190982341300696 Scheduler overhead time: 0.04460388422012329 Adapter cache time: 0.06754351872950792 Engine time: 0.04569825902581215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67401241 . Total output tokens: 59475787
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.5533234449103475,
    "estimated_duration": 3600.092534830732,
    "input_throughput": 4350.050963547337,
    "output_throughput": 3761.8230278730202,
    "total_throughput": 8111.873991420357,
    "itl": 114.44007452572987,
    "ttft": 1520259.6877424556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.419444659148493,
    "arrivals": 100777,
    "finished_requests": 62820,
    "scheduler_time": 72.65155067638895
}
#Debug simulation 
Total elapsed time: 4.553489973302931. Arrivals time: 0.2198745934292674 Scheduler time: 4.154356716666371 Scheduler overhead time: 0.0442116167396307 Adapter cache time: 0.06830508541315794 Engine time: 0.04543811269104481 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_192_slots_128_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_192_slots_128_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66405477 . Total output tokens: 58586931
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.739990852307528,
    "estimated_duration": 3600.0558518388275,
    "input_throughput": 4627.8882010928,
    "output_throughput": 3995.185517095115,
    "total_throughput": 8623.073718187916,
    "itl": 128.66271561963453,
    "ttft": 1403778.072355545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1895,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.530515115545468,
    "arrivals": 99385,
    "finished_requests": 66989,
    "scheduler_time": 71.81680874533609
}
#Debug simulation 
Total elapsed time: 4.740106844343245. Arrivals time: 0.21399537660181522 Scheduler time: 4.370209572836757 Scheduler overhead time: 0.04008839186280966 Adapter cache time: 0.055345197673887014 Engine time: 0.041284391190856695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_192_slots_128_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_192_slots_128_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66405477 . Total output tokens: 58586931
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.645161048043519,
    "estimated_duration": 3600.104824448495,
    "input_throughput": 4479.359014906015,
    "output_throughput": 3869.443718804498,
    "total_throughput": 8348.802733710512,
    "itl": 111.48116301452868,
    "ttft": 1451664.4524220694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1819,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.287934905686209,
    "arrivals": 99385,
    "finished_requests": 64839,
    "scheduler_time": 73.00701314603614
}
#Debug simulation 
Total elapsed time: 4.645262124948204. Arrivals time: 0.2085563689470291 Scheduler time: 4.2637061276473105 Scheduler overhead time: 0.045317748095840216 Adapter cache time: 0.05936410557478666 Engine time: 0.046568007208406925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_192_slots_128_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_192_slots_128_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66405477 . Total output tokens: 58586931
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.642380949109793,
    "estimated_duration": 3600.054798819702,
    "input_throughput": 4480.640407276159,
    "output_throughput": 3870.36164131951,
    "total_throughput": 8351.00204859567,
    "itl": 111.45216753142526,
    "ttft": 1451603.4508032342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1824,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.46609861180205,
    "arrivals": 99385,
    "finished_requests": 64859,
    "scheduler_time": 73.01734751760182
}
#Debug simulation 
Total elapsed time: 4.6424734918400645. Arrivals time: 0.2124910168349743 Scheduler time: 4.256212300620973 Scheduler overhead time: 0.04526676097884774 Adapter cache time: 0.059923110995441675 Engine time: 0.04680888867005706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_192_slots_128_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_192_slots_128_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66405477 . Total output tokens: 58586931
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.628618376329541,
    "estimated_duration": 3600.0918538591914,
    "input_throughput": 4469.86706262784,
    "output_throughput": 3861.0737070776063,
    "total_throughput": 8330.940769705447,
    "itl": 111.58194262844432,
    "ttft": 1453327.2322925003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1814,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.580432586195384,
    "arrivals": 99385,
    "finished_requests": 64705,
    "scheduler_time": 72.89554454822688
}
#Debug simulation 
Total elapsed time: 4.62870945641771. Arrivals time: 0.20922090485692024 Scheduler time: 4.246779630891979 Scheduler overhead time: 0.04519592132419348 Adapter cache time: 0.05906572891399264 Engine time: 0.0467890496365726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 65941883 . Total output tokens: 58176621
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.796355946920812,
    "estimated_duration": 3600.024513814217,
    "input_throughput": 4712.419577950543,
    "output_throughput": 4069.3128460058065,
    "total_throughput": 8781.73242395635,
    "itl": 126.77547464014471,
    "ttft": 1370358.3796192552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.761441967333882,
    "arrivals": 98651,
    "finished_requests": 68421,
    "scheduler_time": 72.28288912885823
}
#Debug simulation 
Total elapsed time: 4.796444891951978. Arrivals time: 0.21668806858360767 Scheduler time: 4.429687136784196 Scheduler overhead time: 0.040340748615562916 Adapter cache time: 0.04878637194633484 Engine time: 0.041583238169550896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 65941883 . Total output tokens: 58176621
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.705222900956869,
    "estimated_duration": 3600.1023517316826,
    "input_throughput": 4552.89222322133,
    "output_throughput": 3932.5576377543985,
    "total_throughput": 8485.449860975728,
    "itl": 110.04488974445253,
    "ttft": 1422240.3415102295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.378047205177106,
    "arrivals": 98651,
    "finished_requests": 66094,
    "scheduler_time": 73.43283177928028
}
#Debug simulation 
Total elapsed time: 4.70531589910388. Arrivals time: 0.21303802682086825 Scheduler time: 4.323395108338445 Scheduler overhead time: 0.045863532926887274 Adapter cache time: 0.05350668728351593 Engine time: 0.04747877502813935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 65941883 . Total output tokens: 58176621
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.677547264844179,
    "estimated_duration": 3600.0063500565266,
    "input_throughput": 4553.276690676565,
    "output_throughput": 3932.848896163111,
    "total_throughput": 8486.125586839675,
    "itl": 110.0215120193591,
    "ttft": 1421869.6452221747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.718094536610893,
    "arrivals": 98651,
    "finished_requests": 66097,
    "scheduler_time": 73.43840118907747
}
#Debug simulation 
Total elapsed time: 4.677668219897896. Arrivals time: 0.2130423467606306 Scheduler time: 4.29555143462494 Scheduler overhead time: 0.04543000552803278 Adapter cache time: 0.054047191981226206 Engine time: 0.04774033045396209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 65941883 . Total output tokens: 58176621
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.69035637518391,
    "estimated_duration": 3600.119898613858,
    "input_throughput": 4553.942774603815,
    "output_throughput": 3933.5412149613257,
    "total_throughput": 8487.483989565142,
    "itl": 110.00771052459463,
    "ttft": 1421570.2440835687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.209722329573692,
    "arrivals": 98651,
    "finished_requests": 66110,
    "scheduler_time": 73.44564196736071
}
#Debug simulation 
Total elapsed time: 4.690488616935909. Arrivals time: 0.2088131713680923 Scheduler time: 4.3128884974867105 Scheduler overhead time: 0.04547819262370467 Adapter cache time: 0.05439641047269106 Engine time: 0.047025750391185284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_192_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_192_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64478348 . Total output tokens: 56901163
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.981431899126619,
    "estimated_duration": 3600.0157535484673,
    "input_throughput": 4870.768407809393,
    "output_throughput": 4231.117040247955,
    "total_throughput": 9101.885448057348,
    "itl": 121.70390427255055,
    "ttft": 1300013.7504375356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.852489457605657,
    "arrivals": 96558,
    "finished_requests": 70658,
    "scheduler_time": 72.9121842285523
}
#Debug simulation 
Total elapsed time: 4.9815612700767815. Arrivals time: 0.2174798445776105 Scheduler time: 4.6118655344471335 Scheduler overhead time: 0.0427859197370708 Adapter cache time: 0.04505431931465864 Engine time: 0.043916975148022175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_192_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_192_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64478348 . Total output tokens: 56901163
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.858802016824484,
    "estimated_duration": 3600.059773369292,
    "input_throughput": 4681.346716703866,
    "output_throughput": 4073.0387613194384,
    "total_throughput": 8754.385478023305,
    "itl": 105.78669765037696,
    "ttft": 1362729.663447326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.594382675858112,
    "arrivals": 96558,
    "finished_requests": 67920,
    "scheduler_time": 74.09380760256916
}
#Debug simulation 
Total elapsed time: 4.858932863920927. Arrivals time: 0.2177895149216056 Scheduler time: 4.47371022682637 Scheduler overhead time: 0.04783474188297987 Adapter cache time: 0.047383854165673256 Engine time: 0.04930988047271967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_192_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_192_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64478348 . Total output tokens: 56901163
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.856029449030757,
    "estimated_duration": 3600.0186981158245,
    "input_throughput": 4682.223736455072,
    "output_throughput": 4073.621619708647,
    "total_throughput": 8755.84535616372,
    "itl": 105.76384939478801,
    "ttft": 1362555.3229875285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.872507769735599,
    "arrivals": 96558,
    "finished_requests": 67933,
    "scheduler_time": 74.09946148942548
}
#Debug simulation 
Total elapsed time: 4.85615308675915. Arrivals time: 0.21666911570355296 Scheduler time: 4.472015020437539 Scheduler overhead time: 0.047706834971904755 Adapter cache time: 0.04766247654333711 Engine time: 0.04921123571693897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_192_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_192_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64478348 . Total output tokens: 56901163
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.837710411287844,
    "estimated_duration": 3600.099843153204,
    "input_throughput": 4683.92176180054,
    "output_throughput": 4075.0869806850746,
    "total_throughput": 8759.008742485614,
    "itl": 105.79185082790912,
    "ttft": 1362178.4144827486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1447,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.237533601005685,
    "arrivals": 96558,
    "finished_requests": 67957,
    "scheduler_time": 74.10301099945893
}
#Debug simulation 
Total elapsed time: 4.837804844137281. Arrivals time: 0.21606517862528563 Scheduler time: 4.4543371787294745 Scheduler overhead time: 0.04753613192588091 Adapter cache time: 0.04791584890335798 Engine time: 0.04906611377373338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 63996954 . Total output tokens: 56486835
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.028303503990173,
    "estimated_duration": 3600.113128670197,
    "input_throughput": 4988.194914484066,
    "output_throughput": 4300.890123894339,
    "total_throughput": 9289.085038378405,
    "itl": 119.63762181688895,
    "ttft": 1217047.0799339819,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1074,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.101727300314394,
    "arrivals": 95849,
    "finished_requests": 71999,
    "scheduler_time": 72.90722466150812
}
#Debug simulation 
Total elapsed time: 5.0284017329104245. Arrivals time: 0.21380675164982677 Scheduler time: 4.6649592709727585 Scheduler overhead time: 0.04308303352445364 Adapter cache time: 0.04120559664443135 Engine time: 0.04473818838596344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 63996954 . Total output tokens: 56486835
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.920987754128873,
    "estimated_duration": 3600.042928550766,
    "input_throughput": 4787.474855734059,
    "output_throughput": 4132.100726362277,
    "total_throughput": 8919.575582096337,
    "itl": 104.31332600172331,
    "ttft": 1333652.8811229265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1030,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.559687238866476,
    "arrivals": 95849,
    "finished_requests": 69078,
    "scheduler_time": 74.06954679182039
}
#Debug simulation 
Total elapsed time: 4.921082956250757. Arrivals time: 0.21950138546526432 Scheduler time: 4.535106432624161 Scheduler overhead time: 0.04858183301985264 Adapter cache time: 0.0446064081043005 Engine time: 0.05002650152891874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 63996954 . Total output tokens: 56486835
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.9081202037632465,
    "estimated_duration": 3600.0907287842715,
    "input_throughput": 4787.9948864013495,
    "output_throughput": 4132.386687105483,
    "total_throughput": 8920.381573506833,
    "itl": 104.29948448745793,
    "ttft": 1333288.3251077125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.0754719723015915,
    "arrivals": 95849,
    "finished_requests": 69084,
    "scheduler_time": 74.07357319965617
}
#Debug simulation 
Total elapsed time: 4.908211468718946. Arrivals time: 0.21793822245672345 Scheduler time: 4.523703103419393 Scheduler overhead time: 0.0484287585131824 Adapter cache time: 0.04479824844747782 Engine time: 0.05013235053047538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 63996954 . Total output tokens: 56486835
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.903295522090048,
    "estimated_duration": 3600.001228343026,
    "input_throughput": 4788.757532711967,
    "output_throughput": 4132.850534289408,
    "total_throughput": 8921.608067001374,
    "itl": 104.28300197382188,
    "ttft": 1333048.002143427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1030,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.575438568787616,
    "arrivals": 95849,
    "finished_requests": 69090,
    "scheduler_time": 74.07228372661554
}
#Debug simulation 
Total elapsed time: 4.903425909113139. Arrivals time: 0.2167689031921327 Scheduler time: 4.520996849983931 Scheduler overhead time: 0.048141372855752707 Adapter cache time: 0.04450623597949743 Engine time: 0.04981548013165593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_192_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63017650 . Total output tokens: 55613965
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.216676637995988,
    "estimated_duration": 3600.1178992633886,
    "input_throughput": 5167.107167186427,
    "output_throughput": 4479.988281300457,
    "total_throughput": 9647.095448486885,
    "itl": 114.6713694099773,
    "ttft": 1033724.5236793151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.951168128755068,
    "arrivals": 94443,
    "finished_requests": 74911,
    "scheduler_time": 73.35407922457875
}
#Debug simulation 
Total elapsed time: 5.216795634012669. Arrivals time: 0.2136065219528973 Scheduler time: 4.858639778103679 Scheduler overhead time: 0.04483940079808235 Adapter cache time: 0.03205528762191534 Engine time: 0.04613689333200455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_192_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63017650 . Total output tokens: 55613965
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.025971831288189,
    "estimated_duration": 3600.0161406731436,
    "input_throughput": 4943.87977845901,
    "output_throughput": 4285.687173923369,
    "total_throughput": 9229.56695238238,
    "itl": 100.55521641796759,
    "ttft": 1194022.3236179252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.30450053629932,
    "arrivals": 94443,
    "finished_requests": 71656,
    "scheduler_time": 74.19668000342766
}
#Debug simulation 
Total elapsed time: 5.026075128931552. Arrivals time: 0.21624089078977704 Scheduler time: 4.652160165831447 Scheduler overhead time: 0.049584785010665655 Adapter cache time: 0.033338694367557764 Engine time: 0.05102229630574584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_192_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63017650 . Total output tokens: 55613965
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.051982405595481,
    "estimated_duration": 3600.0497252503737,
    "input_throughput": 4944.001155084643,
    "output_throughput": 4286.095520229758,
    "total_throughput": 9230.096675314402,
    "itl": 100.54323234497338,
    "ttft": 1193763.690380283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 862,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.877759513566261,
    "arrivals": 94443,
    "finished_requests": 71661,
    "scheduler_time": 74.19987586152915
}
#Debug simulation 
Total elapsed time: 5.052109389565885. Arrivals time: 0.21451571071520448 Scheduler time: 4.678380537778139 Scheduler overhead time: 0.05018712719902396 Adapter cache time: 0.03356520412489772 Engine time: 0.051439385395497084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_192_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63017650 . Total output tokens: 55613965
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.069262832868844,
    "estimated_duration": 3600.0379864397046,
    "input_throughput": 4944.389494512942,
    "output_throughput": 4286.615601870806,
    "total_throughput": 9231.005096383748,
    "itl": 100.53603695096979,
    "ttft": 1193411.2252696953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.496555929831202,
    "arrivals": 94443,
    "finished_requests": 71667,
    "scheduler_time": 74.20122369671414
}
#Debug simulation 
Total elapsed time: 5.069378240965307. Arrivals time: 0.21927175158634782 Scheduler time: 4.69170740339905 Scheduler overhead time: 0.04983282694593072 Adapter cache time: 0.033177876845002174 Engine time: 0.05147571908310056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_192_slots_128_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_192_slots_128_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26967765 . Total output tokens: 23776682
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.1062827948480844,
    "estimated_duration": 3599.8469403455497,
    "input_throughput": 2788.531058777856,
    "output_throughput": 2413.2734374440083,
    "total_throughput": 5201.804496221864,
    "itl": 77.4879393019475,
    "ttft": 19042.306534517535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.07729599195173,
    "arrivals": 40505,
    "finished_requests": 40293,
    "scheduler_time": 26.881838789967397
}
#Debug simulation 
Total elapsed time: 3.1063755392096937. Arrivals time: 0.10194590594619513 Scheduler time: 2.7060633208602667 Scheduler overhead time: 0.052996364422142506 Adapter cache time: 0.1672041341662407 Engine time: 0.05280590383335948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_192_slots_128_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_192_slots_128_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26967765 . Total output tokens: 23776682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.1153357536531985,
    "estimated_duration": 3599.8595822646544,
    "input_throughput": 2788.3343143305015,
    "output_throughput": 2412.990785194852,
    "total_throughput": 5201.325099525353,
    "itl": 77.98859528677056,
    "ttft": 19316.000322431868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 68.46484150903213,
    "arrivals": 40505,
    "finished_requests": 40290,
    "scheduler_time": 26.93544835385508
}
#Debug simulation 
Total elapsed time: 3.115429519675672. Arrivals time: 0.10035537416115403 Scheduler time: 2.71506101032719 Scheduler overhead time: 0.05274712573736906 Adapter cache time: 0.1677112253382802 Engine time: 0.054281970020383596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_192_slots_128_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_192_slots_128_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26967765 . Total output tokens: 23776682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 3.106717868708074,
    "estimated_duration": 3599.814251502429,
    "input_throughput": 2788.4085951964366,
    "output_throughput": 2413.165344954782,
    "total_throughput": 5201.573940151218,
    "itl": 77.64710209559166,
    "ttft": 19222.43198109424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.15830619669748,
    "arrivals": 40505,
    "finished_requests": 40291,
    "scheduler_time": 26.89906907161214
}
#Debug simulation 
Total elapsed time: 3.106817458756268. Arrivals time: 0.09911970002576709 Scheduler time: 2.708714733365923 Scheduler overhead time: 0.05307064903900027 Adapter cache time: 0.16688335128128529 Engine time: 0.05360083468258381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_192_slots_128_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_192_slots_128_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26967765 . Total output tokens: 23776682
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.097597699146718,
    "estimated_duration": 3599.7933322552003,
    "input_throughput": 2788.1961750598775,
    "output_throughput": 2412.950744191282,
    "total_throughput": 5201.1469192511595,
    "itl": 78.042023109667,
    "ttft": 19499.612966960885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.09184781359734,
    "arrivals": 40505,
    "finished_requests": 40288,
    "scheduler_time": 26.941986272687288
}
#Debug simulation 
Total elapsed time: 3.097724139224738. Arrivals time: 0.10008900612592697 Scheduler time: 2.7006633207201958 Scheduler overhead time: 0.052870828192681074 Adapter cache time: 0.16550299059599638 Engine time: 0.053222625982016325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_192_slots_128_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_192_slots_128_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25044361 . Total output tokens: 22119615
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.9801462469622493,
    "estimated_duration": 3600.018195775476,
    "input_throughput": 2590.1357973529384,
    "output_throughput": 2281.857911062717,
    "total_throughput": 4871.993708415655,
    "itl": 60.732267124527645,
    "ttft": 10601.513323125975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.52084254778845,
    "arrivals": 37714,
    "finished_requests": 37603,
    "scheduler_time": 22.517019228412195
}
#Debug simulation 
Total elapsed time: 2.9802373498678207. Arrivals time: 0.0956884827464819 Scheduler time: 2.5570428958162665 Scheduler overhead time: 0.06393995229154825 Adapter cache time: 0.16915823239833117 Engine time: 0.06393087282776833 
