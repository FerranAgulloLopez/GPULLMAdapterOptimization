INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 97.47000898502301,
    "estimated_duration": 3600.0513227493966,
    "input_throughput": 7251.1494030767635,
    "output_throughput": 6335.613288585255,
    "total_throughput": 13586.762691662017,
    "itl": 85.49406021508412,
    "ttft": 1562934.286046811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.137334353495388,
    "arrivals": 251722,
    "finished_requests": 105678,
    "scheduler_time": 266.06052088954027
}
#Debug simulation 
Total elapsed time: 97.47021490498446. Arrivals time: 0.4775325018563308 Scheduler time: 96.76459111040458 Scheduler overhead time: 0.0884301514015533 Adapter cache time: 0.016781587793957442 Engine time: 0.0879191619460471 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 94.71527014899766,
    "estimated_duration": 3600.0492677921357,
    "input_throughput": 7248.270248257796,
    "output_throughput": 6332.091119958588,
    "total_throughput": 13580.361368216385,
    "itl": 84.85660815850234,
    "ttft": 1562505.3240256987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 199,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.460586540517399,
    "arrivals": 251722,
    "finished_requests": 105653,
    "scheduler_time": 266.2380696470519
}
#Debug simulation 
Total elapsed time: 94.71547143597854. Arrivals time: 0.48308203369379044 Scheduler time: 94.00383465283085 Scheduler overhead time: 0.08923319826135412 Adapter cache time: 0.01725359633564949 Engine time: 0.08772136020706967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 92.88365578401135,
    "estimated_duration": 3600.088034020172,
    "input_throughput": 7161.72236799683,
    "output_throughput": 6255.430641470201,
    "total_throughput": 13417.15300946703,
    "itl": 82.67414927171778,
    "ttft": 1573020.0238377182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4816228453582174,
    "arrivals": 251722,
    "finished_requests": 104344,
    "scheduler_time": 269.9054811346752
}
#Debug simulation 
Total elapsed time: 92.88393219199497. Arrivals time: 0.4673805530183017 Scheduler time: 92.18481203232659 Scheduler overhead time: 0.09068248159019276 Adapter cache time: 0.01724461099365726 Engine time: 0.08865181496366858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 95.22621458000503,
    "estimated_duration": 3600.0062173711367,
    "input_throughput": 7283.915475887266,
    "output_throughput": 6362.511789417456,
    "total_throughput": 13646.427265304723,
    "itl": 84.8891870076664,
    "ttft": 1562805.8093486277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4291956866905078,
    "arrivals": 251722,
    "finished_requests": 106150,
    "scheduler_time": 264.8529193603563
}
#Debug simulation 
Total elapsed time: 95.22638087102678. Arrivals time: 0.4811926002148539 Scheduler time: 94.51748094370123 Scheduler overhead time: 0.08858787990175188 Adapter cache time: 0.01740906381746754 Engine time: 0.0870187200489454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 92.76669145899359,
    "estimated_duration": 3600.0056395453075,
    "input_throughput": 7204.548158228956,
    "output_throughput": 6294.323195244211,
    "total_throughput": 13498.871353473167,
    "itl": 82.87367198144847,
    "ttft": 1572738.092529092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4694548009196318,
    "arrivals": 251722,
    "finished_requests": 104987,
    "scheduler_time": 268.10008972799926
}
#Debug simulation 
Total elapsed time: 92.76686100498773. Arrivals time: 0.4813348719617352 Scheduler time: 92.05698343145195 Scheduler overhead time: 0.08894718869123608 Adapter cache time: 0.016944514587521553 Engine time: 0.08748094778275117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 99.29600365500664,
    "estimated_duration": 3600.0612701069017,
    "input_throughput": 7226.470620381268,
    "output_throughput": 6312.4111771923235,
    "total_throughput": 13538.881797573593,
    "itl": 84.50764139518925,
    "ttft": 1567031.863398215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1108022436592702,
    "arrivals": 251722,
    "finished_requests": 105308,
    "scheduler_time": 267.227442687871
}
#Debug simulation 
Total elapsed time: 99.29617831902578. Arrivals time: 0.48281567479716614 Scheduler time: 98.58358458802104 Scheduler overhead time: 0.09036991640459746 Adapter cache time: 0.016574309556744993 Engine time: 0.08829203376080841 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 33, 33, 17280, 33, 270, 270, 270, 33, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 270, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 17280, 33, 270, 270, 33, 270, 33, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 33, 270, 17280, 17280, 270, 33, 33, 33, 17280, 270, 270, 270, 270, 17280, 270, 17280, 33, 33, 270, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 17280, 17280, 270, 270, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 270, 17280, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 270, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33]
Prompts retrieved: 756036 . Total input tokens: 168224195 . Total output tokens: 148616065
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 93.98528872302268,
    "estimated_duration": 3600.002614840365,
    "input_throughput": 7207.5000426494325,
    "output_throughput": 6296.1415379430455,
    "total_throughput": 13503.641580592479,
    "itl": 82.92853980972282,
    "ttft": 1571958.8241916467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 195,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4413417269103255,
    "arrivals": 251722,
    "finished_requests": 105010,
    "scheduler_time": 268.00516606506187
}
#Debug simulation 
Total elapsed time: 93.98545741604175. Arrivals time: 0.48253782727988437 Scheduler time: 93.27275190211367 Scheduler overhead time: 0.08983480033930391 Adapter cache time: 0.017030607617925853 Engine time: 0.08848151407437399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_128_slots_16_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_128_slots_16_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 96.53509114595363,
    "estimated_duration": 3600.0909110132197,
    "input_throughput": 7261.959391087165,
    "output_throughput": 6364.081787465691,
    "total_throughput": 13626.041178552856,
    "itl": 85.85800484182082,
    "ttft": 1553963.0836587045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3886058967094852,
    "arrivals": 250208,
    "finished_requests": 106150,
    "scheduler_time": 263.5288773583691
}
#Debug simulation 
Total elapsed time: 96.53527401597239. Arrivals time: 0.5200681171845645 Scheduler time: 95.78367950883694 Scheduler overhead time: 0.09108736802591011 Adapter cache time: 0.016871455241926014 Engine time: 0.08884637523442507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_128_slots_16_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_128_slots_16_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 92.95960212196223,
    "estimated_duration": 3600.022895892882,
    "input_throughput": 7265.59462436771,
    "output_throughput": 6371.680031860143,
    "total_throughput": 13637.274656227853,
    "itl": 85.19474847009278,
    "ttft": 1555485.858826538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 233,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7012396090431154,
    "arrivals": 250208,
    "finished_requests": 106164,
    "scheduler_time": 263.17369871472744
}
#Debug simulation 
Total elapsed time: 92.95977341197431. Arrivals time: 0.48966457176720724 Scheduler time: 92.24139743304113 Scheduler overhead time: 0.08918808109592646 Adapter cache time: 0.017343247134704143 Engine time: 0.0875299681792967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_128_slots_16_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_128_slots_16_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 91.05749320599716,
    "estimated_duration": 3600.021738107997,
    "input_throughput": 7185.758554223475,
    "output_throughput": 6303.135272712423,
    "total_throughput": 13488.893826935897,
    "itl": 83.14360674546901,
    "ttft": 1562155.8503700679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8282630138238922,
    "arrivals": 250208,
    "finished_requests": 105000,
    "scheduler_time": 266.4462553518774
}
#Debug simulation 
Total elapsed time: 91.05766130296979. Arrivals time: 0.49385496543254703 Scheduler time: 90.33272797352402 Scheduler overhead time: 0.08994041703408584 Adapter cache time: 0.017488784389570355 Engine time: 0.08838381560053676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_128_slots_16_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_128_slots_16_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 93.06377634999808,
    "estimated_duration": 3600.0438266977603,
    "input_throughput": 7222.13929930104,
    "output_throughput": 6331.561530157352,
    "total_throughput": 13553.700829458392,
    "itl": 84.94174024334475,
    "ttft": 1557376.3827410662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.534114863686262,
    "arrivals": 250208,
    "finished_requests": 105509,
    "scheduler_time": 265.0662159465029
}
#Debug simulation 
Total elapsed time: 93.06394784298027. Arrivals time: 0.4879159099073149 Scheduler time: 92.345941378735 Scheduler overhead time: 0.08927605889039114 Adapter cache time: 0.017561793385539204 Engine time: 0.08863951434614137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_128_slots_16_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_128_slots_16_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 90.57673736097058,
    "estimated_duration": 3600.0891769658347,
    "input_throughput": 7187.642785506912,
    "output_throughput": 6304.036062553175,
    "total_throughput": 13491.678848060088,
    "itl": 83.14663494391993,
    "ttft": 1562076.4111875892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8537828129576557,
    "arrivals": 250208,
    "finished_requests": 105024,
    "scheduler_time": 266.3973181374553
}
#Debug simulation 
Total elapsed time: 90.5769090380054. Arrivals time: 0.4854541816166602 Scheduler time: 89.85900051193312 Scheduler overhead time: 0.09048128838185221 Adapter cache time: 0.01779751747380942 Engine time: 0.08877322648186237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_128_slots_16_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_128_slots_16_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 96.64037337800255,
    "estimated_duration": 3600.0341418956505,
    "input_throughput": 7239.462453063434,
    "output_throughput": 6347.258136826396,
    "total_throughput": 13586.72058988983,
    "itl": 84.83311665827046,
    "ttft": 1556385.852985644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.302319871876385,
    "arrivals": 250208,
    "finished_requests": 105832,
    "scheduler_time": 264.34678753133016
}
#Debug simulation 
Total elapsed time: 96.64054694701917. Arrivals time: 0.5020451121381484 Scheduler time: 95.90710345207481 Scheduler overhead time: 0.09035101078916341 Adapter cache time: 0.01697822503047064 Engine time: 0.08895184972789139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_128_slots_16_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_128_slots_16_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 66, 66, 17280, 66, 135, 135, 135, 66, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 135, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 17280, 66, 135, 135, 66, 135, 66, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 66, 135, 17280, 17280, 135, 66, 66, 66, 17280, 135, 135, 135, 135, 17280, 135, 17280, 66, 66, 135, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 17280, 17280, 135, 135, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 135, 17280, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 135, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66]
Prompts retrieved: 751617 . Total input tokens: 167256539 . Total output tokens: 147740194
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 90.31413873203564,
    "estimated_duration": 3600.039803142189,
    "input_throughput": 7177.259534032844,
    "output_throughput": 6296.63788167419,
    "total_throughput": 13473.897415707033,
    "itl": 83.10318966212957,
    "ttft": 1563129.4396092365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.81749028636143,
    "arrivals": 250208,
    "finished_requests": 104874,
    "scheduler_time": 266.81715751989753
}
#Debug simulation 
Total elapsed time: 90.31430418702075. Arrivals time: 0.48722816654480994 Scheduler time: 89.59757922956487 Scheduler overhead time: 0.08920160599518567 Adapter cache time: 0.017319155216682702 Engine time: 0.08845688652945682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 100.578670168994,
    "estimated_duration": 3600.066822044318,
    "input_throughput": 7361.47391423996,
    "output_throughput": 6423.998537579173,
    "total_throughput": 13785.472451819132,
    "itl": 86.312573477769,
    "ttft": 1545976.3724008529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.408443123805335,
    "arrivals": 249718,
    "finished_requests": 107306,
    "scheduler_time": 261.5560468918196
}
#Debug simulation 
Total elapsed time: 100.57883770397166. Arrivals time: 0.5110365619184449 Scheduler time: 99.8364176202449 Scheduler overhead time: 0.0904233506298624 Adapter cache time: 0.017823959700763226 Engine time: 0.08857240481302142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 92.85152498702519,
    "estimated_duration": 3600.094059509642,
    "input_throughput": 7329.682103804301,
    "output_throughput": 6392.8818579631225,
    "total_throughput": 13722.563961767422,
    "itl": 85.41151688894553,
    "ttft": 1547194.7200895974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7781299911346309,
    "arrivals": 249718,
    "finished_requests": 106796,
    "scheduler_time": 262.99367721496657
}
#Debug simulation 
Total elapsed time: 92.85169070202392. Arrivals time: 0.49127935693832114 Scheduler time: 92.13119762414135 Scheduler overhead time: 0.08930817258078605 Adapter cache time: 0.017452758795116097 Engine time: 0.08785879041533917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 90.43021659099031,
    "estimated_duration": 3600.027949582435,
    "input_throughput": 7215.476480679248,
    "output_throughput": 6296.6319477128645,
    "total_throughput": 13512.108428392114,
    "itl": 83.24644301270791,
    "ttft": 1556410.5539941692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 235,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.773134376006205,
    "arrivals": 249718,
    "finished_requests": 105202,
    "scheduler_time": 267.5620638948302
}
#Debug simulation 
Total elapsed time: 90.43039131403202. Arrivals time: 0.48218743823235855 Scheduler time: 89.71973402024014 Scheduler overhead time: 0.08842857490526512 Adapter cache time: 0.016917934641242027 Engine time: 0.08810210734372959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 94.07624033896718,
    "estimated_duration": 3600.0933157470536,
    "input_throughput": 7276.498330034,
    "output_throughput": 6349.03848186972,
    "total_throughput": 13625.53681190372,
    "itl": 85.28126716357123,
    "ttft": 1550545.399133477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6351527085667459,
    "arrivals": 249718,
    "finished_requests": 106081,
    "scheduler_time": 265.0620364283083
}
#Debug simulation 
Total elapsed time: 94.0764034659951. Arrivals time: 0.49155946786049753 Scheduler time: 93.35408850829117 Scheduler overhead time: 0.0886907132808119 Adapter cache time: 0.01782470161560923 Engine time: 0.08976969070499763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 93.51960345800035,
    "estimated_duration": 3600.0446380569465,
    "input_throughput": 7282.061650810373,
    "output_throughput": 6354.817314806338,
    "total_throughput": 13636.878965616712,
    "itl": 83.49889444341372,
    "ttft": 1550098.284658972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.904001783840363,
    "arrivals": 249718,
    "finished_requests": 106089,
    "scheduler_time": 264.78800531406785
}
#Debug simulation 
Total elapsed time: 93.51977422798518. Arrivals time: 0.49045242747524753 Scheduler time: 92.79840808908921 Scheduler overhead time: 0.09013149054953828 Adapter cache time: 0.01741738896816969 Engine time: 0.08827185747213662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 99.10704005800653,
    "estimated_duration": 3600.0645010818953,
    "input_throughput": 7298.962280287836,
    "output_throughput": 6370.339196174947,
    "total_throughput": 13669.301476462782,
    "itl": 85.15571167570336,
    "ttft": 1548929.2995409425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 201,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2831681090546736,
    "arrivals": 249718,
    "finished_requests": 106406,
    "scheduler_time": 264.16551438755636
}
#Debug simulation 
Total elapsed time: 99.1072088520159. Arrivals time: 0.5002614263212308 Scheduler time: 98.3742402967764 Scheduler overhead time: 0.09046802646480501 Adapter cache time: 0.017537342268042266 Engine time: 0.08944096532650292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 135, 17280, 17280, 33, 33, 17280, 33, 135, 135, 135, 33, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 135, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 17280, 33, 135, 135, 33, 135, 33, 135, 135, 17280, 17280, 17280, 17280, 135, 135, 33, 135, 17280, 17280, 135, 33, 33, 33, 17280, 135, 135, 135, 135, 17280, 135, 17280, 33, 33, 135, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 17280, 17280, 135, 135, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 135, 17280, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 135, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33]
Prompts retrieved: 750231 . Total input tokens: 166948513 . Total output tokens: 147470349
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 93.16649197798688,
    "estimated_duration": 3600.0256771663294,
    "input_throughput": 7282.1000045297105,
    "output_throughput": 6354.850784844278,
    "total_throughput": 13636.950789373988,
    "itl": 83.49852173652063,
    "ttft": 1550090.7263818206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8849470035918103,
    "arrivals": 249718,
    "finished_requests": 106089,
    "scheduler_time": 264.7876946788112
}
#Debug simulation 
Total elapsed time: 93.1666617069859. Arrivals time: 0.48219278012402356 Scheduler time: 92.45519642240833 Scheduler overhead time: 0.0891000721603632 Adapter cache time: 0.01771097182063386 Engine time: 0.08751690300414339 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_128_slots_16_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 101.38856917398516,
    "estimated_duration": 3600.029013964963,
    "input_throughput": 7335.819210777346,
    "output_throughput": 6413.040258965172,
    "total_throughput": 13748.859469742518,
    "itl": 86.48893139710488,
    "ttft": 1523599.929548921,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7258387573389316,
    "arrivals": 248697,
    "finished_requests": 107170,
    "scheduler_time": 261.47495769115585
}
#Debug simulation 
Total elapsed time: 101.3887418259983. Arrivals time: 0.504070577386301 Scheduler time: 100.65440018533263 Scheduler overhead time: 0.09009319712640718 Adapter cache time: 0.017397606803569943 Engine time: 0.08859579922864214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_128_slots_16_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 104.00441536604194,
    "estimated_duration": 3600.053869867103,
    "input_throughput": 7209.126012594381,
    "output_throughput": 6294.428033332876,
    "total_throughput": 13503.554045927258,
    "itl": 84.84604504406457,
    "ttft": 1550899.277181424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.232144129946829,
    "arrivals": 248697,
    "finished_requests": 105138,
    "scheduler_time": 267.16980720773984
}
#Debug simulation 
Total elapsed time: 104.00458206003532. Arrivals time: 0.4993893045466393 Scheduler time: 103.27101966558257 Scheduler overhead time: 0.09124074940336868 Adapter cache time: 0.01741546206176281 Engine time: 0.08989066071808338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_128_slots_16_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 99.32704922399716,
    "estimated_duration": 3600.0275645192974,
    "input_throughput": 7127.6054252729755,
    "output_throughput": 6224.69761644512,
    "total_throughput": 13352.303041718094,
    "itl": 82.73855260333507,
    "ttft": 1562737.2416310415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2951002685679145,
    "arrivals": 248697,
    "finished_requests": 103935,
    "scheduler_time": 270.6247515033786
}
#Debug simulation 
Total elapsed time: 99.3272258869838. Arrivals time: 0.48855099198408425 Scheduler time: 98.60243065695977 Scheduler overhead time: 0.09250678058015183 Adapter cache time: 0.017349214875139296 Engine time: 0.09098175499821082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_128_slots_16_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 99.98253949201899,
    "estimated_duration": 3600.0882110751236,
    "input_throughput": 7310.70280973479,
    "output_throughput": 6393.035017641053,
    "total_throughput": 13703.737827375844,
    "itl": 85.4660393089589,
    "ttft": 1528333.5772845368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.879687109207732,
    "arrivals": 248697,
    "finished_requests": 106774,
    "scheduler_time": 262.45133834014666
}
#Debug simulation 
Total elapsed time: 99.98271414003102. Arrivals time: 0.5073951964150183 Scheduler time: 99.24204040982295 Scheduler overhead time: 0.09086791903246194 Adapter cache time: 0.017911598552018404 Engine time: 0.0894192805280909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_128_slots_16_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 99.25590805301908,
    "estimated_duration": 3600.016767339235,
    "input_throughput": 7127.626802406518,
    "output_throughput": 6224.716285575111,
    "total_throughput": 13352.34308798163,
    "itl": 82.73840745661384,
    "ttft": 1562733.5609831072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.283708823854106,
    "arrivals": 248697,
    "finished_requests": 103935,
    "scheduler_time": 270.6246348282724
}
#Debug simulation 
Total elapsed time: 99.25608002202353. Arrivals time: 0.4886044989689253 Scheduler time: 98.5297416622634 Scheduler overhead time: 0.09285026282304898 Adapter cache time: 0.01757457898929715 Engine time: 0.09094818128505722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_128_slots_16_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 100.74577268597204,
    "estimated_duration": 3600.046752255585,
    "input_throughput": 7305.42429303786,
    "output_throughput": 6387.443714610811,
    "total_throughput": 13692.86800764867,
    "itl": 85.45382134089925,
    "ttft": 1525879.8209007627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.672587286429474,
    "arrivals": 248697,
    "finished_requests": 106738,
    "scheduler_time": 262.681608667215
}
#Debug simulation 
Total elapsed time: 100.74595424096333. Arrivals time: 0.49976531887659803 Scheduler time: 100.01431086019147 Scheduler overhead time: 0.09034183662151918 Adapter cache time: 0.017993847897741944 Engine time: 0.0887040252564475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_128_slots_16_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 66, 17280, 17280, 33, 33, 17280, 33, 66, 66, 66, 33, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 66, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 17280, 33, 66, 66, 33, 66, 33, 66, 66, 17280, 17280, 17280, 17280, 66, 66, 33, 66, 17280, 17280, 66, 33, 33, 33, 17280, 66, 66, 66, 66, 17280, 66, 17280, 33, 33, 66, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 17280, 17280, 66, 66, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 66, 17280, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 66, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33]
Prompts retrieved: 747264 . Total input tokens: 166273979 . Total output tokens: 146883886
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 99.76340361195616,
    "estimated_duration": 3600.0378665227086,
    "input_throughput": 7125.729770386621,
    "output_throughput": 6220.399570860665,
    "total_throughput": 13346.129341247286,
    "itl": 82.74127299534919,
    "ttft": 1561368.32159401,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2708675589039944,
    "arrivals": 248697,
    "finished_requests": 103884,
    "scheduler_time": 270.7536945278089
}
#Debug simulation 
Total elapsed time: 99.76358465995872. Arrivals time: 0.48477925721090287 Scheduler time: 99.04391267924802 Scheduler overhead time: 0.09237062133615837 Adapter cache time: 0.016700652020517737 Engine time: 0.0906760300276801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_128_slots_16_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_128_slots_16_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 97.24206752696773,
    "estimated_duration": 3600.0407124529074,
    "input_throughput": 6820.355924050175,
    "output_throughput": 5978.197948027103,
    "total_throughput": 12798.553872077278,
    "itl": 84.63210652098111,
    "ttft": 1549607.735989356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8580869379779301,
    "arrivals": 200319,
    "finished_requests": 99474,
    "scheduler_time": 269.5005045220519
}
#Debug simulation 
Total elapsed time: 97.24223412695574. Arrivals time: 0.5120993431773968 Scheduler time: 96.48972942505497 Scheduler overhead time: 0.09471852047136053 Adapter cache time: 0.017652531038038433 Engine time: 0.09186171891633421 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_128_slots_16_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_128_slots_16_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 95.9560484510148,
    "estimated_duration": 3600.078356826021,
    "input_throughput": 6778.413018075124,
    "output_throughput": 5949.619390752364,
    "total_throughput": 12728.032408827487,
    "itl": 83.65910088117154,
    "ttft": 1546285.8943111827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0640276901703354,
    "arrivals": 200319,
    "finished_requests": 98911,
    "scheduler_time": 270.9675873010942
}
#Debug simulation 
Total elapsed time: 95.95621393603506. Arrivals time: 0.5053896623430774 Scheduler time: 95.20983873767545 Scheduler overhead time: 0.09445781109388918 Adapter cache time: 0.017854388162959367 Engine time: 0.09214503114344552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_128_slots_16_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_128_slots_16_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 93.63892918103375,
    "estimated_duration": 3600.042245791776,
    "input_throughput": 6730.164910792933,
    "output_throughput": 5911.520906421863,
    "total_throughput": 12641.685817214797,
    "itl": 81.78519458384625,
    "ttft": 1551762.3444508081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.073494869223802,
    "arrivals": 200319,
    "finished_requests": 98157,
    "scheduler_time": 273.25566945026895
}
#Debug simulation 
Total elapsed time: 93.63909109804081. Arrivals time: 0.44580630876589566 Scheduler time: 92.9629641912179 Scheduler overhead time: 0.09057201922405511 Adapter cache time: 0.016670105687808245 Engine time: 0.08734606351936236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_128_slots_16_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_128_slots_16_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 95.08649734698702,
    "estimated_duration": 3600.027964607619,
    "input_throughput": 6779.122062364312,
    "output_throughput": 5938.514703268467,
    "total_throughput": 12717.63676563278,
    "itl": 83.23701586283838,
    "ttft": 1550465.431058877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9257627767650383,
    "arrivals": 200319,
    "finished_requests": 98835,
    "scheduler_time": 271.45433979682895
}
#Debug simulation 
Total elapsed time: 95.08665927901166. Arrivals time: 0.46252591791562736 Scheduler time: 94.3932654443779 Scheduler overhead time: 0.09041936125140637 Adapter cache time: 0.01729541545500979 Engine time: 0.08748005970846862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_128_slots_16_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_128_slots_16_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 94.03732909401879,
    "estimated_duration": 3600.012891980114,
    "input_throughput": 6739.180588504963,
    "output_throughput": 5918.713248907359,
    "total_throughput": 12657.893837412323,
    "itl": 81.81381251129389,
    "ttft": 1549529.859035189,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.103723142659298,
    "arrivals": 200319,
    "finished_requests": 98265,
    "scheduler_time": 273.08304326726983
}
#Debug simulation 
Total elapsed time: 94.03748667304171. Arrivals time: 0.4675147990346886 Scheduler time: 93.3345095400582 Scheduler overhead time: 0.09142811206402257 Adapter cache time: 0.017484404786955565 Engine time: 0.08972433774033561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_128_slots_16_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_128_slots_16_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 94.94433110998943,
    "estimated_duration": 3600.006552110119,
    "input_throughput": 6780.002104633223,
    "output_throughput": 5941.966407661604,
    "total_throughput": 12721.968512294827,
    "itl": 83.36630309681554,
    "ttft": 1549063.1580528142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8066496261814544,
    "arrivals": 200319,
    "finished_requests": 98898,
    "scheduler_time": 271.3045089844426
}
#Debug simulation 
Total elapsed time: 94.94448894303059. Arrivals time: 0.4698411353165284 Scheduler time: 94.24316396412905 Scheduler overhead time: 0.08993887406541035 Adapter cache time: 0.017727774276863784 Engine time: 0.08825908612925559 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_128_slots_16_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_128_slots_16_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080]
Prompts retrieved: 602640 . Total input tokens: 134073297 . Total output tokens: 118407227
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 92.28370652499143,
    "estimated_duration": 3600.0627256375874,
    "input_throughput": 6746.023292052174,
    "output_throughput": 5915.196934861335,
    "total_throughput": 12661.220226913509,
    "itl": 82.11201285355875,
    "ttft": 1557744.0060274946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 288,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.123598909042783,
    "arrivals": 200319,
    "finished_requests": 98439,
    "scheduler_time": 272.57699602932536
}
#Debug simulation 
Total elapsed time: 92.28386355302064. Arrivals time: 0.46458908857312053 Scheduler time: 91.58543669135543 Scheduler overhead time: 0.09164605173282325 Adapter cache time: 0.01745187380583957 Engine time: 0.08880331565160304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_128_slots_16_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_128_slots_16_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 99.27408894599648,
    "estimated_duration": 3600.0419374375883,
    "input_throughput": 6698.782519507269,
    "output_throughput": 5859.281465763672,
    "total_throughput": 12558.063985270941,
    "itl": 82.44182854406652,
    "ttft": 1538284.7607658952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5142416683165338,
    "arrivals": 192932,
    "finished_requests": 97465,
    "scheduler_time": 273.2881346798425
}
#Debug simulation 
Total elapsed time: 99.27425158204278. Arrivals time: 0.4635070155491121 Scheduler time: 98.57823291863315 Scheduler overhead time: 0.09155076293973252 Adapter cache time: 0.01645968039520085 Engine time: 0.08829651807900518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_128_slots_16_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_128_slots_16_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 99.95944791700458,
    "estimated_duration": 3600.072516867591,
    "input_throughput": 6338.354545106308,
    "output_throughput": 5547.849913139566,
    "total_throughput": 11886.204458245873,
    "itl": 76.10876426609359,
    "ttft": 1591635.5908031762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5519068385846926,
    "arrivals": 192932,
    "finished_requests": 92330,
    "scheduler_time": 288.09294354069806
}
#Debug simulation 
Total elapsed time: 99.95960745500633. Arrivals time: 0.4386803219676949 Scheduler time: 99.27929676510394 Scheduler overhead time: 0.09584290668135509 Adapter cache time: 0.017274573212489486 Engine time: 0.0902558829402551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_128_slots_16_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_128_slots_16_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 99.08564347296488,
    "estimated_duration": 3600.0764762086897,
    "input_throughput": 6597.46568078827,
    "output_throughput": 5773.793178385544,
    "total_throughput": 12371.258859173815,
    "itl": 79.72329058522328,
    "ttft": 1552878.8784678984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8355661980016205,
    "arrivals": 192932,
    "finished_requests": 96016,
    "scheduler_time": 277.64265345464713
}
#Debug simulation 
Total elapsed time: 99.08580375695601. Arrivals time: 0.4562336945091374 Scheduler time: 98.39344361290568 Scheduler overhead time: 0.0927667535142973 Adapter cache time: 0.01702505227876827 Engine time: 0.08887790807057172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_128_slots_16_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_128_slots_16_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 98.4550111789722,
    "estimated_duration": 3600.057479962653,
    "input_throughput": 6693.904787389672,
    "output_throughput": 5874.787032627992,
    "total_throughput": 12568.691820017664,
    "itl": 82.55596873508605,
    "ttft": 1533117.2142664932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6423676665546354,
    "arrivals": 192932,
    "finished_requests": 97477,
    "scheduler_time": 273.3269212476188
}
#Debug simulation 
Total elapsed time: 98.4551565820002. Arrivals time: 0.46849763666978106 Scheduler time: 97.75486302468926 Scheduler overhead time: 0.0917788841179572 Adapter cache time: 0.016470983799081296 Engine time: 0.08718936599325389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_128_slots_16_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_128_slots_16_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 96.89753060805378,
    "estimated_duration": 3600.074701686868,
    "input_throughput": 6653.388050191462,
    "output_throughput": 5823.267775576133,
    "total_throughput": 12476.655825767595,
    "itl": 80.54636513321981,
    "ttft": 1543270.1076629623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8491780766192871,
    "arrivals": 192932,
    "finished_requests": 96902,
    "scheduler_time": 274.92789442082363
}
#Debug simulation 
Total elapsed time: 96.89767035102705. Arrivals time: 0.47158865310484543 Scheduler time: 96.18869974045083 Scheduler overhead time: 0.09331905242288485 Adapter cache time: 0.017468109028413892 Engine time: 0.08977993647567928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_128_slots_16_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_128_slots_16_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 101.21479532402009,
    "estimated_duration": 3600.061262742296,
    "input_throughput": 6757.3080635493025,
    "output_throughput": 5914.589071126096,
    "total_throughput": 12671.897134675399,
    "itl": 82.70851324231225,
    "ttft": 1524947.8475948088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.519373183855782,
    "arrivals": 192932,
    "finished_requests": 98365,
    "scheduler_time": 270.981866528329
}
#Debug simulation 
Total elapsed time: 101.21493880898925. Arrivals time: 0.476512715453282 Scheduler time: 100.5062459296314 Scheduler overhead time: 0.09163725329563022 Adapter cache time: 0.016890327271539718 Engine time: 0.08747384446905926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_128_slots_16_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_128_slots_16_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 540, 540, 8640, 540, 4320, 4320, 4320, 540, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 540, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 540, 540, 4320, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 4320, 8640, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 4320, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540]
Prompts retrieved: 579960 . Total input tokens: 129013245 . Total output tokens: 113946092
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 98.52090731798671,
    "estimated_duration": 3600.0004172581266,
    "input_throughput": 6630.531175932495,
    "output_throughput": 5801.027660965018,
    "total_throughput": 12431.558836897513,
    "itl": 80.21700130080974,
    "ttft": 1550579.236112793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.772919417507951,
    "arrivals": 192932,
    "finished_requests": 96517,
    "scheduler_time": 276.04508766499976
}
#Debug simulation 
Total elapsed time: 98.52104287501425. Arrivals time: 0.467520625970792 Scheduler time: 97.81718902953435 Scheduler overhead time: 0.09280837618280202 Adapter cache time: 0.0170372134889476 Engine time: 0.08945432875771075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_128_slots_16_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_128_slots_16_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 99.83198161399923,
    "estimated_duration": 3600.027883762557,
    "input_throughput": 6706.537499028,
    "output_throughput": 5909.178119411225,
    "total_throughput": 12615.715618439224,
    "itl": 84.16246311174241,
    "ttft": 1526573.551990077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 259,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7126139392750317,
    "arrivals": 188974,
    "finished_requests": 98326,
    "scheduler_time": 269.67160932080156
}
#Debug simulation 
Total elapsed time: 99.83212198095862. Arrivals time: 0.4682312077493407 Scheduler time: 99.13041411573067 Scheduler overhead time: 0.09244271146599203 Adapter cache time: 0.01674427726538852 Engine time: 0.08801924181170762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_128_slots_16_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_128_slots_16_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 97.78939594898839,
    "estimated_duration": 3600.0436757154243,
    "input_throughput": 6694.315450273176,
    "output_throughput": 5903.799207596079,
    "total_throughput": 12598.114657869255,
    "itl": 83.51632378848046,
    "ttft": 1534569.9968832042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9246863196464277,
    "arrivals": 188974,
    "finished_requests": 98164,
    "scheduler_time": 269.8707192043366
}
#Debug simulation 
Total elapsed time: 97.78954140900169. Arrivals time: 0.4684036663384177 Scheduler time: 97.08772936463356 Scheduler overhead time: 0.09176350181223825 Adapter cache time: 0.017013172851875424 Engine time: 0.0883200285024941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_128_slots_16_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_128_slots_16_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 97.03035376803018,
    "estimated_duration": 3600.004279976228,
    "input_throughput": 6625.734622781478,
    "output_throughput": 5845.179161881149,
    "total_throughput": 12470.913784662627,
    "itl": 81.3736811548206,
    "ttft": 1541191.9383143778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9851260207127837,
    "arrivals": 188974,
    "finished_requests": 97164,
    "scheduler_time": 272.7019371292887
}
#Debug simulation 
Total elapsed time: 97.0304967900156. Arrivals time: 0.4686971670598723 Scheduler time: 96.32435902149882 Scheduler overhead time: 0.09344669076381251 Adapter cache time: 0.01730858359951526 Engine time: 0.08986631274456158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_128_slots_16_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_128_slots_16_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 98.82592568499967,
    "estimated_duration": 3600.0390288977605,
    "input_throughput": 6658.491146230504,
    "output_throughput": 5873.733542959467,
    "total_throughput": 12532.22468918997,
    "itl": 82.92772228236096,
    "ttft": 1533029.3714109522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7112025759275984,
    "arrivals": 188974,
    "finished_requests": 97655,
    "scheduler_time": 271.36608784983616
}
#Debug simulation 
Total elapsed time: 98.82606989098713. Arrivals time: 0.4667011251440272 Scheduler time: 98.12470238108654 Scheduler overhead time: 0.09216129156993702 Adapter cache time: 0.016996202466543764 Engine time: 0.08909451909130439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_128_slots_16_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_128_slots_16_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 97.33775413100375,
    "estimated_duration": 3600.056009123745,
    "input_throughput": 6587.323347164306,
    "output_throughput": 5812.848174296471,
    "total_throughput": 12400.171521460778,
    "itl": 80.93492002188988,
    "ttft": 1544493.3603935177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9159078490920418,
    "arrivals": 188974,
    "finished_requests": 96694,
    "scheduler_time": 274.26389452663756
}
#Debug simulation 
Total elapsed time: 97.33789767499547. Arrivals time: 0.46445003198459744 Scheduler time: 96.63476827234263 Scheduler overhead time: 0.09447638969868422 Adapter cache time: 0.01764443767024204 Engine time: 0.08967509574722499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_128_slots_16_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_128_slots_16_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 97.86960924300365,
    "estimated_duration": 3600.0826470922143,
    "input_throughput": 6656.480239239957,
    "output_throughput": 5868.87887617398,
    "total_throughput": 12525.359115413936,
    "itl": 82.8460769502336,
    "ttft": 1536069.9790799741,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.647051602667192,
    "arrivals": 188974,
    "finished_requests": 97612,
    "scheduler_time": 271.56885769408814
}
#Debug simulation 
Total elapsed time: 97.86974995798664. Arrivals time: 0.46411231585079804 Scheduler time: 97.1720203179284 Scheduler overhead time: 0.0914708057534881 Adapter cache time: 0.01718368468573317 Engine time: 0.08850956335663795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_128_slots_16_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_128_slots_16_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 270, 270, 8640, 270, 4320, 4320, 4320, 270, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 270, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 270, 270, 4320, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 270, 8640, 270, 8640, 4320, 270, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 4320, 8640, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 4320, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270]
Prompts retrieved: 568620 . Total input tokens: 126498117 . Total output tokens: 111714288
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 98.31828871800099,
    "estimated_duration": 3600.017718791565,
    "input_throughput": 6635.995116162697,
    "output_throughput": 5852.715082489268,
    "total_throughput": 12488.710198651965,
    "itl": 81.33823217651224,
    "ttft": 1537933.3825328657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 259,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9134194499440547,
    "arrivals": 188974,
    "finished_requests": 97319,
    "scheduler_time": 272.32292162093063
}
#Debug simulation 
Total elapsed time: 98.31842814199626. Arrivals time: 0.4682857738225721 Scheduler time: 97.61369025905151 Scheduler overhead time: 0.09292470949003473 Adapter cache time: 0.0169884588685818 Engine time: 0.08970556524582207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_128_slots_16_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_128_slots_16_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 98.51861034298781,
    "estimated_duration": 3600.001147483103,
    "input_throughput": 6831.040322637959,
    "output_throughput": 5939.997828875794,
    "total_throughput": 12771.038151513754,
    "itl": 84.23400465900916,
    "ttft": 1505235.3171479057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7324511663708815,
    "arrivals": 187135,
    "finished_requests": 99186,
    "scheduler_time": 267.7566647969623
}
#Debug simulation 
Total elapsed time: 98.51875705498969. Arrivals time: 0.47335799713619053 Scheduler time: 97.81280890700873 Scheduler overhead time: 0.09141868929145858 Adapter cache time: 0.01701276784297079 Engine time: 0.08826909528579563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_128_slots_16_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_128_slots_16_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 100.04248429904692,
    "estimated_duration": 3600.0058475763353,
    "input_throughput": 6808.14810800951,
    "output_throughput": 5943.3939570972625,
    "total_throughput": 12751.542065106772,
    "itl": 83.43252216146975,
    "ttft": 1493593.2111968175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.844745642486962,
    "arrivals": 187135,
    "finished_requests": 98952,
    "scheduler_time": 268.4366832068401
}
#Debug simulation 
Total elapsed time: 100.04262959305197. Arrivals time: 0.4699425785802305 Scheduler time: 99.33916263264837 Scheduler overhead time: 0.09154533129185438 Adapter cache time: 0.017096280003897846 Engine time: 0.08808788988972083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_128_slots_16_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_128_slots_16_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 100.25493106502108,
    "estimated_duration": 3600.045836700056,
    "input_throughput": 6745.613278707625,
    "output_throughput": 5879.942356346074,
    "total_throughput": 12625.555635053699,
    "itl": 81.47049965904894,
    "ttft": 1508084.1119719297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7871097577596131,
    "arrivals": 187135,
    "finished_requests": 97971,
    "scheduler_time": 271.0656409489815
}
#Debug simulation 
Total elapsed time: 100.25506919901818. Arrivals time: 0.4635704950778745 Scheduler time: 99.55606846598675 Scheduler overhead time: 0.09286167926620692 Adapter cache time: 0.017334399337414652 Engine time: 0.08878994308179244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_128_slots_16_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_128_slots_16_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 98.42810975096654,
    "estimated_duration": 3600.0925000041125,
    "input_throughput": 6811.988580841183,
    "output_throughput": 5932.55562182794,
    "total_throughput": 12744.544202669123,
    "itl": 83.39166607897243,
    "ttft": 1510402.0218650384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.843602841584941,
    "arrivals": 187135,
    "finished_requests": 99034,
    "scheduler_time": 268.22871160204005
}
#Debug simulation 
Total elapsed time: 98.42825661599636. Arrivals time: 0.47323356254491955 Scheduler time: 97.72165942902211 Scheduler overhead time: 0.09160510264337063 Adapter cache time: 0.017449583509005606 Engine time: 0.08812760276487097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_128_slots_16_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_128_slots_16_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 98.51428327197209,
    "estimated_duration": 3600.002917923842,
    "input_throughput": 6717.0684444738445,
    "output_throughput": 5876.921625441742,
    "total_throughput": 12593.990069915586,
    "itl": 81.3910593131593,
    "ttft": 1504038.2811366047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8602038041828253,
    "arrivals": 187135,
    "finished_requests": 97628,
    "scheduler_time": 272.1670856138992
}
#Debug simulation 
Total elapsed time: 98.51442257699091. Arrivals time: 0.4653700421913527 Scheduler time: 97.81350676581496 Scheduler overhead time: 0.09245062002446502 Adapter cache time: 0.017164313641842455 Engine time: 0.08914095041109249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_128_slots_16_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_128_slots_16_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 98.12301506800577,
    "estimated_duration": 3600.0537920074207,
    "input_throughput": 6812.632370785821,
    "output_throughput": 5932.89107163318,
    "total_throughput": 12745.523442419002,
    "itl": 83.39012994907857,
    "ttft": 1510252.6430891294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7172747330134674,
    "arrivals": 187135,
    "finished_requests": 99040,
    "scheduler_time": 268.2317746428449
}
#Debug simulation 
Total elapsed time: 98.1231545630144. Arrivals time: 0.4647803860716522 Scheduler time: 97.42645319440635 Scheduler overhead time: 0.091256090963725 Adapter cache time: 0.01748556870734319 Engine time: 0.08718625514302403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_128_slots_16_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_128_slots_16_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 135, 135, 8640, 135, 4320, 4320, 4320, 135, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 135, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 135, 135, 4320, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 135, 8640, 135, 8640, 4320, 135, 8640, 8640, 4320, 4320, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 4320, 8640, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 4320, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135]
Prompts retrieved: 562950 . Total input tokens: 125229921 . Total output tokens: 110625736
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 98.02206585503882,
    "estimated_duration": 3600.0181914451236,
    "input_throughput": 6728.618499084949,
    "output_throughput": 5868.56006733655,
    "total_throughput": 12597.178566421499,
    "itl": 81.27769590479534,
    "ttft": 1507470.0195317483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7777849952690354,
    "arrivals": 187135,
    "finished_requests": 97752,
    "scheduler_time": 271.9592685503281
}
#Debug simulation 
Total elapsed time: 98.02221158501925. Arrivals time: 0.45955440343823284 Scheduler time: 97.32608855183935 Scheduler overhead time: 0.09258240758208558 Adapter cache time: 0.01723229343770072 Engine time: 0.08926715358393267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 97.39027279202128,
    "estimated_duration": 3600.0807521659776,
    "input_throughput": 6848.014446666885,
    "output_throughput": 5958.574120064907,
    "total_throughput": 12806.588566731793,
    "itl": 84.92563432746792,
    "ttft": 1500586.4390624557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9374358463613293,
    "arrivals": 186179,
    "finished_requests": 99616,
    "scheduler_time": 266.90907040682043
}
#Debug simulation 
Total elapsed time: 97.39041272702161. Arrivals time: 0.4538544829702005 Scheduler time: 96.70438389823539 Scheduler overhead time: 0.09104880812810734 Adapter cache time: 0.017366854182910174 Engine time: 0.08759259444195777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 98.38242065196391,
    "estimated_duration": 3600.1084969829776,
    "input_throughput": 6804.9985217197855,
    "output_throughput": 5937.624384907828,
    "total_throughput": 12742.622906627614,
    "itl": 83.81070688280376,
    "ttft": 1503569.6389372118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0259980176482375,
    "arrivals": 186179,
    "finished_requests": 99102,
    "scheduler_time": 268.5238842607399
}
#Debug simulation 
Total elapsed time: 98.382561395003. Arrivals time: 0.45941554044838995 Scheduler time: 97.69049671158427 Scheduler overhead time: 0.09148211171850562 Adapter cache time: 0.017261985572986305 Engine time: 0.08765545394271612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 95.80887730797986,
    "estimated_duration": 3600.00622157247,
    "input_throughput": 6711.883400425281,
    "output_throughput": 5847.9785045494245,
    "total_throughput": 12559.861904974707,
    "itl": 81.57805412656128,
    "ttft": 1520508.5692968306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.055633916081867,
    "arrivals": 186179,
    "finished_requests": 97522,
    "scheduler_time": 272.4195670227038
}
#Debug simulation 
Total elapsed time: 95.80901734298095. Arrivals time: 0.4481690099928528 Scheduler time: 95.12516050069826 Scheduler overhead time: 0.09302927856333554 Adapter cache time: 0.01753346179611981 Engine time: 0.08847442141268402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 98.76173608499812,
    "estimated_duration": 3600.0085471404586,
    "input_throughput": 6805.187454196383,
    "output_throughput": 5937.7892358003855,
    "total_throughput": 12742.976689996769,
    "itl": 83.80805857460504,
    "ttft": 1503535.1793218888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9010581300500755,
    "arrivals": 186179,
    "finished_requests": 99102,
    "scheduler_time": 268.52464880983626
}
#Debug simulation 
Total elapsed time: 98.7618723869673. Arrivals time: 0.4597232798114419 Scheduler time: 98.06952076684684 Scheduler overhead time: 0.09113063727272674 Adapter cache time: 0.017472780775278807 Engine time: 0.0878307546954602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 94.48972551099723,
    "estimated_duration": 3600.046185907342,
    "input_throughput": 6743.5337621595845,
    "output_throughput": 5871.830223387048,
    "total_throughput": 12615.363985546632,
    "itl": 81.83200178639338,
    "ttft": 1517565.786739388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.133904395406142,
    "arrivals": 186179,
    "finished_requests": 98100,
    "scheduler_time": 271.19355515619253
}
#Debug simulation 
Total elapsed time: 94.48987026698887. Arrivals time: 0.4475648579536937 Scheduler time: 93.80988217599224 Scheduler overhead time: 0.0918052697670646 Adapter cache time: 0.016928320634178817 Engine time: 0.0873848712653853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 96.31964030500967,
    "estimated_duration": 3600.0763403363067,
    "input_throughput": 6787.050520633535,
    "output_throughput": 5931.859766619581,
    "total_throughput": 12718.910287253117,
    "itl": 83.86011175080574,
    "ttft": 1510329.3095636794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.825801389003166,
    "arrivals": 186179,
    "finished_requests": 98777,
    "scheduler_time": 268.8951600574355
}
#Debug simulation 
Total elapsed time: 96.31978540797718. Arrivals time: 0.45781932276440784 Scheduler time: 95.6300223476137 Scheduler overhead time: 0.09103388548828661 Adapter cache time: 0.01753168011782691 Engine time: 0.08749237412121147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 66, 66, 8640, 66, 4320, 4320, 4320, 66, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 66, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 66, 66, 4320, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 66, 8640, 66, 8640, 4320, 66, 8640, 8640, 4320, 4320, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 4320, 8640, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 4320, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66]
Prompts retrieved: 560052 . Total input tokens: 124571866 . Total output tokens: 110080304
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 94.637250624015,
    "estimated_duration": 3600.0260177389378,
    "input_throughput": 6743.571540976705,
    "output_throughput": 5871.86311872175,
    "total_throughput": 12615.434659698454,
    "itl": 81.83133931458981,
    "ttft": 1517557.4830638778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.114228263627745,
    "arrivals": 186179,
    "finished_requests": 98100,
    "scheduler_time": 271.1929619883471
}
#Debug simulation 
Total elapsed time: 94.6373897800222. Arrivals time: 0.4529214006033726 Scheduler time: 93.95170173776569 Scheduler overhead time: 0.09153154247906059 Adapter cache time: 0.017381178273353726 Engine time: 0.08777341997483745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 98.48013730399543,
    "estimated_duration": 3600.035767074063,
    "input_throughput": 6722.504043249998,
    "output_throughput": 5894.014774538064,
    "total_throughput": 12616.518817788063,
    "itl": 84.50798677531483,
    "ttft": 1524465.9028162225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7655132115306311,
    "arrivals": 185762,
    "finished_requests": 98115,
    "scheduler_time": 269.7211560416578
}
#Debug simulation 
Total elapsed time: 98.4802740830346. Arrivals time: 0.4569548809668049 Scheduler time: 97.78925915021682 Scheduler overhead time: 0.09208258561557159 Adapter cache time: 0.017269182193558663 Engine time: 0.08832694712327793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 97.89251391799189,
    "estimated_duration": 3600.070230169818,
    "input_throughput": 6683.175455403568,
    "output_throughput": 5865.543072753869,
    "total_throughput": 12548.718528157437,
    "itl": 83.41333045205698,
    "ttft": 1528929.1466783728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9366231244802499,
    "arrivals": 185762,
    "finished_requests": 97523,
    "scheduler_time": 271.00739862251925
}
#Debug simulation 
Total elapsed time: 97.8926585589652. Arrivals time: 0.4548313217237592 Scheduler time: 97.20391658652807 Scheduler overhead time: 0.0921598183340393 Adapter cache time: 0.017286575865000486 Engine time: 0.0883949197595939 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 95.52904816198861,
    "estimated_duration": 3600.0679384152936,
    "input_throughput": 6679.9792146661,
    "output_throughput": 5859.438310846292,
    "total_throughput": 12539.417525512392,
    "itl": 82.00630568017282,
    "ttft": 1530286.7918485077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0756716342177315,
    "arrivals": 185762,
    "finished_requests": 97446,
    "scheduler_time": 271.55456207719607
}
#Debug simulation 
Total elapsed time: 95.52918230497744. Arrivals time: 0.4552508389460854 Scheduler time: 94.84018983325223 Scheduler overhead time: 0.0917898136540316 Adapter cache time: 0.017132505890913308 Engine time: 0.0886729751364328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 96.82700930000283,
    "estimated_duration": 3600.096132927603,
    "input_throughput": 6698.750008208453,
    "output_throughput": 5881.385168118175,
    "total_throughput": 12580.135176326628,
    "itl": 83.65903508023281,
    "ttft": 1524231.3546266023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8236200417159107,
    "arrivals": 185762,
    "finished_requests": 97874,
    "scheduler_time": 270.53447272282955
}
#Debug simulation 
Total elapsed time: 96.82714455499081. Arrivals time: 0.4606252960511483 Scheduler time: 96.13250407594023 Scheduler overhead time: 0.09224207897204906 Adapter cache time: 0.017031307390425354 Engine time: 0.08820948377251625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 95.20746896404307,
    "estimated_duration": 3600.047213403909,
    "input_throughput": 6680.017670452113,
    "output_throughput": 5859.4720428832625,
    "total_throughput": 12539.489713335375,
    "itl": 82.00568750849538,
    "ttft": 1530278.0279588392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0555812680861054,
    "arrivals": 185762,
    "finished_requests": 97446,
    "scheduler_time": 271.5539274319487
}
#Debug simulation 
Total elapsed time: 95.20760408701608. Arrivals time: 0.45012052566744387 Scheduler time: 94.52371584792854 Scheduler overhead time: 0.09192336315754801 Adapter cache time: 0.01721562969032675 Engine time: 0.08808068407233804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 98.35071981599322,
    "estimated_duration": 3600.0702826993033,
    "input_throughput": 6683.806456677946,
    "output_throughput": 5865.731039052553,
    "total_throughput": 12549.537495730498,
    "itl": 83.40576948803454,
    "ttft": 1528975.02537236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.685355128310615,
    "arrivals": 185762,
    "finished_requests": 97530,
    "scheduler_time": 271.02413156059856
}
#Debug simulation 
Total elapsed time: 98.35085168096703. Arrivals time: 0.46070915792370215 Scheduler time: 97.65596053015906 Scheduler overhead time: 0.09244900837074965 Adapter cache time: 0.016893478808924556 Engine time: 0.08871875412296504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 4320, 8640, 8640, 33, 33, 8640, 33, 4320, 4320, 4320, 33, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 33, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 33, 33, 4320, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 33, 8640, 33, 8640, 4320, 33, 8640, 8640, 4320, 4320, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 4320, 8640, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 4320, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33]
Prompts retrieved: 558666 . Total input tokens: 124277846 . Total output tokens: 109806754
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 96.09442431101343,
    "estimated_duration": 3600.0274676150757,
    "input_throughput": 6680.054309677649,
    "output_throughput": 5859.5041814985025,
    "total_throughput": 12539.55849117615,
    "itl": 82.00527415741406,
    "ttft": 1530269.613858325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.036319370660938,
    "arrivals": 185762,
    "finished_requests": 97446,
    "scheduler_time": 271.5534435405416
}
#Debug simulation 
Total elapsed time: 96.0945675559924. Arrivals time: 0.4523911059368402 Scheduler time: 95.40751445596106 Scheduler overhead time: 0.09253524383530021 Adapter cache time: 0.017380545497871935 Engine time: 0.08837445446988568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_128_slots_16_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_128_slots_16_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 110.32079166296171,
    "estimated_duration": 3600.049335993406,
    "input_throughput": 6553.589075603494,
    "output_throughput": 5729.531479964634,
    "total_throughput": 12283.120555568128,
    "itl": 82.00402890115426,
    "ttft": 1379193.2531964434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5340788954123836,
    "arrivals": 146610,
    "finished_requests": 95662,
    "scheduler_time": 261.9587962667504
}
#Debug simulation 
Total elapsed time: 110.32093907595845. Arrivals time: 0.4521938631660305 Scheduler time: 109.62249332270585 Scheduler overhead time: 0.09745490073692054 Adapter cache time: 0.018105932569596916 Engine time: 0.09265858517028391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_128_slots_16_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_128_slots_16_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 109.2199963569874,
    "estimated_duration": 3600.034753520634,
    "input_throughput": 6456.4262823488825,
    "output_throughput": 5650.562950845527,
    "total_throughput": 12106.989233194408,
    "itl": 80.04076080392505,
    "ttft": 1393166.631921007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9480027453880777,
    "arrivals": 146610,
    "finished_requests": 94260,
    "scheduler_time": 265.6228229074205
}
#Debug simulation 
Total elapsed time: 109.22013508901. Arrivals time: 0.4496992440545 Scheduler time: 108.52242340648081 Scheduler overhead time: 0.09782018238911405 Adapter cache time: 0.017916453070938587 Engine time: 0.09380302985664457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_128_slots_16_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_128_slots_16_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 109.03879396995762,
    "estimated_duration": 3600.049463406645,
    "input_throughput": 6447.5797446503375,
    "output_throughput": 5648.957384256606,
    "total_throughput": 12096.537128906944,
    "itl": 79.10471960472312,
    "ttft": 1396815.2868638155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6044727523578373,
    "arrivals": 146610,
    "finished_requests": 94170,
    "scheduler_time": 265.94320461836503
}
#Debug simulation 
Total elapsed time: 109.03894381294958. Arrivals time: 0.44610203499905765 Scheduler time: 108.34316923189908 Scheduler overhead time: 0.09867391077568755 Adapter cache time: 0.01814768329495564 Engine time: 0.0944793185335584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_128_slots_16_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_128_slots_16_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 109.52008065499831,
    "estimated_duration": 3600.0418781682747,
    "input_throughput": 6456.604335899205,
    "output_throughput": 5650.766765621808,
    "total_throughput": 12107.371101521012,
    "itl": 80.03884077185421,
    "ttft": 1393165.2787026665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8286157416831679,
    "arrivals": 146610,
    "finished_requests": 94263,
    "scheduler_time": 265.63156894704537
}
#Debug simulation 
Total elapsed time: 109.52022225398105. Arrivals time: 0.44681445363676175 Scheduler time: 108.82494053355185 Scheduler overhead time: 0.09776119084563106 Adapter cache time: 0.01845303934533149 Engine time: 0.09338597021996975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_128_slots_16_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_128_slots_16_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 106.93170136399567,
    "estimated_duration": 3600.0416457581014,
    "input_throughput": 6468.037120469636,
    "output_throughput": 5658.533151693655,
    "total_throughput": 12126.570272163292,
    "itl": 79.22961829745998,
    "ttft": 1403658.9981806348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7151509043900344,
    "arrivals": 146610,
    "finished_requests": 94464,
    "scheduler_time": 265.432180925855
}
#Debug simulation 
Total elapsed time: 106.93184267304605. Arrivals time: 0.449387009779457 Scheduler time: 106.23204331204761 Scheduler overhead time: 0.09839687083149329 Adapter cache time: 0.017907990841194987 Engine time: 0.095122603001073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_128_slots_16_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_128_slots_16_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 112.41892315499717,
    "estimated_duration": 3600.022848040526,
    "input_throughput": 6490.3515856066515,
    "output_throughput": 5695.144965860283,
    "total_throughput": 12185.496551466935,
    "itl": 80.83626572835202,
    "ttft": 1378142.9560870288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 211,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3470073184603786,
    "arrivals": 146610,
    "finished_requests": 94855,
    "scheduler_time": 263.90349243888414
}
#Debug simulation 
Total elapsed time: 112.4190724149812. Arrivals time: 0.4531201757490635 Scheduler time: 111.71564455644693 Scheduler overhead time: 0.09895241219783202 Adapter cache time: 0.017975120164919645 Engine time: 0.09458694234490395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_128_slots_16_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_128_slots_16_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 540, 540, 8640, 540, 1080, 1080, 1080, 540, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 540, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 540, 540, 1080, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 540, 8640, 540, 8640, 1080, 540, 8640, 8640, 1080, 1080, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 540, 8640, 540, 540, 8640, 1080, 8640, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 1080, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540]
Prompts retrieved: 440640 . Total input tokens: 97986704 . Total output tokens: 86702070
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 111.26923023100244,
    "estimated_duration": 3600.0515209993937,
    "input_throughput": 6446.981068081194,
    "output_throughput": 5643.740341349248,
    "total_throughput": 12090.721409430444,
    "itl": 78.96308991809352,
    "ttft": 1392504.6116312402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5784778708033302,
    "arrivals": 146610,
    "finished_requests": 94116,
    "scheduler_time": 266.24857343671425
}
#Debug simulation 
Total elapsed time: 111.2693820259883. Arrivals time: 0.45096409937832505 Scheduler time: 110.56494347995613 Scheduler overhead time: 0.10038629680639133 Adapter cache time: 0.018107503768987954 Engine time: 0.09578218503156677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_128_slots_16_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_128_slots_16_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 106.95560169802047,
    "estimated_duration": 3600.0599639880475,
    "input_throughput": 6341.044101585357,
    "output_throughput": 5538.306916952842,
    "total_throughput": 11879.351018538198,
    "itl": 79.59589249662794,
    "ttft": 1431063.076828691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 195,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2894197612302363,
    "arrivals": 142827,
    "finished_requests": 92122,
    "scheduler_time": 269.16119942753414
}
#Debug simulation 
Total elapsed time: 106.95574481302174. Arrivals time: 0.43676242243964225 Scheduler time: 106.26849874027539 Scheduler overhead time: 0.09881844336632639 Adapter cache time: 0.0175403559114784 Engine time: 0.09437806665664539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_128_slots_16_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_128_slots_16_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 107.86670197203057,
    "estimated_duration": 3600.055413685131,
    "input_throughput": 6317.018597422354,
    "output_throughput": 5516.072037255824,
    "total_throughput": 11833.09063467818,
    "itl": 78.60827080578044,
    "ttft": 1419626.5461201742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 194,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4189493890013558,
    "arrivals": 142827,
    "finished_requests": 91741,
    "scheduler_time": 270.36476986728354
}
#Debug simulation 
Total elapsed time: 107.8668382060132. Arrivals time: 0.434715234907344 Scheduler time: 107.17929862171877 Scheduler overhead time: 0.10017361410427839 Adapter cache time: 0.017806690942961723 Engine time: 0.09540260332869366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_128_slots_16_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_128_slots_16_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 107.47675295500085,
    "estimated_duration": 3600.094301296353,
    "input_throughput": 6265.511153937741,
    "output_throughput": 5469.923105322282,
    "total_throughput": 11735.434259260024,
    "itl": 76.8430363203964,
    "ttft": 1423735.942933432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4285079445317412,
    "arrivals": 142827,
    "finished_requests": 90966,
    "scheduler_time": 272.47784031039896
}
#Debug simulation 
Total elapsed time: 107.47689894202631. Arrivals time: 0.44273188430815935 Scheduler time: 106.77859348576749 Scheduler overhead time: 0.10174868023023009 Adapter cache time: 0.018194691045209765 Engine time: 0.0959489291999489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_128_slots_16_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_128_slots_16_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 108.54481520404806,
    "estimated_duration": 3600.0132277393077,
    "input_throughput": 6317.649286606166,
    "output_throughput": 5516.479452624418,
    "total_throughput": 11834.128739230584,
    "itl": 78.60606527939314,
    "ttft": 1419576.4234094291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 194,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.339820793522521,
    "arrivals": 142827,
    "finished_requests": 91748,
    "scheduler_time": 270.3646879252416
}
#Debug simulation 
Total elapsed time: 108.5449501510011. Arrivals time: 0.43658912426326424 Scheduler time: 107.85682702506892 Scheduler overhead time: 0.10028160718502477 Adapter cache time: 0.017229666060302407 Engine time: 0.09477667353348807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_128_slots_16_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_128_slots_16_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 107.34640794602456,
    "estimated_duration": 3600.082004003791,
    "input_throughput": 6265.532555901259,
    "output_throughput": 5469.941789686873,
    "total_throughput": 11735.474345588133,
    "itl": 76.84277568326806,
    "ttft": 1423730.5564083199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.416909382641318,
    "arrivals": 142827,
    "finished_requests": 90966,
    "scheduler_time": 272.4775461046169
}
#Debug simulation 
Total elapsed time: 107.34654578601476. Arrivals time: 0.4355812490102835 Scheduler time: 106.65731416054768 Scheduler overhead time: 0.10057713609421626 Adapter cache time: 0.01803267328068614 Engine time: 0.09600918658543378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_128_slots_16_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_128_slots_16_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 108.34197120799217,
    "estimated_duration": 3600.034054345961,
    "input_throughput": 6317.434406639758,
    "output_throughput": 5516.5064274948945,
    "total_throughput": 11833.940834134653,
    "itl": 78.60486815639365,
    "ttft": 1419615.2780233966,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 194,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2384806624706801,
    "arrivals": 142827,
    "finished_requests": 91748,
    "scheduler_time": 270.3761798145591
}
#Debug simulation 
Total elapsed time: 108.34211314999266. Arrivals time: 0.43614497873932123 Scheduler time: 107.65456942265155 Scheduler overhead time: 0.09990204666974023 Adapter cache time: 0.01823818450793624 Engine time: 0.09390848578186706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_128_slots_16_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_128_slots_16_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 270, 270, 8640, 270, 1080, 1080, 1080, 270, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 270, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 270, 270, 1080, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 270, 8640, 270, 8640, 1080, 270, 8640, 8640, 1080, 1080, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 1080, 8640, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 1080, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270]
Prompts retrieved: 429300 . Total input tokens: 95548537 . Total output tokens: 84484567
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 107.7095305880066,
    "estimated_duration": 3600.0666487984713,
    "input_throughput": 6265.559280000622,
    "output_throughput": 5469.9651203880685,
    "total_throughput": 11735.52440038869,
    "itl": 76.84256658028569,
    "ttft": 1423724.233676024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4019969459250592,
    "arrivals": 142827,
    "finished_requests": 90966,
    "scheduler_time": 272.4769988232706
}
#Debug simulation 
Total elapsed time: 107.70967129798373. Arrivals time: 0.4402379048988223 Scheduler time: 107.0155622252496 Scheduler overhead time: 0.1006706545013003 Adapter cache time: 0.017663392412941903 Engine time: 0.09556807833723724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_128_slots_16_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_128_slots_16_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 106.25271321897162,
    "estimated_duration": 3600.028992794482,
    "input_throughput": 6366.9048348990655,
    "output_throughput": 5588.692768938647,
    "total_throughput": 11955.597603837712,
    "itl": 81.17781002736369,
    "ttft": 1402678.6866058358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 211,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3952183057414351,
    "arrivals": 140936,
    "finished_requests": 93064,
    "scheduler_time": 263.89030803143436
}
#Debug simulation 
Total elapsed time: 106.25285822100705. Arrivals time: 0.43655880499863997 Scheduler time: 105.56512916059 Scheduler overhead time: 0.09947608725633472 Adapter cache time: 0.01797722087940201 Engine time: 0.09439386031590402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_128_slots_16_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_128_slots_16_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 108.68973827001173,
    "estimated_duration": 3600.0920668424424,
    "input_throughput": 6259.53769559145,
    "output_throughput": 5485.0394471492855,
    "total_throughput": 11744.577142740734,
    "itl": 78.6497403474622,
    "ttft": 1416037.4343743147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6621050463523734,
    "arrivals": 140936,
    "finished_requests": 91361,
    "scheduler_time": 268.7568445140353
}
#Debug simulation 
Total elapsed time: 108.68988558999263. Arrivals time: 0.43253429094329476 Scheduler time: 108.004981665581 Scheduler overhead time: 0.09999963437439874 Adapter cache time: 0.018017194815911353 Engine time: 0.0948124787537381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_128_slots_16_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_128_slots_16_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 102.50929049804108,
    "estimated_duration": 3600.010728761095,
    "input_throughput": 6275.317131561584,
    "output_throughput": 5512.518293752277,
    "total_throughput": 11787.83542531386,
    "itl": 78.59162491818776,
    "ttft": 1427725.7763064785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7437797367014025,
    "arrivals": 140936,
    "finished_requests": 91752,
    "scheduler_time": 267.42945301101054
}
#Debug simulation 
Total elapsed time: 102.50943419500254. Arrivals time: 0.43144360836595297 Scheduler time: 101.82389241323108 Scheduler overhead time: 0.09954988496610895 Adapter cache time: 0.01803283003391698 Engine time: 0.09682791802333668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_128_slots_16_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_128_slots_16_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 103.81268338102382,
    "estimated_duration": 3600.001139680269,
    "input_throughput": 6341.494936867596,
    "output_throughput": 5577.745734209234,
    "total_throughput": 11919.24067107683,
    "itl": 80.43928489414786,
    "ttft": 1405604.3494096056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 228,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5707563152350468,
    "arrivals": 140936,
    "finished_requests": 92719,
    "scheduler_time": 264.3522062264217
}
#Debug simulation 
Total elapsed time: 103.81283147702925. Arrivals time: 0.43676280992804095 Scheduler time: 103.12603308237158 Scheduler overhead time: 0.09947382233804092 Adapter cache time: 0.018267470644786954 Engine time: 0.09363148431293666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_128_slots_16_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_128_slots_16_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 105.38319019699702,
    "estimated_duration": 3600.089642123643,
    "input_throughput": 6270.7638542809,
    "output_throughput": 5507.657856070412,
    "total_throughput": 11778.421710351311,
    "itl": 78.04571630514398,
    "ttft": 1420269.1893131365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5214822468813534,
    "arrivals": 140936,
    "finished_requests": 91619,
    "scheduler_time": 267.7108832016143
}
#Debug simulation 
Total elapsed time: 105.38334136200137. Arrivals time: 0.43102973978966475 Scheduler time: 104.6991691076546 Scheduler overhead time: 0.10075403039809316 Adapter cache time: 0.01792400039266795 Engine time: 0.09477845695801079 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_128_slots_16_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_128_slots_16_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 104.74860214698128,
    "estimated_duration": 3600.066756654156,
    "input_throughput": 6336.715550575418,
    "output_throughput": 5572.166950216112,
    "total_throughput": 11908.882500791531,
    "itl": 80.44375187804037,
    "ttft": 1395074.1697892046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5512927885586345,
    "arrivals": 140936,
    "finished_requests": 92726,
    "scheduler_time": 264.7063912817878
}
#Debug simulation 
Total elapsed time: 104.74875121098012. Arrivals time: 0.43854495068080723 Scheduler time: 104.06041590910172 Scheduler overhead time: 0.09820544091053307 Adapter cache time: 0.018051263003144413 Engine time: 0.09450132946949452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_128_slots_16_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_128_slots_16_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 135, 135, 8640, 135, 1080, 1080, 1080, 135, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 135, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 135, 135, 1080, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 135, 8640, 135, 8640, 1080, 135, 8640, 8640, 1080, 1080, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 1080, 8640, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 1080, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135]
Prompts retrieved: 423630 . Total input tokens: 94305641 . Total output tokens: 83365196
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 106.68501439702231,
    "estimated_duration": 3600.0402270499926,
    "input_throughput": 6218.2832935575225,
    "output_throughput": 5454.360440880519,
    "total_throughput": 11672.643734438041,
    "itl": 77.07697973280365,
    "ttft": 1425205.6034130591,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.665396899078045,
    "arrivals": 140936,
    "finished_requests": 90795,
    "scheduler_time": 270.2490461977116
}
#Debug simulation 
Total elapsed time: 106.68515547603602. Arrivals time: 0.4342428213567473 Scheduler time: 105.9979854170233 Scheduler overhead time: 0.09951244876720011 Adapter cache time: 0.01827941491501406 Engine time: 0.09532025473890826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 109.70249018497998,
    "estimated_duration": 3600.015227887821,
    "input_throughput": 6325.334910697097,
    "output_throughput": 5591.006350217359,
    "total_throughput": 11916.341260914456,
    "itl": 80.77501049400979,
    "ttft": 1394842.9503954174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.401830714773385,
    "arrivals": 139992,
    "finished_requests": 92588,
    "scheduler_time": 264.42082423570474
}
#Debug simulation 
Total elapsed time: 109.70263728295686. Arrivals time: 0.43750540167093277 Scheduler time: 109.01357758627273 Scheduler overhead time: 0.09953498363029212 Adapter cache time: 0.018156254314817488 Engine time: 0.09506717161275446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 109.86105533904629,
    "estimated_duration": 3600.0931343194484,
    "input_throughput": 6298.373168139265,
    "output_throughput": 5564.287714958459,
    "total_throughput": 11862.660883097724,
    "itl": 79.77982414435311,
    "ttft": 1396981.118965501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6090882739285022,
    "arrivals": 139992,
    "finished_requests": 92169,
    "scheduler_time": 265.54340892153766
}
#Debug simulation 
Total elapsed time: 109.8611983450246. Arrivals time: 0.43956788536161184 Scheduler time: 109.16922004969092 Scheduler overhead time: 0.09995184710714966 Adapter cache time: 0.0178195663029328 Engine time: 0.09488324110861868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 108.69161042897031,
    "estimated_duration": 3600.0476375483877,
    "input_throughput": 6247.078445693962,
    "output_throughput": 5521.869153247506,
    "total_throughput": 11768.947598941468,
    "itl": 78.0383100938779,
    "ttft": 1406198.7640501775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5721684588631655,
    "arrivals": 139992,
    "finished_requests": 91453,
    "scheduler_time": 267.6521321932507
}
#Debug simulation 
Total elapsed time: 108.69175997597631. Arrivals time: 0.43630480294814333 Scheduler time: 108.00124892906751 Scheduler overhead time: 0.10070249519776553 Adapter cache time: 0.01777050452074036 Engine time: 0.09584074647864327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 110.13301294395933,
    "estimated_duration": 3600.0695172248465,
    "input_throughput": 6298.38504270856,
    "output_throughput": 5563.953669272705,
    "total_throughput": 11862.338711981265,
    "itl": 79.77228617506125,
    "ttft": 1397058.6910498717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.502195258983409,
    "arrivals": 139992,
    "finished_requests": 92165,
    "scheduler_time": 265.5548715340477
}
#Debug simulation 
Total elapsed time: 110.13315828697523. Arrivals time: 0.4382540507358499 Scheduler time: 109.44272618414834 Scheduler overhead time: 0.09967272565700114 Adapter cache time: 0.017642524908296764 Engine time: 0.09579786972608417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 109.85688584594755,
    "estimated_duration": 3600.031903772696,
    "input_throughput": 6234.538359640364,
    "output_throughput": 5514.511962851058,
    "total_throughput": 11749.050322491423,
    "itl": 77.86094968251838,
    "ttft": 1404389.1766105394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6176185276405926,
    "arrivals": 139992,
    "finished_requests": 91275,
    "scheduler_time": 267.9694826290249
}
#Debug simulation 
Total elapsed time: 109.85703348799143. Arrivals time: 0.43020316219190136 Scheduler time: 109.1711224571336 Scheduler overhead time: 0.10054763493826613 Adapter cache time: 0.018005702004302293 Engine time: 0.09720800025388598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 110.50871048099361,
    "estimated_duration": 3600.078681618868,
    "input_throughput": 6289.275874886849,
    "output_throughput": 5557.366871493863,
    "total_throughput": 11846.642746380712,
    "itl": 79.8441920491555,
    "ttft": 1396119.0626591784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3342394765792376,
    "arrivals": 139992,
    "finished_requests": 92015,
    "scheduler_time": 265.89355578424784
}
#Debug simulation 
Total elapsed time: 110.5088558709831. Arrivals time: 0.42907934001414105 Scheduler time: 109.82664090656908 Scheduler overhead time: 0.10017108242027462 Adapter cache time: 0.017949545523151755 Engine time: 0.09578042052453384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 66, 66, 8640, 66, 1080, 1080, 1080, 66, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 66, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 66, 66, 1080, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 8640, 8640, 1080, 1080, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 1080, 8640, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 1080, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66]
Prompts retrieved: 420732 . Total input tokens: 93649346 . Total output tokens: 82806045
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 109.71096083900193,
    "estimated_duration": 3600.0161871348046,
    "input_throughput": 6234.565577846262,
    "output_throughput": 5514.536037628271,
    "total_throughput": 11749.101615474532,
    "itl": 77.86046769226247,
    "ttft": 1404382.859575439,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.60208473939449,
    "arrivals": 139992,
    "finished_requests": 91275,
    "scheduler_time": 267.9689963857124
}
#Debug simulation 
Total elapsed time: 109.71110432798741. Arrivals time: 0.4287784273037687 Scheduler time: 109.02741703536594 Scheduler overhead time: 0.10043656406924129 Adapter cache time: 0.018239987373817712 Engine time: 0.09653830551542342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 111.02633339597378,
    "estimated_duration": 3600.088763059153,
    "input_throughput": 6380.234353022421,
    "output_throughput": 5618.515078726032,
    "total_throughput": 11998.749431748452,
    "itl": 81.32013624088617,
    "ttft": 1378771.981767904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 199,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.315869397358036,
    "arrivals": 139506,
    "finished_requests": 93267,
    "scheduler_time": 263.02893321152635
}
#Debug simulation 
Total elapsed time: 111.02647431497462. Arrivals time: 0.43693903071107343 Scheduler time: 110.33713825285668 Scheduler overhead time: 0.09968718612799421 Adapter cache time: 0.018007983861025423 Engine time: 0.09540781087707728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 109.41203540499555,
    "estimated_duration": 3600.0655326958545,
    "input_throughput": 6366.585772353042,
    "output_throughput": 5589.511306737656,
    "total_throughput": 11956.097079090698,
    "itl": 80.74026416645496,
    "ttft": 1380038.2217301847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6346239576907846,
    "arrivals": 139506,
    "finished_requests": 92955,
    "scheduler_time": 264.41713006484696
}
#Debug simulation 
Total elapsed time: 109.41217934602173. Arrivals time: 0.43087342812214047 Scheduler time: 108.72876646282384 Scheduler overhead time: 0.09970366430934519 Adapter cache time: 0.017910015769302845 Engine time: 0.09537843812722713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 105.0285081799957,
    "estimated_duration": 3600.053880258306,
    "input_throughput": 6321.38205619499,
    "output_throughput": 5550.433594778945,
    "total_throughput": 11871.815650973935,
    "itl": 78.94232886583222,
    "ttft": 1400922.9394305362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5670420396793665,
    "arrivals": 139506,
    "finished_requests": 92278,
    "scheduler_time": 266.2703289804858
}
#Debug simulation 
Total elapsed time: 105.02865194896003. Arrivals time: 0.4231654399773106 Scheduler time: 104.35093994432827 Scheduler overhead time: 0.10044213378569111 Adapter cache time: 0.018041912058833987 Engine time: 0.0962219611974433 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 107.29126533900853,
    "estimated_duration": 3600.0350554229713,
    "input_throughput": 6372.687667427321,
    "output_throughput": 5596.970498842168,
    "total_throughput": 11969.65816626949,
    "itl": 80.9416263395126,
    "ttft": 1384246.610487223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 214,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4716638752538695,
    "arrivals": 139506,
    "finished_requests": 93079,
    "scheduler_time": 264.0210771379274
}
#Debug simulation 
Total elapsed time: 107.2914041930344. Arrivals time: 0.44473703391849995 Scheduler time: 106.59347547701327 Scheduler overhead time: 0.10060150496428832 Adapter cache time: 0.018011547450441867 Engine time: 0.09549249120755121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 105.23078278900357,
    "estimated_duration": 3600.0399462532373,
    "input_throughput": 6321.406523192836,
    "output_throughput": 5550.4550778099665,
    "total_throughput": 11871.861601002802,
    "itl": 78.94195957495758,
    "ttft": 1400917.574253937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5531651888461817,
    "arrivals": 139506,
    "finished_requests": 92278,
    "scheduler_time": 266.27017069502995
}
#Debug simulation 
Total elapsed time: 105.23092334100511. Arrivals time: 0.4432112335343845 Scheduler time: 104.5341745140031 Scheduler overhead time: 0.10046633001184091 Adapter cache time: 0.01815649413038045 Engine time: 0.09539349179249257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 112.08287389198085,
    "estimated_duration": 3600.0559494744307,
    "input_throughput": 6365.28579600142,
    "output_throughput": 5588.614255547112,
    "total_throughput": 11953.900051548533,
    "itl": 80.34579566865685,
    "ttft": 1386363.7105166456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 198,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.264016346232962,
    "arrivals": 139506,
    "finished_requests": 92962,
    "scheduler_time": 264.50462593722193
}
#Debug simulation 
Total elapsed time: 112.0830171770067. Arrivals time: 0.45612610992975533 Scheduler time: 111.37277085561072 Scheduler overhead time: 0.1001983504393138 Adapter cache time: 0.01839280140120536 Engine time: 0.0961790049332194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 1080, 8640, 8640, 33, 33, 8640, 33, 1080, 1080, 1080, 33, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 33, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 33, 33, 1080, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 8640, 8640, 1080, 1080, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 1080, 8640, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 1080, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33]
Prompts retrieved: 419346 . Total input tokens: 93341250 . Total output tokens: 82532507
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 107.19902536296286,
    "estimated_duration": 3600.0545713860674,
    "input_throughput": 6322.461659584411,
    "output_throughput": 5549.482543623788,
    "total_throughput": 11871.944203208199,
    "itl": 78.9447429638584,
    "ttft": 1394911.0455052159,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.671764166057114,
    "arrivals": 139506,
    "finished_requests": 92309,
    "scheduler_time": 266.2689591496319
}
#Debug simulation 
Total elapsed time: 107.19916917599039. Arrivals time: 0.44505366997327656 Scheduler time: 106.49877120513702 Scheduler overhead time: 0.10091971361543983 Adapter cache time: 0.01835072401445359 Engine time: 0.0966414077556692 
