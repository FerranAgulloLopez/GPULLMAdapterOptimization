INFO 05-31 19:31:05 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:05 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666609101 . Total output tokens: 586712027
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.006633467972279,
    "estimated_duration": 3600.034887176882,
    "input_throughput": 4520.014530403769,
    "output_throughput": 3948.683122664847,
    "total_throughput": 8468.697653068615,
    "itl": 110.67358198868588,
    "ttft": 2208371.5763232154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.144997436031691,
    "arrivals": 995247,
    "finished_requests": 65956,
    "scheduler_time": 121.10668716923932
}
#Debug simulation 
Total elapsed time: 5.006742920959368. Arrivals time: 0.3024435768602416 Scheduler time: 4.566290419199504 Scheduler overhead time: 0.04702365200500935 Adapter cache time: 0.01948881975840777 Engine time: 0.04934434010647237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665969540 . Total output tokens: 586163675
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.261363711906597,
    "estimated_duration": 3600.117136345159,
    "input_throughput": 4845.19734758087,
    "output_throughput": 4167.116910876447,
    "total_throughput": 9012.314258457316,
    "itl": 124.47677369880263,
    "ttft": 2172478.356319154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0564592089364298,
    "arrivals": 994382,
    "finished_requests": 70110,
    "scheduler_time": 117.1637075668423
}
#Debug simulation 
Total elapsed time: 5.261471338919364. Arrivals time: 0.3496547716204077 Scheduler time: 4.789852901943959 Scheduler overhead time: 0.04241568851284683 Adapter cache time: 0.015419113798998296 Engine time: 0.044064077315852046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665969540 . Total output tokens: 586163675
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.034031767980196,
    "estimated_duration": 3600.011077140048,
    "input_throughput": 4587.5214398284825,
    "output_throughput": 3948.9703490839993,
    "total_throughput": 8536.49178891248,
    "itl": 109.77533338334032,
    "ttft": 2198006.052825131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.208921944587494,
    "arrivals": 994382,
    "finished_requests": 66393,
    "scheduler_time": 121.49385065219406
}
#Debug simulation 
Total elapsed time: 5.034127585939132. Arrivals time: 0.33417966042179614 Scheduler time: 4.563203960540704 Scheduler overhead time: 0.04699277097824961 Adapter cache time: 0.018834392190910876 Engine time: 0.04875601187814027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665969540 . Total output tokens: 586163675
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.074591606971808,
    "estimated_duration": 3600.0360958873953,
    "input_throughput": 4590.547027814278,
    "output_throughput": 3952.420648297039,
    "total_throughput": 8542.967676111317,
    "itl": 109.94298587175011,
    "ttft": 2198431.2197924424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.068711626282891,
    "arrivals": 994382,
    "finished_requests": 66442,
    "scheduler_time": 121.44334564969574
}
#Debug simulation 
Total elapsed time: 5.074704785947688. Arrivals time: 0.35125423106364906 Scheduler time: 4.586214961484075 Scheduler overhead time: 0.04705080890562385 Adapter cache time: 0.01872586051467806 Engine time: 0.049118136055767536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665969540 . Total output tokens: 586163675
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.045175384962931,
    "estimated_duration": 3600.0088013128066,
    "input_throughput": 4590.852942907556,
    "output_throughput": 3952.6883919869542,
    "total_throughput": 8543.54133489451,
    "itl": 109.9382786417264,
    "ttft": 2198399.964246408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9215602031117234,
    "arrivals": 994382,
    "finished_requests": 66446,
    "scheduler_time": 121.44665793177045
}
#Debug simulation 
Total elapsed time: 5.045306592946872. Arrivals time: 0.2378339811693877 Scheduler time: 4.669987224857323 Scheduler overhead time: 0.04717934352811426 Adapter cache time: 0.018764665466733277 Engine time: 0.049217042746022344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664668594 . Total output tokens: 585018182
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.2365418780827895,
    "estimated_duration": 3600.0119615003227,
    "input_throughput": 4803.472928682504,
    "output_throughput": 4185.439982182862,
    "total_throughput": 8988.912910865365,
    "itl": 124.28089718123645,
    "ttft": 2178307.7114183907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.692776712179182,
    "arrivals": 992438,
    "finished_requests": 70135,
    "scheduler_time": 117.59173210094318
}
#Debug simulation 
Total elapsed time: 5.236641835072078. Arrivals time: 0.30956918362062424 Scheduler time: 4.806763478205539 Scheduler overhead time: 0.04245616926345974 Adapter cache time: 0.013572485302574933 Engine time: 0.044205867568962276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664668594 . Total output tokens: 585018182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.952369588078,
    "estimated_duration": 3600.0350143782734,
    "input_throughput": 4550.28796513776,
    "output_throughput": 3967.814185959215,
    "total_throughput": 8518.102151096975,
    "itl": 109.86511709112672,
    "ttft": 2206308.6260882947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8089352279854953,
    "arrivals": 992438,
    "finished_requests": 66457,
    "scheduler_time": 121.76523872450262
}
#Debug simulation 
Total elapsed time: 4.95246575109195. Arrivals time: 0.2361474810168147 Scheduler time: 4.581293873838149 Scheduler overhead time: 0.04710248962510377 Adapter cache time: 0.016961360815912485 Engine time: 0.048808688996359706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664668594 . Total output tokens: 585018182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.957408757065423,
    "estimated_duration": 3600.048430958324,
    "input_throughput": 4550.436282780564,
    "output_throughput": 3967.996618366985,
    "total_throughput": 8518.43290114755,
    "itl": 109.86291830247463,
    "ttft": 2206257.1858934043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7006539920670893,
    "arrivals": 992438,
    "finished_requests": 66461,
    "scheduler_time": 121.76837895724485
}
#Debug simulation 
Total elapsed time: 4.957502581994049. Arrivals time: 0.23631389532238245 Scheduler time: 4.586285574827343 Scheduler overhead time: 0.04706403776071966 Adapter cache time: 0.016932617989368737 Engine time: 0.04875328065827489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664668594 . Total output tokens: 585018182
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.061962881009094,
    "estimated_duration": 3600.0590285702733,
    "input_throughput": 4550.596495776379,
    "output_throughput": 3968.2454889284154,
    "total_throughput": 8518.841984704794,
    "itl": 109.86045457063176,
    "ttft": 2206193.0652172775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5895963142020575,
    "arrivals": 992438,
    "finished_requests": 66464,
    "scheduler_time": 121.77179897022366
}
#Debug simulation 
Total elapsed time: 5.062063802964985. Arrivals time: 0.3163190473569557 Scheduler time: 4.610890883253887 Scheduler overhead time: 0.04705397377256304 Adapter cache time: 0.016973699908703566 Engine time: 0.048677073209546506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 576987541 . Total output tokens: 507916087
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.804183022934012,
    "estimated_duration": 3600.0446381942197,
    "input_throughput": 3974.417385884672,
    "output_throughput": 3459.4732153785317,
    "total_throughput": 7433.890601263203,
    "itl": 149.78952121945863,
    "ttft": 2246036.4433740787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.902843721840044,
    "arrivals": 861811,
    "finished_requests": 57974,
    "scheduler_time": 97.30177846405421
}
#Debug simulation 
Total elapsed time: 6.804306095931679. Arrivals time: 0.24237623380031437 Scheduler time: 6.416004786617123 Scheduler overhead time: 0.03803559730295092 Adapter cache time: 0.05252893746364862 Engine time: 0.038017065497115254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 576987541 . Total output tokens: 507916087
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.775626330054365,
    "estimated_duration": 3600.0386658712305,
    "input_throughput": 3744.409783092637,
    "output_throughput": 3269.3590520510797,
    "total_throughput": 7013.768835143716,
    "itl": 133.22831837630787,
    "ttft": 2274391.804499302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.693472677207907,
    "arrivals": 861811,
    "finished_requests": 54691,
    "scheduler_time": 100.29417743232452
}
#Debug simulation 
Total elapsed time: 5.775721275014803. Arrivals time: 0.2303498808760196 Scheduler time: 5.379335996345617 Scheduler overhead time: 0.04098338074982166 Adapter cache time: 0.06498018908314407 Engine time: 0.04110463766846806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 576987541 . Total output tokens: 507916087
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.880094126099721,
    "estimated_duration": 3600.0454568625455,
    "input_throughput": 3743.0738476685024,
    "output_throughput": 3266.7551398779547,
    "total_throughput": 7009.828987546457,
    "itl": 132.7139040669631,
    "ttft": 2275305.9034030386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2920,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.059810981192133,
    "arrivals": 861811,
    "finished_requests": 54652,
    "scheduler_time": 100.46136285582554
}
#Debug simulation 
Total elapsed time: 5.880257994052954. Arrivals time: 0.23605428426526487 Scheduler time: 5.478648397489451 Scheduler overhead time: 0.041445976588875055 Adapter cache time: 0.06328749668318778 Engine time: 0.04165077314246446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 576987541 . Total output tokens: 507916087
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.838702162029222,
    "estimated_duration": 3600.0949039704547,
    "input_throughput": 3744.054076222936,
    "output_throughput": 3268.0071814286134,
    "total_throughput": 7012.06125765155,
    "itl": 132.66544429587586,
    "ttft": 2274891.8611487374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2921,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.647433067407906,
    "arrivals": 861811,
    "finished_requests": 54668,
    "scheduler_time": 100.50122256355965
}
#Debug simulation 
Total elapsed time: 5.838823736994527. Arrivals time: 0.23596685263328254 Scheduler time: 5.437847017776221 Scheduler overhead time: 0.0411792506929487 Adapter cache time: 0.06298249715473503 Engine time: 0.04169088648632169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515550935 . Total output tokens: 453793415
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.2217766139656305,
    "estimated_duration": 3600.0697443850795,
    "input_throughput": 4016.9955103106295,
    "output_throughput": 3464.0562226469087,
    "total_throughput": 7481.051732957538,
    "itl": 149.7029396000132,
    "ttft": 2240760.04612545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.324004199379486,
    "arrivals": 769968,
    "finished_requests": 58396,
    "scheduler_time": 97.24240685747564
}
#Debug simulation 
Total elapsed time: 6.221872895956039. Arrivals time: 0.2388682175660506 Scheduler time: 5.844617145252414 Scheduler overhead time: 0.03770873777102679 Adapter cache time: 0.0453686264809221 Engine time: 0.03803713561501354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515550935 . Total output tokens: 453793415
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.289917492074892,
    "estimated_duration": 3600.033502484294,
    "input_throughput": 3785.75587993697,
    "output_throughput": 3268.997077910206,
    "total_throughput": 7054.752957847176,
    "itl": 132.8372586887279,
    "ttft": 2271377.4025623207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.827639344683334,
    "arrivals": 769968,
    "finished_requests": 55027,
    "scheduler_time": 100.27453764450975
}
#Debug simulation 
Total elapsed time: 5.29001388605684. Arrivals time: 0.22630718839354813 Scheduler time: 4.901286366279237 Scheduler overhead time: 0.04119764978531748 Adapter cache time: 0.060622862773016095 Engine time: 0.041544707491993904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515550935 . Total output tokens: 453793415
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.300896911998279,
    "estimated_duration": 3600.0160548393146,
    "input_throughput": 3787.1231106519426,
    "output_throughput": 3270.3476375261603,
    "total_throughput": 7057.470748178102,
    "itl": 132.78934629472167,
    "ttft": 2271233.0008202824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.53326021363069,
    "arrivals": 769968,
    "finished_requests": 55050,
    "scheduler_time": 100.3095903129455
}
#Debug simulation 
Total elapsed time: 5.300989679060876. Arrivals time: 0.22464862780179828 Scheduler time: 4.913928657304496 Scheduler overhead time: 0.04099093016702682 Adapter cache time: 0.06068538164254278 Engine time: 0.04169116576667875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515550935 . Total output tokens: 453793415
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.345788117032498,
    "estimated_duration": 3600.071067529188,
    "input_throughput": 3788.238827562931,
    "output_throughput": 3271.280143945247,
    "total_throughput": 7059.518971508178,
    "itl": 132.74151699771258,
    "ttft": 2270950.1635741163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.168638996865052,
    "arrivals": 769968,
    "finished_requests": 55069,
    "scheduler_time": 100.3485756115673
}
#Debug simulation 
Total elapsed time: 5.345883204950951. Arrivals time: 0.22171749325934798 Scheduler time: 4.961764863110147 Scheduler overhead time: 0.04098031728062779 Adapter cache time: 0.060635032248683274 Engine time: 0.041787503054365516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505288460 . Total output tokens: 444846041
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.981339807040058,
    "estimated_duration": 3600.146823885963,
    "input_throughput": 3988.673713173776,
    "output_throughput": 3456.4934733878977,
    "total_throughput": 7445.167186561674,
    "itl": 148.68834691500624,
    "ttft": 2242573.2673879038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1783,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.78992530396705,
    "arrivals": 754714,
    "finished_requests": 58070,
    "scheduler_time": 97.44764360098581
}
#Debug simulation 
Total elapsed time: 5.981448918930255. Arrivals time: 0.3199857185827568 Scheduler time: 5.526916156872176 Scheduler overhead time: 0.03755293623544276 Adapter cache time: 0.041120746871456504 Engine time: 0.03845205728430301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505288460 . Total output tokens: 444846041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.180136298993602,
    "estimated_duration": 3600.1162172432373,
    "input_throughput": 3761.944388109445,
    "output_throughput": 3265.3662522600007,
    "total_throughput": 7027.3106403694455,
    "itl": 132.30528789289556,
    "ttft": 2272415.355704635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2521,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.43301703121008,
    "arrivals": 754714,
    "finished_requests": 54799,
    "scheduler_time": 100.4375078647295
}
#Debug simulation 
Total elapsed time: 5.180296053993516. Arrivals time: 0.23268545884639025 Scheduler time: 4.790172136155888 Scheduler overhead time: 0.04114894976373762 Adapter cache time: 0.05548021802678704 Engine time: 0.04166917351540178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505288460 . Total output tokens: 444846041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.153625463019125,
    "estimated_duration": 3600.023191810158,
    "input_throughput": 3768.696276975389,
    "output_throughput": 3271.0080942781256,
    "total_throughput": 7039.704371253515,
    "itl": 132.58056135386525,
    "ttft": 2271976.695641626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2544,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.462329329327112,
    "arrivals": 754714,
    "finished_requests": 54904,
    "scheduler_time": 100.39016381690178
}
#Debug simulation 
Total elapsed time: 5.153718448011205. Arrivals time: 0.3000895723234862 Scheduler time: 4.696135119418614 Scheduler overhead time: 0.04103348730131984 Adapter cache time: 0.055840549524873495 Engine time: 0.04156440566293895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505288460 . Total output tokens: 444846041
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.146155027090572,
    "estimated_duration": 3600.108834935997,
    "input_throughput": 3769.6307590215583,
    "output_throughput": 3271.696368093105,
    "total_throughput": 7041.327127114663,
    "itl": 132.53656382660793,
    "ttft": 2271650.8860093174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2544,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.240694872812494,
    "arrivals": 754714,
    "finished_requests": 54916,
    "scheduler_time": 100.42599470201337
}
#Debug simulation 
Total elapsed time: 5.14625176100526. Arrivals time: 0.2994364865589887 Scheduler time: 4.688948824536055 Scheduler overhead time: 0.04117174609564245 Adapter cache time: 0.056035173241980374 Engine time: 0.041623474447987974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500197697 . Total output tokens: 440334485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.004227085970342,
    "estimated_duration": 3600.149329804354,
    "input_throughput": 3961.254018531227,
    "output_throughput": 3466.098724487667,
    "total_throughput": 7427.352743018894,
    "itl": 150.05324697211475,
    "ttft": 2239803.4556768583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.553404814992373,
    "arrivals": 746983,
    "finished_requests": 57809,
    "scheduler_time": 97.27397394270653
}
#Debug simulation 
Total elapsed time: 6.004293164936826. Arrivals time: 0.3211243989644572 Scheduler time: 5.554036611807533 Scheduler overhead time: 0.03709710808470845 Adapter cache time: 0.03726059524342418 Engine time: 0.0376055397791788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500197697 . Total output tokens: 440334485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.983897450030781,
    "estimated_duration": 3600.045311759542,
    "input_throughput": 3742.657614888363,
    "output_throughput": 3273.307133526183,
    "total_throughput": 7015.964748414545,
    "itl": 133.099621686283,
    "ttft": 2271873.7372722365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2306,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.83974689423075,
    "arrivals": 746983,
    "finished_requests": 54595,
    "scheduler_time": 100.31620174272463
}
#Debug simulation 
Total elapsed time: 4.983992418041453. Arrivals time: 0.29722398903686553 Scheduler time: 4.533731930656359 Scheduler overhead time: 0.040923720225691795 Adapter cache time: 0.05184164259117097 Engine time: 0.0413287419360131 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500197697 . Total output tokens: 440334485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.972130892099813,
    "estimated_duration": 3600.0570377312356,
    "input_throughput": 3743.204582250855,
    "output_throughput": 3273.2423060236333,
    "total_throughput": 7016.446888274489,
    "itl": 132.94510066973493,
    "ttft": 2271875.4298827215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.629275071602574,
    "arrivals": 746983,
    "finished_requests": 54591,
    "scheduler_time": 100.37089877564598
}
#Debug simulation 
Total elapsed time: 4.972226133104414. Arrivals time: 0.2987600597552955 Scheduler time: 4.52239419426769 Scheduler overhead time: 0.04079240816645324 Adapter cache time: 0.049776559229940176 Engine time: 0.041565464227460325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500197697 . Total output tokens: 440334485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.987798274960369,
    "estimated_duration": 3600.031698007192,
    "input_throughput": 3744.152588284536,
    "output_throughput": 3274.0817272594063,
    "total_throughput": 7018.234315543942,
    "itl": 132.90449928121473,
    "ttft": 2271795.4623099044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.529804060739364,
    "arrivals": 746983,
    "finished_requests": 54607,
    "scheduler_time": 100.39962392388172
}
#Debug simulation 
Total elapsed time: 4.987888369010761. Arrivals time: 0.2949564695591107 Scheduler time: 4.5416393369669095 Scheduler overhead time: 0.0407960502197966 Adapter cache time: 0.05019999737851322 Engine time: 0.04127592535223812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497594670 . Total output tokens: 438105315
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.436363840010017,
    "estimated_duration": 3600.056123295394,
    "input_throughput": 4009.884986677888,
    "output_throughput": 3468.1812095115274,
    "total_throughput": 7478.066196189415,
    "itl": 149.70492668614523,
    "ttft": 2238131.383832728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.482194551816448,
    "arrivals": 743226,
    "finished_requests": 58341,
    "scheduler_time": 97.26517275786969
}
#Debug simulation 
Total elapsed time: 5.436518064001575. Arrivals time: 0.2274750709766522 Scheduler time: 5.0831546558765694 Scheduler overhead time: 0.03721098485402763 Adapter cache time: 0.033852091641165316 Engine time: 0.03757123067043722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497594670 . Total output tokens: 438105315
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.140054758056067,
    "estimated_duration": 3600.1139670749158,
    "input_throughput": 3787.0576111448668,
    "output_throughput": 3276.0526771830864,
    "total_throughput": 7063.110288327954,
    "itl": 132.73616595359917,
    "ttft": 2270893.1027679644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2085,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.260925628593858,
    "arrivals": 743226,
    "finished_requests": 55106,
    "scheduler_time": 100.33497514226626
}
#Debug simulation 
Total elapsed time: 5.1401211969787255. Arrivals time: 0.5384200535481796 Scheduler time: 4.453669820097275 Scheduler overhead time: 0.040946484776213765 Adapter cache time: 0.04688691010233015 Engine time: 0.04123709734994918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497594670 . Total output tokens: 438105315
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.810699056019075,
    "estimated_duration": 3600.077542877334,
    "input_throughput": 3787.846466523913,
    "output_throughput": 3277.1419113852107,
    "total_throughput": 7064.988377909123,
    "itl": 132.70542100993643,
    "ttft": 2270652.635619596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2085,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.362746658860907,
    "arrivals": 743226,
    "finished_requests": 55121,
    "scheduler_time": 100.35804094518716
}
#Debug simulation 
Total elapsed time: 4.810793446027674. Arrivals time: 0.2193135053385049 Scheduler time: 4.4437776691047475 Scheduler overhead time: 0.040897835744544864 Adapter cache time: 0.046572487452067435 Engine time: 0.041357807465828955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497594670 . Total output tokens: 438105315
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.1291756719583645,
    "estimated_duration": 3600.0310406924245,
    "input_throughput": 3789.424826008197,
    "output_throughput": 3278.4825648975234,
    "total_throughput": 7067.907390905721,
    "itl": 132.66602689108757,
    "ttft": 2270520.4819369805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2085,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.31047516109023,
    "arrivals": 743226,
    "finished_requests": 55143,
    "scheduler_time": 100.38517661580337
}
#Debug simulation 
Total elapsed time: 5.129243067000061. Arrivals time: 0.21964434429537505 Scheduler time: 4.761737695662305 Scheduler overhead time: 0.040956246899440885 Adapter cache time: 0.046758180717006326 Engine time: 0.04116534872446209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496272302 . Total output tokens: 436960987
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.668212297023274,
    "estimated_duration": 3600.051694656402,
    "input_throughput": 3989.897151010472,
    "output_throughput": 3468.9329651950784,
    "total_throughput": 7458.83011620555,
    "itl": 149.6737547112749,
    "ttft": 2236992.3609087444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.893690147972885,
    "arrivals": 741292,
    "finished_requests": 58029,
    "scheduler_time": 97.32458938902829
}
#Debug simulation 
Total elapsed time: 5.668283186969347. Arrivals time: 0.5468935903627425 Scheduler time: 4.9980277883587405 Scheduler overhead time: 0.037125127972103655 Adapter cache time: 0.031145844841375947 Engine time: 0.03795247513335198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496272302 . Total output tokens: 436960987
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.075326149002649,
    "estimated_duration": 3600.109946626028,
    "input_throughput": 3761.262906064965,
    "output_throughput": 3272.210064317715,
    "total_throughput": 7033.47297038268,
    "itl": 132.6673984847934,
    "ttft": 2267288.516100353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2021,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.756567441238792,
    "arrivals": 741292,
    "finished_requests": 54691,
    "scheduler_time": 100.41476549211615
}
#Debug simulation 
Total elapsed time: 5.0753907629987225. Arrivals time: 0.5350355812115595 Scheduler time: 4.393411838565953 Scheduler overhead time: 0.0406119980616495 Adapter cache time: 0.04616701800841838 Engine time: 0.04129472351633012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496272302 . Total output tokens: 436960987
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.072524321964011,
    "estimated_duration": 3600.1131948680863,
    "input_throughput": 3762.045598817974,
    "output_throughput": 3273.0193086141994,
    "total_throughput": 7035.064907432174,
    "itl": 132.63834292103934,
    "ttft": 2266998.070767554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2021,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.890317553891997,
    "arrivals": 741292,
    "finished_requests": 54703,
    "scheduler_time": 100.43813372894763
}
#Debug simulation 
Total elapsed time: 5.0725932699861005. Arrivals time: 0.21854629938025028 Scheduler time: 4.707181340781972 Scheduler overhead time: 0.04089255689177662 Adapter cache time: 0.045759325730614364 Engine time: 0.04129703377839178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496272302 . Total output tokens: 436960987
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.077439920045435,
    "estimated_duration": 3600.0387945415837,
    "input_throughput": 3757.737561192756,
    "output_throughput": 3268.257558179515,
    "total_throughput": 7025.995119372271,
    "itl": 132.18837127365512,
    "ttft": 2267800.9750738433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2007,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.812529327725661,
    "arrivals": 741292,
    "finished_requests": 54624,
    "scheduler_time": 100.55350710580899
}
#Debug simulation 
Total elapsed time: 5.077535358956084. Arrivals time: 0.5363939388189465 Scheduler time: 4.394141845172271 Scheduler overhead time: 0.04086563677992672 Adapter cache time: 0.04578049876727164 Engine time: 0.04134593263734132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495650329 . Total output tokens: 436414531
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.375444208970293,
    "estimated_duration": 3600.022552875305,
    "input_throughput": 4004.836022064605,
    "output_throughput": 3469.6954856639904,
    "total_throughput": 7474.531507728596,
    "itl": 149.89544585344336,
    "ttft": 2236032.7731752396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.814341239589483,
    "arrivals": 740358,
    "finished_requests": 58400,
    "scheduler_time": 97.28562974713286
}
#Debug simulation 
Total elapsed time: 5.37553586892318. Arrivals time: 0.22672709915786982 Scheduler time: 5.026273876661435 Scheduler overhead time: 0.036958023672923446 Adapter cache time: 0.03091959946323186 Engine time: 0.03756003361195326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495650329 . Total output tokens: 436414531
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.829648220911622,
    "estimated_duration": 3600.1040870651864,
    "input_throughput": 3769.433236321393,
    "output_throughput": 3272.7634299054257,
    "total_throughput": 7042.196666226819,
    "itl": 132.62231393416354,
    "ttft": 2267918.785152228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1985,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.52535806640491,
    "arrivals": 740358,
    "finished_requests": 55012,
    "scheduler_time": 100.43067234093226
}
#Debug simulation 
Total elapsed time: 4.829745206981897. Arrivals time: 0.29565601877402514 Scheduler time: 4.3876949429977685 Scheduler overhead time: 0.04099276370834559 Adapter cache time: 0.04493012104649097 Engine time: 0.041490264353342354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495650329 . Total output tokens: 436414531
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.768170032068156,
    "estimated_duration": 3600.0109876254487,
    "input_throughput": 3775.505698932639,
    "output_throughput": 3278.673326434867,
    "total_throughput": 7054.179025367506,
    "itl": 132.98500308693087,
    "ttft": 2267020.872578218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.75986269313395,
    "arrivals": 740358,
    "finished_requests": 55115,
    "scheduler_time": 100.36332482125016
}
#Debug simulation 
Total elapsed time: 4.768262861063704. Arrivals time: 0.21995148819405586 Scheduler time: 4.401046193554066 Scheduler overhead time: 0.04099553287960589 Adapter cache time: 0.046174393384717405 Engine time: 0.04117169906385243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495650329 . Total output tokens: 436414531
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.760072961915284,
    "estimated_duration": 3600.0380852023163,
    "input_throughput": 3776.676156812357,
    "output_throughput": 3279.333084982221,
    "total_throughput": 7056.009241794578,
    "itl": 132.9503723805124,
    "ttft": 2266836.8916433896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.774225802082233,
    "arrivals": 740358,
    "finished_requests": 55128,
    "scheduler_time": 100.39057216489621
}
#Debug simulation 
Total elapsed time: 4.76017211494036. Arrivals time: 0.21709062880836427 Scheduler time: 4.395750676863827 Scheduler overhead time: 0.04088278510607779 Adapter cache time: 0.04622552066575736 Engine time: 0.041241768980398774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433780535 . Total output tokens: 381721736
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.752973589929752,
    "estimated_duration": 3600.1254912568725,
    "input_throughput": 3971.555445698717,
    "output_throughput": 3467.3877425428122,
    "total_throughput": 7438.943188241529,
    "itl": 150.09997128870918,
    "ttft": 2223123.061190693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.886058967095249,
    "arrivals": 648144,
    "finished_requests": 58349,
    "scheduler_time": 96.980662918073
}
#Debug simulation 
Total elapsed time: 5.7530661909841. Arrivals time: 0.23429611697793007 Scheduler time: 5.381023064954206 Scheduler overhead time: 0.0373295156750828 Adapter cache time: 0.04553252412006259 Engine time: 0.037679082714021206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433780535 . Total output tokens: 381721736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.035560978925787,
    "estimated_duration": 3600.024928714391,
    "input_throughput": 3739.3054955336893,
    "output_throughput": 3271.978176052932,
    "total_throughput": 7011.2836715866215,
    "itl": 133.1282411738523,
    "ttft": 2254965.4878266966,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3021,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.0775375387952,
    "arrivals": 648144,
    "finished_requests": 54956,
    "scheduler_time": 99.97428287721135
}
#Debug simulation 
Total elapsed time: 5.035656261956319. Arrivals time: 0.22490812104661018 Scheduler time: 4.645139854517765 Scheduler overhead time: 0.04094498360063881 Adapter cache time: 0.0642978586256504 Engine time: 0.0413814791245386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433780535 . Total output tokens: 381721736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.0331885489868,
    "estimated_duration": 3600.0486809445297,
    "input_throughput": 3740.7571934462685,
    "output_throughput": 3273.307125643719,
    "total_throughput": 7014.064319089987,
    "itl": 133.07813699807397,
    "ttft": 2255042.0943580577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3021,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.753174730255726,
    "arrivals": 648144,
    "finished_requests": 54983,
    "scheduler_time": 100.0106135815622
}
#Debug simulation 
Total elapsed time: 5.033350193989463. Arrivals time: 0.2265467814868316 Scheduler time: 4.639265074278228 Scheduler overhead time: 0.04184138576965779 Adapter cache time: 0.06422994087915868 Engine time: 0.04204910306725651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433780535 . Total output tokens: 381721736
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.341978903976269,
    "estimated_duration": 3600.07722864699,
    "input_throughput": 3742.2919410713193,
    "output_throughput": 3274.554475163441,
    "total_throughput": 7016.84641623476,
    "itl": 133.02453364080813,
    "ttft": 2254772.161198388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3022,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.292209082405616,
    "arrivals": 648144,
    "finished_requests": 55011,
    "scheduler_time": 100.0509435035686
}
#Debug simulation 
Total elapsed time: 5.342067188001238. Arrivals time: 0.536236438434571 Scheduler time: 4.6407651311019436 Scheduler overhead time: 0.041304759797640145 Adapter cache time: 0.06353936565574259 Engine time: 0.04127517691813409 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423505645 . Total output tokens: 372714612
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.296688618022017,
    "estimated_duration": 3600.157336363543,
    "input_throughput": 3982.620941362143,
    "output_throughput": 3463.7961163652767,
    "total_throughput": 7446.41705772742,
    "itl": 149.8657866243685,
    "ttft": 2217248.125356929,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.057981601925952,
    "arrivals": 632850,
    "finished_requests": 58076,
    "scheduler_time": 97.01178694618407
}
#Debug simulation 
Total elapsed time: 5.29677811905276. Arrivals time: 0.2217567862244323 Scheduler time: 4.937170147430152 Scheduler overhead time: 0.03748192766215652 Adapter cache time: 0.045633984031155705 Engine time: 0.037524785147979856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423505645 . Total output tokens: 372714612
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.733347235014662,
    "estimated_duration": 3600.0912047175143,
    "input_throughput": 3755.224307174406,
    "output_throughput": 3263.149273720079,
    "total_throughput": 7018.373580894485,
    "itl": 132.7301641350032,
    "ttft": 2250140.740336967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3010,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.032302385968514,
    "arrivals": 632850,
    "finished_requests": 54682,
    "scheduler_time": 100.0551018919133
}
#Debug simulation 
Total elapsed time: 4.733441882999614. Arrivals time: 0.21144337521400303 Scheduler time: 4.357592474319972 Scheduler overhead time: 0.0411607155110687 Adapter cache time: 0.06286038551479578 Engine time: 0.04137551295571029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423505645 . Total output tokens: 372714612
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.734629201004282,
    "estimated_duration": 3600.131581341074,
    "input_throughput": 3756.5474190146665,
    "output_throughput": 3264.414017784922,
    "total_throughput": 7020.961436799588,
    "itl": 132.68802070285653,
    "ttft": 2249794.0838972046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3010,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.725986450082118,
    "arrivals": 632850,
    "finished_requests": 54706,
    "scheduler_time": 100.09138081343836
}
#Debug simulation 
Total elapsed time: 4.734752840944566. Arrivals time: 0.20979928504675627 Scheduler time: 4.360134997754358 Scheduler overhead time: 0.04114433459471911 Adapter cache time: 0.06292122334707528 Engine time: 0.041605601320043206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423505645 . Total output tokens: 372714612
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.042861751047894,
    "estimated_duration": 3600.1233596474576,
    "input_throughput": 3757.7287355299845,
    "output_throughput": 3265.8075364260117,
    "total_throughput": 7023.536271955996,
    "itl": 132.63738097690492,
    "ttft": 2249511.168918047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.234753793940474,
    "arrivals": 632850,
    "finished_requests": 54730,
    "scheduler_time": 100.1316702021411
}
#Debug simulation 
Total elapsed time: 5.0429274659836665. Arrivals time: 0.21710324264131486 Scheduler time: 4.66149811737705 Scheduler overhead time: 0.04088962497189641 Adapter cache time: 0.06253303994890302 Engine time: 0.041955067426897585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418405157 . Total output tokens: 368275763
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.098748534917831,
    "estimated_duration": 3600.0706448299393,
    "input_throughput": 3988.535064060748,
    "output_throughput": 3464.623678402621,
    "total_throughput": 7453.158742463369,
    "itl": 149.50451019837854,
    "ttft": 2222489.207228535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.880972794238826,
    "arrivals": 625482,
    "finished_requests": 58198,
    "scheduler_time": 97.01675606657685
}
#Debug simulation 
Total elapsed time: 5.098845963017084. Arrivals time: 0.22208388114813715 Scheduler time: 4.742054797359742 Scheduler overhead time: 0.037407706025987864 Adapter cache time: 0.04234317678492516 Engine time: 0.03774533362593502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418405157 . Total output tokens: 368275763
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.919811552972533,
    "estimated_duration": 3600.0984222888414,
    "input_throughput": 3761.0527301616235,
    "output_throughput": 3267.9987100241747,
    "total_throughput": 7029.051440185798,
    "itl": 132.64719487495137,
    "ttft": 2256303.160622327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2813,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.556719267866114,
    "arrivals": 625482,
    "finished_requests": 54872,
    "scheduler_time": 100.01749054500567
}
#Debug simulation 
Total elapsed time: 4.919918978936039. Arrivals time: 0.21393631712999195 Scheduler time: 4.543776533217169 Scheduler overhead time: 0.041181629756465554 Adapter cache time: 0.06075582350604236 Engine time: 0.04124883969780058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418405157 . Total output tokens: 368275763
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.596945893019438,
    "estimated_duration": 3600.081492342965,
    "input_throughput": 3763.4598074562878,
    "output_throughput": 3270.2145840420967,
    "total_throughput": 7033.6743914983845,
    "itl": 132.74790562951665,
    "ttft": 2255719.19750965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2885,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.848867737031963,
    "arrivals": 625482,
    "finished_requests": 54905,
    "scheduler_time": 100.01028137276737
}
#Debug simulation 
Total elapsed time: 4.597041768021882. Arrivals time: 0.21685378276742995 Scheduler time: 4.217506009503268 Scheduler overhead time: 0.04090080433525145 Adapter cache time: 0.06136268994305283 Engine time: 0.04137002758216113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418405157 . Total output tokens: 368275763
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.913832720951177,
    "estimated_duration": 3600.088880634547,
    "input_throughput": 3764.2826189367265,
    "output_throughput": 3271.0253525530684,
    "total_throughput": 7035.307971489795,
    "itl": 132.69959611579822,
    "ttft": 2255164.2820734615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2885,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.417611913547336,
    "arrivals": 625482,
    "finished_requests": 54917,
    "scheduler_time": 100.04949211306199
}
#Debug simulation 
Total elapsed time: 4.913895622943528. Arrivals time: 0.5165566356154159 Scheduler time: 4.233572356053628 Scheduler overhead time: 0.041071807150729 Adapter cache time: 0.06139988545328379 Engine time: 0.042358547798357904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415797701 . Total output tokens: 366005492
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.956579289981164,
    "estimated_duration": 3600.1263247870215,
    "input_throughput": 4007.962970814256,
    "output_throughput": 3466.428917807009,
    "total_throughput": 7474.391888621265,
    "itl": 149.81131076983144,
    "ttft": 2216309.0426764553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1797,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.882499030414353,
    "arrivals": 621618,
    "finished_requests": 58423,
    "scheduler_time": 97.01578158267107
}
#Debug simulation 
Total elapsed time: 4.956672306987457. Arrivals time: 0.22067919478286058 Scheduler time: 4.603872256586328 Scheduler overhead time: 0.037274610716849566 Adapter cache time: 0.04011652083136141 Engine time: 0.0375513075850904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415797701 . Total output tokens: 366005492
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.536318936035968,
    "estimated_duration": 3600.02333997657,
    "input_throughput": 3780.378268349942,
    "output_throughput": 3270.822405300471,
    "total_throughput": 7051.200673650414,
    "itl": 132.8230248197381,
    "ttft": 2249529.0478001214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.2685080704275,
    "arrivals": 621618,
    "finished_requests": 55108,
    "scheduler_time": 100.03179985706558
}
#Debug simulation 
Total elapsed time: 4.53641266503837. Arrivals time: 0.21564819803461432 Scheduler time: 4.163316329009831 Scheduler overhead time: 0.0409847671398893 Adapter cache time: 0.055917983525432646 Engine time: 0.04146809980738908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415797701 . Total output tokens: 366005492
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.52705536398571,
    "estimated_duration": 3600.120288181174,
    "input_throughput": 3782.081961177733,
    "output_throughput": 3272.67259337949,
    "total_throughput": 7054.754554557223,
    "itl": 132.78270737234263,
    "ttft": 2249541.9517315757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.15320944493205,
    "arrivals": 621618,
    "finished_requests": 55135,
    "scheduler_time": 100.06417866119563
}
#Debug simulation 
Total elapsed time: 4.5271730159875005. Arrivals time: 0.21136873529758304 Scheduler time: 4.15769242728129 Scheduler overhead time: 0.04151543660555035 Adapter cache time: 0.05590478656813502 Engine time: 0.04163343459367752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415797701 . Total output tokens: 366005492
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.53052202204708,
    "estimated_duration": 3600.0417198936207,
    "input_throughput": 3783.1728240089537,
    "output_throughput": 3273.5984516169005,
    "total_throughput": 7056.771275625854,
    "itl": 132.73465349573365,
    "ttft": 2249346.848180698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.853551283107347,
    "arrivals": 621618,
    "finished_requests": 55149,
    "scheduler_time": 100.09678470350906
}
#Debug simulation 
Total elapsed time: 4.530618384014815. Arrivals time: 0.21058135852217674 Scheduler time: 4.162640680326149 Scheduler overhead time: 0.04089148645289242 Adapter cache time: 0.05607025418430567 Engine time: 0.04138869734015316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414491744 . Total output tokens: 364854398
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.8496948960237205,
    "estimated_duration": 3600.1133284550165,
    "input_throughput": 4015.887190474773,
    "output_throughput": 3464.377052083637,
    "total_throughput": 7480.26424255841,
    "itl": 149.39037891234707,
    "ttft": 2221273.4251928264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.28738221753884,
    "arrivals": 619780,
    "finished_requests": 58272,
    "scheduler_time": 97.08838310383751
}
#Debug simulation 
Total elapsed time: 4.84984351193998. Arrivals time: 0.2171709364047274 Scheduler time: 4.502753298613243 Scheduler overhead time: 0.03728080401197076 Adapter cache time: 0.03780144453048706 Engine time: 0.037611616076901555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414491744 . Total output tokens: 364854398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.482979402993806,
    "estimated_duration": 3600.127470922246,
    "input_throughput": 3787.8922649665597,
    "output_throughput": 3269.3895133065434,
    "total_throughput": 7057.281778273104,
    "itl": 132.4516439926667,
    "ttft": 2253890.234884817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.667286178795234,
    "arrivals": 619780,
    "finished_requests": 54900,
    "scheduler_time": 100.12345494916782
}
#Debug simulation 
Total elapsed time: 4.483077381039038. Arrivals time: 0.2097185222664848 Scheduler time: 4.117897459655069 Scheduler overhead time: 0.040992380352690816 Adapter cache time: 0.054127862909808755 Engine time: 0.04140444926451892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414491744 . Total output tokens: 364854398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.525448640924878,
    "estimated_duration": 3600.1154460349735,
    "input_throughput": 3790.0506815767953,
    "output_throughput": 3270.569840466615,
    "total_throughput": 7060.62052204341,
    "itl": 132.49145204393352,
    "ttft": 2253559.815300386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.78044891923695,
    "arrivals": 619780,
    "finished_requests": 54924,
    "scheduler_time": 100.13075429814658
}
#Debug simulation 
Total elapsed time: 4.525542511953972. Arrivals time: 0.24798087833914906 Scheduler time: 4.121176780899987 Scheduler overhead time: 0.04095659265294671 Adapter cache time: 0.05489038024097681 Engine time: 0.04156139411497861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414491744 . Total output tokens: 364854398
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.789529131958261,
    "estimated_duration": 3600.0984742156097,
    "input_throughput": 3791.5679523111016,
    "output_throughput": 3271.628563595398,
    "total_throughput": 7063.196515906499,
    "itl": 132.44040760354116,
    "ttft": 2253339.2206056234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.45136426385135,
    "arrivals": 619780,
    "finished_requests": 54944,
    "scheduler_time": 100.16652509261645
}
#Debug simulation 
Total elapsed time: 4.789592628949322. Arrivals time: 0.5142550134332851 Scheduler time: 4.11770586122293 Scheduler overhead time: 0.040818718378432095 Adapter cache time: 0.05524511402472854 Engine time: 0.04257194814272225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413859425 . Total output tokens: 364317658
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.877463212935254,
    "estimated_duration": 3600.014795568602,
    "input_throughput": 3983.917237688668,
    "output_throughput": 3463.786319808856,
    "total_throughput": 7447.703557497524,
    "itl": 149.62597388821965,
    "ttft": 2217752.3151016515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.804676358206478,
    "arrivals": 618816,
    "finished_requests": 58164,
    "scheduler_time": 97.07321779434363
}
#Debug simulation 
Total elapsed time: 4.877586432965472. Arrivals time: 0.25396138068754226 Scheduler time: 4.4949075056938455 Scheduler overhead time: 0.03723961242940277 Adapter cache time: 0.036481363349594176 Engine time: 0.03773456334602088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413859425 . Total output tokens: 364317658
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.473255153046921,
    "estimated_duration": 3600.0302426829917,
    "input_throughput": 3753.147081878495,
    "output_throughput": 3260.9634388101313,
    "total_throughput": 7014.110520688626,
    "itl": 132.18809730369705,
    "ttft": 2252668.041867755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.064959396994286,
    "arrivals": 618816,
    "finished_requests": 54769,
    "scheduler_time": 100.21239455145097
}
#Debug simulation 
Total elapsed time: 4.473369143088348. Arrivals time: 0.24817570741288364 Scheduler time: 4.070071831345558 Scheduler overhead time: 0.04088534496258944 Adapter cache time: 0.05356133764144033 Engine time: 0.0416545660700649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413859425 . Total output tokens: 364317658
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.457018691929989,
    "estimated_duration": 3600.0826453882637,
    "input_throughput": 3754.360477616846,
    "output_throughput": 3261.9953919789764,
    "total_throughput": 7016.355869595823,
    "itl": 132.150988652379,
    "ttft": 2252624.458191541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.0671023703043,
    "arrivals": 618816,
    "finished_requests": 54786,
    "scheduler_time": 100.2403541699587
}
#Debug simulation 
Total elapsed time: 4.457135768025182. Arrivals time: 0.20979814557358623 Scheduler time: 4.0926478549372405 Scheduler overhead time: 0.041011595516465604 Adapter cache time: 0.052949105156585574 Engine time: 0.041608177591115236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413859425 . Total output tokens: 364317658
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.46292891795747,
    "estimated_duration": 3600.0011716932636,
    "input_throughput": 3755.786277602922,
    "output_throughput": 3263.4283822952634,
    "total_throughput": 7019.214659898185,
    "itl": 132.10588883115085,
    "ttft": 2252319.039077339,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.787436486031927,
    "arrivals": 618816,
    "finished_requests": 54804,
    "scheduler_time": 100.27238529730975
}
#Debug simulation 
Total elapsed time: 4.463022937998176. Arrivals time: 0.2113987065386027 Scheduler time: 4.096560833859257 Scheduler overhead time: 0.0409852818120271 Adapter cache time: 0.053569560521282256 Engine time: 0.04149630735628307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.532157648005523,
    "estimated_duration": 3600.013932808047,
    "input_throughput": 4004.2531137527767,
    "output_throughput": 3480.4493076577446,
    "total_throughput": 7484.702421410521,
    "itl": 149.17540881009532,
    "ttft": 2196110.3888299596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.487276881484856,
    "arrivals": 541365,
    "finished_requests": 58384,
    "scheduler_time": 97.30566681445704
}
#Debug simulation 
Total elapsed time: 4.532277374062687. Arrivals time: 0.2697033900767565 Scheduler time: 4.100041058962233 Scheduler overhead time: 0.03696334711275995 Adapter cache time: 0.07056384906172752 Engine time: 0.03776141966227442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.395167295006104,
    "estimated_duration": 3600.046174805324,
    "input_throughput": 3867.4109508478437,
    "output_throughput": 3365.0062837472037,
    "total_throughput": 7232.417234595047,
    "itl": 129.27892442071783,
    "ttft": 2217149.9266275372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.48066818118958,
    "arrivals": 541365,
    "finished_requests": 56404,
    "scheduler_time": 102.75287422101218
}
#Debug simulation 
Total elapsed time: 4.395282693090849. Arrivals time: 0.26436393428593874 Scheduler time: 3.9493923160480335 Scheduler overhead time: 0.040974062867462635 Adapter cache time: 0.07901729026343673 Engine time: 0.04225722071714699 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.390351925976574,
    "estimated_duration": 3600.110660709413,
    "input_throughput": 3868.9816265968043,
    "output_throughput": 3366.3301331998173,
    "total_throughput": 7235.311759796621,
    "itl": 129.2901655634882,
    "ttft": 2216621.8035067855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.867574365568004,
    "arrivals": 541365,
    "finished_requests": 56429,
    "scheduler_time": 102.77717621265515
}
#Debug simulation 
Total elapsed time: 4.390442486968823. Arrivals time: 0.26366035104729235 Scheduler time: 3.9449943699873984 Scheduler overhead time: 0.04083714145235717 Adapter cache time: 0.07942374830599874 Engine time: 0.04221760237123817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_256_slots_128_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_256_slots_128_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.407789678894915,
    "estimated_duration": 3600.0706462821404,
    "input_throughput": 3870.7076524708614,
    "output_throughput": 3367.715023181751,
    "total_throughput": 7238.422675652612,
    "itl": 129.2387640301396,
    "ttft": 2216166.4446985703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.065106358283305,
    "arrivals": 541365,
    "finished_requests": 56450,
    "scheduler_time": 102.82299126676605
}
#Debug simulation 
Total elapsed time: 4.407887180917896. Arrivals time: 0.26428855722770095 Scheduler time: 3.961032672668807 Scheduler overhead time: 0.04105913173407316 Adapter cache time: 0.07991981983650476 Engine time: 0.04224029870238155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_256_slots_128_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_256_slots_128_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.5187161091016605,
    "estimated_duration": 3600.107835583005,
    "input_throughput": 4103.433473294191,
    "output_throughput": 3561.7241442778886,
    "total_throughput": 7665.157617572079,
    "itl": 145.7946805607436,
    "ttft": 2180343.875277976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3004,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.863676731977147,
    "arrivals": 533687,
    "finished_requests": 59690,
    "scheduler_time": 99.61346371238713
}
#Debug simulation 
Total elapsed time: 4.518810973037034. Arrivals time: 0.21952678984962404 Scheduler time: 4.143122535548173 Scheduler overhead time: 0.03707207215484232 Adapter cache time: 0.06348548643290997 Engine time: 0.03816379187628627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_256_slots_128_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_256_slots_128_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.394440675969236,
    "estimated_duration": 3600.088014036982,
    "input_throughput": 3940.8992070976237,
    "output_throughput": 3428.592565479763,
    "total_throughput": 7369.491772577387,
    "itl": 125.96440006789311,
    "ttft": 2204008.7691152967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.255645378506262,
    "arrivals": 533687,
    "finished_requests": 57329,
    "scheduler_time": 105.08419689263562
}
#Debug simulation 
Total elapsed time: 4.394536950974725. Arrivals time: 0.21151451766490936 Scheduler time: 4.0090479016071185 Scheduler overhead time: 0.04180823534261435 Adapter cache time: 0.0691083847777918 Engine time: 0.043325987993739545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_256_slots_128_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_256_slots_128_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.448018284980208,
    "estimated_duration": 3600.0300392470117,
    "input_throughput": 3961.0025040187134,
    "output_throughput": 3446.3190208810142,
    "total_throughput": 7407.321524899728,
    "itl": 126.30610993696295,
    "ttft": 2200678.9026686875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2927,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.200285674934648,
    "arrivals": 533687,
    "finished_requests": 57629,
    "scheduler_time": 105.18974382218231
}
#Debug simulation 
Total elapsed time: 4.4481564570451155. Arrivals time: 0.24134416121523827 Scheduler time: 4.0335672232322395 Scheduler overhead time: 0.04165056312922388 Adapter cache time: 0.06877961836289614 Engine time: 0.04305267543531954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_256_slots_128_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_256_slots_128_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356745963 . Total output tokens: 314402868
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.427593959029764,
    "estimated_duration": 3600.1376280898357,
    "input_throughput": 3962.717394104025,
    "output_throughput": 3447.391817235911,
    "total_throughput": 7410.109211339935,
    "itl": 126.2500139001888,
    "ttft": 2200284.0394899845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2927,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.685736593051335,
    "arrivals": 533687,
    "finished_requests": 57652,
    "scheduler_time": 105.23700454300867
}
#Debug simulation 
Total elapsed time: 4.4276912229834124. Arrivals time: 0.21200917207170278 Scheduler time: 4.0422504196176305 Scheduler overhead time: 0.04187106085009873 Adapter cache time: 0.06843060918617994 Engine time: 0.04344873677473515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.583921585930511,
    "estimated_duration": 3600.0666828036306,
    "input_throughput": 4179.041480499331,
    "output_throughput": 3623.795931979853,
    "total_throughput": 7802.837412479184,
    "itl": 143.37479566706452,
    "ttft": 2173753.1777412174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.63682112438634,
    "arrivals": 529924,
    "finished_requests": 61176,
    "scheduler_time": 101.06458549489638
}
#Debug simulation 
Total elapsed time: 4.584022409981117. Arrivals time: 0.22371212160214782 Scheduler time: 4.2087162241805345 Scheduler overhead time: 0.037539306678809226 Adapter cache time: 0.05780165793839842 Engine time: 0.03856783150695264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.473299223929644,
    "estimated_duration": 3600.0836932470324,
    "input_throughput": 4027.53636733441,
    "output_throughput": 3494.0093263928648,
    "total_throughput": 7521.545693727275,
    "itl": 124.52063741055532,
    "ttft": 2195354.296527274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.879816212034395,
    "arrivals": 529924,
    "finished_requests": 58956,
    "scheduler_time": 106.43028652419449
}
#Debug simulation 
Total elapsed time: 4.473398393951356. Arrivals time: 0.21163055661600083 Scheduler time: 4.092238475452177 Scheduler overhead time: 0.04198002757038921 Adapter cache time: 0.06411715038120747 Engine time: 0.04352139891125262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.476417396101169,
    "estimated_duration": 3600.10724509005,
    "input_throughput": 4029.352186600529,
    "output_throughput": 3495.6991953958336,
    "total_throughput": 7525.051381996363,
    "itl": 124.56358225284814,
    "ttft": 2195054.783022095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.894727027225596,
    "arrivals": 529924,
    "finished_requests": 58985,
    "scheduler_time": 106.4304073432486
}
#Debug simulation 
Total elapsed time: 4.476516337017529. Arrivals time: 0.21609320468269289 Scheduler time: 4.091444413294084 Scheduler overhead time: 0.041896351031027734 Adapter cache time: 0.06386012933216989 Engine time: 0.04329003440216184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354158742 . Total output tokens: 312101720
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.766464895918034,
    "estimated_duration": 3600.1260226204577,
    "input_throughput": 4030.5752934276584,
    "output_throughput": 3496.4984339180364,
    "total_throughput": 7527.073727345695,
    "itl": 124.52820663758528,
    "ttft": 2194758.7122496003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.608686699695928,
    "arrivals": 529924,
    "finished_requests": 59001,
    "scheduler_time": 106.46784998012971
}
#Debug simulation 
Total elapsed time: 4.766530958004296. Arrivals time: 0.503998979460448 Scheduler time: 4.092951855622232 Scheduler overhead time: 0.042183862649835646 Adapter cache time: 0.06390343024395406 Engine time: 0.04368289979174733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_256_slots_128_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_256_slots_128_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.671360865933821,
    "estimated_duration": 3600.1218542463084,
    "input_throughput": 4201.2247397016035,
    "output_throughput": 3653.431337188324,
    "total_throughput": 7854.656076889927,
    "itl": 142.42643532381683,
    "ttft": 2168875.9169910387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.036618138654575,
    "arrivals": 527992,
    "finished_requests": 61137,
    "scheduler_time": 101.98312933818157
}
#Debug simulation 
Total elapsed time: 4.671457110904157. Arrivals time: 0.2720278229098767 Scheduler time: 4.2504605709109455 Scheduler overhead time: 0.037891189102083445 Adapter cache time: 0.054052340448834 Engine time: 0.039216505945660174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_256_slots_128_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_256_slots_128_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.544014189974405,
    "estimated_duration": 3600.0488576575262,
    "input_throughput": 4037.5943701658425,
    "output_throughput": 3518.4978040109127,
    "total_throughput": 7556.092174176755,
    "itl": 123.14687111391204,
    "ttft": 2192586.4483827706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.151378845134435,
    "arrivals": 527992,
    "finished_requests": 58806,
    "scheduler_time": 107.56103081653313
}
#Debug simulation 
Total elapsed time: 4.54411043797154. Arrivals time: 0.26700771565083414 Scheduler time: 4.108736211550422 Scheduler overhead time: 0.04264040570706129 Adapter cache time: 0.06148040224798024 Engine time: 0.044139678706415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_256_slots_128_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_256_slots_128_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.561799600021914,
    "estimated_duration": 3600.1141008220193,
    "input_throughput": 4046.9508998821257,
    "output_throughput": 3525.315210732383,
    "total_throughput": 7572.266110614509,
    "itl": 123.70994818214456,
    "ttft": 2192035.3418318583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.311486200913983,
    "arrivals": 527992,
    "finished_requests": 58925,
    "scheduler_time": 107.40575009594443
}
#Debug simulation 
Total elapsed time: 4.561896560946479. Arrivals time: 0.26880557904951274 Scheduler time: 4.124534602626227 Scheduler overhead time: 0.04228181077633053 Adapter cache time: 0.062035213806666434 Engine time: 0.044142711092717946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_256_slots_128_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_256_slots_128_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 352834765 . Total output tokens: 310943492
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.558806014945731,
    "estimated_duration": 3600.011005880821,
    "input_throughput": 4048.420956544844,
    "output_throughput": 3526.386163615043,
    "total_throughput": 7574.807120159887,
    "itl": 123.66985916067824,
    "ttft": 2191852.313243369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.159536646186224,
    "arrivals": 527992,
    "finished_requests": 58945,
    "scheduler_time": 107.43620371877533
}
#Debug simulation 
Total elapsed time: 4.558934583910741. Arrivals time: 0.26885599782690406 Scheduler time: 4.12234542821534 Scheduler overhead time: 0.042542706592939794 Adapter cache time: 0.06135853519663215 Engine time: 0.043807075591757894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.693721459014341,
    "estimated_duration": 3600.050795408715,
    "input_throughput": 4220.486005191219,
    "output_throughput": 3671.307087348883,
    "total_throughput": 7891.793092540102,
    "itl": 141.274363355093,
    "ttft": 2166999.887361921,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.806710058711847,
    "arrivals": 526966,
    "finished_requests": 61519,
    "scheduler_time": 102.42390568491311
}
#Debug simulation 
Total elapsed time: 4.6938472710317. Arrivals time: 0.27110516908578575 Scheduler time: 4.273282326059416 Scheduler overhead time: 0.03812108014244586 Adapter cache time: 0.05400476569775492 Engine time: 0.03938792075496167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.572261582012288,
    "estimated_duration": 3600.1099470226595,
    "input_throughput": 4061.651509308186,
    "output_throughput": 3535.2386975085606,
    "total_throughput": 7596.890206816747,
    "itl": 122.62634850786344,
    "ttft": 2189525.148457413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.631665464373999,
    "arrivals": 526966,
    "finished_requests": 59156,
    "scheduler_time": 107.86163798383346
}
#Debug simulation 
Total elapsed time: 4.572386426036246. Arrivals time: 0.2679927892750129 Scheduler time: 4.137660245411098 Scheduler overhead time: 0.042630085605196655 Adapter cache time: 0.05938880948815495 Engine time: 0.04460526735056192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.592175915022381,
    "estimated_duration": 3600.1217855443438,
    "input_throughput": 4062.3270186924237,
    "output_throughput": 3535.8751059793017,
    "total_throughput": 7598.202124671726,
    "itl": 122.60004461109303,
    "ttft": 2189280.4277420547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.83066196277289,
    "arrivals": 526966,
    "finished_requests": 59169,
    "scheduler_time": 107.88512898949662
}
#Debug simulation 
Total elapsed time: 4.592297661001794. Arrivals time: 0.2685160569380969 Scheduler time: 4.156842189957388 Scheduler overhead time: 0.042792175780050457 Adapter cache time: 0.05950398568529636 Engine time: 0.04439611651469022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352193568 . Total output tokens: 310393891
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.5647204130655155,
    "estimated_duration": 3600.071449429184,
    "input_throughput": 4064.8626577453865,
    "output_throughput": 3538.5044932982746,
    "total_throughput": 7603.367151043661,
    "itl": 122.70924903184456,
    "ttft": 2189182.621110707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2005,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.799761485844519,
    "arrivals": 526966,
    "finished_requests": 59209,
    "scheduler_time": 107.86209545922007
}
#Debug simulation 
Total elapsed time: 4.564847280038521. Arrivals time: 0.21275178855285048 Scheduler time: 4.185446367948316 Scheduler overhead time: 0.0425707787508145 Adapter cache time: 0.059670214308425784 Engine time: 0.0442699323175475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_256_slots_128_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_256_slots_128_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.790843226015568,
    "estimated_duration": 3600.12234945696,
    "input_throughput": 4304.98924636208,
    "output_throughput": 3762.1638059170423,
    "total_throughput": 8067.153052279123,
    "itl": 137.58816211086895,
    "ttft": 2153345.8051213645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.91250860322305,
    "arrivals": 518548,
    "finished_requests": 62807,
    "scheduler_time": 105.1863352389827
}
#Debug simulation 
Total elapsed time: 4.790973030030727. Arrivals time: 0.22561178065370768 Scheduler time: 4.41805468313396 Scheduler overhead time: 0.039016464026644826 Adapter cache time: 0.049569251481443644 Engine time: 0.04033297568093985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_256_slots_128_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_256_slots_128_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.676586722023785,
    "estimated_duration": 3600.12561215306,
    "input_throughput": 4126.965167505474,
    "output_throughput": 3614.2363911070124,
    "total_throughput": 7741.201558612486,
    "itl": 119.56124546412154,
    "ttft": 2177145.6272620508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2021,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.774614313891858,
    "arrivals": 518548,
    "finished_requests": 60233,
    "scheduler_time": 110.59217955763913
}
#Debug simulation 
Total elapsed time: 4.676712819025852. Arrivals time: 0.293821309809573 Scheduler time: 4.21995870443061 Scheduler overhead time: 0.04388267279136926 Adapter cache time: 0.052933283848688006 Engine time: 0.04546511732041836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_256_slots_128_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_256_slots_128_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.931118501001038,
    "estimated_duration": 3600.041084947113,
    "input_throughput": 4117.338566489652,
    "output_throughput": 3606.0746790590347,
    "total_throughput": 7723.413245548687,
    "itl": 119.88706107255452,
    "ttft": 2176938.688012124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2018,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.919753525136242,
    "arrivals": 518548,
    "finished_requests": 60094,
    "scheduler_time": 110.3043151647104
}
#Debug simulation 
Total elapsed time: 4.931225417996757. Arrivals time: 0.27661645330954343 Scheduler time: 4.49264083604794 Scheduler overhead time: 0.043725539348088205 Adapter cache time: 0.05245433875825256 Engine time: 0.04514444398228079 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_256_slots_128_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_256_slots_128_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346455702 . Total output tokens: 305326594
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.648447443032637,
    "estimated_duration": 3600.124146253844,
    "input_throughput": 4131.285032344354,
    "output_throughput": 3619.48962608947,
    "total_throughput": 7750.774658433824,
    "itl": 119.81831981923423,
    "ttft": 2176274.3463122766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2022,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.908288141834232,
    "arrivals": 518548,
    "finished_requests": 60313,
    "scheduler_time": 110.54078790589345
}
#Debug simulation 
Total elapsed time: 4.648581077926792. Arrivals time: 0.27155625133309513 Scheduler time: 4.215684798546135 Scheduler overhead time: 0.04359923233278096 Adapter cache time: 0.05201413400936872 Engine time: 0.045092878863215446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.820425232988782,
    "estimated_duration": 3600.0771088180772,
    "input_throughput": 4399.1060528143535,
    "output_throughput": 3838.119735312103,
    "total_throughput": 8237.225788126456,
    "itl": 135.6732695112635,
    "ttft": 2142719.837724838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.029498265292784,
    "arrivals": 514751,
    "finished_requests": 64134,
    "scheduler_time": 106.9791590065349
}
#Debug simulation 
Total elapsed time: 4.820519606000744. Arrivals time: 0.22862057748716325 Scheduler time: 4.449288593139499 Scheduler overhead time: 0.039427333045750856 Adapter cache time: 0.04387256724294275 Engine time: 0.04072037653531879 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.651800032006577,
    "estimated_duration": 3600.0210330803607,
    "input_throughput": 4219.829512218545,
    "output_throughput": 3679.6762791869774,
    "total_throughput": 7899.505791405522,
    "itl": 118.17706140206481,
    "ttft": 2169950.216353085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.719105039983843,
    "arrivals": 514751,
    "finished_requests": 61491,
    "scheduler_time": 112.18643961045876
}
#Debug simulation 
Total elapsed time: 4.651893303031102. Arrivals time: 0.2222190028987825 Scheduler time: 4.271151406806894 Scheduler overhead time: 0.04408091073855758 Adapter cache time: 0.047872743336483836 Engine time: 0.04572892596479505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.697954291012138,
    "estimated_duration": 3600.0614320993604,
    "input_throughput": 4223.456540055052,
    "output_throughput": 3683.727139141214,
    "total_throughput": 7907.183679196266,
    "itl": 118.43682825776843,
    "ttft": 2169186.6068333816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.036100321114146,
    "arrivals": 514751,
    "finished_requests": 61552,
    "scheduler_time": 112.11020070800815
}
#Debug simulation 
Total elapsed time: 4.698046089964919. Arrivals time: 0.25036473537329584 Scheduler time: 4.288899787003174 Scheduler overhead time: 0.044204371864907444 Adapter cache time: 0.04821506759617478 Engine time: 0.04557007038965821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 343946049 . Total output tokens: 303053840
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.689774776925333,
    "estimated_duration": 3600.0338924019784,
    "input_throughput": 4224.577171925639,
    "output_throughput": 3684.644477374507,
    "total_throughput": 7909.221649300146,
    "itl": 118.40868804977269,
    "ttft": 2169288.3860197063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.220657425853679,
    "arrivals": 514751,
    "finished_requests": 61569,
    "scheduler_time": 112.13416134944613
}
#Debug simulation 
Total elapsed time: 4.689870255999267. Arrivals time: 0.2256150945322588 Scheduler time: 4.304805431282148 Scheduler overhead time: 0.04447926324792206 Adapter cache time: 0.048301774892024696 Engine time: 0.04580305330455303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_256_slots_128_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_256_slots_128_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.865014589973725,
    "estimated_duration": 3600.034061129217,
    "input_throughput": 4457.285883280437,
    "output_throughput": 3865.72064699709,
    "total_throughput": 8323.006530277527,
    "itl": 134.52342122949867,
    "ttft": 2131837.0633885465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.442520097624747,
    "arrivals": 512803,
    "finished_requests": 64845,
    "scheduler_time": 107.78007660414455
}
#Debug simulation 
Total elapsed time: 4.86514603800606. Arrivals time: 0.256734766648151 Scheduler time: 4.467786750057712 Scheduler overhead time: 0.0398250687867403 Adapter cache time: 0.041084664640948176 Engine time: 0.04097241268027574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_256_slots_128_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_256_slots_128_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.6819417119259015,
    "estimated_duration": 3600.118175002177,
    "input_throughput": 4265.055271412227,
    "output_throughput": 3701.209891531392,
    "total_throughput": 7966.265162943619,
    "itl": 117.60492826320761,
    "ttft": 2158610.8636941444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.09418915142297,
    "arrivals": 512803,
    "finished_requests": 62122,
    "scheduler_time": 112.73879300401849
}
#Debug simulation 
Total elapsed time: 4.682039571925998. Arrivals time: 0.22326020267792046 Scheduler time: 4.302412594552152 Scheduler overhead time: 0.0442892104620114 Adapter cache time: 0.045156631735153496 Engine time: 0.04596027254592627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_256_slots_128_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_256_slots_128_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.689023065962829,
    "estimated_duration": 3600.0731837593735,
    "input_throughput": 4268.240731693707,
    "output_throughput": 3703.9958132393567,
    "total_throughput": 7972.236544933063,
    "itl": 117.78893171002878,
    "ttft": 2158163.621919646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.543896462065206,
    "arrivals": 512803,
    "finished_requests": 62162,
    "scheduler_time": 112.68759247710145
}
#Debug simulation 
Total elapsed time: 4.689114143024199. Arrivals time: 0.22251421585679054 Scheduler time: 4.309700320358388 Scheduler overhead time: 0.044323309673927724 Adapter cache time: 0.04553779074922204 Engine time: 0.04604840849060565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_256_slots_128_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_256_slots_128_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342638423 . Total output tokens: 301905645
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.696943568997085,
    "estimated_duration": 3600.054752104229,
    "input_throughput": 4269.182848126591,
    "output_throughput": 3704.962262644453,
    "total_throughput": 7974.145110771044,
    "itl": 117.75701661535957,
    "ttft": 2158106.9275669428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.828962660809117,
    "arrivals": 512803,
    "finished_requests": 62176,
    "scheduler_time": 112.71165551655525
}
#Debug simulation 
Total elapsed time: 4.697048848960549. Arrivals time: 0.22679651016369462 Scheduler time: 4.313605225994252 Scheduler overhead time: 0.044512801454402506 Adapter cache time: 0.04530173365492374 Engine time: 0.04586572281550616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.879783596028574,
    "estimated_duration": 3600.0936423864637,
    "input_throughput": 4433.584119056251,
    "output_throughput": 3878.5868888521168,
    "total_throughput": 8312.171007908368,
    "itl": 133.57246192336868,
    "ttft": 2132640.5488328114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.305185744129322,
    "arrivals": 511802,
    "finished_requests": 64845,
    "scheduler_time": 108.3028922496264
}
#Debug simulation 
Total elapsed time: 4.8798797050258145. Arrivals time: 0.2278258118312806 Scheduler time: 4.513474704232067 Scheduler overhead time: 0.040143234422430396 Adapter cache time: 0.038208449026569724 Engine time: 0.041308823274448514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.702119822963141,
    "estimated_duration": 3600.0361345579095,
    "input_throughput": 4247.4812553173915,
    "output_throughput": 3715.917424157403,
    "total_throughput": 7963.398679474794,
    "itl": 116.7308801333551,
    "ttft": 2160582.0264804927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.800151216969805,
    "arrivals": 511802,
    "finished_requests": 62124,
    "scheduler_time": 113.3316252114689
}
#Debug simulation 
Total elapsed time: 4.702221257030033. Arrivals time: 0.22104634589049965 Scheduler time: 4.327233530813828 Scheduler overhead time: 0.04454289434943348 Adapter cache time: 0.04214633349329233 Engine time: 0.046227268292568624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.70198434300255,
    "estimated_duration": 3600.0819351895784,
    "input_throughput": 4248.739132987131,
    "output_throughput": 3717.085399973076,
    "total_throughput": 7965.824532960207,
    "itl": 116.78264322643167,
    "ttft": 2160533.407717244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.314547729431647,
    "arrivals": 511802,
    "finished_requests": 62142,
    "scheduler_time": 113.32263000562723
}
#Debug simulation 
Total elapsed time: 4.702074234955944. Arrivals time: 0.22429196815937757 Scheduler time: 4.323822361300699 Scheduler overhead time: 0.04458115668967366 Adapter cache time: 0.04221511958166957 Engine time: 0.04600719071459025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 341997436 . Total output tokens: 301364991
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.699630943010561,
    "estimated_duration": 3600.012175696446,
    "input_throughput": 4249.782848870575,
    "output_throughput": 3717.8071480857557,
    "total_throughput": 7967.589996956331,
    "itl": 116.7629159236081,
    "ttft": 2160495.0728950957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.699008654328024,
    "arrivals": 511802,
    "finished_requests": 62155,
    "scheduler_time": 113.33802823169773
}
#Debug simulation 
Total elapsed time: 4.699725923012011. Arrivals time: 0.22085630160290748 Scheduler time: 4.324986606021412 Scheduler overhead time: 0.04460174520500004 Adapter cache time: 0.04227136913686991 Engine time: 0.04601084114983678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.96456974290777,
    "estimated_duration": 3600.047861544273,
    "input_throughput": 4573.992800455854,
    "output_throughput": 3983.828146620218,
    "total_throughput": 8557.820947076072,
    "itl": 131.6023218609202,
    "ttft": 2112889.915297609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1173,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.756355794477459,
    "arrivals": 507065,
    "finished_requests": 66960,
    "scheduler_time": 110.5496220869401
}
#Debug simulation 
Total elapsed time: 4.964678044896573. Arrivals time: 0.22395593079272658 Scheduler time: 4.605404483969323 Scheduler overhead time: 0.04083656950388104 Adapter cache time: 0.03296977456193417 Engine time: 0.04227412142790854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.785116276005283,
    "estimated_duration": 3600.0025224260944,
    "input_throughput": 4367.864161773739,
    "output_throughput": 3804.4476121005746,
    "total_throughput": 8172.311773874314,
    "itl": 115.4234119983513,
    "ttft": 2141097.8788119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.201422436479477,
    "arrivals": 507065,
    "finished_requests": 63919,
    "scheduler_time": 115.25285780402584
}
#Debug simulation 
Total elapsed time: 4.785204415093176. Arrivals time: 0.21660519135184586 Scheduler time: 4.420437078690156 Scheduler overhead time: 0.04459878441412002 Adapter cache time: 0.03623941354453564 Engine time: 0.04613838589284569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.78360479301773,
    "estimated_duration": 3600.027383127884,
    "input_throughput": 4368.469827120019,
    "output_throughput": 3804.954946786694,
    "total_throughput": 8173.424773906712,
    "itl": 115.40065568149187,
    "ttft": 2140953.048775105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.726650863606473,
    "arrivals": 507065,
    "finished_requests": 63928,
    "scheduler_time": 115.26986093587718
}
#Debug simulation 
Total elapsed time: 4.783688929048367. Arrivals time: 0.22216180129908025 Scheduler time: 4.4126323780510575 Scheduler overhead time: 0.04506358318030834 Adapter cache time: 0.0360554939834401 Engine time: 0.046569488709792495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338792321 . Total output tokens: 298551425
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.761163981049322,
    "estimated_duration": 3600.031309837947,
    "input_throughput": 4369.288943964228,
    "output_throughput": 3805.791900353428,
    "total_throughput": 8175.080844317656,
    "itl": 115.38676055161874,
    "ttft": 2140974.468440107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.175527137201243,
    "arrivals": 507065,
    "finished_requests": 63942,
    "scheduler_time": 115.28470117321655
}
#Debug simulation 
Total elapsed time: 4.761248292052187. Arrivals time: 0.21797953499481082 Scheduler time: 4.394429132109508 Scheduler overhead time: 0.044938103295862675 Adapter cache time: 0.03636815573554486 Engine time: 0.046394179691560566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_256_slots_128_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_256_slots_128_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.045628643012606,
    "estimated_duration": 3600.090632708079,
    "input_throughput": 4626.977679022981,
    "output_throughput": 4002.0211905504752,
    "total_throughput": 8628.998869573456,
    "itl": 129.19223583096306,
    "ttft": 2111062.582896378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 958,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.334687852608177,
    "arrivals": 505172,
    "finished_requests": 67089,
    "scheduler_time": 111.80592329055494
}
#Debug simulation 
Total elapsed time: 5.045737746055238. Arrivals time: 0.286587881622836 Scheduler time: 4.626298982067965 Scheduler overhead time: 0.04099408502224833 Adapter cache time: 0.03006052505224943 Engine time: 0.04235832754056901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_256_slots_128_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_256_slots_128_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.869360707933083,
    "estimated_duration": 3600.0508391076123,
    "input_throughput": 4411.8485293216245,
    "output_throughput": 3816.001110530248,
    "total_throughput": 8227.849639851873,
    "itl": 113.38409546057665,
    "ttft": 2139769.711612264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 923,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.75166781062727,
    "arrivals": 505172,
    "finished_requests": 63951,
    "scheduler_time": 116.50638054038888
}
#Debug simulation 
Total elapsed time: 4.869452929007821. Arrivals time: 0.28483790473546833 Scheduler time: 4.436313807498664 Scheduler overhead time: 0.04556047392543405 Adapter cache time: 0.03418746578972787 Engine time: 0.0470832894789055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_256_slots_128_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_256_slots_128_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.8189266780391335,
    "estimated_duration": 3600.012104738838,
    "input_throughput": 4412.242108600441,
    "output_throughput": 3816.204112734962,
    "total_throughput": 8228.446221335402,
    "itl": 113.37053898968433,
    "ttft": 2139664.6604828127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 923,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.339366181553332,
    "arrivals": 505172,
    "finished_requests": 63955,
    "scheduler_time": 116.51740215184354
}
#Debug simulation 
Total elapsed time: 4.819015022017993. Arrivals time: 0.2649107879260555 Scheduler time: 4.4056891510263085 Scheduler overhead time: 0.04567686258815229 Adapter cache time: 0.03399315616115928 Engine time: 0.04724254214670509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_256_slots_128_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_256_slots_128_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337457494 . Total output tokens: 297380411
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.788520387955941,
    "estimated_duration": 3600.0634683082135,
    "input_throughput": 4413.036920003501,
    "output_throughput": 3816.7960428923225,
    "total_throughput": 8229.832962895824,
    "itl": 113.35517417597822,
    "ttft": 2139514.3943794044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 923,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.892359028146573,
    "arrivals": 505172,
    "finished_requests": 63966,
    "scheduler_time": 116.53276653560974
}
#Debug simulation 
Total elapsed time: 4.788606810034253. Arrivals time: 0.2521944874897599 Scheduler time: 4.389265400939621 Scheduler overhead time: 0.045402710093185306 Adapter cache time: 0.03364578203763813 Engine time: 0.046695748111233115 
