INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.095934192184359,
    "estimated_duration": 3600.118983711133,
    "input_throughput": 4920.03099901468,
    "output_throughput": 4272.938219431448,
    "total_throughput": 9192.969218446127,
    "itl": 111.12562426011841,
    "ttft": 744607.5096365723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1852,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.707318341937066,
    "arrivals": 83337,
    "finished_requests": 71020,
    "scheduler_time": 68.16650717917705
}
#Debug simulation 
Total elapsed time: 5.096054856199771. Arrivals time: 0.19778083078563213 Scheduler time: 4.733996863942593 Scheduler overhead time: 0.046931213699281216 Adapter cache time: 0.047058182302862406 Engine time: 0.048157356679439545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.8125951061956584,
    "estimated_duration": 3600.0534446932083,
    "input_throughput": 4522.41119475587,
    "output_throughput": 3933.778544559038,
    "total_throughput": 8456.189739314908,
    "itl": 86.44541702872696,
    "ttft": 1072204.6141063077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1729,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.856075169928166,
    "arrivals": 83337,
    "finished_requests": 65323,
    "scheduler_time": 71.98902788008905
}
#Debug simulation 
Total elapsed time: 4.812704701907933. Arrivals time: 0.1960655958391726 Scheduler time: 4.419664706103504 Scheduler overhead time: 0.05781004251912236 Adapter cache time: 0.052698150277137756 Engine time: 0.05927526718005538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.129661360755563,
    "estimated_duration": 3600.0194036664197,
    "input_throughput": 4921.331252258345,
    "output_throughput": 4274.357517164605,
    "total_throughput": 9195.68876942295,
    "itl": 111.0944844528183,
    "ttft": 743477.5807053192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.816637660996525,
    "arrivals": 83337,
    "finished_requests": 71039,
    "scheduler_time": 68.16230246015134
}
#Debug simulation 
Total elapsed time: 5.129754800815135. Arrivals time: 0.19388861069455743 Scheduler time: 4.771758703980595 Scheduler overhead time: 0.04730028519406915 Adapter cache time: 0.04659522930160165 Engine time: 0.048131275456398726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55526545 . Total output tokens: 49167836
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.815261714160442,
    "estimated_duration": 3600.0357602235445,
    "input_throughput": 4522.563964472677,
    "output_throughput": 3933.8548123534774,
    "total_throughput": 8456.418776826154,
    "itl": 86.4369634875518,
    "ttft": 1072079.175436822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1730,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.743816163688697,
    "arrivals": 83337,
    "finished_requests": 65325,
    "scheduler_time": 71.9828971112775
}
#Debug simulation 
Total elapsed time: 4.815362143330276. Arrivals time: 0.20261097233742476 Scheduler time: 4.4166305754333735 Scheduler overhead time: 0.057611987460404634 Adapter cache time: 0.05215970706194639 Engine time: 0.059197657741606236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.421205346938223,
    "estimated_duration": 3600.0521534609716,
    "input_throughput": 5210.535347930026,
    "output_throughput": 4528.30828695847,
    "total_throughput": 9738.843634888495,
    "itl": 119.28487540225085,
    "ttft": 383480.85684742033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1953,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.914034839398576,
    "arrivals": 81595,
    "finished_requests": 75217,
    "scheduler_time": 65.62691217814104
}
#Debug simulation 
Total elapsed time: 5.421328271739185. Arrivals time: 0.1900926986709237 Scheduler time: 5.075267252046615 Scheduler overhead time: 0.04534660745412111 Adapter cache time: 0.04278661869466305 Engine time: 0.046738095581531525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.312309617176652,
    "estimated_duration": 3600.054570395757,
    "input_throughput": 5078.853845815456,
    "output_throughput": 4418.35580238202,
    "total_throughput": 9497.209648197475,
    "itl": 107.63186292247408,
    "ttft": 501187.5472956893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.908299082456889,
    "arrivals": 81595,
    "finished_requests": 73339,
    "scheduler_time": 65.83070783889731
}
#Debug simulation 
Total elapsed time: 5.3124479302205145. Arrivals time: 0.19203517120331526 Scheduler time: 4.953920687083155 Scheduler overhead time: 0.04896116582676768 Adapter cache time: 0.04444144293665886 Engine time: 0.05009634839370847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.961737154982984,
    "estimated_duration": 3599.968463408816,
    "input_throughput": 4659.5088736184625,
    "output_throughput": 4056.775815800119,
    "total_throughput": 8716.28468941858,
    "itl": 84.10205431936875,
    "ttft": 865042.8258832837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1748,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.074604356465656,
    "arrivals": 81595,
    "finished_requests": 67399,
    "scheduler_time": 68.79103049161066
}
#Debug simulation 
Total elapsed time: 4.961863768287003. Arrivals time: 0.1984123275615275 Scheduler time: 4.566775269340724 Scheduler overhead time: 0.059602123219519854 Adapter cache time: 0.0476813237182796 Engine time: 0.061517106369137764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.439612729940563,
    "estimated_duration": 3600.0382146265297,
    "input_throughput": 5080.782455498885,
    "output_throughput": 4419.943081534961,
    "total_throughput": 9500.725537033844,
    "itl": 107.60288332205609,
    "ttft": 499709.11355418526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.089248708202692,
    "arrivals": 81595,
    "finished_requests": 73367,
    "scheduler_time": 65.82798742587845
}
#Debug simulation 
Total elapsed time: 5.4397077187895775. Arrivals time: 0.19792603328824043 Scheduler time: 5.0711260456591845 Scheduler overhead time: 0.04973644018173218 Adapter cache time: 0.045566795859485865 Engine time: 0.05214543268084526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.008981131017208,
    "estimated_duration": 3600.0205772672543,
    "input_throughput": 4659.0633692244155,
    "output_throughput": 4056.4498692630377,
    "total_throughput": 8715.513238487454,
    "itl": 84.06037516519577,
    "ttft": 865245.975690784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.94215759093853,
    "arrivals": 81595,
    "finished_requests": 67392,
    "scheduler_time": 68.79436897198445
}
#Debug simulation 
Total elapsed time: 5.009097499772906. Arrivals time: 0.20439844857901335 Scheduler time: 4.608048971742392 Scheduler overhead time: 0.059309654869139194 Adapter cache time: 0.04766613012179732 Engine time: 0.06159799499437213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.317177980672568,
    "estimated_duration": 3600.010925205923,
    "input_throughput": 5082.527908982218,
    "output_throughput": 4420.9832499576705,
    "total_throughput": 9503.51115893989,
    "itl": 107.56988901265986,
    "ttft": 498611.0861501699,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.180521154609094,
    "arrivals": 81595,
    "finished_requests": 73386,
    "scheduler_time": 65.82987932568633
}
#Debug simulation 
Total elapsed time: 5.317272389773279. Arrivals time: 0.19384634960442781 Scheduler time: 4.957145506050438 Scheduler overhead time: 0.04894022736698389 Adapter cache time: 0.04446510644629598 Engine time: 0.04996509198099375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54309658 . Total output tokens: 48090630
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.955052514094859,
    "estimated_duration": 3599.9902754192085,
    "input_throughput": 4658.687862162916,
    "output_throughput": 4056.2445681327813,
    "total_throughput": 8714.932430295697,
    "itl": 84.04121594353067,
    "ttft": 865466.4630348873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1747,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.834039431717047,
    "arrivals": 81595,
    "finished_requests": 67389,
    "scheduler_time": 68.79401636564675
}
#Debug simulation 
Total elapsed time: 4.955205969046801. Arrivals time: 0.20253954688087106 Scheduler time: 4.556385939475149 Scheduler overhead time: 0.05971787637099624 Adapter cache time: 0.04750943370163441 Engine time: 0.06101616704836488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.490995260886848,
    "estimated_duration": 3600.099732330881,
    "input_throughput": 5273.188636835021,
    "output_throughput": 4621.410582208521,
    "total_throughput": 9894.59921904354,
    "itl": 116.39216248905501,
    "ttft": 272209.44403245824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.720241276966654,
    "arrivals": 81010,
    "finished_requests": 76528,
    "scheduler_time": 65.5041217727964
}
#Debug simulation 
Total elapsed time: 5.4910916378721595. Arrivals time: 0.1901378259062767 Scheduler time: 5.14951834641397 Scheduler overhead time: 0.045850217808037996 Adapter cache time: 0.037452812772244215 Engine time: 0.04668109305202961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.439848868176341,
    "estimated_duration": 3600.1123408319145,
    "input_throughput": 5142.86201294529,
    "output_throughput": 4509.35067105395,
    "total_throughput": 9652.21268399924,
    "itl": 105.36975069388362,
    "ttft": 395064.45730153914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.496395126045583,
    "arrivals": 81010,
    "finished_requests": 74631,
    "scheduler_time": 65.65322115553595
}
#Debug simulation 
Total elapsed time: 5.439947163220495. Arrivals time: 0.1955260019749403 Scheduler time: 5.081972246989608 Scheduler overhead time: 0.0498191243968904 Adapter cache time: 0.03825608780607581 Engine time: 0.05092154769226909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.067727678921074,
    "estimated_duration": 3600.064897136441,
    "input_throughput": 4703.3166022835385,
    "output_throughput": 4122.660958641463,
    "total_throughput": 8825.977560925001,
    "itl": 82.72284150051527,
    "ttft": 793715.1009947628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.976100280797025,
    "arrivals": 81010,
    "finished_requests": 68188,
    "scheduler_time": 68.41164083451346
}
#Debug simulation 
Total elapsed time: 5.067824188154191. Arrivals time: 0.20327297318726778 Scheduler time: 4.670487968251109 Scheduler overhead time: 0.060466290917247534 Adapter cache time: 0.04168635420501232 Engine time: 0.06341893877834082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.425143296830356,
    "estimated_duration": 3600.030349642592,
    "input_throughput": 5143.296084111696,
    "output_throughput": 4509.637537253479,
    "total_throughput": 9652.933621365175,
    "itl": 105.30880657423317,
    "ttft": 394554.5828959138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.83338268472818,
    "arrivals": 81010,
    "finished_requests": 74637,
    "scheduler_time": 65.64865116701513
}
#Debug simulation 
Total elapsed time: 5.4252392100170255. Arrivals time: 0.19777669990435243 Scheduler time: 5.0645411550067365 Scheduler overhead time: 0.05024593509733677 Adapter cache time: 0.038224039133638144 Engine time: 0.0510360999032855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.09507093578577,
    "estimated_duration": 3600.078057749655,
    "input_throughput": 4703.731621470735,
    "output_throughput": 4122.772273798324,
    "total_throughput": 8826.50389526906,
    "itl": 82.73667891592184,
    "ttft": 793491.8205684201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.904950861711907,
    "arrivals": 81010,
    "finished_requests": 68192,
    "scheduler_time": 68.4099373825138
}
#Debug simulation 
Total elapsed time: 5.095170482993126. Arrivals time: 0.20195165649056435 Scheduler time: 4.699298809282482 Scheduler overhead time: 0.06061535235494375 Adapter cache time: 0.041715606581419706 Engine time: 0.06303906859830022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.447890875861049,
    "estimated_duration": 3600.0610132627935,
    "input_throughput": 5142.235626507326,
    "output_throughput": 4509.155800470047,
    "total_throughput": 9651.391426977372,
    "itl": 105.20292641098627,
    "ttft": 395392.9309952103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.148158707837686,
    "arrivals": 81010,
    "finished_requests": 74622,
    "scheduler_time": 65.65239479408775
}
#Debug simulation 
Total elapsed time: 5.448012858629227. Arrivals time: 0.1983908754773438 Scheduler time: 5.085236022248864 Scheduler overhead time: 0.05017743958160281 Adapter cache time: 0.03891864558681846 Engine time: 0.05172944813966751 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53919618 . Total output tokens: 47750482
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.037961741909385,
    "estimated_duration": 3600.032542110091,
    "input_throughput": 4702.303882530381,
    "output_throughput": 4121.46774409526,
    "total_throughput": 8823.771626625641,
    "itl": 82.6666669066941,
    "ttft": 794377.5854274593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.797460040077489,
    "arrivals": 81010,
    "finished_requests": 68171,
    "scheduler_time": 68.41216852368811
}
#Debug simulation 
Total elapsed time: 5.038081144914031. Arrivals time: 0.1982688340358436 Scheduler time: 4.64812252111733 Scheduler overhead time: 0.05993577279150486 Adapter cache time: 0.04129043314605951 Engine time: 0.06191013753414154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.55997951887548,
    "estimated_duration": 3600.019968651992,
    "input_throughput": 5406.625288050326,
    "output_throughput": 4784.422350426417,
    "total_throughput": 10191.047638476743,
    "itl": 109.04685513699397,
    "ttft": 27195.67757877694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1090,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.2075258448255966,
    "arrivals": 79794,
    "finished_requests": 79236,
    "scheduler_time": 64.30645082025814
}
#Debug simulation 
Total elapsed time: 5.560106506105512. Arrivals time: 0.1866493532434106 Scheduler time: 5.230822489131242 Scheduler overhead time: 0.04677287070080638 Adapter cache time: 0.026917810551822186 Engine time: 0.04717343859374523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.603710005059838,
    "estimated_duration": 3600.101442925448,
    "input_throughput": 5289.477061103565,
    "output_throughput": 4686.867652898362,
    "total_throughput": 9976.344714001927,
    "itl": 101.85572352449779,
    "ttft": 142349.5463592227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1063,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.767580187958676,
    "arrivals": 79794,
    "finished_requests": 77595,
    "scheduler_time": 64.50623308952844
}
#Debug simulation 
Total elapsed time: 5.603840949945152. Arrivals time: 0.19115589652210474 Scheduler time: 5.255339305382222 Scheduler overhead time: 0.05122747365385294 Adapter cache time: 0.029649547301232815 Engine time: 0.05215484602376819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.147214202210307,
    "estimated_duration": 3600.0380187206483,
    "input_throughput": 4790.608851994533,
    "output_throughput": 4244.353787527505,
    "total_throughput": 9034.962639522038,
    "itl": 80.26650501866332,
    "ttft": 616474.8622231269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 969,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.268644214444812,
    "arrivals": 79794,
    "finished_requests": 70189,
    "scheduler_time": 66.74866995903578
}
#Debug simulation 
Total elapsed time: 5.147309126332402. Arrivals time: 0.19691230822354555 Scheduler time: 4.763621747493744 Scheduler overhead time: 0.061917913146317005 Adapter cache time: 0.03183850459754467 Engine time: 0.06389516359195113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.5919465478509665,
    "estimated_duration": 3600.080795672039,
    "input_throughput": 5290.145716422682,
    "output_throughput": 4687.25758052049,
    "total_throughput": 9977.403296943172,
    "itl": 101.83870409898624,
    "ttft": 141513.7480075102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1063,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.294196836058971,
    "arrivals": 79794,
    "finished_requests": 77604,
    "scheduler_time": 64.50410774862108
}
#Debug simulation 
Total elapsed time: 5.592063958756626. Arrivals time: 0.19464934710413218 Scheduler time: 5.239446218125522 Scheduler overhead time: 0.05125990230590105 Adapter cache time: 0.030007278081029654 Engine time: 0.052491309586912394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.143581992015243,
    "estimated_duration": 3600.02875883394,
    "input_throughput": 4793.314763849079,
    "output_throughput": 4246.820796218319,
    "total_throughput": 9040.135560067398,
    "itl": 80.34837843829928,
    "ttft": 614401.5533724199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 971,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.2184669956937615,
    "arrivals": 79794,
    "finished_requests": 70222,
    "scheduler_time": 66.73456501671275
}
#Debug simulation 
Total elapsed time: 5.1436785706318915. Arrivals time: 0.1993628623895347 Scheduler time: 4.758228804450482 Scheduler overhead time: 0.061785328201949596 Adapter cache time: 0.03181693144142628 Engine time: 0.06351367896422744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.608970034867525,
    "estimated_duration": 3600.0888770541337,
    "input_throughput": 5290.711326989718,
    "output_throughput": 4687.778712232674,
    "total_throughput": 9978.490039222392,
    "itl": 101.8244456444574,
    "ttft": 141166.74968131277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1063,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.786107959826443,
    "arrivals": 79794,
    "finished_requests": 77612,
    "scheduler_time": 64.50073863409568
}
#Debug simulation 
Total elapsed time: 5.6090714312158525. Arrivals time: 0.19333202671259642 Scheduler time: 5.257210252340883 Scheduler overhead time: 0.051742917858064175 Adapter cache time: 0.029876374639570713 Engine time: 0.05278899800032377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53116206 . Total output tokens: 47026003
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.170689474791288,
    "estimated_duration": 3600.032807918841,
    "input_throughput": 4800.074588761795,
    "output_throughput": 4253.845400051487,
    "total_throughput": 9053.91998881328,
    "itl": 80.57659734840517,
    "ttft": 608212.8975188468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 973,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.165442005451787,
    "arrivals": 79794,
    "finished_requests": 70337,
    "scheduler_time": 66.70473919109551
}
#Debug simulation 
Total elapsed time: 5.1707887491211295. Arrivals time: 0.19903522869572043 Scheduler time: 4.785480797290802 Scheduler overhead time: 0.061852516140788794 Adapter cache time: 0.03136297781020403 Engine time: 0.06384456530213356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_160_slots_96_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_160_slots_96_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.7619269508868456,
    "estimated_duration": 3599.8082412673066,
    "input_throughput": 2310.21083419495,
    "output_throughput": 2043.6002439424751,
    "total_throughput": 4353.811078137425,
    "itl": 50.050099891139844,
    "ttft": 14301.837719777748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10110,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.85145531301795,
    "arrivals": 33938,
    "finished_requests": 33804,
    "scheduler_time": 16.817521718162762
}
#Debug simulation 
Total elapsed time: 2.7620226317085326. Arrivals time: 0.09349789563566446 Scheduler time: 2.3197260331362486 Scheduler overhead time: 0.07455811789259315 Adapter cache time: 0.16525244154036045 Engine time: 0.07355944579467177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_160_slots_96_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_160_slots_96_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.717002246994525,
    "estimated_duration": 3599.845871784848,
    "input_throughput": 2310.1866847084393,
    "output_throughput": 2043.5788814348662,
    "total_throughput": 4353.7655661433055,
    "itl": 50.488327957782715,
    "ttft": 14303.670891139911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 73.547463168442,
    "arrivals": 33938,
    "finished_requests": 33804,
    "scheduler_time": 16.931273939280768
}
#Debug simulation 
Total elapsed time: 2.717120090033859. Arrivals time: 0.09189922269433737 Scheduler time: 2.285121933091432 Scheduler overhead time: 0.07365959882736206 Adapter cache time: 0.16031754203140736 Engine time: 0.07110852655023336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_160_slots_96_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_160_slots_96_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.731765331700444,
    "estimated_duration": 3599.8233607865927,
    "input_throughput": 2310.2011311418382,
    "output_throughput": 2043.5916606731853,
    "total_throughput": 4353.7927918150235,
    "itl": 50.55567597612209,
    "ttft": 14303.729621702456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 75.46859660815447,
    "arrivals": 33938,
    "finished_requests": 33804,
    "scheduler_time": 16.9479963922132
}
#Debug simulation 
Total elapsed time: 2.731858311686665. Arrivals time: 0.09412437444552779 Scheduler time: 2.2957898820750415 Scheduler overhead time: 0.0732319918461144 Adapter cache time: 0.1610721475444734 Engine time: 0.07283841026946902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_160_slots_96_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_160_slots_96_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.7563391090370715,
    "estimated_duration": 3599.8572334435516,
    "input_throughput": 2310.2499517861534,
    "output_throughput": 2043.5835431625756,
    "total_throughput": 4353.833494948729,
    "itl": 50.12814210428215,
    "ttft": 14196.030053916791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 69.184766011779,
    "arrivals": 33938,
    "finished_requests": 33805,
    "scheduler_time": 16.838437180153342
}
#Debug simulation 
Total elapsed time: 2.7564309183508158. Arrivals time: 0.0934042576700449 Scheduler time: 2.317106838338077 Scheduler overhead time: 0.0745885893702507 Adapter cache time: 0.16258179768919945 Engine time: 0.0735183828510344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.7396792201325297,
    "estimated_duration": 3599.8213289299283,
    "input_throughput": 2310.2024350947668,
    "output_throughput": 2043.592814143026,
    "total_throughput": 4353.795249237793,
    "itl": 50.530066534974,
    "ttft": 14303.670554333077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 74.77775894144521,
    "arrivals": 33938,
    "finished_requests": 33804,
    "scheduler_time": 16.9419824190294
}
#Debug simulation 
Total elapsed time: 2.7397753801196814. Arrivals time: 0.09408463258296251 Scheduler time: 2.3041279898025095 Scheduler overhead time: 0.07371829869225621 Adapter cache time: 0.16109773889183998 Engine time: 0.07179997116327286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.764372111298144,
    "estimated_duration": 3599.8352636123145,
    "input_throughput": 2310.2393279115468,
    "output_throughput": 2043.6660183770841,
    "total_throughput": 4353.905346288631,
    "itl": 49.96834330313543,
    "ttft": 14195.42618281227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10110,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.54144070917499,
    "arrivals": 33938,
    "finished_requests": 33805,
    "scheduler_time": 16.797384545000824
}
#Debug simulation 
Total elapsed time: 2.76447021542117. Arrivals time: 0.09445824241265655 Scheduler time: 2.3244419670663774 Scheduler overhead time: 0.07475056033581495 Adapter cache time: 0.1629710211418569 Engine time: 0.07261428982019424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22613893 . Total output tokens: 19911549
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.764709690120071,
    "estimated_duration": 3599.8437246259773,
    "input_throughput": 2310.1880626398756,
    "output_throughput": 2043.5801003457018,
    "total_throughput": 4353.768162985577,
    "itl": 50.51074211572969,
    "ttft": 14303.559838304735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 74.08821249499857,
    "arrivals": 33938,
    "finished_requests": 33804,
    "scheduler_time": 16.935926870490068
}
#Debug simulation 
Total elapsed time: 2.764801286160946. Arrivals time: 0.093876913189888 Scheduler time: 2.326479989103973 Scheduler overhead time: 0.07414342183619738 Adapter cache time: 0.16167863784357905 Engine time: 0.07375252526253462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.5990767497569323,
    "estimated_duration": 3599.7417340459992,
    "input_throughput": 2154.1645409333996,
    "output_throughput": 1889.8641909939497,
    "total_throughput": 4044.0287319273493,
    "itl": 43.251210084417096,
    "ttft": 10918.520673614496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.092050889373404,
    "arrivals": 31534,
    "finished_requests": 31439,
    "scheduler_time": 12.536364123988362
}
#Debug simulation 
Total elapsed time: 2.599198516923934. Arrivals time: 0.08836935367435217 Scheduler time: 2.150428846012801 Scheduler overhead time: 0.08288718527182937 Adapter cache time: 0.15540048014372587 Engine time: 0.08257294399663806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.59203450800851,
    "estimated_duration": 3599.775497684488,
    "input_throughput": 2154.144336219841,
    "output_throughput": 1889.8464652520586,
    "total_throughput": 4043.9908014719,
    "itl": 43.38333791104405,
    "ttft": 10918.77112158103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.18422588905612,
    "arrivals": 31534,
    "finished_requests": 31439,
    "scheduler_time": 12.582257307178343
}
#Debug simulation 
Total elapsed time: 2.59214751701802. Arrivals time: 0.08771767886355519 Scheduler time: 2.147175943478942 Scheduler overhead time: 0.08237473526969552 Adapter cache time: 0.15423720283433795 Engine time: 0.08101368928328156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.574431277345866,
    "estimated_duration": 3599.7681650905456,
    "input_throughput": 2154.1487241317805,
    "output_throughput": 1889.8503147990593,
    "total_throughput": 4043.99903893084,
    "itl": 43.42336105618203,
    "ttft": 10919.020532508537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.626666350473315,
    "arrivals": 31534,
    "finished_requests": 31439,
    "scheduler_time": 12.59532850018161
}
#Debug simulation 
Total elapsed time: 2.5745296250097454. Arrivals time: 0.08726471709087491 Scheduler time: 2.1271000667475164 Scheduler overhead time: 0.08443852653726935 Adapter cache time: 0.15373577317222953 Engine time: 0.08254914125427604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.546865648124367,
    "estimated_duration": 3599.761182184661,
    "input_throughput": 2154.1529028028203,
    "output_throughput": 1889.8539807774998,
    "total_throughput": 4044.0068835803204,
    "itl": 43.296533443896564,
    "ttft": 10918.478670588767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.824731133642445,
    "arrivals": 31534,
    "finished_requests": 31439,
    "scheduler_time": 12.552042299962157
}
#Debug simulation 
Total elapsed time: 2.546956028789282. Arrivals time: 0.08454546332359314 Scheduler time: 2.1065161447040737 Scheduler overhead time: 0.08269918849691749 Adapter cache time: 0.15386562794446945 Engine time: 0.08013343997299671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.584842794109136,
    "estimated_duration": 3599.7412117944696,
    "input_throughput": 2154.1648534602346,
    "output_throughput": 1889.8644651760108,
    "total_throughput": 4044.029318636245,
    "itl": 43.40881488307432,
    "ttft": 10918.978492375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.10949775349508,
    "arrivals": 31534,
    "finished_requests": 31439,
    "scheduler_time": 12.590411348077444
}
#Debug simulation 
Total elapsed time: 2.5849302508868277. Arrivals time: 0.08591580064967275 Scheduler time: 2.1404109857976437 Scheduler overhead time: 0.08259863033890724 Adapter cache time: 0.15489153983071446 Engine time: 0.08196511305868626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.5503465132787824,
    "estimated_duration": 3599.7541755766415,
    "input_throughput": 2154.157095673852,
    "output_throughput": 1889.857659213696,
    "total_throughput": 4044.0147548875484,
    "itl": 43.20658974583016,
    "ttft": 10918.181034420879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.46217660547743,
    "arrivals": 31534,
    "finished_requests": 31439,
    "scheduler_time": 12.521833839512196
}
#Debug simulation 
Total elapsed time: 2.550436245277524. Arrivals time: 0.08506380068138242 Scheduler time: 2.1048428933136165 Scheduler overhead time: 0.08301412500441074 Adapter cache time: 0.15609107306227088 Engine time: 0.08187508350238204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20992372 . Total output tokens: 18489589
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.5261524082161486,
    "estimated_duration": 3599.7635855865838,
    "input_throughput": 2154.151464570807,
    "output_throughput": 1889.852719006113,
    "total_throughput": 4044.0041835769202,
    "itl": 43.394739063976346,
    "ttft": 10918.831185570161,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.61220791592895,
    "arrivals": 31534,
    "finished_requests": 31439,
    "scheduler_time": 12.586087306215584
}
#Debug simulation 
Total elapsed time: 2.5262366882525384. Arrivals time: 0.08392149861901999 Scheduler time: 2.0870328904129565 Scheduler overhead time: 0.08231846755370498 Adapter cache time: 0.15384419821202755 Engine time: 0.08006130810827017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.4747653831727803,
    "estimated_duration": 3600.002792923347,
    "input_throughput": 2067.4170071841036,
    "output_throughput": 1810.4666509737283,
    "total_throughput": 3877.8836581578316,
    "itl": 40.1420759572179,
    "ttft": 9080.109371923067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5085,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.62409992746259,
    "arrivals": 30357,
    "finished_requests": 30281,
    "scheduler_time": 10.21681668789014
}
#Debug simulation 
Total elapsed time: 2.4748492720536888. Arrivals time: 0.08221332402899861 Scheduler time: 2.0317896734923124 Scheduler overhead time: 0.08796344930306077 Adapter cache time: 0.14560994924977422 Engine time: 0.08541843155398965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.501443261746317,
    "estimated_duration": 3599.979932609216,
    "input_throughput": 2067.43013553568,
    "output_throughput": 1810.4781476590263,
    "total_throughput": 3877.908283194706,
    "itl": 40.223052801386984,
    "ttft": 9080.30186743085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5081,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.234393982806914,
    "arrivals": 30357,
    "finished_requests": 30281,
    "scheduler_time": 10.248571932983857
}
#Debug simulation 
Total elapsed time: 2.5015327469445765. Arrivals time: 0.08486030623316765 Scheduler time: 2.0510170059278607 Scheduler overhead time: 0.08990533510223031 Adapter cache time: 0.14584632171317935 Engine time: 0.08776638517156243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.4811108433641493,
    "estimated_duration": 3600.000105054068,
    "input_throughput": 2067.418550780353,
    "output_throughput": 1810.4680027230474,
    "total_throughput": 3877.8865535034006,
    "itl": 40.24882356969807,
    "ttft": 9080.473341932931,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5081,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.2594272267774,
    "arrivals": 30357,
    "finished_requests": 30281,
    "scheduler_time": 10.257655445746435
}
#Debug simulation 
Total elapsed time: 2.4811919792555273. Arrivals time: 0.08348354138433933 Scheduler time: 2.029946426395327 Scheduler overhead time: 0.0910066980868578 Adapter cache time: 0.14730107365176082 Engine time: 0.08734586741775274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.4936911650002003,
    "estimated_duration": 3599.9821553924094,
    "input_throughput": 2067.428859015753,
    "output_throughput": 1810.4770297922635,
    "total_throughput": 3877.9058888080162,
    "itl": 40.16912616483434,
    "ttft": 9080.174407194301,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5082,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.82110874726547,
    "arrivals": 30357,
    "finished_requests": 30281,
    "scheduler_time": 10.227152298051516
}
#Debug simulation 
Total elapsed time: 2.493780270218849. Arrivals time: 0.08256346173584461 Scheduler time: 2.047269214875996 Scheduler overhead time: 0.08756000827997923 Adapter cache time: 0.14701754413545132 Engine time: 0.08762497128918767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.4775984501466155,
    "estimated_duration": 3599.9894918629475,
    "input_throughput": 2067.4246457726454,
    "output_throughput": 1810.4733401949968,
    "total_throughput": 3877.8979859676424,
    "itl": 40.24233927501407,
    "ttft": 9080.369095631917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5083,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.909447715501585,
    "arrivals": 30357,
    "finished_requests": 30281,
    "scheduler_time": 10.254466135539952
}
#Debug simulation 
Total elapsed time: 2.4777211248874664. Arrivals time: 0.08302021957933903 Scheduler time: 2.035012973472476 Scheduler overhead time: 0.08760602492839098 Adapter cache time: 0.14561070408672094 Engine time: 0.08460833365097642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.478101468179375,
    "estimated_duration": 3599.9717067165616,
    "input_throughput": 2067.43485958902,
    "output_throughput": 1810.4822845801216,
    "total_throughput": 3877.917144169142,
    "itl": 40.11765001977091,
    "ttft": 9080.074818950781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5081,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.436702299042096,
    "arrivals": 30357,
    "finished_requests": 30281,
    "scheduler_time": 10.2061064534309
}
#Debug simulation 
Total elapsed time: 2.478213371243328. Arrivals time: 0.08273677341639996 Scheduler time: 2.0317096300423145 Scheduler overhead time: 0.08826311584562063 Adapter cache time: 0.1459505665116012 Engine time: 0.0875363745726645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20167235 . Total output tokens: 17778811
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.4995138295926154,
    "estimated_duration": 3599.985830916698,
    "input_throughput": 2067.42674820606,
    "output_throughput": 1810.4751813260168,
    "total_throughput": 3877.901929532077,
    "itl": 40.23198232379954,
    "ttft": 9080.31455963013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5082,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.54828872498161,
    "arrivals": 30357,
    "finished_requests": 30281,
    "scheduler_time": 10.251329407837979
}
#Debug simulation 
Total elapsed time: 2.499614310916513. Arrivals time: 0.08475198224186897 Scheduler time: 2.051571060437709 Scheduler overhead time: 0.08749311789870262 Adapter cache time: 0.1460980004630983 Engine time: 0.08774061594158411 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.470278677996248,
    "estimated_duration": 3600.0188632816953,
    "input_throughput": 2026.0518838923847,
    "output_throughput": 1770.570722562694,
    "total_throughput": 3796.6226064550788,
    "itl": 38.71231490227393,
    "ttft": 6978.505078292286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3919,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.91403099620991,
    "arrivals": 29680,
    "finished_requests": 29623,
    "scheduler_time": 9.016023365276123
}
#Debug simulation 
Total elapsed time: 2.470369587186724. Arrivals time: 0.08222114434465766 Scheduler time: 2.0217689145356417 Scheduler overhead time: 0.09025818668305874 Adapter cache time: 0.14224226959049702 Engine time: 0.0905149350874126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.406980917789042,
    "estimated_duration": 3600.007911301974,
    "input_throughput": 2026.0577697903238,
    "output_throughput": 1770.493886968949,
    "total_throughput": 3796.551656759273,
    "itl": 39.25454095665142,
    "ttft": 6979.718449320062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.04914829909713,
    "arrivals": 29680,
    "finished_requests": 29622,
    "scheduler_time": 9.247756417548763
}
#Debug simulation 
Total elapsed time: 2.407067766878754. Arrivals time: 0.0800065784715116 Scheduler time: 1.9683244414627552 Scheduler overhead time: 0.08890546951442957 Adapter cache time: 0.1400095014832914 Engine time: 0.08717343350872397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.4325259691104293,
    "estimated_duration": 3600.0196431692116,
    "input_throughput": 2026.0514449801763,
    "output_throughput": 1770.5703389964528,
    "total_throughput": 3796.621783976629,
    "itl": 38.785300370875724,
    "ttft": 6978.8477331497725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3919,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.46627697910768,
    "arrivals": 29680,
    "finished_requests": 29623,
    "scheduler_time": 9.047506315625029
}
#Debug simulation 
Total elapsed time: 2.432614377234131. Arrivals time: 0.08084036549553275 Scheduler time: 1.9897974142804742 Scheduler overhead time: 0.09061362920328975 Adapter cache time: 0.14080851431936026 Engine time: 0.08759868098422885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.4613464158028364,
    "estimated_duration": 3600.0263598148,
    "input_throughput": 2026.0476649329935,
    "output_throughput": 1770.567035605792,
    "total_throughput": 3796.614700538785,
    "itl": 38.7322276069401,
    "ttft": 6978.515808529556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3922,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.866024950771433,
    "arrivals": 29680,
    "finished_requests": 29623,
    "scheduler_time": 9.02461520455171
}
#Debug simulation 
Total elapsed time: 2.461507584899664. Arrivals time: 0.08171240799129009 Scheduler time: 2.0149223562330008 Scheduler overhead time: 0.09060169570147991 Adapter cache time: 0.1415891950018704 Engine time: 0.08962559094652534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.4109487389214337,
    "estimated_duration": 3600.0248393875777,
    "input_throughput": 2026.0482428340126,
    "output_throughput": 1770.485561728592,
    "total_throughput": 3796.5338045626045,
    "itl": 39.267278690056834,
    "ttft": 7100.835498459014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.61605928691237,
    "arrivals": 29680,
    "finished_requests": 29622,
    "scheduler_time": 9.252700215337192
}
#Debug simulation 
Total elapsed time: 2.411062528844923. Arrivals time: 0.08023724146187305 Scheduler time: 1.9696864155121148 Scheduler overhead time: 0.08969986392185092 Adapter cache time: 0.1404304038733244 Engine time: 0.08821602957323194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.4338371898047626,
    "estimated_duration": 3600.006938560876,
    "input_throughput": 2026.0585950191946,
    "output_throughput": 1770.5765874296007,
    "total_throughput": 3796.635182448795,
    "itl": 38.69469543859866,
    "ttft": 6857.269246902739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3920,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.02497008703872,
    "arrivals": 29680,
    "finished_requests": 29623,
    "scheduler_time": 9.008167555942023
}
#Debug simulation 
Total elapsed time: 2.433946853969246. Arrivals time: 0.08145881025120616 Scheduler time: 1.986433929298073 Scheduler overhead time: 0.09082855144515634 Adapter cache time: 0.14142011478543282 Engine time: 0.08885225374251604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19776993 . Total output tokens: 17431282
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.4441925892606378,
    "estimated_duration": 3600.0216018261144,
    "input_throughput": 2026.0500648941108,
    "output_throughput": 1770.4871539567673,
    "total_throughput": 3796.537218850878,
    "itl": 39.25770134353013,
    "ttft": 7100.834854045856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.296949572787998,
    "arrivals": 29680,
    "finished_requests": 29622,
    "scheduler_time": 9.249971888125387
}
#Debug simulation 
Total elapsed time: 2.4442696482874453. Arrivals time: 0.08078831434249878 Scheduler time: 2.0016560619696975 Scheduler overhead time: 0.08905257191509008 Adapter cache time: 0.14100902481004596 Engine time: 0.08940549194812775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.271008008159697,
    "estimated_duration": 3599.9564510992855,
    "input_throughput": 1803.4698719806656,
    "output_throughput": 1589.9181219962331,
    "total_throughput": 3393.387993976899,
    "itl": 35.19418135927952,
    "ttft": 9624.398954902543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.070183804953885,
    "arrivals": 26722,
    "finished_requests": 26651,
    "scheduler_time": 4.869019316091445
}
#Debug simulation 
Total elapsed time: 2.2710906020365655. Arrivals time: 0.07462101290002465 Scheduler time: 1.8158257217146456 Scheduler overhead time: 0.0979324709624052 Adapter cache time: 0.1399185466580093 Engine time: 0.09666896099224687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.259018261451274,
    "estimated_duration": 3599.980972030492,
    "input_throughput": 1803.4575878155526,
    "output_throughput": 1589.9072924187446,
    "total_throughput": 3393.3648802342973,
    "itl": 35.25116603493543,
    "ttft": 9624.695292172099,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4848,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.39988516032593,
    "arrivals": 26722,
    "finished_requests": 26651,
    "scheduler_time": 4.896128053761577
}
#Debug simulation 
Total elapsed time: 2.2591112423688173. Arrivals time: 0.0753479078412056 Scheduler time: 1.8050521458499134 Scheduler overhead time: 0.09818885754793882 Adapter cache time: 0.13778030779212713 Engine time: 0.09643926611170173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2445857948623598,
    "estimated_duration": 3599.9574861809433,
    "input_throughput": 1803.4693534360463,
    "output_throughput": 1589.9176648533107,
    "total_throughput": 3393.387018289357,
    "itl": 35.268025638362104,
    "ttft": 9624.668415951868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4848,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.34694361561039,
    "arrivals": 26722,
    "finished_requests": 26651,
    "scheduler_time": 4.903854870914672
}
#Debug simulation 
Total elapsed time: 2.2446714867837727. Arrivals time: 0.07477831793949008 Scheduler time: 1.7924633813090622 Scheduler overhead time: 0.0981704075820744 Adapter cache time: 0.13727265689522028 Engine time: 0.09521822212263942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.2837533759884536,
    "estimated_duration": 3599.980879177419,
    "input_throughput": 1803.4576343315161,
    "output_throughput": 1589.9073334266786,
    "total_throughput": 3393.364967758195,
    "itl": 35.2136880649662,
    "ttft": 9624.519202367164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.220652085348114,
    "arrivals": 26722,
    "finished_requests": 26651,
    "scheduler_time": 4.8782568236716655
}
#Debug simulation 
Total elapsed time: 2.283834747970104. Arrivals time: 0.07550023309886456 Scheduler time: 1.8204954857937992 Scheduler overhead time: 0.10125115979462862 Adapter cache time: 0.1390199870802462 Engine time: 0.10018600476905704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.2703551407903433,
    "estimated_duration": 3599.981925615435,
    "input_throughput": 1803.4571101048207,
    "output_throughput": 1589.9068712745038,
    "total_throughput": 3393.3639813793243,
    "itl": 35.26327631870544,
    "ttft": 9624.794947923485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.04392669668024,
    "arrivals": 26722,
    "finished_requests": 26651,
    "scheduler_time": 4.901456800234219
}
#Debug simulation 
Total elapsed time: 2.2704359027557075. Arrivals time: 0.07538578705862164 Scheduler time: 1.8157746316865087 Scheduler overhead time: 0.09798695100471377 Adapter cache time: 0.1382123939692974 Engine time: 0.09673811541870236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.2964510917663574,
    "estimated_duration": 3599.954824224457,
    "input_throughput": 1803.4706869963761,
    "output_throughput": 1589.9188405046307,
    "total_throughput": 3393.389527501007,
    "itl": 35.17442728514476,
    "ttft": 9624.396031831062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4847,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.942864798948396,
    "arrivals": 26722,
    "finished_requests": 26651,
    "scheduler_time": 4.8598790259699065
}
#Debug simulation 
Total elapsed time: 2.2965457178652287. Arrivals time: 0.07906606746837497 Scheduler time: 1.8365383949130774 Scheduler overhead time: 0.0989466835744679 Adapter cache time: 0.13877130765467882 Engine time: 0.09630118729546666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17771989 . Total output tokens: 15651447
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2729772781021893,
    "estimated_duration": 3599.9768133106722,
    "input_throughput": 1803.4596711830864,
    "output_throughput": 1589.9091290913989,
    "total_throughput": 3393.3688002744852,
    "itl": 35.25907463734674,
    "ttft": 9624.677512787153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.72076903915107,
    "arrivals": 26722,
    "finished_requests": 26651,
    "scheduler_time": 4.898834096651472
}
#Debug simulation 
Total elapsed time: 2.273076687939465. Arrivals time: 0.07635253667831421 Scheduler time: 1.8182155210524797 Scheduler overhead time: 0.09936890145763755 Adapter cache time: 0.13739342568442225 Engine time: 0.09489221684634686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.1958496207371354,
    "estimated_duration": 3600.0029930844994,
    "input_throughput": 1725.884398411711,
    "output_throughput": 1514.0523523092702,
    "total_throughput": 3239.9367507209813,
    "itl": 33.4050103313125,
    "ttft": 5840.857025804583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.92013594091309,
    "arrivals": 25517,
    "finished_requests": 25474,
    "scheduler_time": 3.0865475211178706
}
#Debug simulation 
Total elapsed time: 2.195931143127382. Arrivals time: 0.07220157561823726 Scheduler time: 1.7413350469432771 Scheduler overhead time: 0.1019978760741651 Adapter cache time: 0.13026861799880862 Engine time: 0.10179748991504312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.1753516760654747,
    "estimated_duration": 3600.0093836999217,
    "input_throughput": 1725.8813346798486,
    "output_throughput": 1514.0496646145225,
    "total_throughput": 3239.930999294371,
    "itl": 33.44186667711884,
    "ttft": 5981.8168783292185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.225387238240216,
    "arrivals": 25517,
    "finished_requests": 25474,
    "scheduler_time": 3.1019584490951235
}
#Debug simulation 
Total elapsed time: 2.1754335900768638. Arrivals time: 0.07261718111112714 Scheduler time: 1.7232835474424064 Scheduler overhead time: 0.10054624639451504 Adapter cache time: 0.130126534961164 Engine time: 0.10062338737770915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.172295407857746,
    "estimated_duration": 3600.02633737904,
    "input_throughput": 1725.8732069508817,
    "output_throughput": 1514.0425344688576,
    "total_throughput": 3239.9157414197393,
    "itl": 33.45068304415219,
    "ttft": 5981.993482869387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.866396145132132,
    "arrivals": 25517,
    "finished_requests": 25474,
    "scheduler_time": 3.1065999705104628
}
#Debug simulation 
Total elapsed time: 2.172386965714395. Arrivals time: 0.07254858128726482 Scheduler time: 1.7177751837298274 Scheduler overhead time: 0.10231174249202013 Adapter cache time: 0.12986645521596074 Engine time: 0.10092000104486942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.1684281728230417,
    "estimated_duration": 3600.0057178927373,
    "input_throughput": 1725.8830921071117,
    "output_throughput": 1514.0512063382232,
    "total_throughput": 3239.934298445335,
    "itl": 33.41715180104776,
    "ttft": 5981.74283589551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.702508830517193,
    "arrivals": 25517,
    "finished_requests": 25474,
    "scheduler_time": 3.0917383029228396
}
#Debug simulation 
Total elapsed time: 2.168509623967111. Arrivals time: 0.07166532659903169 Scheduler time: 1.7206850098446012 Scheduler overhead time: 0.10123441135510802 Adapter cache time: 0.12922829389572144 Engine time: 0.09757372876629233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.1737188599072397,
    "estimated_duration": 3600.01924547156,
    "input_throughput": 1725.8766068585685,
    "output_throughput": 1514.0455170777946,
    "total_throughput": 3239.922123936363,
    "itl": 33.44853418149524,
    "ttft": 5981.6874396250505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.64110452595699,
    "arrivals": 25517,
    "finished_requests": 25474,
    "scheduler_time": 3.104757122761674
}
#Debug simulation 
Total elapsed time: 2.1738135111518204. Arrivals time: 0.07591323740780354 Scheduler time: 1.7201563096605241 Scheduler overhead time: 0.10162800177931786 Adapter cache time: 0.1300485241226852 Engine time: 0.09808467421680689 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.1821717405691743,
    "estimated_duration": 3600.0168905985824,
    "input_throughput": 1725.8777358033228,
    "output_throughput": 1514.0465074578353,
    "total_throughput": 3239.924243261158,
    "itl": 33.392737592619554,
    "ttft": 5981.768466754135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.175465759874175,
    "arrivals": 25517,
    "finished_requests": 25474,
    "scheduler_time": 3.0815747421951363
}
#Debug simulation 
Total elapsed time: 2.1822562105953693. Arrivals time: 0.0722237303853035 Scheduler time: 1.7294028652831912 Scheduler overhead time: 0.1013260348699987 Adapter cache time: 0.1293536047451198 Engine time: 0.10129233682528138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16969874 . Total output tokens: 14937635
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.173666867893189,
    "estimated_duration": 3600.022691945894,
    "input_throughput": 1725.8749545941416,
    "output_throughput": 1514.0440676094267,
    "total_throughput": 3239.9190222035686,
    "itl": 33.44565365770118,
    "ttft": 5981.879675608158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.4115668252862,
    "arrivals": 25517,
    "finished_requests": 25474,
    "scheduler_time": 3.1033677102655024
}
#Debug simulation 
Total elapsed time: 2.173750998917967. Arrivals time: 0.07176791923120618 Scheduler time: 1.723589161876589 Scheduler overhead time: 0.10141369281336665 Adapter cache time: 0.13015680061653256 Engine time: 0.09845959953963757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.159154769964516,
    "estimated_duration": 3599.941734690421,
    "input_throughput": 1707.0073498088027,
    "output_throughput": 1494.8458604602313,
    "total_throughput": 3201.853210269034,
    "itl": 32.92188602152188,
    "ttft": 8713.337237020112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.041704311510987,
    "arrivals": 24947,
    "finished_requests": 24887,
    "scheduler_time": 2.756465395839856
}
#Debug simulation 
Total elapsed time: 2.1592399599030614. Arrivals time: 0.07148455502465367 Scheduler time: 1.7134691788814962 Scheduler overhead time: 0.10202343435958028 Adapter cache time: 0.1244689840823412 Engine time: 0.09874935820698738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.171913187019527,
    "estimated_duration": 3599.957095588167,
    "input_throughput": 1707.000066064954,
    "output_throughput": 1494.8394820024334,
    "total_throughput": 3201.839548067387,
    "itl": 32.94737988084251,
    "ttft": 8713.474914563554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.736310178590557,
    "arrivals": 24947,
    "finished_requests": 24887,
    "scheduler_time": 2.7671677081550095
}
#Debug simulation 
Total elapsed time: 2.1720184199512005. Arrivals time: 0.07631425932049751 Scheduler time: 1.7149679684080184 Scheduler overhead time: 0.10572983510792255 Adapter cache time: 0.12435929384082556 Engine time: 0.1013423022814095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.1434962092898786,
    "estimated_duration": 3599.9549274952415,
    "input_throughput": 1707.0010941152605,
    "output_throughput": 1494.8403822778455,
    "total_throughput": 3201.841476393106,
    "itl": 32.95357573351444,
    "ttft": 8713.337892292879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.207179977097464,
    "arrivals": 24947,
    "finished_requests": 24887,
    "scheduler_time": 2.770029347524212
}
#Debug simulation 
Total elapsed time: 2.143592590931803. Arrivals time: 0.07252767635509372 Scheduler time: 1.6938250507228076 Scheduler overhead time: 0.10257698595523834 Adapter cache time: 0.12403997173532844 Engine time: 0.10193825419992208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.1570445080287755,
    "estimated_duration": 3599.94108013023,
    "input_throughput": 1707.007660185843,
    "output_throughput": 1494.8461322609553,
    "total_throughput": 3201.8537924467983,
    "itl": 32.93011349822318,
    "ttft": 8713.350834917075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.657662482327172,
    "arrivals": 24947,
    "finished_requests": 24887,
    "scheduler_time": 2.7602619696085666
}
#Debug simulation 
Total elapsed time: 2.157142400741577. Arrivals time: 0.0751626561395824 Scheduler time: 1.7090301811695099 Scheduler overhead time: 0.10196904372423887 Adapter cache time: 0.12409555679187179 Engine time: 0.09800966177135706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.1411533933132887,
    "estimated_duration": 3599.9557251421375,
    "input_throughput": 1707.0007158927965,
    "output_throughput": 1494.840051064108,
    "total_throughput": 3201.840766956904,
    "itl": 32.95211685378113,
    "ttft": 8713.339833585147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.04624993086782,
    "arrivals": 24947,
    "finished_requests": 24887,
    "scheduler_time": 2.769135861699076
}
#Debug simulation 
Total elapsed time: 2.141302085015923. Arrivals time: 0.07652700180187821 Scheduler time: 1.6910443659871817 Scheduler overhead time: 0.10227139946073294 Adapter cache time: 0.12390926480293274 Engine time: 0.09845482930541039 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.162056970410049,
    "estimated_duration": 3599.944335480995,
    "input_throughput": 1707.0061165762272,
    "output_throughput": 1494.8447805043595,
    "total_throughput": 3201.8508970805865,
    "itl": 32.913732358540024,
    "ttft": 8713.387943490536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.4810082808845,
    "arrivals": 24947,
    "finished_requests": 24887,
    "scheduler_time": 2.75300049633049
}
#Debug simulation 
Total elapsed time: 2.1621576361358166. Arrivals time: 0.07822659937664866 Scheduler time: 1.707170785870403 Scheduler overhead time: 0.1026436067186296 Adapter cache time: 0.1244645370170474 Engine time: 0.10080791637301445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16579172 . Total output tokens: 14599584
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.1729454612359405,
    "estimated_duration": 3599.9462497185073,
    "input_throughput": 1707.005208891802,
    "output_throughput": 1494.8439856347266,
    "total_throughput": 3201.8491945265287,
    "itl": 32.948430479445484,
    "ttft": 8713.483114954915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.871857268158216,
    "arrivals": 24947,
    "finished_requests": 24887,
    "scheduler_time": 2.7676505831619447
}
#Debug simulation 
Total elapsed time: 2.1730471341870725. Arrivals time: 0.07991416519507766 Scheduler time: 1.7135064299218357 Scheduler overhead time: 0.1033070432022214 Adapter cache time: 0.12495752424001694 Engine time: 0.10243335273116827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.064094071742147,
    "estimated_duration": 3599.242503587876,
    "input_throughput": 1572.6247937885867,
    "output_throughput": 1380.3776753156744,
    "total_throughput": 2953.0024691042613,
    "itl": 30.987462152362404,
    "ttft": 7826.094723300806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.091043647085703,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.0937256468101821
}
#Debug simulation 
Total elapsed time: 2.064193904865533. Arrivals time: 0.07462336029857397 Scheduler time: 1.6093459366820753 Scheduler overhead time: 0.10653526755049825 Adapter cache time: 0.11826347187161446 Engine time: 0.10425354773178697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.045255821198225,
    "estimated_duration": 3599.2551918444124,
    "input_throughput": 1572.6192499008223,
    "output_throughput": 1380.372809146112,
    "total_throughput": 2952.992059046934,
    "itl": 31.008288125976495,
    "ttft": 7826.308362117549,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2132,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.566522796693915,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.0990431940064809
}
#Debug simulation 
Total elapsed time: 2.0453540049493313. Arrivals time: 0.07169096171855927 Scheduler time: 1.5927312914282084 Scheduler overhead time: 0.10751139745116234 Adapter cache time: 0.11722670402377844 Engine time: 0.10503575345501304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.0359026370570064,
    "estimated_duration": 3599.2450378688623,
    "input_throughput": 1572.6236864805064,
    "output_throughput": 1380.3767033715974,
    "total_throughput": 2953.0003898521036,
    "itl": 31.013371099921095,
    "ttft": 7826.24706751967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.97464533599061,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.100284783567168
}
#Debug simulation 
Total elapsed time: 2.035998061299324. Arrivals time: 0.06777443736791611 Scheduler time: 1.5875089168548584 Scheduler overhead time: 0.1062895911745727 Adapter cache time: 0.11744174920022488 Engine time: 0.10521773993968964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.0343824001029134,
    "estimated_duration": 3599.262215566738,
    "input_throughput": 1572.616181038296,
    "output_throughput": 1380.3701154398086,
    "total_throughput": 2952.9862964781046,
    "itl": 30.99592599342976,
    "ttft": 7826.0971403143585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.649182586455964,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.095774279763098
}
#Debug simulation 
Total elapsed time: 2.034480358939618. Arrivals time: 0.06969161937013268 Scheduler time: 1.5823866473510861 Scheduler overhead time: 0.1079034460708499 Adapter cache time: 0.1164624379016459 Engine time: 0.10620102612301707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.0776417097076774,
    "estimated_duration": 3599.247035350453,
    "input_throughput": 1572.622813718278,
    "output_throughput": 1380.3759373010757,
    "total_throughput": 2952.9987510193537,
    "itl": 31.01455627542749,
    "ttft": 7826.222813270251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.850320168011496,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.0998675427289017
}
#Debug simulation 
Total elapsed time: 2.077744461130351. Arrivals time: 0.07256478909403086 Scheduler time: 1.6238182536326349 Scheduler overhead time: 0.10647117532789707 Adapter cache time: 0.11784742353484035 Engine time: 0.10580691322684288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.0330657409504056,
    "estimated_duration": 3599.2442558210823,
    "input_throughput": 1572.6240281819234,
    "output_throughput": 1380.3770033013768,
    "total_throughput": 2953.0010314833003,
    "itl": 30.98154231440397,
    "ttft": 7826.048851749306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.616903366237656,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.0921112260456898
}
#Debug simulation 
Total elapsed time: 2.0331699270755053. Arrivals time: 0.07409245381131768 Scheduler time: 1.5808491166681051 Scheduler overhead time: 0.10613004863262177 Adapter cache time: 0.11687699053436518 Engine time: 0.10413999110460281 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15332690 . Total output tokens: 13549395
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.0376187907531857,
    "estimated_duration": 3599.2509693974766,
    "input_throughput": 1572.6210948128303,
    "output_throughput": 1380.3744285249738,
    "total_throughput": 2952.995523337804,
    "itl": 31.010153180722877,
    "ttft": 7826.259077882689,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.69726057449323,
    "arrivals": 23153,
    "finished_requests": 23103,
    "scheduler_time": 1.0994781569269285
}
#Debug simulation 
Total elapsed time: 2.0377217438071966. Arrivals time: 0.07385583221912384 Scheduler time: 1.5834892075508833 Scheduler overhead time: 0.10729117039591074 Adapter cache time: 0.11678848043084145 Engine time: 0.10478531662374735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.9984806687571108,
    "estimated_duration": 3600.0033123907015,
    "input_throughput": 1527.5810944596076,
    "output_throughput": 1347.960981951827,
    "total_throughput": 2875.5420764114347,
    "itl": 30.315746322209915,
    "ttft": 8030.444703124383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.713628867934704,
    "arrivals": 22557,
    "finished_requests": 22506,
    "scheduler_time": 0.7424017045904405
}
#Debug simulation 
Total elapsed time: 1.9985590488649905. Arrivals time: 0.06479405099526048 Scheduler time: 1.5535669978708029 Scheduler overhead time: 0.11003340687602758 Adapter cache time: 0.11089840717613697 Engine time: 0.10656645940616727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.0012975479476154,
    "estimated_duration": 3600.0178657694755,
    "input_throughput": 1527.5749190829554,
    "output_throughput": 1347.955532704775,
    "total_throughput": 2875.5304517877303,
    "itl": 30.32961047204138,
    "ttft": 8189.864483013616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.752318625277734,
    "arrivals": 22557,
    "finished_requests": 22506,
    "scheduler_time": 0.7447673340346211
}
#Debug simulation 
Total elapsed time: 2.0014388826675713. Arrivals time: 0.06900576269254088 Scheduler time: 1.550624469295144 Scheduler overhead time: 0.11033422546461225 Adapter cache time: 0.11007683491334319 Engine time: 0.10867351433262229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9954487229697406,
    "estimated_duration": 3600.0120075153695,
    "input_throughput": 1527.5774048863425,
    "output_throughput": 1347.9577262158014,
    "total_throughput": 2875.5351311021436,
    "itl": 30.333889637888916,
    "ttft": 8189.942087108342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.03715744953125,
    "arrivals": 22557,
    "finished_requests": 22506,
    "scheduler_time": 0.7456083206092079
}
#Debug simulation 
Total elapsed time: 1.995579980313778. Arrivals time: 0.07067647203803062 Scheduler time: 1.546255520079285 Scheduler overhead time: 0.10785704432055354 Adapter cache time: 0.1099890791811049 Engine time: 0.10885909385979176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.0051209880039096,
    "estimated_duration": 3600.032246827876,
    "input_throughput": 1527.5688168753593,
    "output_throughput": 1347.9501480232198,
    "total_throughput": 2875.5189648985793,
    "itl": 30.320539362654383,
    "ttft": 8189.988399046767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.087360779061054,
    "arrivals": 22557,
    "finished_requests": 22506,
    "scheduler_time": 0.7430273158448577
}
#Debug simulation 
Total elapsed time: 2.005224433261901. Arrivals time: 0.07129808561876416 Scheduler time: 1.5569764324463904 Scheduler overhead time: 0.10830130940303206 Adapter cache time: 0.11069542448967695 Engine time: 0.10543595254421234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.0024619181640446,
    "estimated_duration": 3600.014898891432,
    "input_throughput": 1527.576178002325,
    "output_throughput": 1347.9566435945312,
    "total_throughput": 2875.532821596856,
    "itl": 30.332022196601887,
    "ttft": 8189.968014566519,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.946024395306475,
    "arrivals": 22557,
    "finished_requests": 22506,
    "scheduler_time": 0.7453696769347733
}
#Debug simulation 
Total elapsed time: 2.002564350143075. Arrivals time: 0.07172787096351385 Scheduler time: 1.5513283889740705 Scheduler overhead time: 0.1091089672408998 Adapter cache time: 0.1102580139413476 Engine time: 0.10788752231746912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.0027182111516595,
    "estimated_duration": 3600.004995640992,
    "input_throughput": 1527.433158192306,
    "output_throughput": 1347.9139628627092,
    "total_throughput": 2875.3471210550156,
    "itl": 30.475053784317506,
    "ttft": 8190.323815192658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.377979861698256,
    "arrivals": 22557,
    "finished_requests": 22505,
    "scheduler_time": 0.7718830640035816
}
#Debug simulation 
Total elapsed time: 2.0028178431093693. Arrivals time: 0.06707175821065903 Scheduler time: 1.5610528131946921 Scheduler overhead time: 0.10801547858864069 Adapter cache time: 0.10928293550387025 Engine time: 0.10551094869151711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14960057 . Total output tokens: 13207900
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9869621298275888,
    "estimated_duration": 3600.002851878421,
    "input_throughput": 1527.5812898677452,
    "output_throughput": 1347.9611543829642,
    "total_throughput": 2875.5424442507097,
    "itl": 30.331753091785806,
    "ttft": 8030.654885241658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.832318561859312,
    "arrivals": 22557,
    "finished_requests": 22506,
    "scheduler_time": 0.7450497617334997
}
#Debug simulation 
Total elapsed time: 1.9871000377461314. Arrivals time: 0.06939882319420576 Scheduler time: 1.5399399679154158 Scheduler overhead time: 0.10830304818227887 Adapter cache time: 0.1098946025595069 Engine time: 0.10738538578152657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.9012366710230708,
    "estimated_duration": 3599.8833786204714,
    "input_throughput": 1451.8436988930625,
    "output_throughput": 1288.6331339371627,
    "total_throughput": 2740.4768328302252,
    "itl": 29.367298453537057,
    "ttft": 4283.669015684382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.8967426203239395,
    "arrivals": 21252,
    "finished_requests": 21227,
    "scheduler_time": 0.39130751370583533
}
#Debug simulation 
Total elapsed time: 1.9013355593197048. Arrivals time: 0.06690863100811839 Scheduler time: 1.4623238192871213 Scheduler overhead time: 0.11017526779323816 Adapter cache time: 0.10144289815798402 Engine time: 0.10736774979159236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.925927636679262,
    "estimated_duration": 3599.883225639645,
    "input_throughput": 1451.8437605906884,
    "output_throughput": 1288.633188698984,
    "total_throughput": 2740.4769492896726,
    "itl": 29.53469122140108,
    "ttft": 4284.114547726465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.603808023841131,
    "arrivals": 21252,
    "finished_requests": 21227,
    "scheduler_time": 0.40934194027612614
}
#Debug simulation 
Total elapsed time: 1.926004332024604. Arrivals time: 0.061494174879044294 Scheduler time: 1.4925788776017725 Scheduler overhead time: 0.10968807199969888 Adapter cache time: 0.10080614918842912 Engine time: 0.10823729168623686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9170703301206231,
    "estimated_duration": 3599.8784466093884,
    "input_throughput": 1451.8456879905611,
    "output_throughput": 1288.634899428135,
    "total_throughput": 2740.480587418696,
    "itl": 29.538556586063525,
    "ttft": 4283.995122334807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.804756613890656,
    "arrivals": 21252,
    "finished_requests": 21227,
    "scheduler_time": 0.4096842061096186
}
#Debug simulation 
Total elapsed time: 1.9172608540393412. Arrivals time: 0.07101903855800629 Scheduler time: 1.471137353219092 Scheduler overhead time: 0.1102758301422 Adapter cache time: 0.1006539398804307 Engine time: 0.11059519601985812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.902279709931463,
    "estimated_duration": 3599.888440018098,
    "input_throughput": 1451.84165761918,
    "output_throughput": 1288.631322135271,
    "total_throughput": 2740.472979754451,
    "itl": 29.371602097547708,
    "ttft": 4283.645042299782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.149859765567807,
    "arrivals": 21252,
    "finished_requests": 21227,
    "scheduler_time": 0.39175686276442484
}
#Debug simulation 
Total elapsed time: 1.9023885559290648. Arrivals time: 0.06895478116348386 Scheduler time: 1.459647444076836 Scheduler overhead time: 0.10962541634216905 Adapter cache time: 0.10156802833080292 Engine time: 0.10904066218063235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.9254923700354993,
    "estimated_duration": 3599.871469095881,
    "input_throughput": 1451.848502055726,
    "output_throughput": 1288.6373971471492,
    "total_throughput": 2740.485899202875,
    "itl": 29.53661815024618,
    "ttft": 4284.0847535607945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.73702929713765,
    "arrivals": 21252,
    "finished_requests": 21227,
    "scheduler_time": 0.40944414470717366
}
#Debug simulation 
Total elapsed time: 1.9256272143684328. Arrivals time: 0.06847640872001648 Scheduler time: 1.4844179218634963 Scheduler overhead time: 0.10983618069440126 Adapter cache time: 0.10146604245528579 Engine time: 0.1083091888576746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.9055509413592517,
    "estimated_duration": 3599.8769602510843,
    "input_throughput": 1451.8462874451866,
    "output_throughput": 1288.6354314944265,
    "total_throughput": 2740.481718939613,
    "itl": 29.36404643807752,
    "ttft": 4283.851477678772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.658429541015033,
    "arrivals": 21252,
    "finished_requests": 21227,
    "scheduler_time": 0.39088422658951405
}
#Debug simulation 
Total elapsed time: 1.9056913303211331. Arrivals time: 0.06909624766558409 Scheduler time: 1.462242131587118 Scheduler overhead time: 0.11064982879906893 Adapter cache time: 0.10139965917915106 Engine time: 0.10834121238440275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14147624 . Total output tokens: 12487249
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.951298549771309,
    "estimated_duration": 3599.883409832455,
    "input_throughput": 1451.8436863051766,
    "output_throughput": 1288.6331227643575,
    "total_throughput": 2740.476809069534,
    "itl": 29.53606921570183,
    "ttft": 4283.968954467154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.663709816616046,
    "arrivals": 21252,
    "finished_requests": 21227,
    "scheduler_time": 0.4092893577715893
}
#Debug simulation 
Total elapsed time: 1.9514280008152127. Arrivals time: 0.069581413641572 Scheduler time: 1.5070856395177543 Scheduler overhead time: 0.11105612711980939 Adapter cache time: 0.10182203305885196 Engine time: 0.10820598341524601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.6388580189086497,
    "estimated_duration": 3599.5689806482196,
    "input_throughput": 1183.810623691015,
    "output_throughput": 1010.3520781382748,
    "total_throughput": 2194.1627018292897,
    "itl": 27.8405478072324,
    "ttft": 7178.6856239617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.46540211069574,
    "arrivals": 17165,
    "finished_requests": 17131,
    "scheduler_time": 0.013238744793500404
}
#Debug simulation 
Total elapsed time: 1.638965802732855. Arrivals time: 0.05791100300848484 Scheduler time: 1.1753931608982384 Scheduler overhead time: 0.11384829506278038 Adapter cache time: 0.12097992189228535 Engine time: 0.11485769925639033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6610400322824717,
    "estimated_duration": 3599.569866411736,
    "input_throughput": 1183.8100545740547,
    "output_throughput": 1010.1256913856205,
    "total_throughput": 2193.9357459596754,
    "itl": 27.881697484571767,
    "ttft": 7388.624972886573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.053963167009634,
    "arrivals": 17165,
    "finished_requests": 17130,
    "scheduler_time": 0.013500364710175199
}
#Debug simulation 
Total elapsed time: 1.6611476060934365. Arrivals time: 0.06023080088198185 Scheduler time: 1.1951664625667036 Scheduler overhead time: 0.11396555742248893 Adapter cache time: 0.12252147169783711 Engine time: 0.11397846695035696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.665886275935918,
    "estimated_duration": 3599.5684647731377,
    "input_throughput": 1183.810515538718,
    "output_throughput": 1010.1260847192025,
    "total_throughput": 2193.9366002579204,
    "itl": 27.893694668983432,
    "ttft": 7388.7998203071365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5065,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.09603392490675,
    "arrivals": 17165,
    "finished_requests": 17130,
    "scheduler_time": 0.01358138599300407
}
#Debug simulation 
Total elapsed time: 1.6659996579401195. Arrivals time: 0.060173367615789175 Scheduler time: 1.1982700969092548 Scheduler overhead time: 0.11624394310638309 Adapter cache time: 0.12212114315479994 Engine time: 0.11235051183030009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.65351976826787,
    "estimated_duration": 3599.571229719271,
    "input_throughput": 1183.8098840267512,
    "output_throughput": 1010.3514468537508,
    "total_throughput": 2194.1613308805017,
    "itl": 27.852687086040543,
    "ttft": 7178.806454450492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.70870075916044,
    "arrivals": 17165,
    "finished_requests": 17131,
    "scheduler_time": 0.013381272182957033
}
#Debug simulation 
Total elapsed time: 1.653626631014049. Arrivals time: 0.0576673005707562 Scheduler time: 1.1874768333509564 Scheduler overhead time: 0.11507200542837381 Adapter cache time: 0.12185124587267637 Engine time: 0.11490817740559578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.6601933096535504,
    "estimated_duration": 3599.5792523862665,
    "input_throughput": 1183.8069677657802,
    "output_throughput": 1010.1230574627791,
    "total_throughput": 2193.9300252285593,
    "itl": 27.88771700407769,
    "ttft": 7388.832839354417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.71437482344484,
    "arrivals": 17165,
    "finished_requests": 17130,
    "scheduler_time": 0.013546525570646995
}
#Debug simulation 
Total elapsed time: 1.6603140057995915. Arrivals time: 0.059338262770324945 Scheduler time: 1.1935753738507628 Scheduler overhead time: 0.11608871538192034 Adapter cache time: 0.12171884020790458 Engine time: 0.11356018390506506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.6493588043376803,
    "estimated_duration": 3599.571638371579,
    "input_throughput": 1183.8097496311368,
    "output_throughput": 1010.3513321505326,
    "total_throughput": 2194.1610817816695,
    "itl": 27.828368755994408,
    "ttft": 7178.600008737251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5066,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.340943484933526,
    "arrivals": 17165,
    "finished_requests": 17131,
    "scheduler_time": 0.013126907896355705
}
#Debug simulation 
Total elapsed time: 1.649461749009788. Arrivals time: 0.05797186307609081 Scheduler time: 1.183331687003374 Scheduler overhead time: 0.1163741359487176 Adapter cache time: 0.12104395916685462 Engine time: 0.11236777668818831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11249648 . Total output tokens: 9944083
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.645565657876432,
    "estimated_duration": 3599.561991835917,
    "input_throughput": 1183.8126443341564,
    "output_throughput": 1010.1279011854131,
    "total_throughput": 2193.9405455195697,
    "itl": 27.883404076974973,
    "ttft": 7388.615059515198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5064,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.37961710751097,
    "arrivals": 17165,
    "finished_requests": 17130,
    "scheduler_time": 0.01354902752867407
}
#Debug simulation 
Total elapsed time: 1.645693613216281. Arrivals time: 0.058516761753708124 Scheduler time: 1.1810611370019615 Scheduler overhead time: 0.1169562409631908 Adapter cache time: 0.120939115062356 Engine time: 0.11157272849231958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.5864437692798674,
    "estimated_duration": 3599.6072212177014,
    "input_throughput": 1078.162355360294,
    "output_throughput": 964.9127770182171,
    "total_throughput": 2043.0751323785112,
    "itl": 27.2042293245777,
    "ttft": 6383.320732758394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.626137471155772,
    "arrivals": 15906,
    "finished_requests": 15878,
    "scheduler_time": 0.0011866307021832147
}
#Debug simulation 
Total elapsed time: 1.5865448564291. Arrivals time: 0.053540592547506094 Scheduler time: 1.1255989954806864 Scheduler overhead time: 0.1171993650496006 Adapter cache time: 0.1175329708494246 Engine time: 0.11549547547474504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.601778530050069,
    "estimated_duration": 3599.6074409306843,
    "input_throughput": 1078.1622895513772,
    "output_throughput": 964.9127181218324,
    "total_throughput": 2043.0750076732095,
    "itl": 27.231527094561567,
    "ttft": 6383.758444059037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.14591837264993,
    "arrivals": 15906,
    "finished_requests": 15878,
    "scheduler_time": 0.0011940114542605693
}
#Debug simulation 
Total elapsed time: 1.6018824451602995. Arrivals time: 0.05439813947305083 Scheduler time: 1.1463492503389716 Scheduler overhead time: 0.11619743565097451 Adapter cache time: 0.11175386235117912 Engine time: 0.11607085168361664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10420695 . Total output tokens: 9227255
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6185981971211731,
    "estimated_duration": 3599.615954175902,
    "input_throughput": 1078.15973965159,
    "output_throughput": 964.9104360621106,
    "total_throughput": 2043.0701757137006,
    "itl": 27.24069854867161,
    "ttft": 6383.836670192695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.8457858854681,
    "arrivals": 15906,
    "finished_requests": 15878,
    "scheduler_time": 0.001208647836411396
}
#Debug simulation 
Total elapsed time: 1.6187099860981107. Arrivals time: 0.05546918837353587 Scheduler time: 1.1620825962163508 Scheduler overhead time: 0.1150775165297091 Adapter cache time: 0.1128849103115499 Engine time: 0.11689231777563691 
