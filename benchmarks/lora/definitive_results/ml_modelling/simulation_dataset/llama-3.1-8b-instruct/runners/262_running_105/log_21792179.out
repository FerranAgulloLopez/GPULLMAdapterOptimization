INFO 05-31 19:31:04 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:05 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107735412 . Total output tokens: 94837114
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.116980622988194,
    "estimated_duration": 3600.1172500710986,
    "input_throughput": 3801.6409048148944,
    "output_throughput": 3284.3508082317285,
    "total_throughput": 7085.991713046623,
    "itl": 130.9859070017823,
    "ttft": 1931939.4451463292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2632,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.936656450778713,
    "arrivals": 161177,
    "finished_requests": 55285,
    "scheduler_time": 109.6227892254143
}
#Debug simulation 
Total elapsed time: 4.1171237314119935. Arrivals time: 0.1833909717388451 Scheduler time: 3.7717319927178323 Scheduler overhead time: 0.04016149928793311 Adapter cache time: 0.061632219702005386 Engine time: 0.041145140305161476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107735412 . Total output tokens: 94837114
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.431108513381332,
    "estimated_duration": 3600.040165577271,
    "input_throughput": 3812.506630130653,
    "output_throughput": 3294.005470657982,
    "total_throughput": 7106.5121007886355,
    "itl": 131.6293322197866,
    "ttft": 1929612.7484046386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.949310097215918,
    "arrivals": 161177,
    "finished_requests": 55440,
    "scheduler_time": 109.43198412575762
}
#Debug simulation 
Total elapsed time: 4.431220837403089. Arrivals time: 0.21117970207706094 Scheduler time: 4.058237337041646 Scheduler overhead time: 0.03997887345030904 Adapter cache time: 0.0617446918040514 Engine time: 0.04093093378469348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 106942988 . Total output tokens: 94139023
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.560471007134765,
    "estimated_duration": 3600.103021843393,
    "input_throughput": 4018.562222308908,
    "output_throughput": 3491.0198190841434,
    "total_throughput": 7509.582041393051,
    "itl": 148.0141268117796,
    "ttft": 1874802.1050961697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2031,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.429802743890688,
    "arrivals": 159905,
    "finished_requests": 58569,
    "scheduler_time": 105.33654290088228
}
#Debug simulation 
Total elapsed time: 4.560537139419466. Arrivals time: 0.20225906977429986 Scheduler time: 4.220386874396354 Scheduler overhead time: 0.03643962973728776 Adapter cache time: 0.047251617070287466 Engine time: 0.03699882421642542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 106942988 . Total output tokens: 94139023
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.4161133472807705,
    "estimated_duration": 3600.0492765708054,
    "input_throughput": 3852.155327498681,
    "output_throughput": 3346.57585894937,
    "total_throughput": 7198.731186448051,
    "itl": 129.09921680025917,
    "ttft": 1918041.2169801001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1984,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.505091935731205,
    "arrivals": 159905,
    "finished_requests": 56126,
    "scheduler_time": 111.44790875057696
}
#Debug simulation 
Total elapsed time: 4.416230812203139. Arrivals time: 0.20636855997145176 Scheduler time: 4.053820955567062 Scheduler overhead time: 0.040389409288764 Adapter cache time: 0.05513819819316268 Engine time: 0.04121043113991618 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 106942988 . Total output tokens: 94139023
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.396861281711608,
    "estimated_duration": 3600.0077142761697,
    "input_throughput": 3857.003679446786,
    "output_throughput": 3351.083096894312,
    "total_throughput": 7208.086776341098,
    "itl": 129.32360850071566,
    "ttft": 1917124.2226094618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1983,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.48530670427279,
    "arrivals": 159905,
    "finished_requests": 56197,
    "scheduler_time": 111.37538449903876
}
#Debug simulation 
Total elapsed time: 4.396927060093731. Arrivals time: 0.4206647062674165 Scheduler time: 3.8197902874089777 Scheduler overhead time: 0.04028809629380703 Adapter cache time: 0.05591118382290006 Engine time: 0.04104928858578205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 106942988 . Total output tokens: 94139023
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.475474702194333,
    "estimated_duration": 3600.0300570202726,
    "input_throughput": 3853.0464413625,
    "output_throughput": 3347.6531609780764,
    "total_throughput": 7200.699602340576,
    "itl": 128.95836679009074,
    "ttft": 1917621.5840806153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1982,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.652931304211377,
    "arrivals": 159905,
    "finished_requests": 56138,
    "scheduler_time": 111.53497157775507
}
#Debug simulation 
Total elapsed time: 4.475539536215365. Arrivals time: 0.46382558764889836 Scheduler time: 3.8551879175938666 Scheduler overhead time: 0.04043889045715332 Adapter cache time: 0.055161654483526945 Engine time: 0.04163298662751913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105285854 . Total output tokens: 92680623
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.415734050795436,
    "estimated_duration": 3600.0461794301054,
    "input_throughput": 4115.678316755788,
    "output_throughput": 3598.9521673444265,
    "total_throughput": 7714.630484100214,
    "itl": 144.35592865530379,
    "ttft": 1833983.127283772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.906914966036785,
    "arrivals": 157567,
    "finished_requests": 60332,
    "scheduler_time": 107.7594061920836
}
#Debug simulation 
Total elapsed time: 4.415883704088628. Arrivals time: 0.1987260621972382 Scheduler time: 4.0866399998776615 Scheduler overhead time: 0.036957081872969866 Adapter cache time: 0.03824863629415631 Engine time: 0.03768255887553096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105285854 . Total output tokens: 92680623
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.300370112992823,
    "estimated_duration": 3600.0249374062296,
    "input_throughput": 3926.941131187159,
    "output_throughput": 3435.3306477122514,
    "total_throughput": 7362.2717788994105,
    "itl": 125.995320610655,
    "ttft": 1880965.6525547858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.457723506898565,
    "arrivals": 157567,
    "finished_requests": 57555,
    "scheduler_time": 113.73130058883513
}
#Debug simulation 
Total elapsed time: 4.300466624088585. Arrivals time: 0.20976409362629056 Scheduler time: 3.9413371947593987 Scheduler overhead time: 0.04104070132598281 Adapter cache time: 0.04658374050632119 Engine time: 0.042098058853298426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105285854 . Total output tokens: 92680623
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.261091412976384,
    "estimated_duration": 3600.0721836348653,
    "input_throughput": 3935.250816469989,
    "output_throughput": 3442.187647328813,
    "total_throughput": 7377.438463798802,
    "itl": 126.44817463647348,
    "ttft": 1879843.4116409067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.814146159207459,
    "arrivals": 157567,
    "finished_requests": 57669,
    "scheduler_time": 113.5734650465902
}
#Debug simulation 
Total elapsed time: 4.261189180891961. Arrivals time: 0.1926886742003262 Scheduler time: 3.9193337373435497 Scheduler overhead time: 0.041461930610239506 Adapter cache time: 0.046187606174498796 Engine time: 0.041967757511883974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105285854 . Total output tokens: 92680623
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.329775962047279,
    "estimated_duration": 3600.1317207042157,
    "input_throughput": 3935.7276619946556,
    "output_throughput": 3442.689868462814,
    "total_throughput": 7378.41753045747,
    "itl": 126.43714792587316,
    "ttft": 1879680.579774537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.241641934276549,
    "arrivals": 157567,
    "finished_requests": 57677,
    "scheduler_time": 113.5914814162842
}
#Debug simulation 
Total elapsed time: 4.329874508082867. Arrivals time: 0.2099265013821423 Scheduler time: 3.967845229897648 Scheduler overhead time: 0.04145331308245659 Adapter cache time: 0.04650975577533245 Engine time: 0.04437340656295419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44980886 . Total output tokens: 39580602
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.699035296682268,
    "estimated_duration": 3600.1012937039914,
    "input_throughput": 4047.251121928577,
    "output_throughput": 3454.359193100671,
    "total_throughput": 7501.610315029247,
    "itl": 145.7886305716985,
    "ttft": 699741.9677735323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3075,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.333157773245482,
    "arrivals": 67679,
    "finished_requests": 58321,
    "scheduler_time": 58.067622842702825
}
#Debug simulation 
Total elapsed time: 7.699159902986139. Arrivals time: 0.17042557848617435 Scheduler time: 7.36892452603206 Scheduler overhead time: 0.0394197185523808 Adapter cache time: 0.06249517621472478 Engine time: 0.03975128196179867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44980886 . Total output tokens: 39580602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.469191086944193,
    "estimated_duration": 3600.0471604680156,
    "input_throughput": 3818.0741493989435,
    "output_throughput": 3271.632418967763,
    "total_throughput": 7089.706568366706,
    "itl": 130.14453942238612,
    "ttft": 924218.6775043912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3976,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.0598670180134,
    "arrivals": 67679,
    "finished_requests": 55123,
    "scheduler_time": 60.81416994693405
}
#Debug simulation 
Total elapsed time: 6.469318991992623. Arrivals time: 0.17530209850519896 Scheduler time: 6.106591165065765 Scheduler overhead time: 0.04263102309778333 Adapter cache time: 0.08162462618201971 Engine time: 0.043228722643107176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44980886 . Total output tokens: 39580602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.48743224516511,
    "estimated_duration": 3600.029061341998,
    "input_throughput": 3814.681150068468,
    "output_throughput": 3267.675565823012,
    "total_throughput": 7082.35671589148,
    "itl": 129.816787619356,
    "ttft": 928107.3249221303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4055,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.767838832853236,
    "arrivals": 67679,
    "finished_requests": 55070,
    "scheduler_time": 60.90064965350661
}
#Debug simulation 
Total elapsed time: 6.4875314431265. Arrivals time: 0.17768883565440774 Scheduler time: 6.1222264231182635 Scheduler overhead time: 0.042601445224136114 Adapter cache time: 0.08214279683306813 Engine time: 0.043100114446133375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44980886 . Total output tokens: 39580602
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.487732395995408,
    "estimated_duration": 3600.1393231809975,
    "input_throughput": 3823.6564655606044,
    "output_throughput": 3274.7507642518194,
    "total_throughput": 7098.407229812424,
    "itl": 130.19823186042606,
    "ttft": 918832.7908201091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.103852725995285,
    "arrivals": 67679,
    "finished_requests": 55207,
    "scheduler_time": 60.78631855331414
}
#Debug simulation 
Total elapsed time: 6.487915024161339. Arrivals time: 0.17693992471322417 Scheduler time: 6.123415921349078 Scheduler overhead time: 0.04259689478203654 Adapter cache time: 0.08105745119974017 Engine time: 0.04392242105677724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41789387 . Total output tokens: 36762471
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.469618139788508,
    "estimated_duration": 3600.123990377496,
    "input_throughput": 3965.1692658794136,
    "output_throughput": 3445.7990983525056,
    "total_throughput": 7410.96836423192,
    "itl": 144.7397631861795,
    "ttft": 431779.7352744499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.450654899644757,
    "arrivals": 62899,
    "finished_requests": 57639,
    "scheduler_time": 52.83477468442889
}
#Debug simulation 
Total elapsed time: 7.469717065803707. Arrivals time: 0.16226171283051372 Scheduler time: 7.142987832892686 Scheduler overhead time: 0.0393180469982326 Adapter cache time: 0.06736091990023851 Engine time: 0.03957434371113777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41789387 . Total output tokens: 36762471
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.088951205369085,
    "estimated_duration": 3600.0608842126667,
    "input_throughput": 3761.9938761013323,
    "output_throughput": 3274.9051694381114,
    "total_throughput": 7036.899045539444,
    "itl": 130.0293768226223,
    "ttft": 659172.087828044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4000,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.272774622439496,
    "arrivals": 62899,
    "finished_requests": 54713,
    "scheduler_time": 54.59859322503697
}
#Debug simulation 
Total elapsed time: 6.089049661066383. Arrivals time: 0.16210960783064365 Scheduler time: 5.7414101380854845 Scheduler overhead time: 0.04236914683133364 Adapter cache time: 0.08063965709879994 Engine time: 0.04272593976929784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41789387 . Total output tokens: 36762471
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.174092128872871,
    "estimated_duration": 3600.0702387707684,
    "input_throughput": 3764.0498938228743,
    "output_throughput": 3278.596032068017,
    "total_throughput": 7042.645925890892,
    "itl": 129.98536890710182,
    "ttft": 656128.6046022007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.388883476639922,
    "arrivals": 62899,
    "finished_requests": 54751,
    "scheduler_time": 54.58182791888027
}
#Debug simulation 
Total elapsed time: 6.174186645075679. Arrivals time: 0.1596285360865295 Scheduler time: 5.830278274603188 Scheduler overhead time: 0.04257196234539151 Adapter cache time: 0.079034767113626 Engine time: 0.04286753013730049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41789387 . Total output tokens: 36762471
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.2394425622187555,
    "estimated_duration": 3600.0062401256787,
    "input_throughput": 3765.5426395946333,
    "output_throughput": 3278.35903961877,
    "total_throughput": 7043.901679213403,
    "itl": 129.94759543243498,
    "ttft": 654259.4956499197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3815,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.354658388278725,
    "arrivals": 62899,
    "finished_requests": 54775,
    "scheduler_time": 54.588981710849666
}
#Debug simulation 
Total elapsed time: 6.23954053921625. Arrivals time: 0.16261171363294125 Scheduler time: 5.892401339486241 Scheduler overhead time: 0.04274023603647947 Adapter cache time: 0.07820393284782767 Engine time: 0.04351320955902338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40153427 . Total output tokens: 35361785
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.410469815135002,
    "estimated_duration": 3600.010621706874,
    "input_throughput": 3924.39314340177,
    "output_throughput": 3429.0807159193855,
    "total_throughput": 7353.473859321155,
    "itl": 143.21166032636927,
    "ttft": 294059.3139244304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3008,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.89012636810494,
    "arrivals": 60544,
    "finished_requests": 57072,
    "scheduler_time": 50.051681403012715
}
#Debug simulation 
Total elapsed time: 7.410586636979133. Arrivals time: 0.15247282991185784 Scheduler time: 7.096717748325318 Scheduler overhead time: 0.03994001215323806 Adapter cache time: 0.06244621705263853 Engine time: 0.04048519395291805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40153427 . Total output tokens: 35361785
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.988889807835221,
    "estimated_duration": 3600.033338027547,
    "input_throughput": 3737.924829155299,
    "output_throughput": 3267.0466897520723,
    "total_throughput": 7004.971518907371,
    "itl": 129.16254021962908,
    "ttft": 516308.47651250305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.8542786992986,
    "arrivals": 60544,
    "finished_requests": 54322,
    "scheduler_time": 51.25611056173708
}
#Debug simulation 
Total elapsed time: 5.989010084886104. Arrivals time: 0.1582469753921032 Scheduler time: 5.648538372479379 Scheduler overhead time: 0.04276467999443412 Adapter cache time: 0.07615831075236201 Engine time: 0.04332218458876014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40153427 . Total output tokens: 35361785
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.975496955681592,
    "estimated_duration": 3600.0113355719263,
    "input_throughput": 3738.5190615967445,
    "output_throughput": 3267.5297113005377,
    "total_throughput": 7006.048772897282,
    "itl": 129.0709831796073,
    "ttft": 514702.41797865764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.12233610853161,
    "arrivals": 60544,
    "finished_requests": 54337,
    "scheduler_time": 51.236845263076454
}
#Debug simulation 
Total elapsed time: 5.975580537691712. Arrivals time: 0.14776534866541624 Scheduler time: 5.6461580214090645 Scheduler overhead time: 0.04286540066823363 Adapter cache time: 0.07558357436209917 Engine time: 0.043228734750300646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40153427 . Total output tokens: 35361785
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.059199780225754,
    "estimated_duration": 3600.0485503084915,
    "input_throughput": 3740.681219103568,
    "output_throughput": 3269.2289660903243,
    "total_throughput": 7009.910185193892,
    "itl": 128.96651335211624,
    "ttft": 512957.09942906594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3734,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.837560792092443,
    "arrivals": 60544,
    "finished_requests": 54372,
    "scheduler_time": 51.25131124173045
}
#Debug simulation 
Total elapsed time: 6.059301954228431. Arrivals time: 0.15612121485173702 Scheduler time: 5.716564634349197 Scheduler overhead time: 0.04322464484721422 Adapter cache time: 0.07864991063252091 Engine time: 0.04450169950723648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39360850 . Total output tokens: 34676257
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.147415908053517,
    "estimated_duration": 3600.030766594934,
    "input_throughput": 3959.085609004655,
    "output_throughput": 3426.2071075760446,
    "total_throughput": 7385.2927165807,
    "itl": 141.97824408658317,
    "ttft": 173602.7715671525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.641907297242494,
    "arrivals": 59315,
    "finished_requests": 57306,
    "scheduler_time": 48.212387302379994
}
#Debug simulation 
Total elapsed time: 7.147551606874913. Arrivals time: 0.14400092652067542 Scheduler time: 6.848993293009698 Scheduler overhead time: 0.03981626406311989 Adapter cache time: 0.05623860564082861 Engine time: 0.04000825807452202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39360850 . Total output tokens: 34676257
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.781438282225281,
    "estimated_duration": 3600.0059452118157,
    "input_throughput": 3781.1979222159543,
    "output_throughput": 3274.7820918685593,
    "total_throughput": 7055.980014084514,
    "itl": 129.04215958060206,
    "ttft": 389399.82528488437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.343640918726408,
    "arrivals": 59315,
    "finished_requests": 54726,
    "scheduler_time": 49.099874427252026
}
#Debug simulation 
Total elapsed time: 5.781561654061079. Arrivals time: 0.15096265031024814 Scheduler time: 5.455118799582124 Scheduler overhead time: 0.04271387308835983 Adapter cache time: 0.06935910368338227 Engine time: 0.043366940692067146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39360850 . Total output tokens: 34676257
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.689733903855085,
    "estimated_duration": 3600.0617627482256,
    "input_throughput": 3787.6808506725724,
    "output_throughput": 3281.708975731884,
    "total_throughput": 7069.3898264044565,
    "itl": 129.3674171316791,
    "ttft": 379893.7235259593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.46713479276338,
    "arrivals": 59315,
    "finished_requests": 54832,
    "scheduler_time": 49.010579266683756
}
#Debug simulation 
Total elapsed time: 5.689851427916437. Arrivals time: 0.14380902284756303 Scheduler time: 5.371181713417172 Scheduler overhead time: 0.042437830939888954 Adapter cache time: 0.06960244895890355 Engine time: 0.04309114161878824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39360850 . Total output tokens: 34676257
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.76285714795813,
    "estimated_duration": 3600.085738737766,
    "input_throughput": 3792.3685686404947,
    "output_throughput": 3283.5373537921887,
    "total_throughput": 7075.905922432683,
    "itl": 129.31406547286332,
    "ttft": 376957.2192345527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.15631399705246,
    "arrivals": 59315,
    "finished_requests": 54877,
    "scheduler_time": 49.00935423154343
}
#Debug simulation 
Total elapsed time: 5.762952315155417. Arrivals time: 0.1499135890044272 Scheduler time: 5.436046516522765 Scheduler overhead time: 0.04287252575159073 Adapter cache time: 0.07063609408214688 Engine time: 0.04356361413374543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35322033 . Total output tokens: 31136943
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.824093351140618,
    "estimated_duration": 3600.103248906218,
    "input_throughput": 3619.117591685329,
    "output_throughput": 3121.0007666901483,
    "total_throughput": 6740.118358375477,
    "itl": 117.84346814750711,
    "ttft": 88292.38234010912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.0269494140818,
    "arrivals": 53129,
    "finished_requests": 52239,
    "scheduler_time": 41.59276803066107
}
#Debug simulation 
Total elapsed time: 6.82422261685133. Arrivals time: 0.13933103531599045 Scheduler time: 6.487503653857857 Scheduler overhead time: 0.04599345102906227 Adapter cache time: 0.0844740648753941 Engine time: 0.04580621188506484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35322033 . Total output tokens: 31136943
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.80058126617223,
    "estimated_duration": 3600.1131416997837,
    "input_throughput": 3618.4918326898323,
    "output_throughput": 3119.6280666605126,
    "total_throughput": 6738.119899350345,
    "itl": 118.07741156982048,
    "ttft": 88825.79551077537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.00806772184925,
    "arrivals": 53129,
    "finished_requests": 52236,
    "scheduler_time": 41.61534159615695
}
#Debug simulation 
Total elapsed time: 6.80068737687543. Arrivals time: 0.14292984642088413 Scheduler time: 6.460026213899255 Scheduler overhead time: 0.046023712027817965 Adapter cache time: 0.08421791903674603 Engine time: 0.0462100082077086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35322033 . Total output tokens: 31136943
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.790778229013085,
    "estimated_duration": 3600.0160181426127,
    "input_throughput": 3619.120007894328,
    "output_throughput": 3119.2338987962685,
    "total_throughput": 6738.353906690597,
    "itl": 117.9349307310365,
    "ttft": 87905.94873978989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.232995504076595,
    "arrivals": 53129,
    "finished_requests": 52243,
    "scheduler_time": 41.5966680394632
}
#Debug simulation 
Total elapsed time: 6.790886585135013. Arrivals time: 0.1390899266116321 Scheduler time: 6.4538594163022935 Scheduler overhead time: 0.04572151042521 Adapter cache time: 0.08544897707179189 Engine time: 0.045681385323405266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35322033 . Total output tokens: 31136943
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.8240732490085065,
    "estimated_duration": 3600.0424882810858,
    "input_throughput": 3619.276450879119,
    "output_throughput": 3120.4542825725907,
    "total_throughput": 6739.73073345171,
    "itl": 117.74181061417734,
    "ttft": 87496.4561938555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4551,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.053224200539265,
    "arrivals": 53129,
    "finished_requests": 52249,
    "scheduler_time": 41.58924771552352
}
#Debug simulation 
Total elapsed time: 6.824191304855049. Arrivals time: 0.13539350545033813 Scheduler time: 6.490128493402153 Scheduler overhead time: 0.046567673329263926 Adapter cache time: 0.08423575386404991 Engine time: 0.04653653781861067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33714858 . Total output tokens: 29704634
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.406323248986155,
    "estimated_duration": 3600.0512833015187,
    "input_throughput": 3456.8901997937687,
    "output_throughput": 2978.9770078399692,
    "total_throughput": 6435.867207633738,
    "itl": 109.26094278147795,
    "ttft": 62897.15478110441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.64749709123988,
    "arrivals": 50759,
    "finished_requests": 50085,
    "scheduler_time": 38.5012813966469
}
#Debug simulation 
Total elapsed time: 5.40641764877364. Arrivals time: 0.12700952496379614 Scheduler time: 5.063586594071239 Scheduler overhead time: 0.04851154191419482 Adapter cache time: 0.09723672596737742 Engine time: 0.04769996413961053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33714858 . Total output tokens: 29704634
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.356172596104443,
    "estimated_duration": 3600.0403699789367,
    "input_throughput": 3457.323452201405,
    "output_throughput": 2979.022982473596,
    "total_throughput": 6436.346434675001,
    "itl": 109.51523052895317,
    "ttft": 62757.74701981175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.190697620984814,
    "arrivals": 50759,
    "finished_requests": 50089,
    "scheduler_time": 38.51960023688357
}
#Debug simulation 
Total elapsed time: 5.356301294174045. Arrivals time: 0.1266226740553975 Scheduler time: 5.016308314166963 Scheduler overhead time: 0.04789946088567376 Adapter cache time: 0.0962238316424191 Engine time: 0.04731611954048276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33714858 . Total output tokens: 29704634
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.4312995239160955,
    "estimated_duration": 3600.0324911786956,
    "input_throughput": 3457.0554656091963,
    "output_throughput": 2979.0825572489675,
    "total_throughput": 6436.138022858164,
    "itl": 109.34418577259615,
    "ttft": 62669.54834648527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.92033280191132,
    "arrivals": 50759,
    "finished_requests": 50087,
    "scheduler_time": 38.50400730257835
}
#Debug simulation 
Total elapsed time: 5.431399210821837. Arrivals time: 0.1288423934020102 Scheduler time: 5.087305650115013 Scheduler overhead time: 0.04805798642337322 Adapter cache time: 0.0973967663012445 Engine time: 0.04768306529149413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33714858 . Total output tokens: 29704634
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.3692788779735565,
    "estimated_duration": 3600.1038807239347,
    "input_throughput": 3457.2805153325617,
    "output_throughput": 2979.0940359874644,
    "total_throughput": 6436.3745513200265,
    "itl": 109.1652297582442,
    "ttft": 62531.55145332431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.47317307908437,
    "arrivals": 50759,
    "finished_requests": 50090,
    "scheduler_time": 38.49890504873437
}
#Debug simulation 
Total elapsed time: 5.369384763762355. Arrivals time: 0.12871974240988493 Scheduler time: 5.025720496661961 Scheduler overhead time: 0.04812724003568292 Adapter cache time: 0.09710697690024972 Engine time: 0.04769613686949015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32934004 . Total output tokens: 28995001
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.738360278308392,
    "estimated_duration": 3600.100355112355,
    "input_throughput": 3374.682870367051,
    "output_throughput": 2934.169039204556,
    "total_throughput": 6308.8519095716065,
    "itl": 106.87669722939546,
    "ttft": 48724.00541482865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.23447525890834,
    "arrivals": 49552,
    "finished_requests": 49019,
    "scheduler_time": 37.428660292874476
}
#Debug simulation 
Total elapsed time: 4.738484282977879. Arrivals time: 0.12209792248904705 Scheduler time: 4.399061544332653 Scheduler overhead time: 0.04782731272280216 Adapter cache time: 0.09958151401951909 Engine time: 0.047719269059598446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32934004 . Total output tokens: 28995001
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.759567853063345,
    "estimated_duration": 3600.011465927005,
    "input_throughput": 3374.0484203908613,
    "output_throughput": 2933.7845448446,
    "total_throughput": 6307.832965235461,
    "itl": 107.14312900736641,
    "ttft": 49307.31903581087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.91054128660691,
    "arrivals": 49552,
    "finished_requests": 49011,
    "scheduler_time": 37.44576537646461
}
#Debug simulation 
Total elapsed time: 4.759685973171145. Arrivals time: 0.12145017320290208 Scheduler time: 4.419730745721608 Scheduler overhead time: 0.04846649803221226 Adapter cache time: 0.09938184451311827 Engine time: 0.04835621127858758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32934004 . Total output tokens: 28995001
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.747896834276617,
    "estimated_duration": 3600.079965213671,
    "input_throughput": 3374.384212957056,
    "output_throughput": 2933.7887219327736,
    "total_throughput": 6308.17293488983,
    "itl": 106.9511691834374,
    "ttft": 49170.81073598344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.29762608403003,
    "arrivals": 49552,
    "finished_requests": 49013,
    "scheduler_time": 37.43404941535663
}
#Debug simulation 
Total elapsed time: 4.747995185200125. Arrivals time: 0.12206530198454857 Scheduler time: 4.408282769378275 Scheduler overhead time: 0.048093575052917004 Adapter cache time: 0.09934829687699676 Engine time: 0.04795188829302788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32934004 . Total output tokens: 28995001
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.7838076879270375,
    "estimated_duration": 3600.055149723715,
    "input_throughput": 3374.534970924635,
    "output_throughput": 2934.149217355923,
    "total_throughput": 6308.684188280558,
    "itl": 106.78748793219077,
    "ttft": 48622.24614850443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.024465867643215,
    "arrivals": 49552,
    "finished_requests": 49019,
    "scheduler_time": 37.42094362323213
}
#Debug simulation 
Total elapsed time: 4.783899168018252. Arrivals time: 0.12260667327791452 Scheduler time: 4.440409688279033 Scheduler overhead time: 0.04867834458127618 Adapter cache time: 0.10098585858941078 Engine time: 0.04875874472782016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30520999 . Total output tokens: 26815928
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.9076909576542675,
    "estimated_duration": 3600.107874680635,
    "input_throughput": 3149.375628363858,
    "output_throughput": 2725.376666906235,
    "total_throughput": 5874.752295270094,
    "itl": 97.15132894897138,
    "ttft": 31309.70433966826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.457767086636935,
    "arrivals": 45990,
    "finished_requests": 45635,
    "scheduler_time": 33.42750062728321
}
#Debug simulation 
Total elapsed time: 3.90778430365026. Arrivals time: 0.11399135878309608 Scheduler time: 3.536175850313157 Scheduler overhead time: 0.05128888925537467 Adapter cache time: 0.13110226672142744 Engine time: 0.05117140617221594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30520999 . Total output tokens: 26815928
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.8993987082503736,
    "estimated_duration": 3600.088914195796,
    "input_throughput": 3149.391937319069,
    "output_throughput": 2725.3065782103613,
    "total_throughput": 5874.69851552943,
    "itl": 97.4629194858362,
    "ttft": 31473.66434894862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7733,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.63558564969607,
    "arrivals": 45990,
    "finished_requests": 45634,
    "scheduler_time": 33.45135333656592
}
#Debug simulation 
Total elapsed time: 3.8994923080317676. Arrivals time: 0.11340666096657515 Scheduler time: 3.529070107731968 Scheduler overhead time: 0.051536130253225565 Adapter cache time: 0.13069798611104488 Engine time: 0.050828628707677126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30520999 . Total output tokens: 26815928
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.8688319860957563,
    "estimated_duration": 3600.0131387614933,
    "input_throughput": 3149.458227783198,
    "output_throughput": 2725.3639422481056,
    "total_throughput": 5874.822170031303,
    "itl": 97.25563233689128,
    "ttft": 31339.460949112014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7769,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.22826785348073,
    "arrivals": 45990,
    "finished_requests": 45634,
    "scheduler_time": 33.43463400537311
}
#Debug simulation 
Total elapsed time: 3.8689561490900815. Arrivals time: 0.1151079498231411 Scheduler time: 3.496811119839549 Scheduler overhead time: 0.051511106081306934 Adapter cache time: 0.1310560335405171 Engine time: 0.050538609735667706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30520999 . Total output tokens: 26815928
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.9303515758365393,
    "estimated_duration": 3600.092425550148,
    "input_throughput": 3149.460808153371,
    "output_throughput": 2725.5069704218963,
    "total_throughput": 5874.967778575267,
    "itl": 97.04679673393629,
    "ttft": 31201.040577382846,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7800,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.794583336455695,
    "arrivals": 45990,
    "finished_requests": 45636,
    "scheduler_time": 33.41925837850793
}
#Debug simulation 
Total elapsed time: 3.9304542718455195. Arrivals time: 0.11618216009810567 Scheduler time: 3.553883945569396 Scheduler overhead time: 0.05159298935905099 Adapter cache time: 0.13325780211016536 Engine time: 0.05141159053891897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29767840 . Total output tokens: 26129178
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.434419303201139,
    "estimated_duration": 3600.005198345194,
    "input_throughput": 3065.65668434953,
    "output_throughput": 2644.0228487379254,
    "total_throughput": 5709.679533087456,
    "itl": 91.6622180206595,
    "ttft": 24841.54732678739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.61341243105326,
    "arrivals": 44803,
    "finished_requests": 44503,
    "scheduler_time": 31.669060732996993
}
#Debug simulation 
Total elapsed time: 3.434536154847592. Arrivals time: 0.10967136407271028 Scheduler time: 3.0587528799660504 Scheduler overhead time: 0.05118595063686371 Adapter cache time: 0.1406459198333323 Engine time: 0.05017583537846804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29767840 . Total output tokens: 26129178
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.508986541070044,
    "estimated_duration": 3600.033207053312,
    "input_throughput": 3065.360335671087,
    "output_throughput": 2643.876445737199,
    "total_throughput": 5709.236781408286,
    "itl": 92.0688620388651,
    "ttft": 24953.792738953514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8074,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.085982222173186,
    "arrivals": 44803,
    "finished_requests": 44502,
    "scheduler_time": 31.702102345894904
}
#Debug simulation 
Total elapsed time: 3.509079797193408. Arrivals time: 0.11284797498956323 Scheduler time: 3.1258330936543643 Scheduler overhead time: 0.05166556220501661 Adapter cache time: 0.14303997484967113 Engine time: 0.05137627525255084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29767840 . Total output tokens: 26129178
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.5313073582947254,
    "estimated_duration": 3600.0648486167797,
    "input_throughput": 3065.6058888051443,
    "output_throughput": 2643.979039337918,
    "total_throughput": 5709.584928143062,
    "itl": 91.80007484345184,
    "ttft": 24851.418145945732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.39631733981632,
    "arrivals": 44803,
    "finished_requests": 44503,
    "scheduler_time": 31.680336553740126
}
#Debug simulation 
Total elapsed time: 3.5314013231545687. Arrivals time: 0.11083124298602343 Scheduler time: 3.1484102378599346 Scheduler overhead time: 0.05193040845915675 Adapter cache time: 0.14425825979560614 Engine time: 0.051442821975797415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29767840 . Total output tokens: 26129178
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.4656632631085813,
    "estimated_duration": 3600.026900794912,
    "input_throughput": 3065.6382033042833,
    "output_throughput": 2644.006909475662,
    "total_throughput": 5709.645112779945,
    "itl": 91.53042527373002,
    "ttft": 24830.1341761864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.79275059085454,
    "arrivals": 44803,
    "finished_requests": 44503,
    "scheduler_time": 31.658438101287704
}
#Debug simulation 
Total elapsed time: 3.4657550449483097. Arrivals time: 0.11315631726756692 Scheduler time: 3.083475939463824 Scheduler overhead time: 0.05179063510149717 Adapter cache time: 0.14227737206965685 Engine time: 0.05078154196962714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28146979 . Total output tokens: 24677676
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.2219150508753955,
    "estimated_duration": 3600.0379766410447,
    "input_throughput": 2916.176459281495,
    "output_throughput": 2522.3775579369176,
    "total_throughput": 5438.554017218413,
    "itl": 70.93147455670696,
    "ttft": 13807.404372981184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.04068169647556,
    "arrivals": 42341,
    "finished_requests": 42179,
    "scheduler_time": 27.68208292968938
}
#Debug simulation 
Total elapsed time: 3.2220060280524194. Arrivals time: 0.10771228326484561 Scheduler time: 2.822397102136165 Scheduler overhead time: 0.05696412082761526 Adapter cache time: 0.1490224925801158 Engine time: 0.058403626549988985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28146979 . Total output tokens: 24677676
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.2339897388592362,
    "estimated_duration": 3600.049930092819,
    "input_throughput": 2916.203720465988,
    "output_throughput": 2522.369738290234,
    "total_throughput": 5438.573458756223,
    "itl": 71.15293882771338,
    "ttft": 13722.659014432315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.56744380651862,
    "arrivals": 42341,
    "finished_requests": 42180,
    "scheduler_time": 27.70998693947003
}
#Debug simulation 
Total elapsed time: 3.2340810387395322. Arrivals time: 0.10480579035356641 Scheduler time: 2.838008205872029 Scheduler overhead time: 0.056484277825802565 Adapter cache time: 0.15069326339289546 Engine time: 0.05661308579146862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28146979 . Total output tokens: 24677676
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.2846773718483746,
    "estimated_duration": 3600.0357159444484,
    "input_throughput": 2916.1782905383816,
    "output_throughput": 2522.3791419018585,
    "total_throughput": 5438.55743244024,
    "itl": 71.00910623235494,
    "ttft": 13807.473856680363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.22328628883812,
    "arrivals": 42341,
    "finished_requests": 42179,
    "scheduler_time": 27.691526899325506
}
#Debug simulation 
Total elapsed time: 3.284770289901644. Arrivals time: 0.10490360390394926 Scheduler time: 2.8854470709338784 Scheduler overhead time: 0.05721768829971552 Adapter cache time: 0.15259965974837542 Engine time: 0.05697777168825269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28146979 . Total output tokens: 24677676
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.2491925470530987,
    "estimated_duration": 3600.0193398549227,
    "input_throughput": 2916.1915559106615,
    "output_throughput": 2522.390615925397,
    "total_throughput": 5438.5821718360585,
    "itl": 70.85973267478263,
    "ttft": 13807.039312848092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5147,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.85804108111981,
    "arrivals": 42341,
    "finished_requests": 42179,
    "scheduler_time": 27.672600528949893
}
#Debug simulation 
Total elapsed time: 3.2493194192647934. Arrivals time: 0.10508855385705829 Scheduler time: 2.851798734627664 Scheduler overhead time: 0.05700380774214864 Adapter cache time: 0.15066650602966547 Engine time: 0.05719417612999678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22533526 . Total output tokens: 19829764
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.889825712889433,
    "estimated_duration": 3600.048075095387,
    "input_throughput": 2306.9753033172883,
    "output_throughput": 2032.2131392109682,
    "total_throughput": 4339.188442528256,
    "itl": 70.92074571467535,
    "ttft": 16130.680640455548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 110.24869578967181,
    "arrivals": 33871,
    "finished_requests": 33725,
    "scheduler_time": 20.524896636163973
}
#Debug simulation 
Total elapsed time: 2.8899155827239156. Arrivals time: 0.0897426106967032 Scheduler time: 2.400418806821108 Scheduler overhead time: 0.0572374677285552 Adapter cache time: 0.2562929349951446 Engine time: 0.058015947230160236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22533526 . Total output tokens: 19829764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.928044281899929,
    "estimated_duration": 3600.0743579358477,
    "input_throughput": 2306.7920754730108,
    "output_throughput": 2031.875531647102,
    "total_throughput": 4338.667607120113,
    "itl": 71.3829684223987,
    "ttft": 16472.804505453358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 122.18565695401858,
    "arrivals": 33871,
    "finished_requests": 33723,
    "scheduler_time": 20.584323291584475
}
#Debug simulation 
Total elapsed time: 2.9281325438059866. Arrivals time: 0.08940864214673638 Scheduler time: 2.439221803098917 Scheduler overhead time: 0.05748461186885834 Adapter cache time: 0.2576014972291887 Engine time: 0.05672119418159127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22533526 . Total output tokens: 19829764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.8720699409022927,
    "estimated_duration": 3600.0372481890654,
    "input_throughput": 2306.9822414136947,
    "output_throughput": 2032.2192509758659,
    "total_throughput": 4339.20149238956,
    "itl": 70.84632368297822,
    "ttft": 16109.205169618352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16718,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 114.53513325933018,
    "arrivals": 33871,
    "finished_requests": 33725,
    "scheduler_time": 20.508580752350838
}
#Debug simulation 
Total elapsed time: 2.872203947044909. Arrivals time: 0.09134900476783514 Scheduler time: 2.3840207108296454 Scheduler overhead time: 0.057465662714093924 Adapter cache time: 0.25509665021672845 Engine time: 0.05674450332298875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22533526 . Total output tokens: 19829764
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.8968602209351957,
    "estimated_duration": 3600.0304559227447,
    "input_throughput": 2307.10964856855,
    "output_throughput": 2032.5703044988425,
    "total_throughput": 4339.6799530673925,
    "itl": 70.31855765204095,
    "ttft": 15749.25086565191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16750,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 106.93067575452181,
    "arrivals": 33871,
    "finished_requests": 33728,
    "scheduler_time": 20.4335688091895
}
#Debug simulation 
Total elapsed time: 2.8969516032375395. Arrivals time: 0.08942520059645176 Scheduler time: 2.406849508639425 Scheduler overhead time: 0.058015691582113504 Adapter cache time: 0.25642360327765346 Engine time: 0.05832487205043435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20869424 . Total output tokens: 18393465
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.6328037879429758,
    "estimated_duration": 3599.981201690209,
    "input_throughput": 2161.353508275782,
    "output_throughput": 1886.338738883329,
    "total_throughput": 4047.692247159111,
    "itl": 55.105227408932755,
    "ttft": 11879.869327392022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 95.93944264454322,
    "arrivals": 31462,
    "finished_requests": 31359,
    "scheduler_time": 15.565095924830489
}
#Debug simulation 
Total elapsed time: 2.6328964959830046. Arrivals time: 0.08428395027294755 Scheduler time: 2.133237063884735 Scheduler overhead time: 0.06827524770051241 Adapter cache time: 0.24651630781590939 Engine time: 0.06735500320792198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20869424 . Total output tokens: 18393465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.6385684781707823,
    "estimated_duration": 3600.0168677189913,
    "input_throughput": 2161.1437628984186,
    "output_throughput": 1886.0644962205772,
    "total_throughput": 4047.208259118996,
    "itl": 55.63976142247904,
    "ttft": 12109.913320776364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 106.16112549064287,
    "arrivals": 31462,
    "finished_requests": 31357,
    "scheduler_time": 15.674533741489983
}
#Debug simulation 
Total elapsed time: 2.638672715984285. Arrivals time: 0.08419644180685282 Scheduler time: 2.139048717916012 Scheduler overhead time: 0.06739554600790143 Adapter cache time: 0.24952848302200437 Engine time: 0.0656791077926755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20869424 . Total output tokens: 18393465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.6748154321685433,
    "estimated_duration": 3599.9762206180844,
    "input_throughput": 2161.356498811567,
    "output_throughput": 1886.3413488975996,
    "total_throughput": 4047.6978477091666,
    "itl": 55.27803970449014,
    "ttft": 11880.274482864934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 99.3144196502452,
    "arrivals": 31462,
    "finished_requests": 31359,
    "scheduler_time": 15.600813742676927
}
#Debug simulation 
Total elapsed time: 2.6749086030758917. Arrivals time: 0.08517405204474926 Scheduler time: 2.169846286997199 Scheduler overhead time: 0.06854976434260607 Adapter cache time: 0.24912737123668194 Engine time: 0.0690577276982367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20869424 . Total output tokens: 18393465
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.7011460112407804,
    "estimated_duration": 3599.990293137457,
    "input_throughput": 2161.3480499745638,
    "output_throughput": 1886.3339751068352,
    "total_throughput": 4047.682025081399,
    "itl": 54.93122012159866,
    "ttft": 11879.276571818758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 92.598773242955,
    "arrivals": 31462,
    "finished_requests": 31359,
    "scheduler_time": 15.529083555714525
}
#Debug simulation 
Total elapsed time: 2.7012234460562468. Arrivals time: 0.08426664816215634 Scheduler time: 2.19469581451267 Scheduler overhead time: 0.0697620720602572 Adapter cache time: 0.2500462383031845 Engine time: 0.06885178806260228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20091524 . Total output tokens: 17734530
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.563081336207688,
    "estimated_duration": 3600.0174152532845,
    "input_throughput": 2034.9098782025167,
    "output_throughput": 1806.3270950989233,
    "total_throughput": 3841.2369733014402,
    "itl": 48.87114178727213,
    "ttft": 16029.860280220742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 83.1312063496661,
    "arrivals": 30252,
    "finished_requests": 30117,
    "scheduler_time": 12.989234587575156
}
#Debug simulation 
Total elapsed time: 2.563209580257535. Arrivals time: 0.08351444825530052 Scheduler time: 2.0569097972474992 Scheduler overhead time: 0.07605762965977192 Adapter cache time: 0.23501874413341284 Engine time: 0.07530574547126889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20091524 . Total output tokens: 17734530
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.6149943717755377,
    "estimated_duration": 3600.05834726431,
    "input_throughput": 2034.8867416459566,
    "output_throughput": 1806.3065574871848,
    "total_throughput": 3841.1932991331414,
    "itl": 49.20892992678633,
    "ttft": 16149.264690090266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 91.98440892018992,
    "arrivals": 30252,
    "finished_requests": 30117,
    "scheduler_time": 13.078807609970324
}
#Debug simulation 
Total elapsed time: 2.6150728981010616. Arrivals time: 0.08292541140690446 Scheduler time: 2.106845028232783 Scheduler overhead time: 0.07429752964526415 Adapter cache time: 0.23979381332173944 Engine time: 0.07524535059928894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20091524 . Total output tokens: 17734530
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.5733133791945875,
    "estimated_duration": 3600.0393342594416,
    "input_throughput": 2034.8974885595132,
    "output_throughput": 1806.3160971927775,
    "total_throughput": 3841.213585752291,
    "itl": 48.98715622081021,
    "ttft": 16148.585347096476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 86.24659882898946,
    "arrivals": 30252,
    "finished_requests": 30117,
    "scheduler_time": 13.020711324655949
}
#Debug simulation 
Total elapsed time: 2.5734128053300083. Arrivals time: 0.08263587392866611 Scheduler time: 2.069657343439758 Scheduler overhead time: 0.0745945144444704 Adapter cache time: 0.23674954241141677 Engine time: 0.07375306077301502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20091524 . Total output tokens: 17734530
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.564010892994702,
    "estimated_duration": 3600.0133414104666,
    "input_throughput": 2034.912180944814,
    "output_throughput": 1806.3291391726434,
    "total_throughput": 3841.2413201174577,
    "itl": 48.75804201980014,
    "ttft": 16029.500806156697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 80.28418974860651,
    "arrivals": 30252,
    "finished_requests": 30117,
    "scheduler_time": 12.960730409038531
}
#Debug simulation 
Total elapsed time: 2.564090180210769. Arrivals time: 0.0816072877496481 Scheduler time: 2.0606011394411325 Scheduler overhead time: 0.07449865387752652 Adapter cache time: 0.23667134810239077 Engine time: 0.07443084381520748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17643706 . Total output tokens: 15545818
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.3037750869989395,
    "estimated_duration": 3600.001785368863,
    "input_throughput": 1818.5165981325247,
    "output_throughput": 1581.3894935101218,
    "total_throughput": 3399.9060916426465,
    "itl": 39.546371721897934,
    "ttft": 11038.7219287348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 68.65003056970694,
    "arrivals": 26579,
    "finished_requests": 26498,
    "scheduler_time": 6.602455859457537
}
#Debug simulation 
Total elapsed time: 2.30387245118618. Arrivals time: 0.07554736407473683 Scheduler time: 1.7922795941121876 Scheduler overhead time: 0.08759630285203457 Adapter cache time: 0.21861879993230104 Engine time: 0.0874174227938056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17643706 . Total output tokens: 15545818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.2889842218719423,
    "estimated_duration": 3600.010999782905,
    "input_throughput": 1818.4569437134437,
    "output_throughput": 1581.3623903769478,
    "total_throughput": 3399.8193340903913,
    "itl": 39.718968533525405,
    "ttft": 11174.925269452366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 75.89268566616934,
    "arrivals": 26579,
    "finished_requests": 26497,
    "scheduler_time": 6.669801203516252
}
#Debug simulation 
Total elapsed time: 2.2890859646722674. Arrivals time: 0.07396518113091588 Scheduler time: 1.7832749704830348 Scheduler overhead time: 0.08723041461780667 Adapter cache time: 0.21644373564049602 Engine time: 0.08609900064766407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17643706 . Total output tokens: 15545818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.313869941048324,
    "estimated_duration": 3600.0085356284844,
    "input_throughput": 1818.513188290842,
    "output_throughput": 1581.3865282978068,
    "total_throughput": 3399.8997165886485,
    "itl": 39.606018665244115,
    "ttft": 11038.876615132247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 71.11916040055449,
    "arrivals": 26579,
    "finished_requests": 26498,
    "scheduler_time": 6.625369613275163
}
#Debug simulation 
Total elapsed time: 2.3139680339954793. Arrivals time: 0.07561099668964744 Scheduler time: 1.8052045847289264 Scheduler overhead time: 0.08769483491778374 Adapter cache time: 0.21558509906753898 Engine time: 0.08771672705188394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17643706 . Total output tokens: 15545818
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.303047341760248,
    "estimated_duration": 3600.0067630353137,
    "input_throughput": 1818.6310279261488,
    "output_throughput": 1581.500917848179,
    "total_throughput": 3400.1319457743275,
    "itl": 39.48851842440425,
    "ttft": 10903.288193592856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.23956367936509,
    "arrivals": 26579,
    "finished_requests": 26499,
    "scheduler_time": 6.580196280312577
}
#Debug simulation 
Total elapsed time: 2.3031489648856223. Arrivals time: 0.07496055262163281 Scheduler time: 1.788876619655639 Scheduler overhead time: 0.08871416049078107 Adapter cache time: 0.21739577036350965 Engine time: 0.08910836419090629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16884211 . Total output tokens: 14844540
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.2615312188863754,
    "estimated_duration": 3599.925793479723,
    "input_throughput": 1732.2045946876055,
    "output_throughput": 1524.3975333990202,
    "total_throughput": 3256.6021280866257,
    "itl": 37.39730433715919,
    "ttft": 6725.8611356165875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8689,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.45522207861733,
    "arrivals": 25398,
    "finished_requests": 25351,
    "scheduler_time": 4.9110240480221155
}
#Debug simulation 
Total elapsed time: 2.261623769067228. Arrivals time: 0.07336573023349047 Scheduler time: 1.7567551005631685 Scheduler overhead time: 0.09190033376216888 Adapter cache time: 0.20561948465183377 Engine time: 0.08998365001752973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16884211 . Total output tokens: 14844540
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.241761944722384,
    "estimated_duration": 3599.9500690135524,
    "input_throughput": 1732.1929139169192,
    "output_throughput": 1524.3872539331437,
    "total_throughput": 3256.580167850063,
    "itl": 37.5208431661265,
    "ttft": 6726.241214620077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.52879513350096,
    "arrivals": 25398,
    "finished_requests": 25351,
    "scheduler_time": 4.962833910968462
}
#Debug simulation 
Total elapsed time: 2.241863981820643. Arrivals time: 0.0720791295170784 Scheduler time: 1.7390147182159126 Scheduler overhead time: 0.0913557717576623 Adapter cache time: 0.20331562077626586 Engine time: 0.0920828259550035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16884211 . Total output tokens: 14844540
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.2199949766509235,
    "estimated_duration": 3599.9420976664715,
    "input_throughput": 1732.1967495094243,
    "output_throughput": 1524.3906293818472,
    "total_throughput": 3256.5873788912713,
    "itl": 37.43880694141427,
    "ttft": 6726.111705844146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.51489111573178,
    "arrivals": 25398,
    "finished_requests": 25351,
    "scheduler_time": 4.9286118324934325
}
#Debug simulation 
Total elapsed time: 2.2200894029811025. Arrivals time: 0.07194075873121619 Scheduler time: 1.7217528214678168 Scheduler overhead time: 0.0909920958802104 Adapter cache time: 0.20266567915678024 Engine time: 0.08858796069398522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16884211 . Total output tokens: 14844540
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.2661742260679603,
    "estimated_duration": 3599.928313304395,
    "input_throughput": 1732.2033822046071,
    "output_throughput": 1524.3964663737406,
    "total_throughput": 3256.599848578348,
    "itl": 37.35221217692208,
    "ttft": 6725.738127446743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8685,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.44435336886137,
    "arrivals": 25398,
    "finished_requests": 25351,
    "scheduler_time": 4.893886780093286
}
#Debug simulation 
Total elapsed time: 2.266262970864773. Arrivals time: 0.07226426852867007 Scheduler time: 1.761463135946542 Scheduler overhead time: 0.09192736027762294 Adapter cache time: 0.20517657045274973 Engine time: 0.09106607036665082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15203161 . Total output tokens: 13422809
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.0808184021152556,
    "estimated_duration": 3599.970465356581,
    "input_throughput": 1566.0275700182958,
    "output_throughput": 1377.6190798578587,
    "total_throughput": 2943.6466498761542,
    "itl": 33.63127250994593,
    "ttft": 6166.358568188613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.188188395684676,
    "arrivals": 22982,
    "finished_requests": 22943,
    "scheduler_time": 1.8171472663630253
}
#Debug simulation 
Total elapsed time: 2.080931907054037. Arrivals time: 0.06685916054993868 Scheduler time: 1.5916636688634753 Scheduler overhead time: 0.0985828316770494 Adapter cache time: 0.17770556081086397 Engine time: 0.09813563525676727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15203161 . Total output tokens: 13422809
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.067843738012016,
    "estimated_duration": 3599.9633296956463,
    "input_throughput": 1566.0306741170687,
    "output_throughput": 1377.6218105030766,
    "total_throughput": 2943.652484620145,
    "itl": 33.682538074305356,
    "ttft": 6166.543562450614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.021542098371974,
    "arrivals": 22982,
    "finished_requests": 22943,
    "scheduler_time": 1.8351733925310068
}
#Debug simulation 
Total elapsed time: 2.0679401610977948. Arrivals time: 0.06762696197256446 Scheduler time: 1.5769331865012646 Scheduler overhead time: 0.09856423642486334 Adapter cache time: 0.17702228063717484 Engine time: 0.09995005605742335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15203161 . Total output tokens: 13422809
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.0600333311595023,
    "estimated_duration": 3599.9782374731544,
    "input_throughput": 1566.0241890676266,
    "output_throughput": 1377.6161056687451,
    "total_throughput": 2943.6402947363717,
    "itl": 33.398142968812046,
    "ttft": 6166.061261918879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.542434337792336,
    "arrivals": 22982,
    "finished_requests": 22943,
    "scheduler_time": 1.7489379941247851
}
#Debug simulation 
Total elapsed time: 2.060111897997558. Arrivals time: 0.06655382178723812 Scheduler time: 1.5699495910666883 Scheduler overhead time: 0.09930242039263248 Adapter cache time: 0.17880322178825736 Engine time: 0.09702789783477783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15203161 . Total output tokens: 13422809
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.0710117407143116,
    "estimated_duration": 3599.9644614101294,
    "input_throughput": 1566.2393505383106,
    "output_throughput": 1377.715822799329,
    "total_throughput": 2943.9551733376397,
    "itl": 33.355715133476245,
    "ttft": 6009.227028777435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.979778421059216,
    "arrivals": 22982,
    "finished_requests": 22944,
    "scheduler_time": 1.7358263934629898
}
#Debug simulation 
Total elapsed time: 2.0711050210520625. Arrivals time: 0.067147770896554 Scheduler time: 1.5775071154348552 Scheduler overhead time: 0.09921803139150143 Adapter cache time: 0.1793209183961153 Engine time: 0.09970125695690513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11177912 . Total output tokens: 9909804
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.6982558071613312,
    "estimated_duration": 3599.8062947501794,
    "input_throughput": 1176.6727576918015,
    "output_throughput": 1031.7449595597618,
    "total_throughput": 2208.4177172515633,
    "itl": 29.01733804984754,
    "ttft": 8701.945778256455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.05847753670022,
    "arrivals": 17062,
    "finished_requests": 17021,
    "scheduler_time": 0.0207904076731704
}
#Debug simulation 
Total elapsed time: 1.6983519801869988. Arrivals time: 0.054353686049580574 Scheduler time: 1.2087965491227806 Scheduler overhead time: 0.10895909368991852 Adapter cache time: 0.16247413866221905 Engine time: 0.10972726717591286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11177912 . Total output tokens: 9909804
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.6956475679762661,
    "estimated_duration": 3599.821847432992,
    "input_throughput": 1176.6676739907325,
    "output_throughput": 1031.7405020052552,
    "total_throughput": 2208.4081759959877,
    "itl": 29.091075049378052,
    "ttft": 8702.28919714062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.10604917508334,
    "arrivals": 17062,
    "finished_requests": 17021,
    "scheduler_time": 0.021847020293981757
}
#Debug simulation 
Total elapsed time: 1.695723163895309. Arrivals time: 0.05291903857141733 Scheduler time: 1.2109718914143741 Scheduler overhead time: 0.10886128852143884 Adapter cache time: 0.16084528993815184 Engine time: 0.10883021494373679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11177912 . Total output tokens: 9909804
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.6918826308101416,
    "estimated_duration": 3599.814529988184,
    "input_throughput": 1176.670065836393,
    "output_throughput": 1031.742599253354,
    "total_throughput": 2208.412665089747,
    "itl": 29.04403955148236,
    "ttft": 8702.225710131612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.216254007864876,
    "arrivals": 17062,
    "finished_requests": 17021,
    "scheduler_time": 0.02116540733700407
}
#Debug simulation 
Total elapsed time: 1.6919698151759803. Arrivals time: 0.052796974778175354 Scheduler time: 1.2067491807974875 Scheduler overhead time: 0.10949238296598196 Adapter cache time: 0.1620844155550003 Engine time: 0.10731574194505811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11177912 . Total output tokens: 9909804
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.6866558818146586,
    "estimated_duration": 3599.8070830219667,
    "input_throughput": 1176.6725000285667,
    "output_throughput": 1031.7447336322539,
    "total_throughput": 2208.417233660821,
    "itl": 28.989752008035,
    "ttft": 8701.753467700799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.093237717129945,
    "arrivals": 17062,
    "finished_requests": 17021,
    "scheduler_time": 0.020439301491572578
}
#Debug simulation 
Total elapsed time: 1.686748243868351. Arrivals time: 0.0528235430829227 Scheduler time: 1.201503629796207 Scheduler overhead time: 0.10975176515057683 Adapter cache time: 0.16169372340664268 Engine time: 0.10740680294111371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10371118 . Total output tokens: 9223265
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.6100112721323967,
    "estimated_duration": 3599.878379679789,
    "input_throughput": 1079.8128686630153,
    "output_throughput": 955.2053256604373,
    "total_throughput": 2035.0181943234525,
    "itl": 27.798916233161627,
    "ttft": 7292.16748731707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.270585933236106,
    "arrivals": 15904,
    "finished_requests": 15872,
    "scheduler_time": 0.00258717761055528
}
#Debug simulation 
Total elapsed time: 1.6100872880779207. Arrivals time: 0.0505018993280828 Scheduler time: 1.1278453059494495 Scheduler overhead time: 0.11232764646410942 Adapter cache time: 0.15022831549867988 Engine time: 0.11390855768695474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10371118 . Total output tokens: 9223265
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.594865437131375,
    "estimated_duration": 3599.8662933253663,
    "input_throughput": 1079.8164940757326,
    "output_throughput": 955.2085327101362,
    "total_throughput": 2035.025026785869,
    "itl": 27.8574120677385,
    "ttft": 7292.840405936199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.37380759005726,
    "arrivals": 15904,
    "finished_requests": 15872,
    "scheduler_time": 0.0026992647517077406
}
#Debug simulation 
Total elapsed time: 1.5949960802681744. Arrivals time: 0.05012038629502058 Scheduler time: 1.1175271845422685 Scheduler overhead time: 0.11181940138339996 Adapter cache time: 0.1486055883578956 Engine time: 0.11185909155756235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10371118 . Total output tokens: 9223265
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.603527665603906,
    "estimated_duration": 3599.853317314244,
    "input_throughput": 1079.8203863762244,
    "output_throughput": 955.2119758494678,
    "total_throughput": 2035.032362225692,
    "itl": 27.821184476265604,
    "ttft": 7292.274482236615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.96545124745638,
    "arrivals": 15904,
    "finished_requests": 15872,
    "scheduler_time": 0.0026237060049304067
}
#Debug simulation 
Total elapsed time: 1.6036238055676222. Arrivals time: 0.049835991114377975 Scheduler time: 1.1235258518718183 Scheduler overhead time: 0.112866569776088 Adapter cache time: 0.1498886300250888 Engine time: 0.11185746733099222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10371118 . Total output tokens: 9223265
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.6148120947182178,
    "estimated_duration": 3599.8570060673283,
    "input_throughput": 1079.8192798903906,
    "output_throughput": 955.2109970491665,
    "total_throughput": 2035.030276939557,
    "itl": 27.77969134015155,
    "ttft": 7292.124918410093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.58347110334829,
    "arrivals": 15904,
    "finished_requests": 15872,
    "scheduler_time": 0.0025410167500834846
}
#Debug simulation 
Total elapsed time: 1.614898193627596. Arrivals time: 0.050746978260576725 Scheduler time: 1.1310919234529138 Scheduler overhead time: 0.11185731319710612 Adapter cache time: 0.151367396581918 Engine time: 0.11463680816814303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8737358 . Total output tokens: 7776023
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.4412151910364628,
    "estimated_duration": 3599.6508564592204,
    "input_throughput": 898.1098803510097,
    "output_throughput": 807.8939085943947,
    "total_throughput": 1706.0037889454043,
    "itl": 25.924064065857408,
    "ttft": 5945.996627470033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.11189195965177,
    "arrivals": 13422,
    "finished_requests": 13400,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4412923660129309. Arrivals time: 0.044411858543753624 Scheduler time: 0.9673229400068521 Scheduler overhead time: 0.12173580843955278 Adapter cache time: 0.13010975159704685 Engine time: 0.11893981322646141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8737358 . Total output tokens: 7776023
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.4358883928507566,
    "estimated_duration": 3599.6568248213016,
    "input_throughput": 898.1083912521274,
    "output_throughput": 807.8925690768783,
    "total_throughput": 1706.0009603290057,
    "itl": 25.962474834431855,
    "ttft": 5946.345785267884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.79876637710141,
    "arrivals": 13422,
    "finished_requests": 13400,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4360009841620922. Arrivals time: 0.0462570870295167 Scheduler time: 0.9658542526885867 Scheduler overhead time: 0.1201571705751121 Adapter cache time: 0.12763170758262277 Engine time: 0.11749065527692437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8737358 . Total output tokens: 7776023
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.4496592688374221,
    "estimated_duration": 3599.648912467771,
    "input_throughput": 898.1103653755137,
    "output_throughput": 807.8943448977367,
    "total_throughput": 1706.0047102732503,
    "itl": 25.936075722136984,
    "ttft": 5946.1548879184475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.405747272233654,
    "arrivals": 13422,
    "finished_requests": 13400,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.449748070910573. Arrivals time: 0.045017491560429335 Scheduler time: 0.9799000262282789 Scheduler overhead time: 0.11813572095707059 Adapter cache time: 0.1286719716154039 Engine time: 0.1198828094638884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8737358 . Total output tokens: 7776023
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.4407393969595432,
    "estimated_duration": 3599.6469485422863,
    "input_throughput": 898.1108553740773,
    "output_throughput": 807.8947856754894,
    "total_throughput": 1706.0056410495667,
    "itl": 25.91064415017045,
    "ttft": 5945.917582857035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.8858523525518,
    "arrivals": 13422,
    "finished_requests": 13400,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.440809858031571. Arrivals time: 0.04417333472520113 Scheduler time: 0.9708434166386724 Scheduler overhead time: 0.11805206956341863 Adapter cache time: 0.12984064826741815 Engine time: 0.11952763190492988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548279 . Total output tokens: 4907718
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.0804820940829813,
    "estimated_duration": 3599.921965826309,
    "input_throughput": 587.2443958697739,
    "output_throughput": 497.89079236015834,
    "total_throughput": 1085.1351882299323,
    "itl": 22.857941512216676,
    "ttft": 5511.869484488187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.306196829599426,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.080557859968394. Arrivals time: 0.03316354472190142 Scheduler time: 0.6357950903475285 Scheduler overhead time: 0.126180621329695 Adapter cache time: 0.09381467010825872 Engine time: 0.12793494760990143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548279 . Total output tokens: 4907718
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.094625968951732,
    "estimated_duration": 3599.944579471676,
    "input_throughput": 587.2407069972875,
    "output_throughput": 497.88766477706326,
    "total_throughput": 1085.1283717743509,
    "itl": 22.881829256872884,
    "ttft": 5512.1010494178545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.4576433446202,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0946954847313464. Arrivals time: 0.03346885647624731 Scheduler time: 0.6470280638895929 Scheduler overhead time: 0.12664841208606958 Adapter cache time: 0.09484429052099586 Engine time: 0.12935833679512143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548279 . Total output tokens: 4907718
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.099007103126496,
    "estimated_duration": 3599.9315486238775,
    "input_throughput": 587.2428326611149,
    "output_throughput": 497.88946700532597,
    "total_throughput": 1085.132299666441,
    "itl": 22.863588052649224,
    "ttft": 5511.949075372772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.366151521765595,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0990646709688008. Arrivals time: 0.03331955894827843 Scheduler time: 0.643699983600527 Scheduler overhead time: 0.13250947883352637 Adapter cache time: 0.09553000051528215 Engine time: 0.13015592098236084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548279 . Total output tokens: 4907718
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.0897524659521878,
    "estimated_duration": 3599.940939174852,
    "input_throughput": 587.2413008210522,
    "output_throughput": 497.8881682461245,
    "total_throughput": 1085.1294690671766,
    "itl": 22.848675778848342,
    "ttft": 5511.702388265184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.29353760861127,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.089830833952874. Arrivals time: 0.033566566184163094 Scheduler time: 0.640192047227174 Scheduler overhead time: 0.12735660234466195 Adapter cache time: 0.09427132876589894 Engine time: 0.13066722732037306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_384_slots_16_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_384_slots_16_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1726659822 . Total output tokens: 1520242460
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 80.78515880787745,
    "estimated_duration": 3600.036137703763,
    "input_throughput": 6638.172253249329,
    "output_throughput": 5813.829417098555,
    "total_throughput": 12452.001670347883,
    "itl": 75.79678689870575,
    "ttft": 2134833.9284610674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 725,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.793996548163792,
    "arrivals": 2579962,
    "finished_requests": 97013,
    "scheduler_time": 331.12562953047654
}
#Debug simulation 
Total elapsed time: 80.78533634077758. Arrivals time: 0.543973536696285 Scheduler time: 80.01810615276918 Scheduler overhead time: 0.08752844342961907 Adapter cache time: 0.019846800714731216 Engine time: 0.0820632977411151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_384_slots_16_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_384_slots_16_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1726659822 . Total output tokens: 1520242460
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 79.20237375516444,
    "estimated_duration": 3600.057182477262,
    "input_throughput": 6530.709321628531,
    "output_throughput": 5722.516047876726,
    "total_throughput": 12253.225369505257,
    "itl": 73.34219011181904,
    "ttft": 2143548.6883606077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.1559045625059,
    "arrivals": 2579962,
    "finished_requests": 95430,
    "scheduler_time": 335.9670340972288
}
#Debug simulation 
Total elapsed time: 79.20254456112161. Arrivals time: 0.5437191938981414 Scheduler time: 78.43608692334965 Scheduler overhead time: 0.08795556891709566 Adapter cache time: 0.019989609718322754 Engine time: 0.08123824605718255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_384_slots_16_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_384_slots_16_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1726659822 . Total output tokens: 1520242460
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 79.35725424997509,
    "estimated_duration": 3600.0555347684112,
    "input_throughput": 6515.307548306716,
    "output_throughput": 5706.706133165695,
    "total_throughput": 12222.013681472412,
    "itl": 73.13462685298455,
    "ttft": 2144187.2867165217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 709,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.324366519199715,
    "arrivals": 2579962,
    "finished_requests": 95180,
    "scheduler_time": 336.59536654317503
}
#Debug simulation 
Total elapsed time: 79.35743158403784. Arrivals time: 0.5599838537164032 Scheduler time: 78.5733169191517 Scheduler overhead time: 0.08824708731845021 Adapter cache time: 0.02051442675292492 Engine time: 0.08125308947637677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_384_slots_16_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_384_slots_16_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1726659822 . Total output tokens: 1520242460
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 77.34982835734263,
    "estimated_duration": 3600.0017416942346,
    "input_throughput": 6400.577458930873,
    "output_throughput": 5610.261174622349,
    "total_throughput": 12010.838633553221,
    "itl": 71.20902384838433,
    "ttft": 2152181.3097167555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.697272368120023,
    "arrivals": 2579962,
    "finished_requests": 93545,
    "scheduler_time": 341.9721361015541
}
#Debug simulation 
Total elapsed time: 77.35000235307962. Arrivals time: 0.5259909620508552 Scheduler time: 76.6000566049479 Scheduler overhead time: 0.08790391450747848 Adapter cache time: 0.020057492423802614 Engine time: 0.08191545912995934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_384_slots_16_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_384_slots_16_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1726659822 . Total output tokens: 1520242460
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 79.72667034901679,
    "estimated_duration": 3600.0062860254457,
    "input_throughput": 6515.396678902969,
    "output_throughput": 5706.784201947026,
    "total_throughput": 12222.180880849995,
    "itl": 73.13382163445077,
    "ttft": 2144166.7372154985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 709,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.275693982695261,
    "arrivals": 2579962,
    "finished_requests": 95180,
    "scheduler_time": 336.5949925991572
}
#Debug simulation 
Total elapsed time: 79.72684318991378. Arrivals time: 0.5621743402443826 Scheduler time: 78.93965103151277 Scheduler overhead time: 0.0888274279423058 Adapter cache time: 0.020140670705586672 Engine time: 0.08184177055954933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_384_slots_16_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_384_slots_16_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1726659822 . Total output tokens: 1520242460
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 79.8574567171745,
    "estimated_duration": 3600.0535997913153,
    "input_throughput": 6583.468090967832,
    "output_throughput": 5771.39212627401,
    "total_throughput": 12354.860217241841,
    "itl": 74.37445946435766,
    "ttft": 2131688.1781748766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 714,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.558119551567339,
    "arrivals": 2579962,
    "finished_requests": 96218,
    "scheduler_time": 333.54657263263533
}
#Debug simulation 
Total elapsed time: 79.85764067713171. Arrivals time: 0.5533313504420221 Scheduler time: 79.08027591230348 Scheduler overhead time: 0.08777836943045259 Adapter cache time: 0.020735611207783222 Engine time: 0.08167770737782121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_384_slots_16_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_384_slots_16_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1726659822 . Total output tokens: 1520242460
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 79.77166073489934,
    "estimated_duration": 3600.0509389331005,
    "input_throughput": 6515.516140710887,
    "output_throughput": 5706.867027300634,
    "total_throughput": 12222.383168011522,
    "itl": 73.13312154018867,
    "ttft": 2144144.6741647734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 709,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.226192977484348,
    "arrivals": 2579962,
    "finished_requests": 95182,
    "scheduler_time": 336.6027114282679
}
#Debug simulation 
Total elapsed time: 79.7718287431635. Arrivals time: 0.5775799565017223 Scheduler time: 78.96876179473475 Scheduler overhead time: 0.08939264109358191 Adapter cache time: 0.01998347882181406 Engine time: 0.08179091988131404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_384_slots_16_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_384_slots_16_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1603616705 . Total output tokens: 1411485711
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 81.92343949899077,
    "estimated_duration": 3600.0376852438067,
    "input_throughput": 6671.882102360089,
    "output_throughput": 5843.320498067331,
    "total_throughput": 12515.202600427421,
    "itl": 76.9892913698815,
    "ttft": 2118167.0860693273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.674973185588689,
    "arrivals": 2395765,
    "finished_requests": 97379,
    "scheduler_time": 329.64981236074374
}
#Debug simulation 
Total elapsed time: 81.9236116008833. Arrivals time: 0.5694594029337168 Scheduler time: 81.13049448141828 Scheduler overhead time: 0.087899976875633 Adapter cache time: 0.01989306788891554 Engine time: 0.08217698847874999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_384_slots_16_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_384_slots_16_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1603616705 . Total output tokens: 1411485711
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 80.98083837004378,
    "estimated_duration": 3600.0081991320594,
    "input_throughput": 6603.487182537927,
    "output_throughput": 5788.643205041643,
    "total_throughput": 12392.130387579571,
    "itl": 75.95481802137722,
    "ttft": 2125197.9714446412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.03210747580976,
    "arrivals": 2395765,
    "finished_requests": 96429,
    "scheduler_time": 332.9248803095151
}
#Debug simulation 
Total elapsed time: 80.98100915597752. Arrivals time: 0.5478513306006789 Scheduler time: 80.20846501458436 Scheduler overhead time: 0.08823924418538809 Adapter cache time: 0.020365365780889988 Engine time: 0.08234731806442142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_384_slots_16_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_384_slots_16_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1603616705 . Total output tokens: 1411485711
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 80.92110311985016,
    "estimated_duration": 3600.0186897303756,
    "input_throughput": 6590.365507734884,
    "output_throughput": 5767.545335036877,
    "total_throughput": 12357.910842771762,
    "itl": 75.04765224948028,
    "ttft": 2123273.4377064467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.182882769862222,
    "arrivals": 2395765,
    "finished_requests": 96125,
    "scheduler_time": 333.8473775478869
}
#Debug simulation 
Total elapsed time: 80.92127286083996. Arrivals time: 0.5746441227383912 Scheduler time: 80.12127600703388 Scheduler overhead time: 0.0886814221739769 Adapter cache time: 0.020402053371071815 Engine time: 0.08234008215367794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_384_slots_16_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_384_slots_16_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1603616705 . Total output tokens: 1411485711
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 81.50533264316618,
    "estimated_duration": 3600.0306056564596,
    "input_throughput": 6596.030867818128,
    "output_throughput": 5779.126146125149,
    "total_throughput": 12375.157013943277,
    "itl": 75.70307639468166,
    "ttft": 2126354.0361216515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 689,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.726141677754924,
    "arrivals": 2395765,
    "finished_requests": 96302,
    "scheduler_time": 333.2908445506065
}
#Debug simulation 
Total elapsed time: 81.505500363186. Arrivals time: 0.5550089166499674 Scheduler time: 80.72609471483156 Scheduler overhead time: 0.08845848217606544 Adapter cache time: 0.020186524372547865 Engine time: 0.08192856842651963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_384_slots_16_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_384_slots_16_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1603616705 . Total output tokens: 1411485711
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 80.4030279610306,
    "estimated_duration": 3600.0466044503246,
    "input_throughput": 6590.404960499834,
    "output_throughput": 5767.651722711611,
    "total_throughput": 12358.056683211444,
    "itl": 75.04686931965871,
    "ttft": 2123251.844466179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.1360742879473,
    "arrivals": 2395765,
    "finished_requests": 96127,
    "scheduler_time": 333.8541726795777
}
#Debug simulation 
Total elapsed time: 80.40320021379739. Arrivals time: 0.5708369188942015 Scheduler time: 79.60688613448292 Scheduler overhead time: 0.08885761490091681 Adapter cache time: 0.02014532359316945 Engine time: 0.08233895990997553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_384_slots_16_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_384_slots_16_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1603616705 . Total output tokens: 1411485711
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 82.1088959868066,
    "estimated_duration": 3600.0145490969353,
    "input_throughput": 6677.831900993432,
    "output_throughput": 5849.321082683489,
    "total_throughput": 12527.152983676922,
    "itl": 77.40850487554275,
    "ttft": 2111335.831606399,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 715,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.564503472507909,
    "arrivals": 2395765,
    "finished_requests": 97482,
    "scheduler_time": 329.5312945248225
}
#Debug simulation 
Total elapsed time: 82.10906434385106. Arrivals time: 0.5696844011545181 Scheduler time: 81.31397295696661 Scheduler overhead time: 0.08877838589251041 Adapter cache time: 0.020479854196310043 Engine time: 0.0827832748182118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_384_slots_16_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_384_slots_16_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1603616705 . Total output tokens: 1411485711
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 80.77190195862204,
    "estimated_duration": 3600.071633010291,
    "input_throughput": 6590.403308214445,
    "output_throughput": 5767.621902189147,
    "total_throughput": 12358.025210403592,
    "itl": 75.04589828650258,
    "ttft": 2123230.7377319867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.087194634266231,
    "arrivals": 2395765,
    "finished_requests": 96128,
    "scheduler_time": 333.86096187282595
}
#Debug simulation 
Total elapsed time: 80.77207628870383. Arrivals time: 0.7227765382267535 Scheduler time: 79.82307245302945 Scheduler overhead time: 0.08882431732490659 Adapter cache time: 0.020179636776447296 Engine time: 0.08335391618311405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_384_slots_16_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_384_slots_16_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1510742719 . Total output tokens: 1330273881
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 81.01939073204994,
    "estimated_duration": 3600.052889777584,
    "input_throughput": 6506.803015732144,
    "output_throughput": 5682.571513904591,
    "total_throughput": 12189.374529636734,
    "itl": 78.50400891987493,
    "ttft": 2142659.848088296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.046794327553425,
    "arrivals": 2257312,
    "finished_requests": 94843,
    "scheduler_time": 338.01426269919835
}
#Debug simulation 
Total elapsed time: 81.01956036593765. Arrivals time: 0.7355275992304087 Scheduler time: 80.05666056741029 Scheduler overhead time: 0.08953115483745933 Adapter cache time: 0.019751303363591433 Engine time: 0.0836437321268022 
