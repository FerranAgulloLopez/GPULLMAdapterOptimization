INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3441771 . Total output tokens: 3085118
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8292003609240055,
    "estimated_duration": 3599.6800432687733,
    "input_throughput": 359.9389346902735,
    "output_throughput": 313.59064873303106,
    "total_throughput": 673.5295834233046,
    "itl": 21.142268617398205,
    "ttft": 6936.664989118222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8292952009942383. Arrivals time: 0.024985118652693927 Scheduler time: 0.4350373612251133 Scheduler overhead time: 0.13300971139688045 Adapter cache time: 0.031824866659007967 Engine time: 0.13758264703210443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3441771 . Total output tokens: 3085118
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8212638560216874,
    "estimated_duration": 3599.6948742701297,
    "input_throughput": 359.93745171601734,
    "output_throughput": 313.5893567170411,
    "total_throughput": 673.5268084330585,
    "itl": 21.029193011387623,
    "ttft": 6936.621300614172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8213636999716982. Arrivals time: 0.024422919028438628 Scheduler time: 0.43227669049520046 Scheduler overhead time: 0.13338064774870872 Adapter cache time: 0.03202241368126124 Engine time: 0.1325090159662068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3441771 . Total output tokens: 3085118
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8263554819859564,
    "estimated_duration": 3599.6948742701297,
    "input_throughput": 359.93745171601734,
    "output_throughput": 313.5893567170411,
    "total_throughput": 673.5268084330585,
    "itl": 21.02914992223279,
    "ttft": 6936.59567497435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8264424820663407. Arrivals time: 0.024688832345418632 Scheduler time: 0.4360694548813626 Scheduler overhead time: 0.13348883856087923 Adapter cache time: 0.03246223495807499 Engine time: 0.13301209639757872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3441771 . Total output tokens: 3085118
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8197582479333505,
    "estimated_duration": 3599.6800432687733,
    "input_throughput": 359.9389346902735,
    "output_throughput": 313.59064873303106,
    "total_throughput": 673.5295834233046,
    "itl": 21.142271893876202,
    "ttft": 6936.614354713633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8198182109044865. Arrivals time: 0.024631212116219103 Scheduler time: 0.4322942189173773 Scheduler overhead time: 0.13120707869529724 Adapter cache time: 0.03107967448886484 Engine time: 0.13429952564183623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3441771 . Total output tokens: 3085118
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8325641010887921,
    "estimated_duration": 3599.6948742701297,
    "input_throughput": 359.93745171601734,
    "output_throughput": 313.5893567170411,
    "total_throughput": 673.5268084330585,
    "itl": 21.029173203902506,
    "ttft": 6936.549383389496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8326221751049161. Arrivals time: 0.024813794065266848 Scheduler time: 0.43909550830721855 Scheduler overhead time: 0.13452888617757708 Adapter cache time: 0.03230209869798273 Engine time: 0.13491259736474603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3441771 . Total output tokens: 3085118
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8274115759413689,
    "estimated_duration": 3599.6800432687733,
    "input_throughput": 359.9389346902735,
    "output_throughput": 313.59064873303106,
    "total_throughput": 673.5295834233046,
    "itl": 21.142140063287094,
    "ttft": 6936.632513843564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8275618189945817. Arrivals time: 0.024908299441449344 Scheduler time: 0.4385458566248417 Scheduler overhead time: 0.1322529335739091 Adapter cache time: 0.03134910936933011 Engine time: 0.13391749328002334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3441771 . Total output tokens: 3085118
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8255517389625311,
    "estimated_duration": 3599.6948742701297,
    "input_throughput": 359.93745171601734,
    "output_throughput": 313.5893567170411,
    "total_throughput": 673.5268084330585,
    "itl": 21.029187597200814,
    "ttft": 6936.587071468176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8256169939413667. Arrivals time: 0.024703681701794267 Scheduler time: 0.43490916688460857 Scheduler overhead time: 0.13252982404083014 Adapter cache time: 0.03164484805893153 Engine time: 0.13471615745220333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3359563 . Total output tokens: 3023723
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8195343689294532,
    "estimated_duration": 3599.3945245992863,
    "input_throughput": 343.4833251955448,
    "output_throughput": 310.0968766751847,
    "total_throughput": 653.5802018707295,
    "itl": 20.997844721659625,
    "ttft": 6382.52936222013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 5104,
    "finished_requests": 5095,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8195868970360607. Arrivals time: 0.024764822097495198 Scheduler time: 0.4296390370000154 Scheduler overhead time: 0.1337691016960889 Adapter cache time: 0.031219086842611432 Engine time: 0.13344239676371217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3359563 . Total output tokens: 3023723
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8268943770090118,
    "estimated_duration": 3599.3945245992863,
    "input_throughput": 343.4833251955448,
    "output_throughput": 310.0968766751847,
    "total_throughput": 653.5802018707295,
    "itl": 20.99796239245859,
    "ttft": 6382.574999312339,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 5104,
    "finished_requests": 5095,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8269696359056979. Arrivals time: 0.02427518740296364 Scheduler time: 0.43682355200871825 Scheduler overhead time: 0.1331804117653519 Adapter cache time: 0.031297692796215415 Engine time: 0.13465068384539336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3359563 . Total output tokens: 3023723
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8318176900502294,
    "estimated_duration": 3599.3945245992863,
    "input_throughput": 343.4833251955448,
    "output_throughput": 310.0968766751847,
    "total_throughput": 653.5802018707295,
    "itl": 20.998051646348795,
    "ttft": 6382.563577484276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 5104,
    "finished_requests": 5095,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8318752889754251. Arrivals time: 0.02452431747224182 Scheduler time: 0.4402889298507944 Scheduler overhead time: 0.1333832403179258 Adapter cache time: 0.03140682727098465 Engine time: 0.13550652982667089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3359563 . Total output tokens: 3023723
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8290099280420691,
    "estimated_duration": 3599.3945245992863,
    "input_throughput": 343.4833251955448,
    "output_throughput": 310.0968766751847,
    "total_throughput": 653.5802018707295,
    "itl": 20.99792623281142,
    "ttft": 6382.5012967794055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 5104,
    "finished_requests": 5095,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8290877440012991. Arrivals time: 0.024809182505123317 Scheduler time: 0.43773320072796196 Scheduler overhead time: 0.13343888043891639 Adapter cache time: 0.03132600977551192 Engine time: 0.1350925089791417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3359563 . Total output tokens: 3023723
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8353637050604448,
    "estimated_duration": 3599.3945245992863,
    "input_throughput": 343.4833251955448,
    "output_throughput": 310.0968766751847,
    "total_throughput": 653.5802018707295,
    "itl": 20.997980936720754,
    "ttft": 6382.538603664232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861723,
    "arrivals": 5104,
    "finished_requests": 5095,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8354364670813084. Arrivals time: 0.02485805528704077 Scheduler time: 0.4427628576522693 Scheduler overhead time: 0.13330265157856047 Adapter cache time: 0.03138005512300879 Engine time: 0.136150618433021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3359563 . Total output tokens: 3023723
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8321900779847056,
    "estimated_duration": 3599.3945245992863,
    "input_throughput": 343.4833251955448,
    "output_throughput": 310.0968766751847,
    "total_throughput": 653.5802018707295,
    "itl": 20.998383555538783,
    "ttft": 6382.48831726866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 5104,
    "finished_requests": 5095,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8322448719991371. Arrivals time: 0.0247688494855538 Scheduler time: 0.44207666942384094 Scheduler overhead time: 0.13241072767414153 Adapter cache time: 0.03113045881036669 Engine time: 0.13504871260374784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3359563 . Total output tokens: 3023723
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8291572850430384,
    "estimated_duration": 3599.3945245992863,
    "input_throughput": 343.4833251955448,
    "output_throughput": 310.0968766751847,
    "total_throughput": 653.5802018707295,
    "itl": 20.997967606765847,
    "ttft": 6382.56784156146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2367897061258555,
    "arrivals": 5104,
    "finished_requests": 5095,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8293747450225055. Arrivals time: 0.02451755339279771 Scheduler time: 0.43490141071379185 Scheduler overhead time: 0.13463428709656 Adapter cache time: 0.031793428119271994 Engine time: 0.13604378991294652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3094296 . Total output tokens: 2810286
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7956624830840155,
    "estimated_duration": 3598.872779674228,
    "input_throughput": 310.6278183307146,
    "output_throughput": 284.98117682638366,
    "total_throughput": 595.6089951570983,
    "itl": 20.783411062674787,
    "ttft": 5399.44495639933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7957137550693005. Arrivals time: 0.02358244394417852 Scheduler time: 0.4064152694772929 Scheduler overhead time: 0.13367782509885728 Adapter cache time: 0.030631543369963765 Engine time: 0.13443706755060703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3094296 . Total output tokens: 2810286
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.795341387973167,
    "estimated_duration": 3598.872779674228,
    "input_throughput": 310.6278183307146,
    "output_throughput": 284.98117682638366,
    "total_throughput": 595.6089951570983,
    "itl": 20.7834591072607,
    "ttft": 5399.469679399364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7953925000037998. Arrivals time: 0.0234712699893862 Scheduler time: 0.40690521139185876 Scheduler overhead time: 0.13358796737156808 Adapter cache time: 0.030477126012556255 Engine time: 0.1340595808578655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3094296 . Total output tokens: 2810286
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8028380949981511,
    "estimated_duration": 3598.872779674228,
    "input_throughput": 310.6278183307146,
    "output_throughput": 284.98117682638366,
    "total_throughput": 595.6089951570983,
    "itl": 20.78347406685003,
    "ttft": 5399.4337954824805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8029147300403565. Arrivals time: 0.023798508569598198 Scheduler time: 0.4122158717364073 Scheduler overhead time: 0.13358741579577327 Adapter cache time: 0.030929885688237846 Engine time: 0.13514776900410652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3094296 . Total output tokens: 2810286
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8126212380593643,
    "estimated_duration": 3598.872779674228,
    "input_throughput": 310.6278183307146,
    "output_throughput": 284.98117682638366,
    "total_throughput": 595.6089951570983,
    "itl": 20.783343522670716,
    "ttft": 5399.4825962285695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8126729419454932. Arrivals time: 0.024213517317548394 Scheduler time: 0.41618032893165946 Scheduler overhead time: 0.13373040070291609 Adapter cache time: 0.03093277884181589 Engine time: 0.13978045957628638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3094296 . Total output tokens: 2810286
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7908048760145903,
    "estimated_duration": 3598.872779674228,
    "input_throughput": 310.6278183307146,
    "output_throughput": 284.98117682638366,
    "total_throughput": 595.6089951570983,
    "itl": 20.78342942777501,
    "ttft": 5399.371171309626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861723,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7908805609913543. Arrivals time: 0.02335847495123744 Scheduler time: 0.4030589999165386 Scheduler overhead time: 0.1333097704919055 Adapter cache time: 0.03061591845471412 Engine time: 0.13328256749082357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3094296 . Total output tokens: 2810286
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8089712780201808,
    "estimated_duration": 3598.872779674228,
    "input_throughput": 310.6278183307146,
    "output_throughput": 284.98117682638366,
    "total_throughput": 595.6089951570983,
    "itl": 20.783321314629518,
    "ttft": 5399.401010837291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8090404310496524. Arrivals time: 0.023488730541430414 Scheduler time: 0.40891928249038756 Scheduler overhead time: 0.14054923842195421 Adapter cache time: 0.031064522569067776 Engine time: 0.13727095327340066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3094296 . Total output tokens: 2810286
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7933888100087643,
    "estimated_duration": 3598.872779674228,
    "input_throughput": 310.6278183307146,
    "output_throughput": 284.98117682638366,
    "total_throughput": 595.6089951570983,
    "itl": 20.783427624222515,
    "ttft": 5399.4266913196525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2367897061258555,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7936672699870542. Arrivals time: 0.023429080145433545 Scheduler time: 0.4050289742881432 Scheduler overhead time: 0.13282069633714855 Adapter cache time: 0.03075507248286158 Engine time: 0.1340304403565824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3025817 . Total output tokens: 2745069
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8422996900044382,
    "estimated_duration": 3598.2666461723616,
    "input_throughput": 300.5174730867353,
    "output_throughput": 280.1954660787818,
    "total_throughput": 580.7129391655171,
    "itl": 20.74925782486521,
    "ttft": 7913.550530424782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.842360656009987. Arrivals time: 0.025251249666325748 Scheduler time: 0.4445241817738861 Scheduler overhead time: 0.13750312791671604 Adapter cache time: 0.03022738138679415 Engine time: 0.13585692748893052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3025817 . Total output tokens: 2745069
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7958617890253663,
    "estimated_duration": 3598.2666461723616,
    "input_throughput": 300.5174730867353,
    "output_throughput": 280.1954660787818,
    "total_throughput": 580.7129391655171,
    "itl": 20.74948078058007,
    "ttft": 7913.491164298124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7959536929847673. Arrivals time: 0.023638448561541736 Scheduler time: 0.4036584962159395 Scheduler overhead time: 0.13382644939702004 Adapter cache time: 0.03027184389065951 Engine time: 0.13584666443057358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3025817 . Total output tokens: 2745069
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7868815109832212,
    "estimated_duration": 3598.2666461723616,
    "input_throughput": 300.5174730867353,
    "output_throughput": 280.1954660787818,
    "total_throughput": 580.7129391655171,
    "itl": 20.749486864410613,
    "ttft": 7913.560417961356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7869293689727783. Arrivals time: 0.023018195759505033 Scheduler time: 0.4002171214669943 Scheduler overhead time: 0.13296729954890907 Adapter cache time: 0.03011394082568586 Engine time: 0.13378012145403773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3025817 . Total output tokens: 2745069
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7864088770002127,
    "estimated_duration": 3598.2666461723616,
    "input_throughput": 300.5174730867353,
    "output_throughput": 280.1954660787818,
    "total_throughput": 580.7129391655171,
    "itl": 20.74940171564194,
    "ttft": 7913.498876446626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7864659720798954. Arrivals time: 0.023092218791134655 Scheduler time: 0.3995337984524667 Scheduler overhead time: 0.13308927626349032 Adapter cache time: 0.029892897699028254 Engine time: 0.1335600467864424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3025817 . Total output tokens: 2745069
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7926631059963256,
    "estimated_duration": 3598.2666461723616,
    "input_throughput": 300.5174730867353,
    "output_throughput": 280.1954660787818,
    "total_throughput": 580.7129391655171,
    "itl": 20.749500298233677,
    "ttft": 7913.549235986314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7927243480226025. Arrivals time: 0.023417856660671532 Scheduler time: 0.40197041910141706 Scheduler overhead time: 0.13550840981770307 Adapter cache time: 0.029994437587447464 Engine time: 0.1342366556636989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3025817 . Total output tokens: 2745069
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8030289899324998,
    "estimated_duration": 3598.2666461723616,
    "input_throughput": 300.5174730867353,
    "output_throughput": 280.1954660787818,
    "total_throughput": 580.7129391655171,
    "itl": 20.749298800113166,
    "ttft": 7913.488488409177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8031464479863644. Arrivals time: 0.023875564918853343 Scheduler time: 0.40531245328020304 Scheduler overhead time: 0.14018587081227452 Adapter cache time: 0.030482413712888956 Engine time: 0.13530347449705005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3025817 . Total output tokens: 2745069
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7838887620018795,
    "estimated_duration": 3598.2666461723616,
    "input_throughput": 300.5174730867353,
    "output_throughput": 280.1954660787818,
    "total_throughput": 580.7129391655171,
    "itl": 20.749484011480597,
    "ttft": 7913.534827439462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7840134990401566. Arrivals time: 0.023017618455924094 Scheduler time: 0.3981836496386677 Scheduler overhead time: 0.13298136659432203 Adapter cache time: 0.02982628275640309 Engine time: 0.1333514496218413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2852361 . Total output tokens: 2591608
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7692807780113071,
    "estimated_duration": 3599.0522246247815,
    "input_throughput": 285.69632665088614,
    "output_throughput": 255.283041939128,
    "total_throughput": 540.9793685900141,
    "itl": 20.66483809402835,
    "ttft": 5916.238987954522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 4284,
    "finished_requests": 4277,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7693524099886417. Arrivals time: 0.022729655727744102 Scheduler time: 0.37934233364649117 Scheduler overhead time: 0.13333294622134417 Adapter cache time: 0.02947846334427595 Engine time: 0.13723875756841153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2852361 . Total output tokens: 2591608
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8432237399974838,
    "estimated_duration": 3599.0522246247815,
    "input_throughput": 285.69632665088614,
    "output_throughput": 255.283041939128,
    "total_throughput": 540.9793685900141,
    "itl": 20.664955293716293,
    "ttft": 5916.235126364741,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2348263315111399,
    "arrivals": 4284,
    "finished_requests": 4277,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8432827170472592. Arrivals time: 0.0239971176488325 Scheduler time: 0.44352460431400687 Scheduler overhead time: 0.1390041298000142 Adapter cache time: 0.029378525912761688 Engine time: 0.13758732832502574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2852361 . Total output tokens: 2591608
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7628522660816088,
    "estimated_duration": 3599.0522246247815,
    "input_throughput": 285.69632665088614,
    "output_throughput": 255.283041939128,
    "total_throughput": 540.9793685900141,
    "itl": 20.664947176590783,
    "ttft": 5916.259816129968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2413462840113789,
    "arrivals": 4284,
    "finished_requests": 4277,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7629104220541194. Arrivals time: 0.022542447433806956 Scheduler time: 0.3744738711975515 Scheduler overhead time: 0.134566163062118 Adapter cache time: 0.029314996325410903 Engine time: 0.13473193882964551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2852361 . Total output tokens: 2591608
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8326437670039013,
    "estimated_duration": 3599.0522246247815,
    "input_throughput": 285.69632665088614,
    "output_throughput": 255.283041939128,
    "total_throughput": 540.9793685900141,
    "itl": 20.66480054022929,
    "ttft": 5916.296704306899,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 4284,
    "finished_requests": 4277,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8327101870672777. Arrivals time: 0.02410572487860918 Scheduler time: 0.4376999657833949 Scheduler overhead time: 0.1381201365729794 Adapter cache time: 0.02935371908824891 Engine time: 0.1341236358275637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2852361 . Total output tokens: 2591608
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7662521740421653,
    "estimated_duration": 3599.0522246247815,
    "input_throughput": 285.69632665088614,
    "output_throughput": 255.283041939128,
    "total_throughput": 540.9793685900141,
    "itl": 20.664913940385308,
    "ttft": 5916.240877805676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861717,
    "arrivals": 4284,
    "finished_requests": 4277,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7663043210050091. Arrivals time: 0.0226342884125188 Scheduler time: 0.3772351521765813 Scheduler overhead time: 0.13380616484209895 Adapter cache time: 0.029314960236661136 Engine time: 0.13597659498918802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2852361 . Total output tokens: 2591608
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7573077359702438,
    "estimated_duration": 3599.0522246247815,
    "input_throughput": 285.69632665088614,
    "output_throughput": 255.283041939128,
    "total_throughput": 540.9793685900141,
    "itl": 20.66483371134677,
    "ttft": 5916.3010551493435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 4284,
    "finished_requests": 4277,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7573716930346563. Arrivals time: 0.022292657755315304 Scheduler time: 0.3721561129204929 Scheduler overhead time: 0.13291393406689167 Adapter cache time: 0.0291313681518659 Engine time: 0.1339657735079527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2852361 . Total output tokens: 2591608
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7650012919912115,
    "estimated_duration": 3599.0522246247815,
    "input_throughput": 285.69632665088614,
    "output_throughput": 255.283041939128,
    "total_throughput": 540.9793685900141,
    "itl": 20.664948947441122,
    "ttft": 5916.247040846458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585545,
    "arrivals": 4284,
    "finished_requests": 4277,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7650725219864398. Arrivals time: 0.022570547414943576 Scheduler time: 0.37519325071480125 Scheduler overhead time: 0.13362853485159576 Adapter cache time: 0.029307190678082407 Engine time: 0.13702832674607635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2259751 . Total output tokens: 2045991
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7143046370474622,
    "estimated_duration": 3599.4188846215975,
    "input_throughput": 220.96539066294693,
    "output_throughput": 202.593258349441,
    "total_throughput": 423.5586490123879,
    "itl": 20.47818680985684,
    "ttft": 4388.051080305425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 3307,
    "finished_requests": 3303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.714351800037548. Arrivals time: 0.020984259666875005 Scheduler time: 0.3263311026385054 Scheduler overhead time: 0.1330956896999851 Adapter cache time: 0.029727263376116753 Engine time: 0.13661641778890043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2259751 . Total output tokens: 2045991
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7072270000353456,
    "estimated_duration": 3599.4188846215975,
    "input_throughput": 220.96539066294693,
    "output_throughput": 202.593258349441,
    "total_throughput": 423.5586490123879,
    "itl": 20.478259154825132,
    "ttft": 4388.081655154191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 3307,
    "finished_requests": 3303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7072753020329401. Arrivals time: 0.020481473999097943 Scheduler time: 0.32111810136120766 Scheduler overhead time: 0.13365081849042326 Adapter cache time: 0.029483142658136785 Engine time: 0.13526749750599265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2259751 . Total output tokens: 2045991
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7121425770455971,
    "estimated_duration": 3599.4188846215975,
    "input_throughput": 220.96539066294693,
    "output_throughput": 202.593258349441,
    "total_throughput": 423.5586490123879,
    "itl": 20.47828577180836,
    "ttft": 4388.068925493356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 3307,
    "finished_requests": 3303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.712244568974711. Arrivals time: 0.020520685706287622 Scheduler time: 0.32254630548413843 Scheduler overhead time: 0.1350273354910314 Adapter cache time: 0.0292971502058208 Engine time: 0.1376805145991966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2259751 . Total output tokens: 2045991
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7082169590285048,
    "estimated_duration": 3599.4188846215975,
    "input_throughput": 220.96539066294693,
    "output_throughput": 202.593258349441,
    "total_throughput": 423.5586490123879,
    "itl": 20.478178229280605,
    "ttft": 4388.076231819414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 3307,
    "finished_requests": 3303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7082731469999999. Arrivals time: 0.02043368632439524 Scheduler time: 0.32322149991523474 Scheduler overhead time: 0.13354096189141273 Adapter cache time: 0.02935405552852899 Engine time: 0.13442239456344396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2259751 . Total output tokens: 2045991
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7082013579783961,
    "estimated_duration": 3599.4188846215975,
    "input_throughput": 220.96539066294693,
    "output_throughput": 202.593258349441,
    "total_throughput": 423.5586490123879,
    "itl": 20.478278387855603,
    "ttft": 4388.076402172284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 3307,
    "finished_requests": 3303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7082576820394024. Arrivals time: 0.020925049553625286 Scheduler time: 0.3237841505324468 Scheduler overhead time: 0.13235110486857593 Adapter cache time: 0.02950639941263944 Engine time: 0.134462199639529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2259751 . Total output tokens: 2045991
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7071544229984283,
    "estimated_duration": 3599.4188846215975,
    "input_throughput": 220.96539066294693,
    "output_throughput": 202.593258349441,
    "total_throughput": 423.5586490123879,
    "itl": 20.47814540988486,
    "ttft": 4388.051146932588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 3307,
    "finished_requests": 3303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7072492960141972. Arrivals time: 0.020335028995759785 Scheduler time: 0.3215933198807761 Scheduler overhead time: 0.1332041509449482 Adapter cache time: 0.029348055832087994 Engine time: 0.1351346237352118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2259751 . Total output tokens: 2045991
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7199405079009011,
    "estimated_duration": 3599.4188846215975,
    "input_throughput": 220.96539066294693,
    "output_throughput": 202.593258349441,
    "total_throughput": 423.5586490123879,
    "itl": 20.478264305428674,
    "ttft": 4388.082046377819,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 3307,
    "finished_requests": 3303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.72004611894954. Arrivals time: 0.020585303311236203 Scheduler time: 0.32823851180728525 Scheduler overhead time: 0.1381547871278599 Adapter cache time: 0.029345389804802835 Engine time: 0.135841466486454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2107260 . Total output tokens: 1907621
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6853306309785694,
    "estimated_duration": 3592.3808573309116,
    "input_throughput": 211.0667075994152,
    "output_throughput": 184.63326310362385,
    "total_throughput": 395.69997070303907,
    "itl": 20.248089954709226,
    "ttft": 5826.84497795345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 3107,
    "finished_requests": 3102,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6853872280335054. Arrivals time: 0.020110044279135764 Scheduler time: 0.30471602140460163 Scheduler overhead time: 0.13197413238231093 Adapter cache time: 0.0287054245127365 Engine time: 0.1332247199025005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2107260 . Total output tokens: 1907621
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.687046283041127,
    "estimated_duration": 3592.3808573309116,
    "input_throughput": 211.0667075994152,
    "output_throughput": 184.63326310362385,
    "total_throughput": 395.69997070303907,
    "itl": 20.24820170585938,
    "ttft": 5826.801725019413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 3107,
    "finished_requests": 3102,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.687103470088914. Arrivals time: 0.02029854222200811 Scheduler time: 0.3021737199742347 Scheduler overhead time: 0.1333792544901371 Adapter cache time: 0.028635905124247074 Engine time: 0.13562504155561328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2107260 . Total output tokens: 1907621
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6929428429575637,
    "estimated_duration": 3592.3808573309116,
    "input_throughput": 211.0667075994152,
    "output_throughput": 184.63326310362385,
    "total_throughput": 395.69997070303907,
    "itl": 20.248224877723295,
    "ttft": 5826.821443430511,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 3107,
    "finished_requests": 3102,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6930027689086273. Arrivals time: 0.020053086220286787 Scheduler time: 0.3090272839181125 Scheduler overhead time: 0.1333437035791576 Adapter cache time: 0.02863694727420807 Engine time: 0.13438025687355548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2107260 . Total output tokens: 1907621
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6973497970029712,
    "estimated_duration": 3592.3808573309116,
    "input_throughput": 211.0667075994152,
    "output_throughput": 184.63326310362385,
    "total_throughput": 395.69997070303907,
    "itl": 20.24812689270875,
    "ttft": 5826.847860711019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 3107,
    "finished_requests": 3102,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6974104890832677. Arrivals time: 0.0208039665594697 Scheduler time: 0.30836927017662674 Scheduler overhead time: 0.13654970948118716 Adapter cache time: 0.028704063966870308 Engine time: 0.13557290518656373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2107260 . Total output tokens: 1907621
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6851103430381045,
    "estimated_duration": 3592.3808573309116,
    "input_throughput": 211.0667075994152,
    "output_throughput": 184.63326310362385,
    "total_throughput": 395.69997070303907,
    "itl": 20.248219142900794,
    "ttft": 5826.817090951963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 3107,
    "finished_requests": 3102,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6851568090496585. Arrivals time: 0.02025224093813449 Scheduler time: 0.3022902231896296 Scheduler overhead time: 0.13214618770871311 Adapter cache time: 0.02862516138702631 Engine time: 0.134954207460396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2107260 . Total output tokens: 1907621
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6851015039719641,
    "estimated_duration": 3592.3808573309116,
    "input_throughput": 211.0667075994152,
    "output_throughput": 184.63326310362385,
    "total_throughput": 395.69997070303907,
    "itl": 20.248066153643528,
    "ttft": 5826.836162783827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 3107,
    "finished_requests": 3102,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6851514379959553. Arrivals time: 0.020137714687734842 Scheduler time: 0.30341667868196964 Scheduler overhead time: 0.13197061012033373 Adapter cache time: 0.02841904037632048 Engine time: 0.13435610511805862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2107260 . Total output tokens: 1907621
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6909373409580439,
    "estimated_duration": 3592.3808573309116,
    "input_throughput": 211.0667075994152,
    "output_throughput": 184.63326310362385,
    "total_throughput": 395.69997070303907,
    "itl": 20.248207524918193,
    "ttft": 5826.808429549276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 3107,
    "finished_requests": 3102,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6910086809657514. Arrivals time: 0.020109685487113893 Scheduler time: 0.30525783088523895 Scheduler overhead time: 0.13574774272274226 Adapter cache time: 0.029172159964218736 Engine time: 0.1329898505937308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2034863 . Total output tokens: 1835558
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6825568309286609,
    "estimated_duration": 3597.3192341385547,
    "input_throughput": 203.09512513280055,
    "output_throughput": 182.8817397568394,
    "total_throughput": 385.97686488963996,
    "itl": 20.317025208719297,
    "ttft": 7255.295543750533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6826081769540906. Arrivals time: 0.019765537232160568 Scheduler time: 0.300147867645137 Scheduler overhead time: 0.13269831298384815 Adapter cache time: 0.028555887169204652 Engine time: 0.1340719263534993 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2034863 . Total output tokens: 1835558
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6848954820306972,
    "estimated_duration": 3597.3192341385547,
    "input_throughput": 203.09512513280055,
    "output_throughput": 182.8817397568394,
    "total_throughput": 385.97686488963996,
    "itl": 20.315953151266143,
    "ttft": 7255.308681040313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2348263315111399,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6849488840671256. Arrivals time: 0.019918170641176403 Scheduler time: 0.3021928162779659 Scheduler overhead time: 0.13338718935847282 Adapter cache time: 0.02849678392522037 Engine time: 0.1338731428841129 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2034863 . Total output tokens: 1835558
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.681223226012662,
    "estimated_duration": 3597.3192341385547,
    "input_throughput": 203.09512513280055,
    "output_throughput": 182.8817397568394,
    "total_throughput": 385.97686488963996,
    "itl": 20.317385011787376,
    "ttft": 7255.288278134141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2413462840113789,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6812747759977356. Arrivals time: 0.01996864564716816 Scheduler time: 0.2994320089928806 Scheduler overhead time: 0.13201239879708737 Adapter cache time: 0.028474196209572256 Engine time: 0.13435899675823748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2034863 . Total output tokens: 1835558
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6941461690003052,
    "estimated_duration": 3597.3192341385547,
    "input_throughput": 203.09512513280055,
    "output_throughput": 182.8817397568394,
    "total_throughput": 385.97686488963996,
    "itl": 20.315863327941692,
    "ttft": 7255.313809740067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.694221404963173. Arrivals time: 0.020485891494899988 Scheduler time: 0.30540825380012393 Scheduler overhead time: 0.13322309672366828 Adapter cache time: 0.028533419594168663 Engine time: 0.13891824206802994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2034863 . Total output tokens: 1835558
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6902665660018101,
    "estimated_duration": 3597.3192341385547,
    "input_throughput": 203.09512513280055,
    "output_throughput": 182.8817397568394,
    "total_throughput": 385.97686488963996,
    "itl": 20.31597046406397,
    "ttft": 7255.2924752134795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861717,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6903274350333959. Arrivals time: 0.01992010115645826 Scheduler time: 0.3059316212311387 Scheduler overhead time: 0.13337781734298915 Adapter cache time: 0.028277527424506843 Engine time: 0.13556504994630814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2034863 . Total output tokens: 1835558
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6823288809973747,
    "estimated_duration": 3597.3192341385547,
    "input_throughput": 203.09512513280055,
    "output_throughput": 182.8817397568394,
    "total_throughput": 385.97686488963996,
    "itl": 20.316959569194907,
    "ttft": 7255.254716486541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.682389943045564. Arrivals time: 0.01959962269756943 Scheduler time: 0.29822517605498433 Scheduler overhead time: 0.13361672416795045 Adapter cache time: 0.02835982956457883 Engine time: 0.1347347954288125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2034863 . Total output tokens: 1835558
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6864883840316907,
    "estimated_duration": 3597.3192341385547,
    "input_throughput": 203.09512513280055,
    "output_throughput": 182.8817397568394,
    "total_throughput": 385.97686488963996,
    "itl": 20.315961458080423,
    "ttft": 7255.286550645354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585545,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6865613079862669. Arrivals time: 0.019900236278772354 Scheduler time: 0.3014871380291879 Scheduler overhead time: 0.1326826331205666 Adapter cache time: 0.028459016350097954 Engine time: 0.1365101682022214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1779099 . Total output tokens: 1607481
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6569156260229647,
    "estimated_duration": 3599.3840288478104,
    "input_throughput": 179.05258089571024,
    "output_throughput": 162.85175332837048,
    "total_throughput": 341.90433422408074,
    "itl": 20.183741324712518,
    "ttft": 6927.174849392465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6569806049810722. Arrivals time: 0.018946938682347536 Scheduler time: 0.2808182876324281 Scheduler overhead time: 0.13096418417990208 Adapter cache time: 0.02710622944869101 Engine time: 0.13239679287653416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1779099 . Total output tokens: 1607481
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6582689400529489,
    "estimated_duration": 3599.3840288478104,
    "input_throughput": 179.05258089571024,
    "output_throughput": 162.85175332837048,
    "total_throughput": 341.90433422408074,
    "itl": 20.183806521941857,
    "ttft": 6927.109286745205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6583346959669143. Arrivals time: 0.019254644750617445 Scheduler time: 0.2801244091242552 Scheduler overhead time: 0.131287777912803 Adapter cache time: 0.027019010158255696 Engine time: 0.13406382000539452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1779099 . Total output tokens: 1607481
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6626245928928256,
    "estimated_duration": 3599.3840288478104,
    "input_throughput": 179.05258089571024,
    "output_throughput": 162.85175332837048,
    "total_throughput": 341.90433422408074,
    "itl": 20.183833209193708,
    "ttft": 6927.13610793477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6626761299557984. Arrivals time: 0.019161271979101002 Scheduler time: 0.28282634203787893 Scheduler overhead time: 0.13164755108300596 Adapter cache time: 0.026961103663779795 Engine time: 0.1354596649762243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1779099 . Total output tokens: 1607481
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6580599580192938,
    "estimated_duration": 3599.3840288478104,
    "input_throughput": 179.05258089571024,
    "output_throughput": 162.85175332837048,
    "total_throughput": 341.90433422408074,
    "itl": 20.18372084758756,
    "ttft": 6927.174684585209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6581103800563142. Arrivals time: 0.019295609323307872 Scheduler time: 0.2798651622142643 Scheduler overhead time: 0.13212301302701235 Adapter cache time: 0.027073496370576322 Engine time: 0.13305676577147096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1779099 . Total output tokens: 1607481
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6549995800014585,
    "estimated_duration": 3599.3840288478104,
    "input_throughput": 179.05258089571024,
    "output_throughput": 162.85175332837048,
    "total_throughput": 341.90433422408074,
    "itl": 20.183823578317924,
    "ttft": 6927.125209140855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6550972060067579. Arrivals time: 0.018792970571666956 Scheduler time: 0.27711594582069665 Scheduler overhead time: 0.1313276825239882 Adapter cache time: 0.027021728572435677 Engine time: 0.13423742190934718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1779099 . Total output tokens: 1607481
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6563039709581062,
    "estimated_duration": 3599.3840288478104,
    "input_throughput": 179.05258089571024,
    "output_throughput": 162.85175332837048,
    "total_throughput": 341.90433422408074,
    "itl": 20.182395130864375,
    "ttft": 6927.161034234758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6563554219901562. Arrivals time: 0.01911083608865738 Scheduler time: 0.2780324051855132 Scheduler overhead time: 0.1311148996464908 Adapter cache time: 0.027300116838887334 Engine time: 0.1343567274743691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1779099 . Total output tokens: 1607481
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.659695303067565,
    "estimated_duration": 3599.3840288478104,
    "input_throughput": 179.05258089571024,
    "output_throughput": 162.85175332837048,
    "total_throughput": 341.90433422408074,
    "itl": 20.183811468082208,
    "ttft": 6927.121537043827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6597431460395455. Arrivals time: 0.018892854335717857 Scheduler time: 0.28144986496772617 Scheduler overhead time: 0.13225528318434954 Adapter cache time: 0.02681140461936593 Engine time: 0.13379019335843623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1705563 . Total output tokens: 1541512
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6396636109566316,
    "estimated_duration": 3599.2593921377943,
    "input_throughput": 171.32052259055214,
    "output_throughput": 152.73836645418234,
    "total_throughput": 324.0588890447345,
    "itl": 20.17161406853811,
    "ttft": 4291.693404613143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.639710176968947. Arrivals time: 0.01868172688409686 Scheduler time: 0.2668292833259329 Scheduler overhead time: 0.13018210558220744 Adapter cache time: 0.026278781006112695 Engine time: 0.13223490421660244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1705563 . Total output tokens: 1541512
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.640474502928555,
    "estimated_duration": 3599.2593921377943,
    "input_throughput": 171.32052259055214,
    "output_throughput": 152.73836645418234,
    "total_throughput": 324.0588890447345,
    "itl": 20.172029993842013,
    "ttft": 4291.714461732885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6405334629816934. Arrivals time: 0.018594867433421314 Scheduler time: 0.26703428954351693 Scheduler overhead time: 0.13026693044230342 Adapter cache time: 0.02644929604139179 Engine time: 0.13282012182753533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1705563 . Total output tokens: 1541512
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6357941309688613,
    "estimated_duration": 3599.2593921377943,
    "input_throughput": 171.32052259055214,
    "output_throughput": 152.73836645418234,
    "total_throughput": 324.0588890447345,
    "itl": 20.172141141610812,
    "ttft": 4291.673343397766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6358579200459644. Arrivals time: 0.018606159719638526 Scheduler time: 0.2653280080994591 Scheduler overhead time: 0.12897371815051883 Adapter cache time: 0.026218005339615047 Engine time: 0.13116129441186786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1705563 . Total output tokens: 1541512
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6447997710201889,
    "estimated_duration": 3599.2593921377943,
    "input_throughput": 171.32052259055214,
    "output_throughput": 152.73836645418234,
    "total_throughput": 324.0588890447345,
    "itl": 20.171916907366576,
    "ttft": 4291.653575137238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6448527799220756. Arrivals time: 0.01860938558820635 Scheduler time: 0.2698470347095281 Scheduler overhead time: 0.1329660676419735 Adapter cache time: 0.026287312619388103 Engine time: 0.13155863073188812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1705563 . Total output tokens: 1541512
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6428665770217776,
    "estimated_duration": 3599.2593921377943,
    "input_throughput": 171.32052259055214,
    "output_throughput": 152.73836645418234,
    "total_throughput": 324.0588890447345,
    "itl": 20.17211004821268,
    "ttft": 4291.6848802679515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6429176710080355. Arrivals time: 0.01865818235091865 Scheduler time: 0.2697112715104595 Scheduler overhead time: 0.13013738638255745 Adapter cache time: 0.026833749958314 Engine time: 0.13159450853709131 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1705563 . Total output tokens: 1541512
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6434568060794845,
    "estimated_duration": 3599.2593921377943,
    "input_throughput": 171.32052259055214,
    "output_throughput": 152.73836645418234,
    "total_throughput": 324.0588890447345,
    "itl": 20.171587614229622,
    "ttft": 4291.710011365873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6435126140713692. Arrivals time: 0.018969890661537647 Scheduler time: 0.2697180095128715 Scheduler overhead time: 0.13008871406782418 Adapter cache time: 0.026265507913194597 Engine time: 0.13295098091475666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1705563 . Total output tokens: 1541512
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6478357340674847,
    "estimated_duration": 3599.2593921377943,
    "input_throughput": 171.32052259055214,
    "output_throughput": 152.73836645418234,
    "total_throughput": 324.0588890447345,
    "itl": 20.172061958545868,
    "ttft": 4291.6993691402495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6479250220581889. Arrivals time: 0.018614109489135444 Scheduler time: 0.2746155532076955 Scheduler overhead time: 0.13062903098762035 Adapter cache time: 0.02658376656472683 Engine time: 0.13219646248035133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1542781 . Total output tokens: 1380480
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.60817878798116,
    "estimated_duration": 3598.9184836245836,
    "input_throughput": 150.93701134706342,
    "output_throughput": 134.42732926608466,
    "total_throughput": 285.36434061314804,
    "itl": 20.087538715495384,
    "ttft": 4811.255054699612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6082398010184988. Arrivals time: 0.017628421541303396 Scheduler time: 0.24497586698271334 Scheduler overhead time: 0.12767014023847878 Adapter cache time: 0.025376699632033706 Engine time: 0.12842862121760845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1542781 . Total output tokens: 1380480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6037811789428815,
    "estimated_duration": 3598.9184836245836,
    "input_throughput": 150.93701134706342,
    "output_throughput": 134.42732926608466,
    "total_throughput": 285.36434061314804,
    "itl": 20.087726512409205,
    "ttft": 4811.265554291054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.60383582895156. Arrivals time: 0.01772393728606403 Scheduler time: 0.243553529959172 Scheduler overhead time: 0.12577214767225087 Adapter cache time: 0.025079504470340908 Engine time: 0.127780205802992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1542781 . Total output tokens: 1380480
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6088366300100461,
    "estimated_duration": 3598.9184836245836,
    "input_throughput": 150.93701134706342,
    "output_throughput": 134.42732926608466,
    "total_throughput": 285.36434061314804,
    "itl": 20.087761682600835,
    "ttft": 4811.285611668784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6088910429971293. Arrivals time: 0.017642446444369853 Scheduler time: 0.24625416309572756 Scheduler overhead time: 0.12655061425175518 Adapter cache time: 0.025067647569812834 Engine time: 0.12951270665507764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1542781 . Total output tokens: 1380480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6069746100110933,
    "estimated_duration": 3598.9184836245836,
    "input_throughput": 150.93701134706342,
    "output_throughput": 134.42732926608466,
    "total_throughput": 285.36434061314804,
    "itl": 20.087666442510656,
    "ttft": 4811.252458738178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6070316570112482. Arrivals time: 0.017454308574087918 Scheduler time: 0.24528290703892708 Scheduler overhead time: 0.1262878879206255 Adapter cache time: 0.02525442000478506 Engine time: 0.12874477822333574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1542781 . Total output tokens: 1380480
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6069341759430245,
    "estimated_duration": 3598.9184836245836,
    "input_throughput": 150.93701134706342,
    "output_throughput": 134.42732926608466,
    "total_throughput": 285.36434061314804,
    "itl": 20.0877525112496,
    "ttft": 4811.2765388367125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6069972750265151. Arrivals time: 0.017649037181399763 Scheduler time: 0.24542625551111996 Scheduler overhead time: 0.12667903176043183 Adapter cache time: 0.02516393770929426 Engine time: 0.12797918426804245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1542781 . Total output tokens: 1380480
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6050423070555553,
    "estimated_duration": 3598.9184836245836,
    "input_throughput": 150.93701134706342,
    "output_throughput": 134.42732926608466,
    "total_throughput": 285.36434061314804,
    "itl": 20.087508279115823,
    "ttft": 4811.3057679052345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6051112259738147. Arrivals time: 0.017521663568913937 Scheduler time: 0.24376705358736217 Scheduler overhead time: 0.12625635671429336 Adapter cache time: 0.024983262410387397 Engine time: 0.12846963584888726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1542781 . Total output tokens: 1380480
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6065969750052318,
    "estimated_duration": 3598.9184836245836,
    "input_throughput": 150.93701134706342,
    "output_throughput": 134.42732926608466,
    "total_throughput": 285.36434061314804,
    "itl": 20.087738604669887,
    "ttft": 4811.2620932925465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.606644825078547. Arrivals time: 0.017612319672480226 Scheduler time: 0.2452811273979023 Scheduler overhead time: 0.12613493076059967 Adapter cache time: 0.025164378224872053 Engine time: 0.12854340102057904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1131339 . Total output tokens: 1006643
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.5337607839610428,
    "estimated_duration": 3595.9936533764953,
    "input_throughput": 115.21321780170082,
    "output_throughput": 95.77630919248473,
    "total_throughput": 210.98952699418555,
    "itl": 19.82561124975007,
    "ttft": 10960.755122744004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 1647,
    "finished_requests": 1642,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5338074290193617. Arrivals time: 0.01536272547673434 Scheduler time: 0.19794136914424598 Scheduler overhead time: 0.11735479650087655 Adapter cache time: 0.022894730791449547 Engine time: 0.12062460056040436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1131339 . Total output tokens: 1006643
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5390768289798871,
    "estimated_duration": 3595.9936533764953,
    "input_throughput": 115.21321780170082,
    "output_throughput": 95.77630919248473,
    "total_throughput": 210.98952699418555,
    "itl": 19.82572294486505,
    "ttft": 10960.760142966887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2348263315111399,
    "arrivals": 1647,
    "finished_requests": 1642,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5391347259283066. Arrivals time: 0.015256374375894666 Scheduler time: 0.20225407392717898 Scheduler overhead time: 0.11945221677888185 Adapter cache time: 0.022840461460873485 Engine time: 0.11937169218435884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1131339 . Total output tokens: 1006643
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5398875289829448,
    "estimated_duration": 3595.9936533764953,
    "input_throughput": 115.21321780170082,
    "output_throughput": 95.77630919248473,
    "total_throughput": 210.98952699418555,
    "itl": 19.825759928484434,
    "ttft": 10960.727489467843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2413462840113789,
    "arrivals": 1647,
    "finished_requests": 1642,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5399470329284668. Arrivals time: 0.01582812052220106 Scheduler time: 0.20242350292392075 Scheduler overhead time: 0.11877314350567758 Adapter cache time: 0.022987318458035588 Engine time: 0.11996076931245625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1131339 . Total output tokens: 1006643
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5340252460446209,
    "estimated_duration": 3595.9936533764953,
    "input_throughput": 115.21321780170082,
    "output_throughput": 95.77630919248473,
    "total_throughput": 210.98952699418555,
    "itl": 19.82563363172708,
    "ttft": 10960.774275462138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 1647,
    "finished_requests": 1642,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.534092957037501. Arrivals time: 0.015470175887458026 Scheduler time: 0.1982719344086945 Scheduler overhead time: 0.11776792956516147 Adapter cache time: 0.022920142277143896 Engine time: 0.12008115788921714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1131339 . Total output tokens: 1006643
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5383147000102326,
    "estimated_duration": 3595.9936533764953,
    "input_throughput": 115.21321780170082,
    "output_throughput": 95.77630919248473,
    "total_throughput": 210.98952699418555,
    "itl": 19.825741570103776,
    "ttft": 10960.768040536708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861717,
    "arrivals": 1647,
    "finished_requests": 1642,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5383664050605148. Arrivals time: 0.015477327746339142 Scheduler time: 0.20159003988374025 Scheduler overhead time: 0.11847588000819087 Adapter cache time: 0.022960426984354854 Engine time: 0.12011270050425082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1131339 . Total output tokens: 1006643
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.5345542760333046,
    "estimated_duration": 3595.9936533764953,
    "input_throughput": 115.21321780170082,
    "output_throughput": 95.77630919248473,
    "total_throughput": 210.98952699418555,
    "itl": 19.825576720047593,
    "ttft": 10960.727746652792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 1647,
    "finished_requests": 1642,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5346154699800536. Arrivals time: 0.015860061044804752 Scheduler time: 0.198095275554806 Scheduler overhead time: 0.11846300109755248 Adapter cache time: 0.02304678491782397 Engine time: 0.1192615085747093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1131339 . Total output tokens: 1006643
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5464326509973034,
    "estimated_duration": 3595.9936533764953,
    "input_throughput": 115.21321780170082,
    "output_throughput": 95.77630919248473,
    "total_throughput": 210.98952699418555,
    "itl": 19.825731724329483,
    "ttft": 10960.770330750456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585545,
    "arrivals": 1647,
    "finished_requests": 1642,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5464870079886168. Arrivals time: 0.015306230401620269 Scheduler time: 0.20412146556191146 Scheduler overhead time: 0.11983610934112221 Adapter cache time: 0.02293364331126213 Engine time: 0.12359909492079169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1057278 . Total output tokens: 940766
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.523377867997624,
    "estimated_duration": 3590.005186061703,
    "input_throughput": 103.72798386080093,
    "output_throughput": 89.06143123173322,
    "total_throughput": 192.78941509253414,
    "itl": 19.737817778337615,
    "ttft": 9424.207955805581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5234343740157783. Arrivals time: 0.015042555052787066 Scheduler time: 0.1909635686315596 Scheduler overhead time: 0.11778205400332808 Adapter cache time: 0.022417354863137007 Engine time: 0.11775397032033652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1057278 . Total output tokens: 940766
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5246324229519814,
    "estimated_duration": 3590.005186061703,
    "input_throughput": 103.72798386080093,
    "output_throughput": 89.06143123173322,
    "total_throughput": 192.78941509253414,
    "itl": 19.737898763753325,
    "ttft": 9424.234675753816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5246989279985428. Arrivals time: 0.015435722656548023 Scheduler time: 0.1911959795979783 Scheduler overhead time: 0.11743850773200393 Adapter cache time: 0.02252759167458862 Engine time: 0.11841912381350994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1057278 . Total output tokens: 940766
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5248679619980976,
    "estimated_duration": 3590.005186061703,
    "input_throughput": 103.72798386080093,
    "output_throughput": 89.06143123173322,
    "total_throughput": 192.78941509253414,
    "itl": 19.737937823587334,
    "ttft": 9424.244624361465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5249265868915245. Arrivals time: 0.015344639774411917 Scheduler time: 0.19085617107339203 Scheduler overhead time: 0.11790468776598573 Adapter cache time: 0.022381553309969604 Engine time: 0.11881282087415457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1057278 . Total output tokens: 940766
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.526713712955825,
    "estimated_duration": 3590.005186061703,
    "input_throughput": 103.72798386080093,
    "output_throughput": 89.06143123173322,
    "total_throughput": 192.78941509253414,
    "itl": 19.737829820735737,
    "ttft": 9424.238895213257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5267683689016849. Arrivals time: 0.015360545716248453 Scheduler time: 0.19044401566497982 Scheduler overhead time: 0.1173992125550285 Adapter cache time: 0.022434026934206486 Engine time: 0.12157575320452452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1057278 . Total output tokens: 940766
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5323094660416245,
    "estimated_duration": 3590.005186061703,
    "input_throughput": 103.72798386080093,
    "output_throughput": 89.06143123173322,
    "total_throughput": 192.78941509253414,
    "itl": 19.73792325589962,
    "ttft": 9424.246869990413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5323679900029674. Arrivals time: 0.015261005493812263 Scheduler time: 0.19387355202343315 Scheduler overhead time: 0.1192309643374756 Adapter cache time: 0.02244960959069431 Engine time: 0.12112771556712687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1057278 . Total output tokens: 940766
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.5259282710030675,
    "estimated_duration": 3590.005186061703,
    "input_throughput": 103.72798386080093,
    "output_throughput": 89.06143123173322,
    "total_throughput": 192.78941509253414,
    "itl": 19.73779037828442,
    "ttft": 9424.215098371911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5260064869653434. Arrivals time: 0.015398167073726654 Scheduler time: 0.19176552002318203 Scheduler overhead time: 0.11796060262713581 Adapter cache time: 0.022279680124484003 Engine time: 0.11912695434875786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1057278 . Total output tokens: 940766
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5235704419901595,
    "estimated_duration": 3590.005186061703,
    "input_throughput": 103.72798386080093,
    "output_throughput": 89.06143123173322,
    "total_throughput": 192.78941509253414,
    "itl": 19.73790664047941,
    "ttft": 9424.246262096456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5236532679991797. Arrivals time: 0.015424884273670614 Scheduler time: 0.19105813885107636 Scheduler overhead time: 0.1175519326934591 Adapter cache time: 0.02236606809310615 Engine time: 0.11774699378293008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 883288 . Total output tokens: 783629
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.4664629229810089,
    "estimated_duration": 3599.849807134307,
    "input_throughput": 90.21681942295635,
    "output_throughput": 73.26972349715015,
    "total_throughput": 163.4865429201065,
    "itl": 19.68426146152939,
    "ttft": 5590.337401502853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 1295,
    "finished_requests": 1293,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.46651269297581166. Arrivals time: 0.013384579215198755 Scheduler time: 0.16503481264226139 Scheduler overhead time: 0.10501794808078557 Adapter cache time: 0.019762569689191878 Engine time: 0.11004562966991216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 883288 . Total output tokens: 783629
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.464298139908351,
    "estimated_duration": 3599.849807134307,
    "input_throughput": 90.21681942295635,
    "output_throughput": 73.26972349715015,
    "total_throughput": 163.4865429201065,
    "itl": 19.684355339395054,
    "ttft": 5590.344829233417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 1295,
    "finished_requests": 1293,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.46434670698363334. Arrivals time: 0.013379353564232588 Scheduler time: 0.1671944356057793 Scheduler overhead time: 0.10463456681463867 Adapter cache time: 0.019796174368821084 Engine time: 0.10634931607637554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 883288 . Total output tokens: 783629
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.4634948279708624,
    "estimated_duration": 3599.849807134307,
    "input_throughput": 90.21681942295635,
    "output_throughput": 73.26972349715015,
    "total_throughput": 163.4865429201065,
    "itl": 19.68438148392858,
    "ttft": 5590.370620074578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 1295,
    "finished_requests": 1293,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4635548510123044. Arrivals time: 0.01345154142472893 Scheduler time: 0.16457803850062191 Scheduler overhead time: 0.1060157804749906 Adapter cache time: 0.01971480145584792 Engine time: 0.1064522365340963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 883288 . Total output tokens: 783629
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.4621531330049038,
    "estimated_duration": 3599.849807134307,
    "input_throughput": 90.21681942295635,
    "output_throughput": 73.26972349715015,
    "total_throughput": 163.4865429201065,
    "itl": 19.684260341412223,
    "ttft": 5590.301958278724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 1295,
    "finished_requests": 1293,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4622020609676838. Arrivals time: 0.013170107617042959 Scheduler time: 0.16399087070021778 Scheduler overhead time: 0.10579631756991148 Adapter cache time: 0.01964263874106109 Engine time: 0.10634036711417139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 883288 . Total output tokens: 783629
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.46125489100813866,
    "estimated_duration": 3599.849807134307,
    "input_throughput": 90.21681942295635,
    "output_throughput": 73.26972349715015,
    "total_throughput": 163.4865429201065,
    "itl": 19.68436791392075,
    "ttft": 5590.359264615474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 1295,
    "finished_requests": 1293,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4613005790160969. Arrivals time: 0.013252076460048556 Scheduler time: 0.16432167880702764 Scheduler overhead time: 0.10518249496817589 Adapter cache time: 0.01961472420953214 Engine time: 0.10587922343984246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 883288 . Total output tokens: 783629
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.4689249530201778,
    "estimated_duration": 3599.849807134307,
    "input_throughput": 90.21681942295635,
    "output_throughput": 73.26972349715015,
    "total_throughput": 163.4865429201065,
    "itl": 19.684226170026754,
    "ttft": 5590.338738915724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 1295,
    "finished_requests": 1293,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.468975494033657. Arrivals time: 0.013677869806997478 Scheduler time: 0.16983426630031317 Scheduler overhead time: 0.10579235828481615 Adapter cache time: 0.019712666631676257 Engine time: 0.10647030116524547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 883288 . Total output tokens: 783629
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.4679713799851015,
    "estimated_duration": 3599.849807134307,
    "input_throughput": 90.21681942295635,
    "output_throughput": 73.26972349715015,
    "total_throughput": 163.4865429201065,
    "itl": 19.68436293114303,
    "ttft": 5590.352387365594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 1295,
    "finished_requests": 1293,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.46802866004873067. Arrivals time: 0.013391806627623737 Scheduler time: 0.16997878591064364 Scheduler overhead time: 0.10619907139334828 Adapter cache time: 0.019623873056843877 Engine time: 0.10548944177571684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 557882 . Total output tokens: 512159
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.39624180598184466,
    "estimated_duration": 3598.01031664571,
    "input_throughput": 54.394785666555805,
    "output_throughput": 54.871715927722974,
    "total_throughput": 109.26650159427878,
    "itl": 19.533582679444283,
    "ttft": 4225.613498908557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.39629415702074766. Arrivals time: 0.011222560075111687 Scheduler time: 0.13417917082551867 Scheduler overhead time: 0.09341288986615837 Adapter cache time: 0.016899761627428234 Engine time: 0.09362443012651056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 557882 . Total output tokens: 512159
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.3966961429687217,
    "estimated_duration": 3598.01031664571,
    "input_throughput": 54.394785666555805,
    "output_throughput": 54.871715927722974,
    "total_throughput": 109.26650159427878,
    "itl": 19.533655326081306,
    "ttft": 4225.6723242037715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.39674311701674014. Arrivals time: 0.01110648235771805 Scheduler time: 0.1342878408031538 Scheduler overhead time: 0.09304432990029454 Adapter cache time: 0.016877792542800307 Engine time: 0.09431985043920577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 557882 . Total output tokens: 512159
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.395918674999848,
    "estimated_duration": 3598.01031664571,
    "input_throughput": 54.394785666555805,
    "output_throughput": 54.871715927722974,
    "total_throughput": 109.26650159427878,
    "itl": 19.533675846678268,
    "ttft": 4225.696523608821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.39596535300370306. Arrivals time: 0.011269497452303767 Scheduler time: 0.13378791266586632 Scheduler overhead time: 0.09258851094637066 Adapter cache time: 0.016874278662726283 Engine time: 0.09438960009720176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 557882 . Total output tokens: 512159
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.3979247329989448,
    "estimated_duration": 3598.01031664571,
    "input_throughput": 54.394785666555805,
    "output_throughput": 54.871715927722974,
    "total_throughput": 109.26650159427878,
    "itl": 19.533629069236042,
    "ttft": 4225.641407539147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.39797058107797056. Arrivals time: 0.01115964981727302 Scheduler time: 0.13614929665345699 Scheduler overhead time: 0.09368074289523065 Adapter cache time: 0.01680840493645519 Engine time: 0.09325980022549629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 557882 . Total output tokens: 512159
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.3966797459870577,
    "estimated_duration": 3598.01031664571,
    "input_throughput": 54.394785666555805,
    "output_throughput": 54.871715927722974,
    "total_throughput": 109.26650159427878,
    "itl": 19.533672175774853,
    "ttft": 4225.688316168255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861723,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.3967244030209258. Arrivals time: 0.010916551458649337 Scheduler time: 0.135908363154158 Scheduler overhead time: 0.09295185550581664 Adapter cache time: 0.016837912029586732 Engine time: 0.0931649876292795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 557882 . Total output tokens: 512159
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.3974457570584491,
    "estimated_duration": 3598.01031664571,
    "input_throughput": 54.394785666555805,
    "output_throughput": 54.871715927722974,
    "total_throughput": 109.26650159427878,
    "itl": 19.533556574889715,
    "ttft": 4225.606799585145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.3974908690433949. Arrivals time: 0.011305632418952882 Scheduler time: 0.13428268290590495 Scheduler overhead time: 0.09270514047238976 Adapter cache time: 0.017000947264023125 Engine time: 0.09515648940578103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 557882 . Total output tokens: 512159
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.39761639095377177,
    "estimated_duration": 3598.01031664571,
    "input_throughput": 54.394785666555805,
    "output_throughput": 54.871715927722974,
    "total_throughput": 109.26650159427878,
    "itl": 19.533661359899988,
    "ttft": 4225.679384541758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2367897061258555,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.3976620299508795. Arrivals time: 0.01115812233183533 Scheduler time: 0.13582959887571633 Scheduler overhead time: 0.092936878092587 Adapter cache time: 0.01697321399115026 Engine time: 0.09401580621488392 
