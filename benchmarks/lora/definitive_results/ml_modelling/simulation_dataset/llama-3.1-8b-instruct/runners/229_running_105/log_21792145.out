INFO 05-31 19:31:05 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:05 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 621975333 . Total output tokens: 546547488
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 87.65432424703613,
    "estimated_duration": 3600.025548463043,
    "input_throughput": 6960.663379374694,
    "output_throughput": 6071.372746043827,
    "total_throughput": 13032.03612541852,
    "itl": 84.41661778206385,
    "ttft": 2011526.7497217155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6899063036497513,
    "arrivals": 928080,
    "finished_requests": 101340,
    "scheduler_time": 312.61365219992945
}
#Debug simulation 
Total elapsed time: 87.65454563684762. Arrivals time: 0.5424835090525448 Scheduler time: 86.88220537826419 Scheduler overhead time: 0.08937315549701452 Adapter cache time: 0.019893995486199856 Engine time: 0.08554696198552847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 621975333 . Total output tokens: 546547488
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 85.73277930403128,
    "estimated_duration": 3600.075323069703,
    "input_throughput": 6912.732864372394,
    "output_throughput": 6014.091111165565,
    "total_throughput": 12926.82397553796,
    "itl": 82.13060881515236,
    "ttft": 2014492.138046876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.106697785649486,
    "arrivals": 928080,
    "finished_requests": 100550,
    "scheduler_time": 314.6196881788407
}
#Debug simulation 
Total elapsed time: 85.73297393135726. Arrivals time: 0.533101131208241 Scheduler time: 84.96938948845491 Scheduler overhead time: 0.08942391816526651 Adapter cache time: 0.01979759894311428 Engine time: 0.08641048381105065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 620346366 . Total output tokens: 545118137
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 85.32903400110081,
    "estimated_duration": 3600.0060860669255,
    "input_throughput": 6988.439296636316,
    "output_throughput": 6070.521959554745,
    "total_throughput": 13058.96125619106,
    "itl": 84.70463722326963,
    "ttft": 2022322.0290384311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6236001495086154,
    "arrivals": 925677,
    "finished_requests": 101609,
    "scheduler_time": 311.1631857516835
}
#Debug simulation 
Total elapsed time: 85.32920604106039. Arrivals time: 0.5496849589981139 Scheduler time: 84.55066412361339 Scheduler overhead time: 0.08842967404052615 Adapter cache time: 0.02001131698489189 Engine time: 0.08572418475523591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 620346366 . Total output tokens: 545118137
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 86.10198832117021,
    "estimated_duration": 3600.002309839123,
    "input_throughput": 6720.870687741652,
    "output_throughput": 5851.029579184158,
    "total_throughput": 12571.90026692581,
    "itl": 81.07297282702672,
    "ttft": 2040910.0432952468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6214874126482806,
    "arrivals": 925677,
    "finished_requests": 97846,
    "scheduler_time": 323.0591257910224
}
#Debug simulation 
Total elapsed time: 86.10216171620414. Arrivals time: 0.5388908651657403 Scheduler time: 85.3340663430281 Scheduler overhead time: 0.08952910639345646 Adapter cache time: 0.01946285180747509 Engine time: 0.0856088106520474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 620346366 . Total output tokens: 545118137
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.04778141481802,
    "estimated_duration": 3600.018085405381,
    "input_throughput": 6915.01637197936,
    "output_throughput": 6025.806394680168,
    "total_throughput": 12940.822766659528,
    "itl": 82.31428343050032,
    "ttft": 2017882.8850994061,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.039519088999405,
    "arrivals": 925677,
    "finished_requests": 100641,
    "scheduler_time": 314.19252891334395
}
#Debug simulation 
Total elapsed time: 84.04795539798215. Arrivals time: 0.5952736879698932 Scheduler time: 83.22218097699806 Scheduler overhead time: 0.08980017760768533 Adapter cache time: 0.019706780556589365 Engine time: 0.08658837713301182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 620346366 . Total output tokens: 545118137
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 85.75504868291318,
    "estimated_duration": 3600.0220772534813,
    "input_throughput": 6981.619129173549,
    "output_throughput": 6085.348792281165,
    "total_throughput": 13066.967921454712,
    "itl": 84.94551801471704,
    "ttft": 2014983.2075497909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 551,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7729730973439235,
    "arrivals": 925677,
    "finished_requests": 101875,
    "scheduler_time": 310.3303778665848
}
#Debug simulation 
Total elapsed time: 85.75521554006264. Arrivals time: 0.5680178999900818 Scheduler time: 84.95678588794544 Scheduler overhead time: 0.08995948359370232 Adapter cache time: 0.019962530583143234 Engine time: 0.08642266597598791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 620346366 . Total output tokens: 545118137
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 84.07424518093467,
    "estimated_duration": 3600.038208486985,
    "input_throughput": 6914.977719212171,
    "output_throughput": 6025.772712317153,
    "total_throughput": 12940.750431529323,
    "itl": 82.31341065160572,
    "ttft": 2017868.0006257824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.0014095285022995,
    "arrivals": 925677,
    "finished_requests": 100641,
    "scheduler_time": 314.1987110870874
}
#Debug simulation 
Total elapsed time: 84.07441250095144. Arrivals time: 0.539013687055558 Scheduler time: 83.30320795997977 Scheduler overhead time: 0.09046733472496271 Adapter cache time: 0.019724322017282248 Engine time: 0.08744731033220887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 620346366 . Total output tokens: 545118137
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 85.64199244603515,
    "estimated_duration": 3600.0151679522396,
    "input_throughput": 6956.614300668482,
    "output_throughput": 6047.993684533513,
    "total_throughput": 13004.607985201996,
    "itl": 83.78091258225992,
    "ttft": 2026512.5586969622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.428165545086361,
    "arrivals": 925677,
    "finished_requests": 101284,
    "scheduler_time": 312.2759625832248
}
#Debug simulation 
Total elapsed time: 85.64217228908092. Arrivals time: 0.5643331599421799 Scheduler time: 84.84990864945576 Scheduler overhead time: 0.08908617403358221 Adapter cache time: 0.019427742809057236 Engine time: 0.0854656514711678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 620346366 . Total output tokens: 545118137
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.19916945695877,
    "estimated_duration": 3600.000675237978,
    "input_throughput": 6915.049814082151,
    "output_throughput": 6025.835536424165,
    "total_throughput": 12940.885350506316,
    "itl": 82.31262367475121,
    "ttft": 2017852.008033772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.964335553888268,
    "arrivals": 925677,
    "finished_requests": 100641,
    "scheduler_time": 314.198352943917
}
#Debug simulation 
Total elapsed time: 84.19933874765411. Arrivals time: 0.5587042011320591 Scheduler time: 83.41266911430284 Scheduler overhead time: 0.08831360377371311 Adapter cache time: 0.019484444987028837 Engine time: 0.08582289982587099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 619565730 . Total output tokens: 544442464
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 86.50756732933223,
    "estimated_duration": 3600.008385697929,
    "input_throughput": 6997.607588937926,
    "output_throughput": 6121.5482407071095,
    "total_throughput": 13119.155829645035,
    "itl": 84.18977046389475,
    "ttft": 2016307.5004356564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4186154695181608,
    "arrivals": 924451,
    "finished_requests": 101984,
    "scheduler_time": 309.2051629108001
}
#Debug simulation 
Total elapsed time: 86.50773643096909. Arrivals time: 0.5502302893437445 Scheduler time: 85.73141203541309 Scheduler overhead time: 0.08790787635371089 Adapter cache time: 0.019195215310901403 Engine time: 0.0845232610590756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 619565730 . Total output tokens: 544442464
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 85.41639770613983,
    "estimated_duration": 3600.038798593705,
    "input_throughput": 6995.3118310384525,
    "output_throughput": 6102.168679010196,
    "total_throughput": 13097.480510048648,
    "itl": 84.29256778369808,
    "ttft": 2020362.114787305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.838824055432347,
    "arrivals": 924451,
    "finished_requests": 101986,
    "scheduler_time": 308.93244691398513
}
#Debug simulation 
Total elapsed time: 85.41657092701644. Arrivals time: 0.5541846784763038 Scheduler time: 84.63540000794455 Scheduler overhead time: 0.08785313786938787 Adapter cache time: 0.019365547224879265 Engine time: 0.08527090027928352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 619565730 . Total output tokens: 544442464
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.92459527403116,
    "estimated_duration": 3600.0647869635013,
    "input_throughput": 6936.723775202766,
    "output_throughput": 6048.214765147434,
    "total_throughput": 12984.9385403502,
    "itl": 82.31606702915869,
    "ttft": 2027527.3019716823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 521,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.912010721415315,
    "arrivals": 924451,
    "finished_requests": 101020,
    "scheduler_time": 311.88146937044576
}
#Debug simulation 
Total elapsed time: 84.92476336704567. Arrivals time: 0.5426591262221336 Scheduler time: 84.15473212720826 Scheduler overhead time: 0.08814837643876672 Adapter cache time: 0.019277786370366812 Engine time: 0.08547100750729442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 619565730 . Total output tokens: 544442464
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 85.97175050899386,
    "estimated_duration": 3600.0886429105867,
    "input_throughput": 6996.03773634791,
    "output_throughput": 6102.775008961264,
    "total_throughput": 13098.812745309173,
    "itl": 84.28761671235314,
    "ttft": 2020377.4880520906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5944971641292747,
    "arrivals": 924451,
    "finished_requests": 101999,
    "scheduler_time": 308.9541658120638
}
#Debug simulation 
Total elapsed time: 85.97191951796412. Arrivals time: 0.553046424407512 Scheduler time: 85.19171588588506 Scheduler overhead time: 0.08821695111691952 Adapter cache time: 0.019111407920718193 Engine time: 0.08544531557708979 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 619565730 . Total output tokens: 544442464
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 84.53359554708004,
    "estimated_duration": 3600.0283901998578,
    "input_throughput": 6936.793906398507,
    "output_throughput": 6048.275913399451,
    "total_throughput": 12985.069819797958,
    "itl": 82.31534138303319,
    "ttft": 2027511.8939961954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 521,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8759723326843565,
    "arrivals": 924451,
    "finished_requests": 101020,
    "scheduler_time": 311.88111099553316
}
#Debug simulation 
Total elapsed time: 84.53376172296703. Arrivals time: 0.5311718881130219 Scheduler time: 83.77532926015556 Scheduler overhead time: 0.08807888301089406 Adapter cache time: 0.019415189512073994 Engine time: 0.0847863513045013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 619565730 . Total output tokens: 544442464
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 85.84421956632286,
    "estimated_duration": 3600.070160101791,
    "input_throughput": 6996.2442063317585,
    "output_throughput": 6103.142167478968,
    "total_throughput": 13099.386373810727,
    "itl": 84.28185365845574,
    "ttft": 2020342.80952898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.351558493799515,
    "arrivals": 924451,
    "finished_requests": 102002,
    "scheduler_time": 308.9734216259637
}
#Debug simulation 
Total elapsed time: 85.84438382228836. Arrivals time: 0.5401754430495203 Scheduler time: 85.0757087180391 Scheduler overhead time: 0.08915281808003783 Adapter cache time: 0.019422020763158798 Engine time: 0.0861100978218019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 619565730 . Total output tokens: 544442464
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.86033071065322,
    "estimated_duration": 3600.0912689645747,
    "input_throughput": 6936.716636959722,
    "output_throughput": 6048.245273032343,
    "total_throughput": 12984.961909992064,
    "itl": 82.31467860425613,
    "ttft": 2027494.2888466984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 521,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.839933943953398,
    "arrivals": 924451,
    "finished_requests": 101021,
    "scheduler_time": 311.888738766581
}
#Debug simulation 
Total elapsed time: 84.86049375589937. Arrivals time: 0.5470103919506073 Scheduler time: 84.08408386679366 Scheduler overhead time: 0.0891071455553174 Adapter cache time: 0.019108597189188004 Engine time: 0.08640933223068714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_320_slots_16_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_320_slots_16_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 541239502 . Total output tokens: 475575346
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 86.52734555117786,
    "estimated_duration": 3600.0400308907006,
    "input_throughput": 6810.2867717096115,
    "output_throughput": 5924.655230770561,
    "total_throughput": 12734.942002480173,
    "itl": 81.18297054148209,
    "ttft": 1984555.9728484447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.947608192074173,
    "arrivals": 807771,
    "finished_requests": 99150,
    "scheduler_time": 319.57922488545694
}
#Debug simulation 
Total elapsed time: 86.52751530287787. Arrivals time: 0.54682671232149 Scheduler time: 85.75029816105962 Scheduler overhead time: 0.0897367144934833 Adapter cache time: 0.020006866194307804 Engine time: 0.08600491657853127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_320_slots_16_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_320_slots_16_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 541239502 . Total output tokens: 475575346
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 85.5433993008919,
    "estimated_duration": 3600.028874998641,
    "input_throughput": 6809.532881874247,
    "output_throughput": 5920.965008928726,
    "total_throughput": 12730.497890802973,
    "itl": 80.79135375459502,
    "ttft": 1980609.0646105853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.454202009919105,
    "arrivals": 807771,
    "finished_requests": 99109,
    "scheduler_time": 319.8755208527496
}
#Debug simulation 
Total elapsed time: 85.5435735238716. Arrivals time: 0.5519179995171726 Scheduler time: 84.75997153203934 Scheduler overhead time: 0.08934019645676017 Adapter cache time: 0.020167911425232887 Engine time: 0.087701256852597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_320_slots_16_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_320_slots_16_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 541239502 . Total output tokens: 475575346
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 85.59386053774506,
    "estimated_duration": 3600.055657706534,
    "input_throughput": 6768.398135134136,
    "output_throughput": 5881.0218543920855,
    "total_throughput": 12649.41998952622,
    "itl": 78.78278929247254,
    "ttft": 1996417.7248977982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.314410514300724,
    "arrivals": 807771,
    "finished_requests": 98440,
    "scheduler_time": 321.97621912794517
}
#Debug simulation 
Total elapsed time: 85.59402586566284. Arrivals time: 0.549317947588861 Scheduler time: 84.81281635630876 Scheduler overhead time: 0.08956791600212455 Adapter cache time: 0.019779325928539038 Engine time: 0.08746093045920134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_320_slots_16_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_320_slots_16_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 541239502 . Total output tokens: 475575346
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 85.67176682595164,
    "estimated_duration": 3600.043978519411,
    "input_throughput": 6809.575145824241,
    "output_throughput": 5921.175720960728,
    "total_throughput": 12730.750866784969,
    "itl": 80.78522159571087,
    "ttft": 1980496.4263781132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.176557815256523,
    "arrivals": 807771,
    "finished_requests": 99111,
    "scheduler_time": 319.90976756800376
}
#Debug simulation 
Total elapsed time: 85.67194199608639. Arrivals time: 0.5489897239021957 Scheduler time: 84.88943115016446 Scheduler overhead time: 0.09011607151478529 Adapter cache time: 0.020483318716287613 Engine time: 0.08795664319768548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_320_slots_16_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_320_slots_16_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 541239502 . Total output tokens: 475575346
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 85.59217640012503,
    "estimated_duration": 3600.0161584888983,
    "input_throughput": 6768.472397698307,
    "output_throughput": 5881.086380703057,
    "total_throughput": 12649.558778401364,
    "itl": 78.78209340369102,
    "ttft": 1996402.3635873976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.275265367920547,
    "arrivals": 807771,
    "finished_requests": 98440,
    "scheduler_time": 321.9759661879114
}
#Debug simulation 
Total elapsed time: 85.59234271012247. Arrivals time: 0.5354112451896071 Scheduler time: 84.82272149715573 Scheduler overhead time: 0.09052341291680932 Adapter cache time: 0.020302494056522846 Engine time: 0.08807693840935826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_320_slots_16_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_320_slots_16_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 541239502 . Total output tokens: 475575346
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 85.8476716671139,
    "estimated_duration": 3600.0243576351313,
    "input_throughput": 6809.759202880557,
    "output_throughput": 5921.36132490038,
    "total_throughput": 12731.120527780937,
    "itl": 80.77946766532379,
    "ttft": 1980393.6643187124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8878078528074367,
    "arrivals": 807771,
    "finished_requests": 99114,
    "scheduler_time": 319.9412286776797
}
#Debug simulation 
Total elapsed time: 85.84784875623882. Arrivals time: 0.5558997238986194 Scheduler time: 85.06142285326496 Scheduler overhead time: 0.08963018050417304 Adapter cache time: 0.020435717422515154 Engine time: 0.08588113263249397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_320_slots_16_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_320_slots_16_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 541239502 . Total output tokens: 475575346
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 85.74183703493327,
    "estimated_duration": 3600.037903550558,
    "input_throughput": 6784.5157896563205,
    "output_throughput": 5884.739707630825,
    "total_throughput": 12669.255497287146,
    "itl": 79.27186387127576,
    "ttft": 1996355.3979795887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.292909866049922,
    "arrivals": 807771,
    "finished_requests": 98657,
    "scheduler_time": 320.9411152420935
}
#Debug simulation 
Total elapsed time: 85.74200819572434. Arrivals time: 0.542263600975275 Scheduler time: 84.9649362959899 Scheduler overhead time: 0.09075379045680165 Adapter cache time: 0.02040081936866045 Engine time: 0.08795722294598818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_320_slots_16_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_320_slots_16_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 528543537 . Total output tokens: 464345000
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 86.90046307677403,
    "estimated_duration": 3600.0051199846175,
    "input_throughput": 6840.450826943608,
    "output_throughput": 5950.9379253581565,
    "total_throughput": 12791.388752301764,
    "itl": 81.32762472594915,
    "ttft": 1989385.7170065946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.689724239828117,
    "arrivals": 788657,
    "finished_requests": 99574,
    "scheduler_time": 318.14308603233945
}
#Debug simulation 
Total elapsed time: 86.90064002061263. Arrivals time: 0.5615128446370363 Scheduler time: 86.10856136120856 Scheduler overhead time: 0.08945240685716271 Adapter cache time: 0.020000663120299578 Engine time: 0.08601063815876842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_320_slots_16_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_320_slots_16_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 528543537 . Total output tokens: 464345000
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 90.49496499588713,
    "estimated_duration": 3600.009524867161,
    "input_throughput": 6919.85335814333,
    "output_throughput": 6020.152683012612,
    "total_throughput": 12940.006041155943,
    "itl": 82.59979766218599,
    "ttft": 1977554.4625498056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2327007042151,
    "arrivals": 788657,
    "finished_requests": 100744,
    "scheduler_time": 314.40211912990685
}
#Debug simulation 
Total elapsed time: 90.49513034708798. Arrivals time: 0.5658416138030589 Scheduler time: 89.69623360829428 Scheduler overhead time: 0.08990769041702151 Adapter cache time: 0.01998847909271717 Engine time: 0.08857531333342195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_320_slots_16_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_320_slots_16_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 528543537 . Total output tokens: 464345000
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 87.08454707171768,
    "estimated_duration": 3600.017454062016,
    "input_throughput": 6900.843764512492,
    "output_throughput": 6005.9656031955265,
    "total_throughput": 12906.80936770802,
    "itl": 81.02932937852916,
    "ttft": 1979732.2645219383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 566,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.25151073370598,
    "arrivals": 788657,
    "finished_requests": 100476,
    "scheduler_time": 315.2057698141746
}
#Debug simulation 
Total elapsed time: 87.08472416969016. Arrivals time: 0.5612758793868124 Scheduler time: 86.291042430792 Scheduler overhead time: 0.08991001732647419 Adapter cache time: 0.020067797042429447 Engine time: 0.08766301721334457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_320_slots_16_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_320_slots_16_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 528543537 . Total output tokens: 464345000
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 86.22580773709342,
    "estimated_duration": 3600.0106151121536,
    "input_throughput": 6769.530594631531,
    "output_throughput": 5884.078205513869,
    "total_throughput": 12653.608800145399,
    "itl": 80.59848580981851,
    "ttft": 2000682.0684625015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6258595849061326,
    "arrivals": 788657,
    "finished_requests": 98522,
    "scheduler_time": 320.87587738622557
}
#Debug simulation 
Total elapsed time: 86.22597525594756. Arrivals time: 0.5474310317076743 Scheduler time: 85.445940092206 Scheduler overhead time: 0.09059037966653705 Adapter cache time: 0.019717338029295206 Engine time: 0.08722326019778848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_320_slots_16_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_320_slots_16_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 528543537 . Total output tokens: 464345000
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 87.16414700821042,
    "estimated_duration": 3600.0220768472273,
    "input_throughput": 6900.863791856758,
    "output_throughput": 6006.303166600719,
    "total_throughput": 12907.166958457477,
    "itl": 81.02837353000719,
    "ttft": 1979706.994573162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 566,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.211951352972572,
    "arrivals": 788657,
    "finished_requests": 100478,
    "scheduler_time": 315.2111497018124
}
#Debug simulation 
Total elapsed time: 87.16432230686769. Arrivals time: 0.544270440004766 Scheduler time: 86.38725077128038 Scheduler overhead time: 0.08977667381986976 Adapter cache time: 0.01997972186654806 Engine time: 0.08821722585707903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_320_slots_16_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_320_slots_16_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 528543537 . Total output tokens: 464345000
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 88.08297632122412,
    "estimated_duration": 3600.053294065893,
    "input_throughput": 6861.580644019174,
    "output_throughput": 5972.732691330662,
    "total_throughput": 12834.313335349836,
    "itl": 81.33485177824825,
    "ttft": 1984239.4395772857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.479236912610925,
    "arrivals": 788657,
    "finished_requests": 99998,
    "scheduler_time": 316.8354906646095
}
#Debug simulation 
Total elapsed time: 88.08314695209265. Arrivals time: 0.5460322559811175 Scheduler time: 87.30695351073518 Scheduler overhead time: 0.08950543217360973 Adapter cache time: 0.019553042016923428 Engine time: 0.08686960116028786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_320_slots_16_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_320_slots_16_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 528543537 . Total output tokens: 464345000
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 87.14227397320792,
    "estimated_duration": 3600.0275313631346,
    "input_throughput": 6900.853336139129,
    "output_throughput": 6006.294066260269,
    "total_throughput": 12907.147402399398,
    "itl": 81.02768141808464,
    "ttft": 1979691.1191746206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 566,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.173013323769009,
    "arrivals": 788657,
    "finished_requests": 100478,
    "scheduler_time": 315.21663883739495
}
#Debug simulation 
Total elapsed time: 87.14245118480176. Arrivals time: 0.5462026563473046 Scheduler time: 86.36432659579441 Scheduler overhead time: 0.08966952469199896 Adapter cache time: 0.020185898058116436 Engine time: 0.0871894876472652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_320_slots_16_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_320_slots_16_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 522202324 . Total output tokens: 458730338
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 89.15808834694326,
    "estimated_duration": 3600.0680793947536,
    "input_throughput": 6933.041389649553,
    "output_throughput": 6037.617767399067,
    "total_throughput": 12970.65915704862,
    "itl": 83.54555265820525,
    "ttft": 1991606.742542849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6764994217642166,
    "arrivals": 779141,
    "finished_requests": 101181,
    "scheduler_time": 312.95767972900205
}
#Debug simulation 
Total elapsed time: 89.1582566909492. Arrivals time: 0.5304567525163293 Scheduler time: 88.39823767868802 Scheduler overhead time: 0.08906589634716511 Adapter cache time: 0.019709328655153513 Engine time: 0.08650751365348697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_320_slots_16_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_320_slots_16_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 522202324 . Total output tokens: 458730338
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 87.23892445024103,
    "estimated_duration": 3600.085106817213,
    "input_throughput": 6890.186555042305,
    "output_throughput": 6005.036925116683,
    "total_throughput": 12895.223480158988,
    "itl": 83.40030961161574,
    "ttft": 1980961.7641514428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.464193409853622,
    "arrivals": 779141,
    "finished_requests": 100574,
    "scheduler_time": 314.8260867221052
}
#Debug simulation 
Total elapsed time: 87.23910596035421. Arrivals time: 0.5480883195996284 Scheduler time: 86.45889472961426 Scheduler overhead time: 0.0899313478730619 Adapter cache time: 0.020283279474824667 Engine time: 0.08732616296038032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_320_slots_16_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_320_slots_16_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 522202324 . Total output tokens: 458730338
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 86.46007175790146,
    "estimated_duration": 3600.0022961976397,
    "input_throughput": 6859.388124858105,
    "output_throughput": 5986.242848445361,
    "total_throughput": 12845.630973303467,
    "itl": 81.09462340245125,
    "ttft": 1986535.3560882558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.330094702448732,
    "arrivals": 779141,
    "finished_requests": 100168,
    "scheduler_time": 315.9007020035157
}
#Debug simulation 
Total elapsed time: 86.46023558499292. Arrivals time: 0.5318561508320272 Scheduler time: 85.69760813610628 Scheduler overhead time: 0.08890737779438496 Adapter cache time: 0.020108794793486595 Engine time: 0.0870990976691246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_320_slots_16_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_320_slots_16_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 522202324 . Total output tokens: 458730338
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 87.08917354792356,
    "estimated_duration": 3600.000103299866,
    "input_throughput": 6890.84869116007,
    "output_throughput": 6005.201216573199,
    "total_throughput": 12896.04990773327,
    "itl": 83.39494298590378,
    "ttft": 1980994.80097455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.180996331297787,
    "arrivals": 779141,
    "finished_requests": 100578,
    "scheduler_time": 314.84099359995093
}
#Debug simulation 
Total elapsed time: 87.08935286430642. Arrivals time: 0.5195112344808877 Scheduler time: 86.33750725537539 Scheduler overhead time: 0.08990097139030695 Adapter cache time: 0.020543993450701237 Engine time: 0.08709352044388652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_320_slots_16_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_320_slots_16_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 522202324 . Total output tokens: 458730338
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 86.01349767670035,
    "estimated_duration": 3600.007029231089,
    "input_throughput": 6859.422439870704,
    "output_throughput": 5986.3077557942825,
    "total_throughput": 12845.730195664986,
    "itl": 81.09371043565555,
    "ttft": 1986516.1775425544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2901210873620945,
    "arrivals": 779141,
    "finished_requests": 100169,
    "scheduler_time": 315.9064041113017
}
#Debug simulation 
Total elapsed time: 86.01366782467812. Arrivals time: 0.5323307337239385 Scheduler time: 85.24997465172783 Scheduler overhead time: 0.08923517679795623 Adapter cache time: 0.020017115399241447 Engine time: 0.0874696928076446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_320_slots_16_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_320_slots_16_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 522202324 . Total output tokens: 458730338
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 87.27273696521297,
    "estimated_duration": 3600.016492905708,
    "input_throughput": 6891.36287261165,
    "output_throughput": 6005.339709582896,
    "total_throughput": 12896.702582194546,
    "itl": 83.38856540958506,
    "ttft": 1981057.0320833023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9005756946885777,
    "arrivals": 779141,
    "finished_requests": 100587,
    "scheduler_time": 314.86332890785775
}
#Debug simulation 
Total elapsed time: 87.2729144259356. Arrivals time: 0.5219397940672934 Scheduler time: 86.51911074901 Scheduler overhead time: 0.0892854523845017 Adapter cache time: 0.020533314906060696 Engine time: 0.0876091392710805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_320_slots_16_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_320_slots_16_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 522202324 . Total output tokens: 458730338
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 87.40758008230478,
    "estimated_duration": 3600.0087809106794,
    "input_throughput": 6847.481353577182,
    "output_throughput": 5974.328205543794,
    "total_throughput": 12821.809559120975,
    "itl": 81.12302729404091,
    "ttft": 1988502.5450999818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.187249546945131,
    "arrivals": 779141,
    "finished_requests": 100028,
    "scheduler_time": 316.3658159228781
}
#Debug simulation 
Total elapsed time: 87.40774796204641. Arrivals time: 0.5348304347135127 Scheduler time: 86.64130802219734 Scheduler overhead time: 0.08892337186262012 Adapter cache time: 0.020002559758722782 Engine time: 0.08785700844600797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 518989457 . Total output tokens: 455926465
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 89.78942228294909,
    "estimated_duration": 3600.0332384846965,
    "input_throughput": 6812.324602403599,
    "output_throughput": 5946.8998150170855,
    "total_throughput": 12759.224417420684,
    "itl": 82.11247748751717,
    "ttft": 1985280.074172421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.38555342435841,
    "arrivals": 774377,
    "finished_requests": 99434,
    "scheduler_time": 317.7113348017385
}
#Debug simulation 
Total elapsed time: 89.78959670523182. Arrivals time: 0.5322937597520649 Scheduler time: 89.02744451165199 Scheduler overhead time: 0.08893648441880941 Adapter cache time: 0.019375557079911232 Engine time: 0.08685317961499095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 518989457 . Total output tokens: 455926465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 88.4031165628694,
    "estimated_duration": 3600.0539900563567,
    "input_throughput": 6798.679149702654,
    "output_throughput": 5932.87963430394,
    "total_throughput": 12731.558784006595,
    "itl": 81.52566384112683,
    "ttft": 1999149.681947867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7708201831067027,
    "arrivals": 774377,
    "finished_requests": 99245,
    "scheduler_time": 317.87402360753407
}
#Debug simulation 
Total elapsed time: 88.40328868385404. Arrivals time: 0.5302332662977278 Scheduler time: 87.63892954448238 Scheduler overhead time: 0.08949610171839595 Adapter cache time: 0.019886624068021774 Engine time: 0.08966172952204943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_320_slots_16_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_320_slots_16_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 518989457 . Total output tokens: 455926465
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 87.13286812137812,
    "estimated_duration": 3600.013773956118,
    "input_throughput": 6788.950413693032,
    "output_throughput": 5927.694542276527,
    "total_throughput": 12716.64495596956,
    "itl": 80.513113948054,
    "ttft": 1986476.8456432316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.076481843078543,
    "arrivals": 774377,
    "finished_requests": 99081,
    "scheduler_time": 318.63074808683615
}
#Debug simulation 
Total elapsed time: 87.1330402949825. Arrivals time: 0.5206789383664727 Scheduler time: 86.37828982062638 Scheduler overhead time: 0.09098676452413201 Adapter cache time: 0.02017535036429763 Engine time: 0.08810037141665816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_320_slots_16_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_320_slots_16_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 518989457 . Total output tokens: 455926465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 88.80140066379681,
    "estimated_duration": 3600.031756470938,
    "input_throughput": 6873.177981145331,
    "output_throughput": 5982.9911114768465,
    "total_throughput": 12856.169092622176,
    "itl": 82.25041604816782,
    "ttft": 1988332.782440738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7474374135816415,
    "arrivals": 774377,
    "finished_requests": 100232,
    "scheduler_time": 314.92649444140966
}
#Debug simulation 
Total elapsed time: 88.80157235497609. Arrivals time: 0.5375904557295144 Scheduler time: 88.03328650584444 Scheduler overhead time: 0.08928013266995549 Adapter cache time: 0.020045801997184753 Engine time: 0.08692417806014419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_320_slots_16_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_320_slots_16_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 518989457 . Total output tokens: 455926465
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 86.69719785591587,
    "estimated_duration": 3600.048497821549,
    "input_throughput": 6789.0063188841805,
    "output_throughput": 5927.719310701855,
    "total_throughput": 12716.725629586035,
    "itl": 80.51232293447374,
    "ttft": 1986458.1194209743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.038372282581438,
    "arrivals": 774377,
    "finished_requests": 99082,
    "scheduler_time": 318.6371704109178
}
#Debug simulation 
Total elapsed time: 86.69737316807732. Arrivals time: 0.5749044721014798 Scheduler time: 85.8901875843294 Scheduler overhead time: 0.09052061848342419 Adapter cache time: 0.019934324081987143 Engine time: 0.08711285423487425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_320_slots_16_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_320_slots_16_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 518989457 . Total output tokens: 455926465
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 88.62945836596191,
    "estimated_duration": 3600.0553859961256,
    "input_throughput": 6887.278761445889,
    "output_throughput": 6016.8568751078965,
    "total_throughput": 12904.135636553787,
    "itl": 82.93907233939902,
    "ttft": 1980768.0782678574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4983886754326363,
    "arrivals": 774377,
    "finished_requests": 100463,
    "scheduler_time": 314.34960076878036
}
#Debug simulation 
Total elapsed time: 88.62963415775448. Arrivals time: 0.5360143184661865 Scheduler time: 87.8624532870017 Scheduler overhead time: 0.08943051332607865 Adapter cache time: 0.019727430306375027 Engine time: 0.0875300895422697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_320_slots_16_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_320_slots_16_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 518989457 . Total output tokens: 455926465
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 86.84384248312563,
    "estimated_duration": 3600.010527477393,
    "input_throughput": 6789.077924482119,
    "output_throughput": 5927.7818320585475,
    "total_throughput": 12716.859756540667,
    "itl": 80.51161308409792,
    "ttft": 1986442.9750420111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.000676956437563,
    "arrivals": 774377,
    "finished_requests": 99082,
    "scheduler_time": 318.636895392906
}
#Debug simulation 
Total elapsed time: 86.84401838388294. Arrivals time: 0.5271346913650632 Scheduler time: 86.0825880295597 Scheduler overhead time: 0.09075306821614504 Adapter cache time: 0.019950293470174074 Engine time: 0.08842263836413622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_320_slots_16_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_320_slots_16_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 517376606 . Total output tokens: 454521569
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 89.41225054720417,
    "estimated_duration": 3600.0263664945264,
    "input_throughput": 7010.883374328301,
    "output_throughput": 6108.101930767743,
    "total_throughput": 13118.985305096045,
    "itl": 84.83525757533081,
    "ttft": 1962551.0516542175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.650049785636416,
    "arrivals": 771975,
    "finished_requests": 102267,
    "scheduler_time": 309.73627456019716
}
#Debug simulation 
Total elapsed time: 89.41241919295862. Arrivals time: 0.5406762133352458 Scheduler time: 88.64155875286087 Scheduler overhead time: 0.08890379592776299 Adapter cache time: 0.019724704790860415 Engine time: 0.08692508330568671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_320_slots_16_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_320_slots_16_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 517376606 . Total output tokens: 454521569
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 90.16348682809621,
    "estimated_duration": 3600.025275447261,
    "input_throughput": 6866.7429000005495,
    "output_throughput": 5980.94828579362,
    "total_throughput": 12847.691185794169,
    "itl": 83.12360031642156,
    "ttft": 1979434.8523380319,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.73973161545117,
    "arrivals": 771975,
    "finished_requests": 100236,
    "scheduler_time": 315.77453880274174
}
#Debug simulation 
Total elapsed time: 90.16366852913052. Arrivals time: 0.5480639380402863 Scheduler time: 89.38446324970573 Scheduler overhead time: 0.09019436640664935 Adapter cache time: 0.019522254820913076 Engine time: 0.08730459166690707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_320_slots_16_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_320_slots_16_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 517376606 . Total output tokens: 454521569
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 89.49325667414814,
    "estimated_duration": 3600.045397470691,
    "input_throughput": 6744.841889232783,
    "output_throughput": 5888.793795460074,
    "total_throughput": 12633.635684692856,
    "itl": 80.28962364482763,
    "ttft": 1986113.9645068264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 485,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.646904175882258,
    "arrivals": 771975,
    "finished_requests": 98442,
    "scheduler_time": 321.2117665380355
}
#Debug simulation 
Total elapsed time: 89.49343245197088. Arrivals time: 0.5457824161276221 Scheduler time: 88.71180939488113 Scheduler overhead time: 0.09152918169274926 Adapter cache time: 0.019570030737668276 Engine time: 0.08897454617545009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_320_slots_16_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_320_slots_16_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 517376606 . Total output tokens: 454521569
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 90.46624283725396,
    "estimated_duration": 3600.0505061317335,
    "input_throughput": 6918.746266913781,
    "output_throughput": 6038.432506147883,
    "total_throughput": 12957.178773061665,
    "itl": 82.73830556332123,
    "ttft": 1973688.2285341108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5051222709612873,
    "arrivals": 771975,
    "finished_requests": 100990,
    "scheduler_time": 313.45663852540196
}
#Debug simulation 
Total elapsed time: 90.46642103837803. Arrivals time: 0.5397140281274915 Scheduler time: 89.69372964836657 Scheduler overhead time: 0.09092419547960162 Adapter cache time: 0.019720281939953566 Engine time: 0.08796733012422919 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_320_slots_16_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_320_slots_16_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 517376606 . Total output tokens: 454521569
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 89.2716618697159,
    "estimated_duration": 3600.011497892064,
    "input_throughput": 6744.9054021682505,
    "output_throughput": 5888.849247401937,
    "total_throughput": 12633.754649570186,
    "itl": 80.28897955624201,
    "ttft": 1986100.7967329365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 485,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6133511932706757,
    "arrivals": 771975,
    "finished_requests": 98442,
    "scheduler_time": 321.2116222044639
}
#Debug simulation 
Total elapsed time: 89.27183223003522. Arrivals time: 0.5421987944282591 Scheduler time: 88.4971559974365 Scheduler overhead time: 0.09020369639620185 Adapter cache time: 0.01966396253556013 Engine time: 0.0876296553760767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_320_slots_16_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_320_slots_16_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 517376606 . Total output tokens: 454521569
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 86.73913091327995,
    "estimated_duration": 3600.083706377972,
    "input_throughput": 6951.3422578659865,
    "output_throughput": 6051.458459536362,
    "total_throughput": 13002.80071740235,
    "itl": 82.6068408519062,
    "ttft": 1969977.261396893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6388349361251873,
    "arrivals": 771975,
    "finished_requests": 101400,
    "scheduler_time": 311.717757279521
}
#Debug simulation 
Total elapsed time: 86.7393029332161. Arrivals time: 0.555670308880508 Scheduler time: 85.95553887076676 Scheduler overhead time: 0.08795672981068492 Adapter cache time: 0.01969255181029439 Engine time: 0.08656109450384974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_320_slots_16_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_320_slots_16_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 517376606 . Total output tokens: 454521569
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 89.70782649097964,
    "estimated_duration": 3600.043285956071,
    "input_throughput": 6744.846678573046,
    "output_throughput": 5889.099745746419,
    "total_throughput": 12633.946424319465,
    "itl": 80.28808655944172,
    "ttft": 1986077.2957016262,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 485,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.57917685912925,
    "arrivals": 771975,
    "finished_requests": 98445,
    "scheduler_time": 321.2179492926229
}
#Debug simulation 
Total elapsed time: 89.70807221997529. Arrivals time: 0.5240688673220575 Scheduler time: 88.95178713509813 Scheduler overhead time: 0.0903830286115408 Adapter cache time: 0.019646824337542057 Engine time: 0.08732727123424411 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 516598869 . Total output tokens: 453846498
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 89.14008652698249,
    "estimated_duration": 3600.017171397681,
    "input_throughput": 7015.278482739814,
    "output_throughput": 6116.006105451928,
    "total_throughput": 13131.284588191742,
    "itl": 83.88640300148921,
    "ttft": 1973169.9363485721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 530,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5045767869335127,
    "arrivals": 770785,
    "finished_requests": 102809,
    "scheduler_time": 308.17710035657103
}
#Debug simulation 
Total elapsed time: 89.1402623062022. Arrivals time: 0.6328451498411596 Scheduler time: 88.27988831000403 Scheduler overhead time: 0.08815447427332401 Adapter cache time: 0.019400607328861952 Engine time: 0.08572617918252945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 516598869 . Total output tokens: 453846498
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 89.96344470698386,
    "estimated_duration": 3600.020574758985,
    "input_throughput": 6905.6691437560385,
    "output_throughput": 6027.869716120388,
    "total_throughput": 12933.538859876428,
    "itl": 82.45454285751103,
    "ttft": 1973062.8926458005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6461920593632438,
    "arrivals": 770785,
    "finished_requests": 101130,
    "scheduler_time": 313.4209420617087
}
#Debug simulation 
Total elapsed time: 89.96361834928393. Arrivals time: 0.5476187099702656 Scheduler time: 89.18477040715516 Scheduler overhead time: 0.0899935681372881 Adapter cache time: 0.01929589919745922 Engine time: 0.08701545791700482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_320_slots_16_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_320_slots_16_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 516598869 . Total output tokens: 453846498
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 88.84870589803904,
    "estimated_duration": 3600.0417351285696,
    "input_throughput": 6896.146441233789,
    "output_throughput": 6022.708233749313,
    "total_throughput": 12918.854674983102,
    "itl": 81.62009440666046,
    "ttft": 1971988.9651400791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.67920846937693,
    "arrivals": 770785,
    "finished_requests": 100979,
    "scheduler_time": 313.72601761960493
}
#Debug simulation 
Total elapsed time: 88.84887472214177. Arrivals time: 0.5490970159880817 Scheduler time: 88.06934796273708 Scheduler overhead time: 0.09060807339847088 Adapter cache time: 0.019075707998126745 Engine time: 0.08657856984063983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_320_slots_16_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_320_slots_16_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 516598869 . Total output tokens: 453846498
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 88.24914875579998,
    "estimated_duration": 3600.032033875907,
    "input_throughput": 6976.866528867609,
    "output_throughput": 6079.019518178644,
    "total_throughput": 13055.886047046253,
    "itl": 83.53516185673917,
    "ttft": 1974993.954147329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5725689593609378,
    "arrivals": 770785,
    "finished_requests": 102215,
    "scheduler_time": 310.143981685347
}
#Debug simulation 
Total elapsed time: 88.24932011263445. Arrivals time: 0.5461273430846632 Scheduler time: 87.47601410141215 Scheduler overhead time: 0.08900680532678962 Adapter cache time: 0.018517872784286737 Engine time: 0.08564506657421589 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_320_slots_16_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_320_slots_16_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 516598869 . Total output tokens: 453846498
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 87.30911628808826,
    "estimated_duration": 3600.038443161034,
    "input_throughput": 6853.350148765724,
    "output_throughput": 5990.503251699672,
    "total_throughput": 12843.853400465396,
    "itl": 80.89702359244042,
    "ttft": 1976640.8816041583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6531620775908538,
    "arrivals": 770785,
    "finished_requests": 100360,
    "scheduler_time": 315.49478637871454
}
#Debug simulation 
Total elapsed time: 87.30929195787758. Arrivals time: 0.5311705423519015 Scheduler time: 86.54914784152061 Scheduler overhead time: 0.08944474346935749 Adapter cache time: 0.0187032213434577 Engine time: 0.08664367208257318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_320_slots_16_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_320_slots_16_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 516598869 . Total output tokens: 453846498
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 87.25574180204421,
    "estimated_duration": 3600.1113786704955,
    "input_throughput": 6977.237745704487,
    "output_throughput": 6079.349413929111,
    "total_throughput": 13056.587159633598,
    "itl": 83.53200891484894,
    "ttft": 1974868.956414721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.338790651918374,
    "arrivals": 770785,
    "finished_requests": 102225,
    "scheduler_time": 310.1668091341459
}
#Debug simulation 
Total elapsed time: 87.25590389594436. Arrivals time: 0.5087258298881352 Scheduler time: 86.52514474419877 Scheduler overhead time: 0.08676919853314757 Adapter cache time: 0.018036859575659037 Engine time: 0.0842624381184578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_320_slots_16_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_320_slots_16_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 516598869 . Total output tokens: 453846498
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 85.35592986783013,
    "estimated_duration": 3600.005152336392,
    "input_throughput": 6853.413524696692,
    "output_throughput": 5990.558648507408,
    "total_throughput": 12843.9721732041,
    "itl": 80.89639875840433,
    "ttft": 1976628.0633856934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6200233293325015,
    "arrivals": 770785,
    "finished_requests": 100360,
    "scheduler_time": 315.49453317110914
}
#Debug simulation 
Total elapsed time: 85.35609607491642. Arrivals time: 0.42167800525203347 Scheduler time: 84.71974125364795 Scheduler overhead time: 0.08406145451590419 Adapter cache time: 0.016769948415458202 Engine time: 0.08059464208781719 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_320_slots_16_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_320_slots_16_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 451189375 . Total output tokens: 396562865
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 87.29414473101497,
    "estimated_duration": 3600.03023548719,
    "input_throughput": 6907.840038358613,
    "output_throughput": 6013.497827489852,
    "total_throughput": 12921.337865848465,
    "itl": 84.96043973065973,
    "ttft": 1945095.958045593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3260417430708586,
    "arrivals": 673640,
    "finished_requests": 100491,
    "scheduler_time": 314.4088771418468
}
#Debug simulation 
Total elapsed time: 87.29430650593713. Arrivals time: 0.4246807931922376 Scheduler time: 86.65247801505029 Scheduler overhead time: 0.0850045601837337 Adapter cache time: 0.017088549211621284 Engine time: 0.08160807378590107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_320_slots_16_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_320_slots_16_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 451189375 . Total output tokens: 396562865
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 83.96418617013842,
    "estimated_duration": 3600.012278448851,
    "input_throughput": 6874.9468295325005,
    "output_throughput": 5984.314033862841,
    "total_throughput": 12859.260863395342,
    "itl": 83.8477960405576,
    "ttft": 1933149.2821477388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.231312483241787,
    "arrivals": 673640,
    "finished_requests": 100091,
    "scheduler_time": 315.73598147138273
}
#Debug simulation 
Total elapsed time: 83.96435704594478. Arrivals time: 0.4260207284241915 Scheduler time: 83.32094382168725 Scheduler overhead time: 0.08520746557042003 Adapter cache time: 0.017503452952951193 Engine time: 0.08139094617217779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_320_slots_16_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_320_slots_16_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 451189375 . Total output tokens: 396562865
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.12146937288344,
    "estimated_duration": 3600.0251960146647,
    "input_throughput": 6832.117738294798,
    "output_throughput": 5943.66701202189,
    "total_throughput": 12775.784750316689,
    "itl": 81.69814252736808,
    "ttft": 1939871.4531827436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.25881391788371,
    "arrivals": 673640,
    "finished_requests": 99390,
    "scheduler_time": 317.8773669959246
}
#Debug simulation 
Total elapsed time: 84.12162933684886. Arrivals time: 0.4431169028393924 Scheduler time: 83.45716902147979 Scheduler overhead time: 0.08693005377426744 Adapter cache time: 0.017762986477464437 Engine time: 0.08303060149773955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_320_slots_16_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_320_slots_16_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 451189375 . Total output tokens: 396562865
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 82.53409563237801,
    "estimated_duration": 3600.0253688051625,
    "input_throughput": 6778.532787978448,
    "output_throughput": 5882.652712258196,
    "total_throughput": 12661.185500236645,
    "itl": 83.0140468121055,
    "ttft": 1938416.923595956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 608,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.168785673342639,
    "arrivals": 673640,
    "finished_requests": 98690,
    "scheduler_time": 320.01137847448456
}
#Debug simulation 
Total elapsed time: 82.53426507906988. Arrivals time: 0.439574655611068 Scheduler time: 81.87389338156208 Scheduler overhead time: 0.0864249779842794 Adapter cache time: 0.018113066907972097 Engine time: 0.08247923012822866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_320_slots_16_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_320_slots_16_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 451189375 . Total output tokens: 396562865
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 84.35231332900003,
    "estimated_duration": 3600.028843776185,
    "input_throughput": 6832.261925490607,
    "output_throughput": 5943.724877924977,
    "total_throughput": 12775.986803415582,
    "itl": 81.6971280549939,
    "ttft": 1939852.2566069087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.219461654326916,
    "arrivals": 673640,
    "finished_requests": 99391,
    "scheduler_time": 317.882778317356
}
#Debug simulation 
Total elapsed time: 84.35247640917078. Arrivals time: 0.451885131187737 Scheduler time: 83.67925779195502 Scheduler overhead time: 0.0866233934648335 Adapter cache time: 0.018071515019983053 Engine time: 0.08259762497618794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_320_slots_16_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_320_slots_16_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 451189375 . Total output tokens: 396562865
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 85.87059037899598,
    "estimated_duration": 3600.026212678567,
    "input_throughput": 6868.383600352336,
    "output_throughput": 5975.702600230147,
    "total_throughput": 12844.086200582482,
    "itl": 83.76707190504128,
    "ttft": 1944206.0877466283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2941032053343804,
    "arrivals": 673640,
    "finished_requests": 99813,
    "scheduler_time": 316.29770608476116
}
#Debug simulation 
Total elapsed time: 85.87074526585639. Arrivals time: 0.44548539025709033 Scheduler time: 85.20732782874256 Scheduler overhead time: 0.08540354063734412 Adapter cache time: 0.017301360610872507 Engine time: 0.08188132056966424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_320_slots_16_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_320_slots_16_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 451189375 . Total output tokens: 396562865
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 83.80579579807818,
    "estimated_duration": 3600.0340992637966,
    "input_throughput": 6887.523650142819,
    "output_throughput": 5998.9548444600705,
    "total_throughput": 12886.47849460289,
    "itl": 82.19516420981199,
    "ttft": 1946453.9754078975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8114614976011567,
    "arrivals": 673640,
    "finished_requests": 100170,
    "scheduler_time": 315.0914792429754
}
#Debug simulation 
Total elapsed time: 83.80595017410815. Arrivals time: 0.4409332536160946 Scheduler time: 83.1455568857491 Scheduler overhead time: 0.08613395737484097 Adapter cache time: 0.017273991834372282 Engine time: 0.08203043695539236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_320_slots_16_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_320_slots_16_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 444831474 . Total output tokens: 390978691
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 85.33367174817249,
    "estimated_duration": 3600.0422028093835,
    "input_throughput": 6903.903232191081,
    "output_throughput": 6059.053136370956,
    "total_throughput": 12962.956368562036,
    "itl": 85.99330951190224,
    "ttft": 1918731.0168591028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5508636501571638,
    "arrivals": 664253,
    "finished_requests": 100934,
    "scheduler_time": 311.98247166890116
}
#Debug simulation 
Total elapsed time: 85.33383580809459. Arrivals time: 0.42405002377927303 Scheduler time: 84.69456167472526 Scheduler overhead time: 0.084424854721874 Adapter cache time: 0.017197916749864817 Engine time: 0.08048287639394403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_320_slots_16_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_320_slots_16_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 444831474 . Total output tokens: 390978691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 87.32859408203512,
    "estimated_duration": 3600.0315994635544,
    "input_throughput": 6937.3627175165675,
    "output_throughput": 6091.586252539507,
    "total_throughput": 13028.948970056075,
    "itl": 85.31910234877242,
    "ttft": 1936929.0940958369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.599833061001268,
    "arrivals": 664253,
    "finished_requests": 101535,
    "scheduler_time": 310.11161332076733
}
#Debug simulation 
Total elapsed time: 87.32873124163598. Arrivals time: 0.43827419681474566 Scheduler time: 86.67384468112141 Scheduler overhead time: 0.08581271907314658 Adapter cache time: 0.01688780914992094 Engine time: 0.0807860353961587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_320_slots_16_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_320_slots_16_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 444831474 . Total output tokens: 390978691
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.44489012099802,
    "estimated_duration": 3600.048984152541,
    "input_throughput": 6926.814637737545,
    "output_throughput": 6081.633637869496,
    "total_throughput": 13008.448275607041,
    "itl": 84.02674818899615,
    "ttft": 1944187.5088016298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7539068667311546,
    "arrivals": 664253,
    "finished_requests": 101398,
    "scheduler_time": 310.57147616673313
}
#Debug simulation 
Total elapsed time: 84.44501652242616. Arrivals time: 0.4288607556372881 Scheduler time: 83.798595612403 Scheduler overhead time: 0.08522264286875725 Adapter cache time: 0.017053250689059496 Engine time: 0.0818373472429812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_320_slots_16_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_320_slots_16_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 444831474 . Total output tokens: 390978691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 86.01763359084725,
    "estimated_duration": 3600.00215791084,
    "input_throughput": 6929.241957587129,
    "output_throughput": 6075.79524693766,
    "total_throughput": 13005.03720452479,
    "itl": 85.4456336217019,
    "ttft": 1930389.4338656696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.455712977531361,
    "arrivals": 664253,
    "finished_requests": 101267,
    "scheduler_time": 311.13207559933073
}
#Debug simulation 
Total elapsed time: 86.01775942696258. Arrivals time: 0.44536953000351787 Scheduler time: 85.35635488806292 Scheduler overhead time: 0.08438866958022118 Adapter cache time: 0.017317621503025293 Engine time: 0.08120722230523825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_320_slots_16_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_320_slots_16_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 444831474 . Total output tokens: 390978691
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 84.48224511696026,
    "estimated_duration": 3600.0148169999193,
    "input_throughput": 6926.880379003885,
    "output_throughput": 6081.691357661012,
    "total_throughput": 13008.571736664897,
    "itl": 84.0261305777099,
    "ttft": 1944172.5270997891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7199396497663435,
    "arrivals": 664253,
    "finished_requests": 101398,
    "scheduler_time": 310.5711750998544
}
#Debug simulation 
Total elapsed time: 84.4823706438765. Arrivals time: 0.4434609850868583 Scheduler time: 83.82051593018696 Scheduler overhead time: 0.08529854286462069 Adapter cache time: 0.01729021267965436 Engine time: 0.08235860150307417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_320_slots_16_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_320_slots_16_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 444831474 . Total output tokens: 390978691
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 86.56356849521399,
    "estimated_duration": 3600.026000918532,
    "input_throughput": 6956.611422698094,
    "output_throughput": 6100.887603144016,
    "total_throughput": 13057.49902584211,
    "itl": 85.57917813365722,
    "ttft": 1931302.6935245604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.185576549344682,
    "arrivals": 664253,
    "finished_requests": 101696,
    "scheduler_time": 309.77180445313184
}
#Debug simulation 
Total elapsed time: 86.56370078632608. Arrivals time: 0.4551282236352563 Scheduler time: 85.89246813720092 Scheduler overhead time: 0.08513183332979679 Adapter cache time: 0.01694942219182849 Engine time: 0.08094153553247452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_320_slots_16_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_320_slots_16_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 444831474 . Total output tokens: 390978691
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.56030883220956,
    "estimated_duration": 3600.0376756514333,
    "input_throughput": 6927.014172285714,
    "output_throughput": 6081.653852702585,
    "total_throughput": 13008.6680249883,
    "itl": 84.02439496062546,
    "ttft": 1944267.1969636246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6855581984483026,
    "arrivals": 664253,
    "finished_requests": 101400,
    "scheduler_time": 310.5772749153247
}
#Debug simulation 
Total elapsed time: 84.56044371798635. Arrivals time: 0.453912362921983 Scheduler time: 83.88749502552673 Scheduler overhead time: 0.0860961526632309 Adapter cache time: 0.017398360650986433 Engine time: 0.08193251257762313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 441609414 . Total output tokens: 388185374
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 87.30870871897787,
    "estimated_duration": 3600.011145875238,
    "input_throughput": 6989.083083486646,
    "output_throughput": 6101.766386242535,
    "total_throughput": 13090.84946972918,
    "itl": 86.25935515747908,
    "ttft": 1936828.4690901632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.167343926304055,
    "arrivals": 659440,
    "finished_requests": 101795,
    "scheduler_time": 309.8661084746741
}
#Debug simulation 
Total elapsed time: 87.3088398440741. Arrivals time: 0.45098706567659974 Scheduler time: 86.64140915172175 Scheduler overhead time: 0.08507902221754193 Adapter cache time: 0.016827834770083427 Engine time: 0.08100321469828486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 441609414 . Total output tokens: 388185374
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.12181019410491,
    "estimated_duration": 3600.0436718630226,
    "input_throughput": 6951.107620050045,
    "output_throughput": 6057.9806768604685,
    "total_throughput": 13009.088296910513,
    "itl": 84.69970985200952,
    "ttft": 1926064.8506226018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9096043697046166,
    "arrivals": 659440,
    "finished_requests": 101042,
    "scheduler_time": 312.0257539415546
}
#Debug simulation 
Total elapsed time: 84.12194184400141. Arrivals time: 0.4475107449106872 Scheduler time: 83.45821846090257 Scheduler overhead time: 0.08508733473718166 Adapter cache time: 0.017216403502970934 Engine time: 0.08092798432335258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_320_slots_16_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_320_slots_16_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 441609414 . Total output tokens: 388185374
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 82.37570162909105,
    "estimated_duration": 3600.038593025135,
    "input_throughput": 6873.327704858646,
    "output_throughput": 5987.019984107575,
    "total_throughput": 12860.347688966222,
    "itl": 83.1545741851206,
    "ttft": 1930592.7398424584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.032683863421005,
    "arrivals": 659440,
    "finished_requests": 99873,
    "scheduler_time": 315.50212184083335
}
#Debug simulation 
Total elapsed time: 82.37583630392328. Arrivals time: 0.4385399539023638 Scheduler time: 81.71697651268914 Scheduler overhead time: 0.08643334312364459 Adapter cache time: 0.01755753718316555 Engine time: 0.08247675187885761 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_320_slots_16_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_320_slots_16_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 441609414 . Total output tokens: 388185374
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 87.46804570313543,
    "estimated_duration": 3600.006846823938,
    "input_throughput": 6957.48093426472,
    "output_throughput": 6059.374031259121,
    "total_throughput": 13016.85496552384,
    "itl": 85.34595798145114,
    "ttft": 1947925.8537513965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.223946418771516,
    "arrivals": 659440,
    "finished_requests": 101255,
    "scheduler_time": 311.477650900807
}
#Debug simulation 
Total elapsed time: 87.4681801549159. Arrivals time: 0.4422928560525179 Scheduler time: 86.80931152263656 Scheduler overhead time: 0.08483592420816422 Adapter cache time: 0.017078605480492115 Engine time: 0.0812849784269929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_320_slots_16_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_320_slots_16_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 441609414 . Total output tokens: 388185374
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 82.33795681968331,
    "estimated_duration": 3600.0017191710413,
    "input_throughput": 6873.398106514728,
    "output_throughput": 5987.081307550888,
    "total_throughput": 12860.479414065616,
    "itl": 83.15402394842701,
    "ttft": 1930578.6483440038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9962312403368183,
    "arrivals": 659440,
    "finished_requests": 99873,
    "scheduler_time": 315.5018017410456
}
#Debug simulation 
Total elapsed time: 82.338082249742. Arrivals time: 0.4397416249848902 Scheduler time: 81.67901814496145 Scheduler overhead time: 0.08592654066160321 Adapter cache time: 0.017501194961369038 Engine time: 0.08204174460843205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_320_slots_16_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_320_slots_16_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 441609414 . Total output tokens: 388185374
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 88.71164800599217,
    "estimated_duration": 3600.0273165664817,
    "input_throughput": 6942.22010066197,
    "output_throughput": 6045.962734738058,
    "total_throughput": 12988.182835400028,
    "itl": 85.2267077592818,
    "ttft": 1942391.953753282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0004428420681375,
    "arrivals": 659440,
    "finished_requests": 101011,
    "scheduler_time": 312.8244087391292
}
#Debug simulation 
Total elapsed time: 88.711778704077. Arrivals time: 0.4430841114372015 Scheduler time: 88.05031798873097 Scheduler overhead time: 0.0856786067597568 Adapter cache time: 0.017268097028136253 Engine time: 0.08183236885815859 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_320_slots_16_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_320_slots_16_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 441609414 . Total output tokens: 388185374
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.15994931571186,
    "estimated_duration": 3600.046126636001,
    "input_throughput": 6964.3999321276015,
    "output_throughput": 6045.071433663994,
    "total_throughput": 13009.471365791595,
    "itl": 83.37234837547618,
    "ttft": 1946772.035449703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.664594198185981,
    "arrivals": 659440,
    "finished_requests": 101251,
    "scheduler_time": 311.39915651609255
}
#Debug simulation 
Total elapsed time: 84.16007774462923. Arrivals time: 0.46072911098599434 Scheduler time: 83.48128875019029 Scheduler overhead time: 0.08606934081763029 Adapter cache time: 0.01745504280552268 Engine time: 0.0811561094596982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_320_slots_16_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_320_slots_16_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439990887 . Total output tokens: 386751648
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 88.81395153421909,
    "estimated_duration": 3600.027424862204,
    "input_throughput": 7068.716150398227,
    "output_throughput": 6160.800844690491,
    "total_throughput": 13229.516995088718,
    "itl": 86.49292752020881,
    "ttft": 1917682.0526891544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3591037882306094,
    "arrivals": 657053,
    "finished_requests": 102960,
    "scheduler_time": 306.50330396210023
}
#Debug simulation 
Total elapsed time: 88.81407850794494. Arrivals time: 0.46200665831565857 Scheduler time: 88.13614088855684 Scheduler overhead time: 0.08438078640028834 Adapter cache time: 0.01709347777068615 Engine time: 0.08150937501341105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_320_slots_16_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_320_slots_16_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439990887 . Total output tokens: 386751648
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 88.14866316411644,
    "estimated_duration": 3600.0337025779672,
    "input_throughput": 6922.650746895406,
    "output_throughput": 6030.724652508944,
    "total_throughput": 12953.37539940435,
    "itl": 84.00014145195458,
    "ttft": 1928148.4383857958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.695318021988501,
    "arrivals": 657053,
    "finished_requests": 100725,
    "scheduler_time": 313.3021811982204
}
#Debug simulation 
Total elapsed time: 88.14880047691986. Arrivals time: 0.45612877048552036 Scheduler time: 87.47584947338328 Scheduler overhead time: 0.08483662363141775 Adapter cache time: 0.017177126836031675 Engine time: 0.08150166505947709 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_320_slots_16_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_320_slots_16_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439990887 . Total output tokens: 386751648
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 88.88226494425908,
    "estimated_duration": 3600.0029750298218,
    "input_throughput": 7017.439478585633,
    "output_throughput": 6089.868300683387,
    "total_throughput": 13107.30777926902,
    "itl": 83.44005013454628,
    "ttft": 1947145.1184549103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.456496027703424,
    "arrivals": 657053,
    "finished_requests": 102141,
    "scheduler_time": 308.9079506585947
}
#Debug simulation 
Total elapsed time: 88.88239965308458. Arrivals time: 0.4674187581986189 Scheduler time: 88.19745219824836 Scheduler overhead time: 0.08539603790268302 Adapter cache time: 0.017364969942718744 Engine time: 0.08134424267336726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_320_slots_16_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_320_slots_16_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439990887 . Total output tokens: 386751648
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 87.53646295703948,
    "estimated_duration": 3600.0377173854945,
    "input_throughput": 7026.523604972363,
    "output_throughput": 6121.8183613935935,
    "total_throughput": 13148.341966365955,
    "itl": 84.85508497236023,
    "ttft": 1920998.6640244368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4274008518224526,
    "arrivals": 657053,
    "finished_requests": 102358,
    "scheduler_time": 308.50987203773815
}
#Debug simulation 
Total elapsed time: 87.53659904189408. Arrivals time: 0.46385484281927347 Scheduler time: 86.85554621182382 Scheduler overhead time: 0.08555828919634223 Adapter cache time: 0.017602059058845043 Engine time: 0.08088282682001591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_320_slots_16_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_320_slots_16_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439990887 . Total output tokens: 386751648
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 89.08792274398729,
    "estimated_duration": 3600.066756125814,
    "input_throughput": 7017.48153892208,
    "output_throughput": 6089.786241517633,
    "total_throughput": 13107.267780439714,
    "itl": 83.43947646909274,
    "ttft": 1947108.4809233723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4254284512112183,
    "arrivals": 657053,
    "finished_requests": 102143,
    "scheduler_time": 308.9155551975497
}
#Debug simulation 
Total elapsed time: 89.08806525822729. Arrivals time: 0.4660930153913796 Scheduler time: 88.40387442335486 Scheduler overhead time: 0.08557779807597399 Adapter cache time: 0.017281312495470047 Engine time: 0.08188251778483391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_320_slots_16_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_320_slots_16_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439990887 . Total output tokens: 386751648
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 88.31887919502333,
    "estimated_duration": 3600.019984546928,
    "input_throughput": 7052.914736304021,
    "output_throughput": 6147.27893039326,
    "total_throughput": 13200.193666697282,
    "itl": 85.43720321247172,
    "ttft": 1922347.3713222342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2557996796909574,
    "arrivals": 657053,
    "finished_requests": 102704,
    "scheduler_time": 307.25990577615084
}
#Debug simulation 
Total elapsed time: 88.31901181396097. Arrivals time: 0.454306036233902 Scheduler time: 87.64823938300833 Scheduler overhead time: 0.08490232098847628 Adapter cache time: 0.017279835883527994 Engine time: 0.08132676407694817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_320_slots_16_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_320_slots_16_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439990887 . Total output tokens: 386751648
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 88.64522909466177,
    "estimated_duration": 3600.034504477101,
    "input_throughput": 7017.544406472145,
    "output_throughput": 6089.840798118787,
    "total_throughput": 13107.385204590932,
    "itl": 83.43891242835858,
    "ttft": 1947095.0775404454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3933252888359395,
    "arrivals": 657053,
    "finished_requests": 102143,
    "scheduler_time": 308.9152044487687
}
#Debug simulation 
Total elapsed time: 88.64536598604172. Arrivals time: 0.46069816406816244 Scheduler time: 87.96597920311615 Scheduler overhead time: 0.08565021213144064 Adapter cache time: 0.01699081528931856 Engine time: 0.08217156073078513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 439211238 . Total output tokens: 386048354
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 88.51599367428571,
    "estimated_duration": 3600.001771116132,
    "input_throughput": 7062.276525524477,
    "output_throughput": 6152.409750935511,
    "total_throughput": 13214.686276459986,
    "itl": 85.12804833996456,
    "ttft": 1917920.1755596716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1475066992082046,
    "arrivals": 655825,
    "finished_requests": 102621,
    "scheduler_time": 307.0807247434453
}
#Debug simulation 
Total elapsed time: 88.51612344337627. Arrivals time: 0.4451523316092789 Scheduler time: 87.85584358824417 Scheduler overhead time: 0.08372612902894616 Adapter cache time: 0.01681977091357112 Engine time: 0.08190501714125276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 439211238 . Total output tokens: 386048354
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 88.410077476874,
    "estimated_duration": 3600.0115573185617,
    "input_throughput": 7037.914072384738,
    "output_throughput": 6114.219537782513,
    "total_throughput": 13152.13361016725,
    "itl": 84.9432537894797,
    "ttft": 1941228.8727580383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1740368075156624,
    "arrivals": 655825,
    "finished_requests": 102154,
    "scheduler_time": 308.00723130610965
}
#Debug simulation 
Total elapsed time: 88.41020294558257. Arrivals time: 0.4468507175333798 Scheduler time: 87.74766805721447 Scheduler overhead time: 0.08464351668953896 Adapter cache time: 0.01654350245371461 Engine time: 0.08138906629756093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_320_slots_16_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_320_slots_16_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 439211238 . Total output tokens: 386048354
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 86.18028669524938,
    "estimated_duration": 3600.040512711586,
    "input_throughput": 6968.599634203572,
    "output_throughput": 6070.549184886585,
    "total_throughput": 13039.148819090156,
    "itl": 82.74967448233191,
    "ttft": 1942157.0208941025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3115946655767288,
    "arrivals": 655825,
    "finished_requests": 101236,
    "scheduler_time": 311.35616929853205
}
#Debug simulation 
Total elapsed time: 86.18041706690565. Arrivals time: 0.4417869024910033 Scheduler time: 85.52166278241202 Scheduler overhead time: 0.08513682009652257 Adapter cache time: 0.016576566267758608 Engine time: 0.08155531203374267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_320_slots_16_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_320_slots_16_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 439211238 . Total output tokens: 386048354
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 85.84261863213032,
    "estimated_duration": 3600.0326010417857,
    "input_throughput": 7018.726995052209,
    "output_throughput": 6128.111449217382,
    "total_throughput": 13146.838444269591,
    "itl": 85.11649223485954,
    "ttft": 1924139.0029377618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3982576890662264,
    "arrivals": 655825,
    "finished_requests": 102040,
    "scheduler_time": 308.3324278769623
}
#Debug simulation 
Total elapsed time: 85.84274138417095. Arrivals time: 0.4418743075802922 Scheduler time: 85.18578928569332 Scheduler overhead time: 0.08468138566240668 Adapter cache time: 0.0169187244027853 Engine time: 0.08061980316415429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_320_slots_16_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_320_slots_16_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 439211238 . Total output tokens: 386048354
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 85.22512838896364,
    "estimated_duration": 3600.0610988653148,
    "input_throughput": 6932.430398991319,
    "output_throughput": 6031.942070884395,
    "total_throughput": 12964.372469875714,
    "itl": 82.3834499621585,
    "ttft": 1939840.8868703896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4370755303046003,
    "arrivals": 655825,
    "finished_requests": 100686,
    "scheduler_time": 312.83283853917686
}
#Debug simulation 
Total elapsed time: 85.22525855712593. Arrivals time: 0.437419462017715 Scheduler time: 84.5694893351756 Scheduler overhead time: 0.08609597058966756 Adapter cache time: 0.016861120238900185 Engine time: 0.08187973918393254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_320_slots_16_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_320_slots_16_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 439211238 . Total output tokens: 386048354
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 88.12774349423125,
    "estimated_duration": 3600.0194697393067,
    "input_throughput": 7040.28331319979,
    "output_throughput": 6136.244313589692,
    "total_throughput": 13176.527626789482,
    "itl": 84.88239758820941,
    "ttft": 1926892.1112237114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9110679489001505,
    "arrivals": 655825,
    "finished_requests": 102218,
    "scheduler_time": 308.0385608939542
}
#Debug simulation 
Total elapsed time: 88.12792584626004. Arrivals time: 0.4760003611445427 Scheduler time: 87.43763176025823 Scheduler overhead time: 0.08404312888160348 Adapter cache time: 0.016565975733101368 Engine time: 0.08053344395011663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_320_slots_16_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_320_slots_16_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 439211238 . Total output tokens: 386048354
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 85.12481459835544,
    "estimated_duration": 3600.0274889459965,
    "input_throughput": 6932.495120282227,
    "output_throughput": 6031.9983852005935,
    "total_throughput": 12964.49350548282,
    "itl": 82.38350108428956,
    "ttft": 1939827.3299650215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4045581335760917,
    "arrivals": 655825,
    "finished_requests": 100686,
    "scheduler_time": 312.832453935139
}
#Debug simulation 
Total elapsed time: 85.12494003819302. Arrivals time: 0.4403591430746019 Scheduler time: 84.46612972347066 Scheduler overhead time: 0.08572475565597415 Adapter cache time: 0.017090175300836563 Engine time: 0.08199765626341105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_320_slots_16_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_320_slots_16_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431864763 . Total output tokens: 379689871
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 86.36821901425719,
    "estimated_duration": 3600.0590757166483,
    "input_throughput": 6978.539649380293,
    "output_throughput": 6044.793860964076,
    "total_throughput": 13023.333510344368,
    "itl": 86.49076627126271,
    "ttft": 1955363.7364712073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0615453817928526,
    "arrivals": 644956,
    "finished_requests": 101475,
    "scheduler_time": 311.3122259161778
}
#Debug simulation 
Total elapsed time: 86.36839085211977. Arrivals time: 0.47927403077483177 Scheduler time: 85.671812298242 Scheduler overhead time: 0.08488054061308503 Adapter cache time: 0.01715793740004301 Engine time: 0.0816965289413929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_320_slots_16_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_320_slots_16_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431864763 . Total output tokens: 379689871
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 87.19326491607353,
    "estimated_duration": 3600.018761945994,
    "input_throughput": 6899.513486583494,
    "output_throughput": 5997.774852797814,
    "total_throughput": 12897.288339381308,
    "itl": 85.11639134935693,
    "ttft": 1946140.111926557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.490749221085576,
    "arrivals": 644956,
    "finished_requests": 100304,
    "scheduler_time": 315.1824645428783
}
#Debug simulation 
Total elapsed time: 87.19339126022533. Arrivals time: 0.7034630179405212 Scheduler time: 86.2673799074255 Scheduler overhead time: 0.08852588944137096 Adapter cache time: 0.017376015428453684 Engine time: 0.08226985298097134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_320_slots_16_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_320_slots_16_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431864763 . Total output tokens: 379689871
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.51907712081447,
    "estimated_duration": 3600.095377091675,
    "input_throughput": 6836.891643655259,
    "output_throughput": 5922.193655109122,
    "total_throughput": 12759.085298764381,
    "itl": 82.86197198576195,
    "ttft": 1962265.7935165793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3800888239546,
    "arrivals": 644956,
    "finished_requests": 99439,
    "scheduler_time": 317.7253179923287
}
#Debug simulation 
Total elapsed time: 84.51920603169128. Arrivals time: 0.45383369736373425 Scheduler time: 83.84128394303843 Scheduler overhead time: 0.08778492268174887 Adapter cache time: 0.017455426044762135 Engine time: 0.08414148259907961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_320_slots_16_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_320_slots_16_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431864763 . Total output tokens: 379689871
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 86.95587164070457,
    "estimated_duration": 3600.024644774496,
    "input_throughput": 6969.233956889089,
    "output_throughput": 6032.651479629075,
    "total_throughput": 13001.885436518165,
    "itl": 85.33713656035128,
    "ttft": 1954058.310914518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.228111081691455,
    "arrivals": 644956,
    "finished_requests": 101269,
    "scheduler_time": 311.8816035142082
}
#Debug simulation 
Total elapsed time: 86.95599778788164. Arrivals time: 0.44765335880219936 Scheduler time: 86.2876185956411 Scheduler overhead time: 0.08668140089139342 Adapter cache time: 0.017816702369600534 Engine time: 0.08245521550998092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_320_slots_16_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_320_slots_16_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431864763 . Total output tokens: 379689871
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 84.40997929312289,
    "estimated_duration": 3600.0643893782462,
    "input_throughput": 6836.950492502413,
    "output_throughput": 5922.244630652892,
    "total_throughput": 12759.195123155305,
    "itl": 82.86185487574463,
    "ttft": 1962252.778309694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3490212474623946,
    "arrivals": 644956,
    "finished_requests": 99439,
    "scheduler_time": 317.7249933305044
}
#Debug simulation 
Total elapsed time: 84.41010388825089. Arrivals time: 0.44415977131575346 Scheduler time: 83.7433515721932 Scheduler overhead time: 0.08734112093225121 Adapter cache time: 0.017256902065128088 Engine time: 0.08363907737657428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_320_slots_16_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_320_slots_16_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431864763 . Total output tokens: 379689871
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 86.0044798371382,
    "estimated_duration": 3600.0272762369677,
    "input_throughput": 6986.179845361955,
    "output_throughput": 6076.710347280162,
    "total_throughput": 13062.890192642117,
    "itl": 85.79728229719687,
    "ttft": 1936580.561663156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.172808707463541,
    "arrivals": 644956,
    "finished_requests": 101567,
    "scheduler_time": 311.10470797449835
}
#Debug simulation 
Total elapsed time: 86.0046043950133. Arrivals time: 0.4442118061706424 Scheduler time: 85.33990334672853 Scheduler overhead time: 0.08696903614327312 Adapter cache time: 0.01696191169321537 Engine time: 0.08242156729102135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_320_slots_16_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_320_slots_16_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431864763 . Total output tokens: 379689871
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.54691442102194,
    "estimated_duration": 3600.0320995265365,
    "input_throughput": 6837.011815321612,
    "output_throughput": 5922.297749179512,
    "total_throughput": 12759.309564501124,
    "itl": 82.8613016335633,
    "ttft": 1962239.1370278443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.316918085087116,
    "arrivals": 644956,
    "finished_requests": 99439,
    "scheduler_time": 317.72480664117035
}
#Debug simulation 
Total elapsed time: 84.54704276612028. Arrivals time: 0.4466422460973263 Scheduler time: 83.87637292407453 Scheduler overhead time: 0.08875407697632909 Adapter cache time: 0.017117443960160017 Engine time: 0.08353759068995714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 428625514 . Total output tokens: 376917001
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 86.27840812178329,
    "estimated_duration": 3600.0877497623783,
    "input_throughput": 7022.274943622873,
    "output_throughput": 6099.910759522312,
    "total_throughput": 13122.185703145185,
    "itl": 87.09530198200311,
    "ttft": 1941225.4208095982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0615453817928526,
    "arrivals": 640132,
    "finished_requests": 102374,
    "scheduler_time": 308.2240623085723
}
#Debug simulation 
Total elapsed time: 86.27853257302195. Arrivals time: 0.4529002974741161 Scheduler time: 85.60864186706021 Scheduler overhead time: 0.08532770676538348 Adapter cache time: 0.017025108449161053 Engine time: 0.08138165902346373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 428625514 . Total output tokens: 376917001
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 87.01042566774413,
    "estimated_duration": 3600.0459598008956,
    "input_throughput": 7018.75344985803,
    "output_throughput": 6109.021452941765,
    "total_throughput": 13127.774902799796,
    "itl": 86.17255018724387,
    "ttft": 1941374.2577347308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.419411722887312,
    "arrivals": 640132,
    "finished_requests": 102340,
    "scheduler_time": 308.36706650331547
}
#Debug simulation 
Total elapsed time: 87.01055521005765. Arrivals time: 0.45957635482773185 Scheduler time: 86.33205767953768 Scheduler overhead time: 0.08599483408033848 Adapter cache time: 0.017674787901341915 Engine time: 0.08167270896956325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_320_slots_16_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_320_slots_16_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 428625514 . Total output tokens: 376917001
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.87204443989322,
    "estimated_duration": 3600.0173239971955,
    "input_throughput": 6918.5497619620355,
    "output_throughput": 6036.435951333475,
    "total_throughput": 12954.98571329551,
    "itl": 84.18251363302079,
    "ttft": 1930083.7333645015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6838669299614,
    "arrivals": 640132,
    "finished_requests": 100907,
    "scheduler_time": 313.0304124510982
}
#Debug simulation 
Total elapsed time: 84.87217471282929. Arrivals time: 0.4470719648525119 Scheduler time: 84.20278232404962 Scheduler overhead time: 0.08735987870022655 Adapter cache time: 0.01734348712489009 Engine time: 0.08317770669236779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_320_slots_16_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_320_slots_16_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 428625514 . Total output tokens: 376917001
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 86.02353650983423,
    "estimated_duration": 3600.090865150872,
    "input_throughput": 6990.324673081649,
    "output_throughput": 6073.3955944425015,
    "total_throughput": 13063.72026752415,
    "itl": 86.23493398665693,
    "ttft": 1942730.352161057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1362335996981665,
    "arrivals": 640132,
    "finished_requests": 101878,
    "scheduler_time": 309.69790693933203
}
#Debug simulation 
Total elapsed time: 86.0236685751006. Arrivals time: 0.4600729304365814 Scheduler time: 85.34364706138149 Scheduler overhead time: 0.086139933206141 Adapter cache time: 0.01740721007809043 Engine time: 0.082635881844908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_320_slots_16_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_320_slots_16_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 428625514 . Total output tokens: 376917001
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 85.54624046199024,
    "estimated_duration": 3600.024468319078,
    "input_throughput": 6918.5360319591155,
    "output_throughput": 6036.423971903379,
    "total_throughput": 12954.960003862494,
    "itl": 84.18194992621696,
    "ttft": 1930069.71740687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6486570099369002,
    "arrivals": 640132,
    "finished_requests": 100907,
    "scheduler_time": 313.03588590791156
}
#Debug simulation 
Total elapsed time: 85.54636637913063. Arrivals time: 0.4454757208004594 Scheduler time: 84.88057749252766 Scheduler overhead time: 0.08662031916901469 Adapter cache time: 0.017617432866245508 Engine time: 0.08233713265508413 
