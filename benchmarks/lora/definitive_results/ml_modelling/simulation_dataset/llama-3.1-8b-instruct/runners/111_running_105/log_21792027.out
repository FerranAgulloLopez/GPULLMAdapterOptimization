INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8381627430208027,
    "estimated_duration": 3599.614017783939,
    "input_throughput": 1388.890579739954,
    "output_throughput": 1234.5684781880807,
    "total_throughput": 2623.459057928035,
    "itl": 29.05549703867592,
    "ttft": 5332.652794685382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.040689382851316,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.17017626751773085
}
#Debug simulation 
Total elapsed time: 1.8382960290182382. Arrivals time: 0.059669719310477376 Scheduler time: 1.399592951638624 Scheduler overhead time: 0.11091060168109834 Adapter cache time: 0.10236778017133474 Engine time: 0.11175416153855622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8263922871556133,
    "estimated_duration": 3599.6284330024496,
    "input_throughput": 1388.8850177322172,
    "output_throughput": 1234.5635341849118,
    "total_throughput": 2623.448551917129,
    "itl": 29.065939291351672,
    "ttft": 5332.773241685123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.854546732683652,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.17095103618166146
}
#Debug simulation 
Total elapsed time: 1.8265281959902495. Arrivals time: 0.058273573871701956 Scheduler time: 1.3946904668118805 Scheduler overhead time: 0.1113290733192116 Adapter cache time: 0.10212504421360791 Engine time: 0.10676159057766199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8338487742003053,
    "estimated_duration": 3599.6290892410643,
    "input_throughput": 1388.884764528357,
    "output_throughput": 1234.5633091149828,
    "total_throughput": 2623.4480736433397,
    "itl": 29.06685074450722,
    "ttft": 5332.73788040121,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.095971311069999,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.17114435298163228
}
#Debug simulation 
Total elapsed time: 1.8340058571193367. Arrivals time: 0.05873518134467304 Scheduler time: 1.400845694821328 Scheduler overhead time: 0.11113773356191814 Adapter cache time: 0.10275184200145304 Engine time: 0.10697375750169158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.8596162730827928,
    "estimated_duration": 3599.6255202021034,
    "input_throughput": 1388.886141611559,
    "output_throughput": 1234.5645331880219,
    "total_throughput": 2623.4506747995806,
    "itl": 29.058524046146506,
    "ttft": 5332.5946159049945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.213188643013124,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.1703765064497818
}
#Debug simulation 
Total elapsed time: 1.8596981670707464. Arrivals time: 0.05891799624077976 Scheduler time: 1.4206474577076733 Scheduler overhead time: 0.11285707470960915 Adapter cache time: 0.10298269963823259 Engine time: 0.11033749184571207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8437692981678993,
    "estimated_duration": 3599.6175509458317,
    "input_throughput": 1388.8892164908866,
    "output_throughput": 1234.5672664120407,
    "total_throughput": 2623.4564829029273,
    "itl": 29.06836642452124,
    "ttft": 5332.725276378738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.99220710210034,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.17100303494419652
}
#Debug simulation 
Total elapsed time: 1.8438809539657086. Arrivals time: 0.059390765614807606 Scheduler time: 1.4075283608399332 Scheduler overhead time: 0.11158345802687109 Adapter cache time: 0.10315692517906427 Engine time: 0.10834737285040319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8185759738553315,
    "estimated_duration": 3599.6210832152483,
    "input_throughput": 1388.8878535888507,
    "output_throughput": 1234.566054944473,
    "total_throughput": 2623.453908533324,
    "itl": 29.053116033183727,
    "ttft": 5332.591968821065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.756463942793158,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.16995321933346083
}
#Debug simulation 
Total elapsed time: 1.818746737902984. Arrivals time: 0.05815637018531561 Scheduler time: 1.386444729520008 Scheduler overhead time: 0.11145883589051664 Adapter cache time: 0.10133602726273239 Engine time: 0.1078135622665286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9035479300655425,
    "estimated_duration": 3599.6176766695385,
    "input_throughput": 1388.8891679812068,
    "output_throughput": 1234.5672232923578,
    "total_throughput": 2623.4563912735643,
    "itl": 29.06738542218874,
    "ttft": 5332.733636105852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.924065550994104,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.1709453234016022
}
#Debug simulation 
Total elapsed time: 1.903656966984272. Arrivals time: 0.0609128640498966 Scheduler time: 1.463742240332067 Scheduler overhead time: 0.11060994351282716 Adapter cache time: 0.10444670892320573 Engine time: 0.11043253354728222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8416996500454843,
    "estimated_duration": 3600.020070603764,
    "input_throughput": 1366.2121053606045,
    "output_throughput": 1187.376991285247,
    "total_throughput": 2553.5890966458514,
    "itl": 28.415410891083884,
    "ttft": 6712.794635834593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.324515506895331,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.11765879364405853
}
#Debug simulation 
Total elapsed time: 1.8418093391228467. Arrivals time: 0.05892268870957196 Scheduler time: 1.3963151318021119 Scheduler overhead time: 0.11421560822054744 Adapter cache time: 0.10200643446296453 Engine time: 0.11465373006649315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.84602290391922,
    "estimated_duration": 3600.0233718924733,
    "input_throughput": 1366.210852518572,
    "output_throughput": 1187.3759024383564,
    "total_throughput": 2553.5867549569284,
    "itl": 28.421077339162608,
    "ttft": 6712.738608484696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.788677965337418,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.11790923824462245
}
#Debug simulation 
Total elapsed time: 1.8461805088445544. Arrivals time: 0.05878395028412342 Scheduler time: 1.4085137280635536 Scheduler overhead time: 0.11310715856961906 Adapter cache time: 0.10056101763620973 Engine time: 0.11042224802076817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8458084370940924,
    "estimated_duration": 3600.0276284864485,
    "input_throughput": 1366.2092371407239,
    "output_throughput": 1187.374498511044,
    "total_throughput": 2553.5837356517677,
    "itl": 28.422193375919356,
    "ttft": 6712.871608824142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.9194850307237665,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.11804688684002917
}
#Debug simulation 
Total elapsed time: 1.845918885199353. Arrivals time: 0.0591596020385623 Scheduler time: 1.407440145034343 Scheduler overhead time: 0.11229071742855012 Adapter cache time: 0.10120908077806234 Engine time: 0.11117662535980344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.8562441170215607,
    "estimated_duration": 3600.0160018184397,
    "input_throughput": 1366.2136494714532,
    "output_throughput": 1187.3783332743033,
    "total_throughput": 2553.5919827457565,
    "itl": 28.416823516122726,
    "ttft": 6712.703455162879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.437458059089249,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.11765049565198658
}
#Debug simulation 
Total elapsed time: 1.8563571511767805. Arrivals time: 0.059815506218001246 Scheduler time: 1.4162246433552355 Scheduler overhead time: 0.11254493868909776 Adapter cache time: 0.10068426025100052 Engine time: 0.11225587641820312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8633009039331228,
    "estimated_duration": 3600.019630136323,
    "input_throughput": 1366.212272518568,
    "output_throughput": 1187.377136562484,
    "total_throughput": 2553.589409081052,
    "itl": 28.421960938109603,
    "ttft": 6712.734303238869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.867084385040248,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.11809863535855632
}
#Debug simulation 
Total elapsed time: 1.8634965419769287. Arrivals time: 0.060818866128101945 Scheduler time: 1.4202350864652544 Scheduler overhead time: 0.11270727426744998 Adapter cache time: 0.1014592123683542 Engine time: 0.1132104666903615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8439447660930455,
    "estimated_duration": 3600.023056696555,
    "input_throughput": 1366.2109721356069,
    "output_throughput": 1187.376006397701,
    "total_throughput": 2553.586978533308,
    "itl": 28.414171168946467,
    "ttft": 6712.684490109615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.175084295133109,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.11772421943672352
}
#Debug simulation 
Total elapsed time: 1.8440517419949174. Arrivals time: 0.05888059246353805 Scheduler time: 1.4055880310479552 Scheduler overhead time: 0.11290263058617711 Adapter cache time: 0.10053818230517209 Engine time: 0.11130147147923708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8566842549480498,
    "estimated_duration": 3600.0259983791093,
    "input_throughput": 1366.209855766174,
    "output_throughput": 1187.3750361593513,
    "total_throughput": 2553.5848919255254,
    "itl": 28.42116794440312,
    "ttft": 6712.704909984461,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.827939238660069,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.11803675388591667
}
#Debug simulation 
Total elapsed time: 1.8567928860429674. Arrivals time: 0.05897520552389324 Scheduler time: 1.4034380631055683 Scheduler overhead time: 0.1219194084405899 Adapter cache time: 0.10161075904034078 Engine time: 0.11277684615924954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.7335271241609007,
    "estimated_duration": 3600.025207937854,
    "input_throughput": 1279.13965431308,
    "output_throughput": 1115.555244209092,
    "total_throughput": 2394.694898522172,
    "itl": 27.487724918139172,
    "ttft": 7017.491185803604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1017,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.724819985493236,
    "arrivals": 18589,
    "finished_requests": 18553,
    "scheduler_time": 0.018416603912770155
}
#Debug simulation 
Total elapsed time: 1.7336237141862512. Arrivals time: 0.05653080600313842 Scheduler time: 1.293730832869187 Scheduler overhead time: 0.11845280276611447 Adapter cache time: 0.09393181162886322 Engine time: 0.1146647606510669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7254843320697546,
    "estimated_duration": 3600.026975270081,
    "input_throughput": 1279.1390263553592,
    "output_throughput": 1115.5546965585472,
    "total_throughput": 2394.693722913906,
    "itl": 27.495975642579726,
    "ttft": 7017.634120597787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1018,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.446986442273493,
    "arrivals": 18589,
    "finished_requests": 18553,
    "scheduler_time": 0.01850558968967766
}
#Debug simulation 
Total elapsed time: 1.725593086099252. Arrivals time: 0.055238854605704546 Scheduler time: 1.290012481622398 Scheduler overhead time: 0.11590183922089636 Adapter cache time: 0.09391834284178913 Engine time: 0.11430834396742284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7726091709919274,
    "estimated_duration": 3600.010487118108,
    "input_throughput": 1279.144884849032,
    "output_throughput": 1115.5598058312667,
    "total_throughput": 2394.704690680299,
    "itl": 27.49594569463374,
    "ttft": 6824.36329006999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1018,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.6489925522031434,
    "arrivals": 18589,
    "finished_requests": 18553,
    "scheduler_time": 0.01853236049595224
}
#Debug simulation 
Total elapsed time: 1.7727222910616547. Arrivals time: 0.0563832544721663 Scheduler time: 1.3364201176445931 Scheduler overhead time: 0.11574573372490704 Adapter cache time: 0.09400643943808973 Engine time: 0.11356693133711815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.7272511119954288,
    "estimated_duration": 3600.0270478153157,
    "input_throughput": 1279.1390005790415,
    "output_throughput": 1115.554674078667,
    "total_throughput": 2394.6936746577085,
    "itl": 27.489462327802812,
    "ttft": 7017.6933211675905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1018,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.925015356307836,
    "arrivals": 18589,
    "finished_requests": 18553,
    "scheduler_time": 0.01842360929883588
}
#Debug simulation 
Total elapsed time: 1.7273620360065252. Arrivals time: 0.05759312701411545 Scheduler time: 1.289962091250345 Scheduler overhead time: 0.11658612918108702 Adapter cache time: 0.09322957042604685 Engine time: 0.11374441510997713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.73427688004449,
    "estimated_duration": 3600.000265168206,
    "input_throughput": 1279.1485168918007,
    "output_throughput": 1115.5629733856022,
    "total_throughput": 2394.711490277403,
    "itl": 27.495434606900066,
    "ttft": 6824.377506452016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1017,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.564749226816948,
    "arrivals": 18589,
    "finished_requests": 18553,
    "scheduler_time": 0.018521768921842655
}
#Debug simulation 
Total elapsed time: 1.734385987976566. Arrivals time: 0.05581502104178071 Scheduler time: 1.2968580781016499 Scheduler overhead time: 0.11602080799639225 Adapter cache time: 0.09414884145371616 Engine time: 0.11517020338214934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.7130403819028288,
    "estimated_duration": 3600.0007547511855,
    "input_throughput": 1279.1483429336865,
    "output_throughput": 1115.562821674344,
    "total_throughput": 2394.7111646080307,
    "itl": 27.484499061900333,
    "ttft": 6824.276208011083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1017,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.4924475965602,
    "arrivals": 18589,
    "finished_requests": 18553,
    "scheduler_time": 0.018394003036540735
}
#Debug simulation 
Total elapsed time: 1.7131445140112191. Arrivals time: 0.05475258827209473 Scheduler time: 1.2815421568229795 Scheduler overhead time: 0.11500142817385495 Adapter cache time: 0.09372266218997538 Engine time: 0.11224218015559018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7490810591261834,
    "estimated_duration": 3600.009341289344,
    "input_throughput": 1279.1452919815874,
    "output_throughput": 1115.5601608971547,
    "total_throughput": 2394.705452878742,
    "itl": 27.49487100297327,
    "ttft": 6824.330460502626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1017,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.501164253596236,
    "arrivals": 18589,
    "finished_requests": 18553,
    "scheduler_time": 0.018467518445288367
}
#Debug simulation 
Total elapsed time: 1.74918382614851. Arrivals time: 0.056327100144699216 Scheduler time: 1.3132546278648078 Scheduler overhead time: 0.11565485876053572 Adapter cache time: 0.09367097704671323 Engine time: 0.11426023487001657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.7003780209925026,
    "estimated_duration": 3599.8344113147623,
    "input_throughput": 1231.7911029636743,
    "output_throughput": 1095.43955344317,
    "total_throughput": 2327.2306564068444,
    "itl": 27.528931206759243,
    "ttft": 7205.06662596923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 699,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.622073913333088,
    "arrivals": 18102,
    "finished_requests": 18066,
    "scheduler_time": 0.018682060743547186
}
#Debug simulation 
Total elapsed time: 1.7004823370371014. Arrivals time: 0.05389321339316666 Scheduler time: 1.2711498530115932 Scheduler overhead time: 0.1157265289220959 Adapter cache time: 0.08953807037323713 Engine time: 0.1139705739915371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6905039499979466,
    "estimated_duration": 3599.823712324601,
    "input_throughput": 1231.8064311923047,
    "output_throughput": 1095.5530923633137,
    "total_throughput": 2327.359523555618,
    "itl": 27.26842080511886,
    "ttft": 7005.70156085496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.150351678612648,
    "arrivals": 18102,
    "finished_requests": 18067,
    "scheduler_time": 0.015633817366358205
}
#Debug simulation 
Total elapsed time: 1.690603684168309. Arrivals time: 0.053829814074561 Scheduler time: 1.2557506328448653 Scheduler overhead time: 0.11763908318243921 Adapter cache time: 0.09014764940366149 Engine time: 0.11635372648015618 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6993416741024703,
    "estimated_duration": 3599.8232559983326,
    "input_throughput": 1231.8065873404241,
    "output_throughput": 1095.5532312394803,
    "total_throughput": 2327.359818579904,
    "itl": 27.2692100862268,
    "ttft": 7005.768518043937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.288644612915845,
    "arrivals": 18102,
    "finished_requests": 18067,
    "scheduler_time": 0.0156409478744278
}
#Debug simulation 
Total elapsed time: 1.6994477030821145. Arrivals time: 0.05552865075878799 Scheduler time: 1.2654677079990506 Scheduler overhead time: 0.11708660679869354 Adapter cache time: 0.09008103562518954 Engine time: 0.11389236617833376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.720443459926173,
    "estimated_duration": 3599.822666038622,
    "input_throughput": 1231.7951219746071,
    "output_throughput": 1095.443127574799,
    "total_throughput": 2327.238249549406,
    "itl": 27.406699665116577,
    "ttft": 7204.765699772584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.788026004577977,
    "arrivals": 18102,
    "finished_requests": 18066,
    "scheduler_time": 0.016877200021072243
}
#Debug simulation 
Total elapsed time: 1.7205514670349658. Arrivals time: 0.05431893281638622 Scheduler time: 1.2909177865367383 Scheduler overhead time: 0.11577785341069102 Adapter cache time: 0.0889482235070318 Engine time: 0.11438267631456256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6990497610531747,
    "estimated_duration": 3599.84441116655,
    "input_throughput": 1231.7993483954615,
    "output_throughput": 1095.5467930131986,
    "total_throughput": 2327.34614140866,
    "itl": 27.268780137492257,
    "ttft": 7005.785517699963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.234587029819407,
    "arrivals": 18102,
    "finished_requests": 18067,
    "scheduler_time": 0.0156548753925735
}
#Debug simulation 
Total elapsed time: 1.699158385163173. Arrivals time: 0.05446874652989209 Scheduler time: 1.2677535263355821 Scheduler overhead time: 0.1168809593655169 Adapter cache time: 0.08987438399344683 Engine time: 0.1136314116884023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.688110528048128,
    "estimated_duration": 3599.831476513779,
    "input_throughput": 1231.8037744073342,
    "output_throughput": 1095.5507294522943,
    "total_throughput": 2327.3545038596285,
    "itl": 27.262122986264554,
    "ttft": 7005.664361597551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.5006642631022045,
    "arrivals": 18102,
    "finished_requests": 18067,
    "scheduler_time": 0.015547917289479074
}
#Debug simulation 
Total elapsed time: 1.688220402924344. Arrivals time: 0.0536642603110522 Scheduler time: 1.2574377888813615 Scheduler overhead time: 0.11664730496704578 Adapter cache time: 0.08944279467687011 Engine time: 0.11374258482828736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6909678799565881,
    "estimated_duration": 3599.8398983284746,
    "input_throughput": 1231.8008926060813,
    "output_throughput": 1095.5481664146332,
    "total_throughput": 2327.3490590207143,
    "itl": 27.26834441162361,
    "ttft": 7005.791459496195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.1917137742601644,
    "arrivals": 18102,
    "finished_requests": 18067,
    "scheduler_time": 0.015653082298551554
}
#Debug simulation 
Total elapsed time: 1.6910721310414374. Arrivals time: 0.054092308739200234 Scheduler time: 1.2604772669728845 Scheduler overhead time: 0.11601466638967395 Adapter cache time: 0.08954232977703214 Engine time: 0.11479466105811298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.6279706070199609,
    "estimated_duration": 3600.0194759704273,
    "input_throughput": 1186.0058059405546,
    "output_throughput": 1020.2211472786406,
    "total_throughput": 2206.2269532191954,
    "itl": 26.44015602945219,
    "ttft": 5289.494092133992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.39216583339036,
    "arrivals": 17157,
    "finished_requests": 17132,
    "scheduler_time": 0.0008121733943832338
}
#Debug simulation 
Total elapsed time: 1.6281013700645417. Arrivals time: 0.052190319634974 Scheduler time: 1.1967105998191983 Scheduler overhead time: 0.11920976173132658 Adapter cache time: 0.08342426107265055 Engine time: 0.11825523851439357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6062795110046864,
    "estimated_duration": 3600.0196623866905,
    "input_throughput": 1186.005744526787,
    "output_throughput": 1020.2210944495364,
    "total_throughput": 2206.2268389763235,
    "itl": 26.44341700452052,
    "ttft": 5289.4534994573605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.747777610486377,
    "arrivals": 17157,
    "finished_requests": 17132,
    "scheduler_time": 0.0008261009125289168
}
#Debug simulation 
Total elapsed time: 1.6063921449240297. Arrivals time: 0.051968235056847334 Scheduler time: 1.1793949899729341 Scheduler overhead time: 0.11901614186353981 Adapter cache time: 0.08314893511123955 Engine time: 0.1153363767080009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6175576820969582,
    "estimated_duration": 3600.0040732904267,
    "input_throughput": 1186.0108802870097,
    "output_throughput": 1020.2255123125522,
    "total_throughput": 2206.236392599562,
    "itl": 26.443692773615307,
    "ttft": 5079.958668572261,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8469341758266404,
    "arrivals": 17157,
    "finished_requests": 17132,
    "scheduler_time": 0.0008131325023961425
}
#Debug simulation 
Total elapsed time: 1.6176656011957675. Arrivals time: 0.05261791264638305 Scheduler time: 1.1882856965530664 Scheduler overhead time: 0.11894584819674492 Adapter cache time: 0.083932438865304 Engine time: 0.11559784249402583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.6255761480424553,
    "estimated_duration": 3600.0204865561504,
    "input_throughput": 1186.0054730089673,
    "output_throughput": 1020.2208608855688,
    "total_throughput": 2206.2263338945363,
    "itl": 26.299372784558702,
    "ttft": 5289.354573180191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4804081465629797,
    "arrivals": 17157,
    "finished_requests": 17132,
    "scheduler_time": 0.0007542116077811861
}
#Debug simulation 
Total elapsed time: 1.6256808480247855. Arrivals time: 0.052686333656311035 Scheduler time: 1.193679308751598 Scheduler overhead time: 0.11880885576829314 Adapter cache time: 0.08417432080022991 Engine time: 0.11857557483017445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6140855560079217,
    "estimated_duration": 3600.0252783360247,
    "input_throughput": 1186.0038943875086,
    "output_throughput": 1020.2195029301628,
    "total_throughput": 2206.2233973176712,
    "itl": 26.443863997221197,
    "ttft": 5289.514657306981,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8016288796440074,
    "arrivals": 17157,
    "finished_requests": 17132,
    "scheduler_time": 0.0008210969964747587
}
#Debug simulation 
Total elapsed time: 1.614191492088139. Arrivals time: 0.05202402826398611 Scheduler time: 1.1868865233846009 Scheduler overhead time: 0.11864217650145292 Adapter cache time: 0.08350308053195477 Engine time: 0.11545048910193145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.5865776690188795,
    "estimated_duration": 3600.012987470575,
    "input_throughput": 1186.0079435435366,
    "output_throughput": 1020.2229860788857,
    "total_throughput": 2206.230929622422,
    "itl": 26.438613563114938,
    "ttft": 5289.456553549213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2813353634532394,
    "arrivals": 17157,
    "finished_requests": 17132,
    "scheduler_time": 0.0008121733943832336
}
#Debug simulation 
Total elapsed time: 1.586680272128433. Arrivals time: 0.05111840181052685 Scheduler time: 1.1623633962590247 Scheduler overhead time: 0.11931646172888577 Adapter cache time: 0.08268219861201942 Engine time: 0.1137502274941653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.5988328631501645,
    "estimated_duration": 3600.0110713634194,
    "input_throughput": 1186.0085747966805,
    "output_throughput": 1020.2235290929278,
    "total_throughput": 2206.2321038896084,
    "itl": 26.44369450505772,
    "ttft": 5289.603215403886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7773428044840998,
    "arrivals": 17157,
    "finished_requests": 17132,
    "scheduler_time": 0.0008185950384476792
}
#Debug simulation 
Total elapsed time: 1.598934967070818. Arrivals time: 0.05181640153750777 Scheduler time: 1.1633730607572943 Scheduler overhead time: 0.1257625469006598 Adapter cache time: 0.08384404727257788 Engine time: 0.11587174655869603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.4343064820859581,
    "estimated_duration": 3599.54757374599,
    "input_throughput": 925.3474031831333,
    "output_throughput": 809.5470167567322,
    "total_throughput": 1734.8944199398657,
    "itl": 25.41354694129481,
    "ttft": 5543.705973072368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.380463408315983,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4344110309612006. Arrivals time: 0.04555909219197929 Scheduler time: 0.9864814630709589 Scheduler overhead time: 0.12369924294762313 Adapter cache time: 0.0965639513451606 Engine time: 0.1221439961809665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4066358041018248,
    "estimated_duration": 3599.5290551510147,
    "input_throughput": 925.352163843072,
    "output_throughput": 809.5511816552752,
    "total_throughput": 1734.903345498347,
    "itl": 25.426566211026305,
    "ttft": 5543.775558715099,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.99185610663579,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4067095159552991. Arrivals time: 0.044242144329473376 Scheduler time: 0.9649110254831612 Scheduler overhead time: 0.12312656547874212 Adapter cache time: 0.09616354084573686 Engine time: 0.11857965402305126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4151477569248527,
    "estimated_duration": 3599.543016195066,
    "input_throughput": 925.3485748090574,
    "output_throughput": 809.5480417623338,
    "total_throughput": 1734.8966165713912,
    "itl": 25.431395376433308,
    "ttft": 5543.784989220775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.44648330158072,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4152290700003505. Arrivals time: 0.0446038288064301 Scheduler time: 0.9739974399562925 Scheduler overhead time: 0.1213470094371587 Adapter cache time: 0.09657350881025195 Engine time: 0.11881615221500397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.4211301361210644,
    "estimated_duration": 3599.543663011875,
    "input_throughput": 925.3484085293651,
    "output_throughput": 809.5478962913156,
    "total_throughput": 1734.8963048206808,
    "itl": 25.41900554802252,
    "ttft": 5543.696563888616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.861013197312477,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4212344831321388. Arrivals time: 0.045110541861504316 Scheduler time: 0.9774641459807754 Scheduler overhead time: 0.12152430880814791 Adapter cache time: 0.09674286469817162 Engine time: 0.12094591977074742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4056114989798516,
    "estimated_duration": 3599.550417902291,
    "input_throughput": 925.3466720271995,
    "output_throughput": 809.5463770995581,
    "total_throughput": 1734.8930491267577,
    "itl": 25.432348830796485,
    "ttft": 5543.681216417338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.28679446189646,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4057121090590954. Arrivals time: 0.04455759166739881 Scheduler time: 0.9627718238625675 Scheduler overhead time: 0.1222000049892813 Adapter cache time: 0.09622390056028962 Engine time: 0.12044350290670991 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.4455626890994608,
    "estimated_duration": 3599.528426057224,
    "input_throughput": 925.3523255679514,
    "output_throughput": 809.5513231414815,
    "total_throughput": 1734.903648709433,
    "itl": 25.409415463743567,
    "ttft": 5543.579027755115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.849000107767933,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4456657550763339. Arrivals time: 0.04514846159145236 Scheduler time: 1.0006286392454058 Scheduler overhead time: 0.12264860654249787 Adapter cache time: 0.09676851751282811 Engine time: 0.12040700763463974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3943335569929332,
    "estimated_duration": 3599.5482575358924,
    "input_throughput": 925.3472273990724,
    "output_throughput": 809.5468629707469,
    "total_throughput": 1734.8940903698192,
    "itl": 25.432697258122005,
    "ttft": 5543.871843098924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.135598922967706,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3944319558795542. Arrivals time: 0.04447575146332383 Scheduler time: 0.9560358708258718 Scheduler overhead time: 0.12172532454133034 Adapter cache time: 0.09505349164828658 Engine time: 0.11789184296503663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.3523529209196568,
    "estimated_duration": 3599.9377610352635,
    "input_throughput": 863.9529920943913,
    "output_throughput": 758.0131049863642,
    "total_throughput": 1621.9660970807556,
    "itl": 24.732563598842457,
    "ttft": 5981.149673050378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.609356559599028,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3524283829610795. Arrivals time: 0.04259079578332603 Scheduler time: 0.915151251014322 Scheduler overhead time: 0.1249883605632931 Adapter cache time: 0.0885757771320641 Engine time: 0.12052270816639066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3561093311291188,
    "estimated_duration": 3599.9236927275847,
    "input_throughput": 863.956368376099,
    "output_throughput": 758.0160672607054,
    "total_throughput": 1621.9724356368044,
    "itl": 24.74224086572297,
    "ttft": 5981.089192577978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.550989209865174,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.356192059116438. Arrivals time: 0.04293909692205489 Scheduler time: 0.9170198547653854 Scheduler overhead time: 0.12387871416285634 Adapter cache time: 0.08873115689493716 Engine time: 0.12316821957938373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3783055529929698,
    "estimated_duration": 3599.921853249977,
    "input_throughput": 863.9568098380136,
    "output_throughput": 758.0164545895527,
    "total_throughput": 1621.9732644275664,
    "itl": 24.74328564521025,
    "ttft": 5981.201227568328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.805892878756806,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.37841614196077. Arrivals time: 0.04373373091220856 Scheduler time: 0.9362201681360602 Scheduler overhead time: 0.12427608389407396 Adapter cache time: 0.0893449371214956 Engine time: 0.124124527676031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.3446097730193287,
    "estimated_duration": 3599.9366002991246,
    "input_throughput": 863.9532706608139,
    "output_throughput": 758.0133493943364,
    "total_throughput": 1621.9666200551503,
    "itl": 24.736579424894458,
    "ttft": 5981.15625289972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.90185897828083,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3447119011543691. Arrivals time: 0.04238976282067597 Scheduler time: 0.9075656668283045 Scheduler overhead time: 0.12449388182722032 Adapter cache time: 0.08841897384263575 Engine time: 0.12099289195612073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3609812590293586,
    "estimated_duration": 3599.9386694413474,
    "input_throughput": 863.9527740850789,
    "output_throughput": 758.012913709851,
    "total_throughput": 1621.9656877949299,
    "itl": 24.742731659486275,
    "ttft": 5981.270456257898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.71020474316082,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3610603450797498. Arrivals time: 0.04256249638274312 Scheduler time: 0.9218363363761455 Scheduler overhead time: 0.1251099130604416 Adapter cache time: 0.08786941226571798 Engine time: 0.12232007062993944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.350048508029431,
    "estimated_duration": 3599.936011645018,
    "input_throughput": 863.9534119326696,
    "output_throughput": 758.0134733431148,
    "total_throughput": 1621.9668852757845,
    "itl": 24.730487508387757,
    "ttft": 5981.1064052870925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.311865064622834,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3501343769021332. Arrivals time: 0.042390023823827505 Scheduler time: 0.9099059728905559 Scheduler overhead time: 0.12540015438571572 Adapter cache time: 0.08882997976616025 Engine time: 0.12262195651419461 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3543118140660226,
    "estimated_duration": 3599.9354168961386,
    "input_throughput": 863.9535546672646,
    "output_throughput": 758.0135985752681,
    "total_throughput": 1621.9671532425327,
    "itl": 24.743326512120106,
    "ttft": 5981.171855470678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.622179943099573,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3544158739969134. Arrivals time: 0.0419342783279717 Scheduler time: 0.9176888719666749 Scheduler overhead time: 0.12380275642499328 Adapter cache time: 0.08880773279815912 Engine time: 0.12149737635627389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.3274873790796846,
    "estimated_duration": 3599.9469021548957,
    "input_throughput": 834.1678590321583,
    "output_throughput": 732.5621937427479,
    "total_throughput": 1566.7300527749062,
    "itl": 24.453772621856945,
    "ttft": 7082.855678798247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.132755644968777,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.327601338038221. Arrivals time: 0.04155176435597241 Scheduler time: 0.8822758276946843 Scheduler overhead time: 0.13124401541426778 Adapter cache time: 0.08703321940265596 Engine time: 0.1210869518108666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3246888471767306,
    "estimated_duration": 3599.945828591748,
    "input_throughput": 834.168107794755,
    "output_throughput": 732.5624122048615,
    "total_throughput": 1566.7305199996165,
    "itl": 24.45754997203115,
    "ttft": 7082.645619683114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.581332722487866,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3247906200122088. Arrivals time: 0.04174607479944825 Scheduler time: 0.8865619632415473 Scheduler overhead time: 0.12626058282330632 Adapter cache time: 0.08509572176262736 Engine time: 0.12341155298054218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3047174280509353,
    "estimated_duration": 3599.950604618282,
    "input_throughput": 834.167001110399,
    "output_throughput": 732.5614403199935,
    "total_throughput": 1566.7284414303924,
    "itl": 24.45930408887167,
    "ttft": 7082.878806448112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.707493386017192,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3047814730089158. Arrivals time: 0.0408278729300946 Scheduler time: 0.8716111383400857 Scheduler overhead time: 0.1240005069412291 Adapter cache time: 0.08560881018638611 Engine time: 0.12126362882554531 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.3221157561056316,
    "estimated_duration": 3599.961057532859,
    "input_throughput": 834.164579007419,
    "output_throughput": 732.5593132408292,
    "total_throughput": 1566.7238922482481,
    "itl": 24.45408886988069,
    "ttft": 7082.8851171559545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.250936130839392,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3222201489843428. Arrivals time: 0.04142207885161042 Scheduler time: 0.8861962934024632 Scheduler overhead time: 0.12517375615425408 Adapter cache time: 0.08503496088087559 Engine time: 0.12324413633905351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.322226433781907,
    "estimated_duration": 3599.9422169529958,
    "input_throughput": 834.1689446731499,
    "output_throughput": 732.5631471474347,
    "total_throughput": 1566.7320918205846,
    "itl": 24.45773262718928,
    "ttft": 7082.777213463882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.658199497982894,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3223300178069621. Arrivals time: 0.04151453799568117 Scheduler time: 0.885123243322596 Scheduler overhead time: 0.126464304048568 Adapter cache time: 0.08513042819686234 Engine time: 0.12262272601947188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.3230612529441714,
    "estimated_duration": 3599.9540995943667,
    "input_throughput": 834.1661912684847,
    "output_throughput": 732.5607291207272,
    "total_throughput": 1566.7269203892117,
    "itl": 24.452339592991574,
    "ttft": 7082.851814352952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9899505878565646,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.323139923857525. Arrivals time: 0.04167422535829246 Scheduler time: 0.883784749545157 Scheduler overhead time: 0.12543887831270695 Adapter cache time: 0.08564572711475194 Engine time: 0.125181078677997 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3054597340524197,
    "estimated_duration": 3599.9390503410773,
    "input_throughput": 834.1696784326067,
    "output_throughput": 732.5637915314536,
    "total_throughput": 1566.7334699640603,
    "itl": 24.457524693633108,
    "ttft": 7082.918878663978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.61926146877933,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3055622531101108. Arrivals time: 0.040871641831472516 Scheduler time: 0.8692240819800645 Scheduler overhead time: 0.12650343542918563 Adapter cache time: 0.0851398385129869 Engine time: 0.12173643591813743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.222947885049507,
    "estimated_duration": 3600.0146756332433,
    "input_throughput": 725.3339875734498,
    "output_throughput": 648.2006909012201,
    "total_throughput": 1373.5346784746698,
    "itl": 23.676712988885853,
    "ttft": 6061.564353959254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1068,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.062052846122693,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2230310449376702. Arrivals time: 0.03760931920260191 Scheduler time: 0.7926489990204573 Scheduler overhead time: 0.12783856224268675 Adapter cache time: 0.07773353066295385 Engine time: 0.1246796865016222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.228286836994812,
    "estimated_duration": 3600.0086193418415,
    "input_throughput": 725.3352078021928,
    "output_throughput": 648.2017813686845,
    "total_throughput": 1373.5369891708774,
    "itl": 23.682064503684327,
    "ttft": 6061.542952449616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1068,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.798111571688216,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2283843469340354. Arrivals time: 0.038070765091106296 Scheduler time: 0.7971906948368996 Scheduler overhead time: 0.12644559307955205 Adapter cache time: 0.07822603615932167 Engine time: 0.12611890025436878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2493032969068736,
    "estimated_duration": 3600.00943795859,
    "input_throughput": 725.3350428660838,
    "output_throughput": 648.2016339721724,
    "total_throughput": 1373.5366768382562,
    "itl": 23.683797179419557,
    "ttft": 6061.696048231836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.014734521606018,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2494057300500572. Arrivals time: 0.039173117373138666 Scheduler time: 0.8137921190354973 Scheduler overhead time: 0.12675878475420177 Adapter cache time: 0.07863627281039953 Engine time: 0.12740885792300105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.2398869460448623,
    "estimated_duration": 3600.017546169416,
    "input_throughput": 725.3334092158663,
    "output_throughput": 648.200174047203,
    "total_throughput": 1373.5335832630692,
    "itl": 23.677777859100445,
    "ttft": 6061.5603815006925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1068,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.258093613069491,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.240013456204906. Arrivals time: 0.03990063560195267 Scheduler time: 0.8010483307298273 Scheduler overhead time: 0.12676288560032845 Adapter cache time: 0.07829498127102852 Engine time: 0.13112058048136532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2177686020731926,
    "estimated_duration": 3600.012996168437,
    "input_throughput": 725.3343259535908,
    "output_throughput": 648.2009932974195,
    "total_throughput": 1373.5353192510102,
    "itl": 23.68359710206641,
    "ttft": 6061.675397802908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1068,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.926089866529233,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2178649380803108. Arrivals time: 0.03735508071258664 Scheduler time: 0.7887824585195631 Scheduler overhead time: 0.12715914356522262 Adapter cache time: 0.07781458599492908 Engine time: 0.1243450129404664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2478272840380669,
    "estimated_duration": 3599.9988211170244,
    "input_throughput": 725.3371819687932,
    "output_throughput": 648.2035455989235,
    "total_throughput": 1373.5407275677167,
    "itl": 23.673826311607545,
    "ttft": 6061.376087368004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1068,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.818027564529295,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2478981751482934. Arrivals time: 0.038178843446075916 Scheduler time: 0.8078381749801338 Scheduler overhead time: 0.12815612507984042 Adapter cache time: 0.07932742591947317 Engine time: 0.13159785978496075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2254398430231959,
    "estimated_duration": 3599.9985295288066,
    "input_throughput": 725.337240718755,
    "output_throughput": 648.2035981013107,
    "total_throughput": 1373.5408388200658,
    "itl": 23.68131450976236,
    "ttft": 6061.636236128985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1068,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.860433721542373,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2255218678619713. Arrivals time: 0.03785368776880205 Scheduler time: 0.7922561045270413 Scheduler overhead time: 0.12818109802901745 Adapter cache time: 0.0787125057540834 Engine time: 0.12546287779696286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.1999891840387136,
    "estimated_duration": 3600.0222284149463,
    "input_throughput": 695.5165388249369,
    "output_throughput": 612.4526072636975,
    "total_throughput": 1307.9691460886345,
    "itl": 23.333136573040523,
    "ttft": 4598.979061191641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.423701642374583,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.20009480509907. Arrivals time: 0.037641295697540045 Scheduler time: 0.7687724956776947 Scheduler overhead time: 0.12840901804156601 Adapter cache time: 0.07439078204333782 Engine time: 0.12750244583003223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1809727579820901,
    "estimated_duration": 3600.003110234842,
    "input_throughput": 695.520232435761,
    "output_throughput": 612.4558597551238,
    "total_throughput": 1307.9760921908849,
    "itl": 23.336119643714376,
    "ttft": 4248.668864857158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.896930768205791,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1810522351879627. Arrivals time: 0.0366141686681658 Scheduler time: 0.7525054805446416 Scheduler overhead time: 0.1283721518702805 Adapter cache time: 0.07463344931602478 Engine time: 0.12581738410517573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.192888654069975,
    "estimated_duration": 3600.0080675651852,
    "input_throughput": 695.519274681365,
    "output_throughput": 612.4550163831201,
    "total_throughput": 1307.974291064485,
    "itl": 23.337010692184446,
    "ttft": 4248.829452593338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.030373292961188,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1929791681468487. Arrivals time: 0.03659024625085294 Scheduler time: 0.760383877903223 Scheduler overhead time: 0.12980618537403643 Adapter cache time: 0.07500470825470984 Engine time: 0.12723719305358827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.194052770966664,
    "estimated_duration": 3600.0234834516405,
    "input_throughput": 695.516296354636,
    "output_throughput": 612.4523937510637,
    "total_throughput": 1307.9686901056996,
    "itl": 23.334005229143393,
    "ttft": 4599.161430339386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.551263745850875,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.194151656003669. Arrivals time: 0.037435647333040833 Scheduler time: 0.7591756989713758 Scheduler overhead time: 0.1310566335450858 Adapter cache time: 0.07533344556577504 Engine time: 0.12803308642469347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.196699369000271,
    "estimated_duration": 3600.021089910038,
    "input_throughput": 695.516758781702,
    "output_throughput": 612.4528009515349,
    "total_throughput": 1307.9695597332368,
    "itl": 23.338414770084366,
    "ttft": 4599.15754425532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.978801115984128,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1967969848774374. Arrivals time: 0.03745223395526409 Scheduler time: 0.7631074604578316 Scheduler overhead time: 0.12899805465713143 Adapter cache time: 0.07526372373104095 Engine time: 0.1276582875289023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.201649592956528,
    "estimated_duration": 3600.013437658931,
    "input_throughput": 695.5182371842079,
    "output_throughput": 612.4541027918489,
    "total_throughput": 1307.972339976057,
    "itl": 23.331817383892545,
    "ttft": 4248.694452529547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2708431092416665,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2017200789414346. Arrivals time: 0.03737055463716388 Scheduler time: 0.7648865110240877 Scheduler overhead time: 0.12908456637524068 Adapter cache time: 0.07507135439664125 Engine time: 0.1304132908117026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1919617799576372,
    "estimated_duration": 3600.014582054973,
    "input_throughput": 695.5180160883485,
    "output_throughput": 612.4539081009566,
    "total_throughput": 1307.9719241893051,
    "itl": 23.335752987867338,
    "ttft": 4599.20879483423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.936963446307959,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1920569699723274. Arrivals time: 0.03706730855628848 Scheduler time: 0.7608407696243376 Scheduler overhead time: 0.12849945155903697 Adapter cache time: 0.07457723002880812 Engine time: 0.1278853251133114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.1191816860809922,
    "estimated_duration": 3599.926374971835,
    "input_throughput": 630.3792810256446,
    "output_throughput": 555.0802410551061,
    "total_throughput": 1185.4595220807505,
    "itl": 22.820147721132567,
    "ttft": 4291.180185707872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7624607391795686,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.119252054952085. Arrivals time: 0.034732521045953035 Scheduler time: 0.693338374607265 Scheduler overhead time: 0.12982385093346238 Adapter cache time: 0.06924917525611818 Engine time: 0.12765718321315944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.124125842936337,
    "estimated_duration": 3599.9322632053386,
    "input_throughput": 630.378249945021,
    "output_throughput": 555.0793331374471,
    "total_throughput": 1185.457583082468,
    "itl": 22.823605498441438,
    "ttft": 4291.408356510152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.155810322123585,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1242250548675656. Arrivals time: 0.034416002221405506 Scheduler time: 0.6984778884798288 Scheduler overhead time: 0.12972941249608994 Adapter cache time: 0.0691351555287838 Engine time: 0.1282451229635626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1159748318605125,
    "estimated_duration": 3599.9477862200984,
    "input_throughput": 630.3755317470194,
    "output_throughput": 555.0769396292095,
    "total_throughput": 1185.452471376229,
    "itl": 22.822580698445325,
    "ttft": 4291.268035005445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.267194921853988,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1160568408668041. Arrivals time: 0.034654360031709075 Scheduler time: 0.6916876665782183 Scheduler overhead time: 0.12967124115675688 Adapter cache time: 0.06897343578748405 Engine time: 0.12687474652193487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.1221596279647201,
    "estimated_duration": 3599.9438096024164,
    "input_throughput": 630.3762280808008,
    "output_throughput": 555.0775527856613,
    "total_throughput": 1185.4537808664622,
    "itl": 22.819888958503896,
    "ttft": 4291.403566889796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.867060359674499,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.122245745966211. Arrivals time: 0.034781956346705556 Scheduler time: 0.6931377009022981 Scheduler overhead time: 0.13028654945082963 Adapter cache time: 0.06919431732967496 Engine time: 0.12962563894689083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1292685170192271,
    "estimated_duration": 3599.945881110311,
    "input_throughput": 630.3758653449776,
    "output_throughput": 555.0772333787672,
    "total_throughput": 1185.453098723745,
    "itl": 22.824607887444465,
    "ttft": 4291.263253661005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.22411454911813,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1293634348548949. Arrivals time: 0.03511284873820841 Scheduler time: 0.6994425500743091 Scheduler overhead time: 0.13133389013819396 Adapter cache time: 0.06902247969992459 Engine time: 0.12897813529707491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.127764267846942,
    "estimated_duration": 3599.9261551661916,
    "input_throughput": 630.3793195155794,
    "output_throughput": 555.0802749474038,
    "total_throughput": 1185.4595944629832,
    "itl": 22.818353817400496,
    "ttft": 4291.09676903879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6324510151846168,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.12783291679807. Arrivals time: 0.03420667024329305 Scheduler time: 0.6995410965755582 Scheduler overhead time: 0.13068083464168012 Adapter cache time: 0.06936594936996698 Engine time: 0.12831123475916684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.118025166913867,
    "estimated_duration": 3599.9252326624905,
    "input_throughput": 630.379481054283,
    "output_throughput": 555.0804171902491,
    "total_throughput": 1185.4598982445323,
    "itl": 22.82251385714763,
    "ttft": 4291.294585182746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.189111746270247,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.118127782130614. Arrivals time: 0.03487617033533752 Scheduler time: 0.6920731493737549 Scheduler overhead time: 0.1291364619974047 Adapter cache time: 0.0694245882332325 Engine time: 0.1284372282680124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9669029768556356,
    "estimated_duration": 3598.573779148417,
    "input_throughput": 457.5245919758855,
    "output_throughput": 406.4852049097506,
    "total_throughput": 864.0097968856362,
    "itl": 22.121974559764674,
    "ttft": 3201.7754072109888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.538146296423104,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9669671098235995. Arrivals time: 0.028914494439959526 Scheduler time: 0.5449658031575382 Scheduler overhead time: 0.132463569752872 Adapter cache time: 0.061639874475076795 Engine time: 0.13303889869712293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9616300149355084,
    "estimated_duration": 3598.559216321957,
    "input_throughput": 457.5264435089113,
    "output_throughput": 406.486849894074,
    "total_throughput": 864.0132934029853,
    "itl": 22.126389505634332,
    "ttft": 3201.7784011462372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.328553149048243,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9617426621261984. Arrivals time: 0.028845931170508265 Scheduler time: 0.5414304852019995 Scheduler overhead time: 0.13300185929983854 Adapter cache time: 0.06096359249204397 Engine time: 0.13116550026461482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9634666081983596,
    "estimated_duration": 3598.5755915229015,
    "input_throughput": 457.5243615497418,
    "output_throughput": 406.4850001889118,
    "total_throughput": 864.0093617386536,
    "itl": 22.129501108124824,
    "ttft": 3201.8837131619093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.552250796849833,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9635454041417688. Arrivals time: 0.02889606193639338 Scheduler time: 0.5415019413921982 Scheduler overhead time: 0.13310255575925112 Adapter cache time: 0.06180953676812351 Engine time: 0.13125240453518927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.9633712209761143,
    "estimated_duration": 3598.567094860126,
    "input_throughput": 457.525441821447,
    "output_throughput": 406.48595995036095,
    "total_throughput": 864.011401771808,
    "itl": 22.12289650499892,
    "ttft": 3201.738489544014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.789923411402838,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9634670158848166. Arrivals time: 0.02884311811067164 Scheduler time: 0.5439158834051341 Scheduler overhead time: 0.13196196360513568 Adapter cache time: 0.06101321359165013 Engine time: 0.13167376397177577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9663267971482128,
    "estimated_duration": 3598.5559591165934,
    "input_throughput": 457.52685763546725,
    "output_throughput": 406.4872178225328,
    "total_throughput": 864.014075458,
    "itl": 22.12935443452413,
    "ttft": 3201.9994912306956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.471889332323332,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9664177661761642. Arrivals time: 0.029115846613422036 Scheduler time: 0.5446183141320944 Scheduler overhead time: 0.13195865415036678 Adapter cache time: 0.061723615508526564 Engine time: 0.13232564041391015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9612795829307288,
    "estimated_duration": 3598.5650587748432,
    "input_throughput": 457.5257006915253,
    "output_throughput": 406.48618994205685,
    "total_throughput": 864.0118906335822,
    "itl": 22.120130795921483,
    "ttft": 3201.8023982584864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.277669872250371,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9613632438704371. Arrivals time: 0.028966195648536086 Scheduler time: 0.5417372232768685 Scheduler overhead time: 0.1324769153725356 Adapter cache time: 0.06107670767232776 Engine time: 0.13094680197536945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9614238499198109,
    "estimated_duration": 3598.5645256855405,
    "input_throughput": 457.52576846912245,
    "output_throughput": 406.4862501586899,
    "total_throughput": 864.0120186278124,
    "itl": 22.126681436448155,
    "ttft": 3201.755208956073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.39546309415251,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9615027089603245. Arrivals time: 0.02928246487863362 Scheduler time: 0.5382826097775251 Scheduler overhead time: 0.13313252828083932 Adapter cache time: 0.06112485844641924 Engine time: 0.1328485757112503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9285021941177547,
    "estimated_duration": 3599.9994809581435,
    "input_throughput": 428.2667284134327,
    "output_throughput": 376.3297764808072,
    "total_throughput": 804.5965048942398,
    "itl": 21.615573719887173,
    "ttft": 6289.528286515818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.589011868173337,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9285617480054498. Arrivals time: 0.027732725255191326 Scheduler time: 0.5107319189701229 Scheduler overhead time: 0.13404451520182192 Adapter cache time: 0.05793055519461632 Engine time: 0.13156350725330412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.93349205609411,
    "estimated_duration": 3600.011888615177,
    "input_throughput": 428.2652523664502,
    "output_throughput": 376.3284794376466,
    "total_throughput": 804.5937318040968,
    "itl": 21.618789017162495,
    "ttft": 6289.523426529022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.062912712660625,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9335869271308184. Arrivals time: 0.0279329651966691 Scheduler time: 0.5149044874124229 Scheduler overhead time: 0.1328283918555826 Adapter cache time: 0.05868570110760629 Engine time: 0.13243120908737183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.935524569125846,
    "estimated_duration": 3600.0079931999394,
    "input_throughput": 428.2657157740296,
    "output_throughput": 376.3288866466572,
    "total_throughput": 804.5946024206869,
    "itl": 21.618204230836717,
    "ttft": 6289.59046822274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.1878461610433,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9355973959900439. Arrivals time: 0.027776651084423065 Scheduler time: 0.5148042023647577 Scheduler overhead time: 0.13325882866047323 Adapter cache time: 0.058659959584474564 Engine time: 0.13438297412358224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.9327544819097966,
    "estimated_duration": 3600.0148399702643,
    "input_throughput": 428.2649012671111,
    "output_throughput": 376.32817091698166,
    "total_throughput": 804.5930721840928,
    "itl": 21.614835734227995,
    "ttft": 6289.452324761637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.728908642018205,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.932848921045661. Arrivals time: 0.02827667724341154 Scheduler time: 0.5134551166556776 Scheduler overhead time: 0.1330472263507545 Adapter cache time: 0.05848263017833233 Engine time: 0.13268632418476045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9357481650076807,
    "estimated_duration": 3600.0078705627334,
    "input_throughput": 428.2657303632507,
    "output_throughput": 376.3288994666079,
    "total_throughput": 804.5946298298586,
    "itl": 21.618340149085522,
    "ttft": 6289.59870078257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.147249697912515,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9358065300621092. Arrivals time: 0.028241368709132075 Scheduler time: 0.5158037832006812 Scheduler overhead time: 0.13320772466249764 Adapter cache time: 0.058807116001844406 Engine time: 0.13294940232299268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9356824429705739,
    "estimated_duration": 3600.0116961762533,
    "input_throughput": 428.26527525940486,
    "output_throughput": 376.3284995543167,
    "total_throughput": 804.5937748137216,
    "itl": 21.613758653432033,
    "ttft": 6289.476332261897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.430441132755929,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9357712580822408. Arrivals time: 0.028632129775360227 Scheduler time: 0.5125051341019571 Scheduler overhead time: 0.13614919735118747 Adapter cache time: 0.0578895821236074 Engine time: 0.1337871642317623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9312499889638275,
    "estimated_duration": 3599.997969475923,
    "input_throughput": 428.26690822396347,
    "output_throughput": 376.32993448527577,
    "total_throughput": 804.5968427092392,
    "itl": 21.619134602031252,
    "ttft": 6289.497693299674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.094643431566687,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9313311669975519. Arrivals time: 0.027481175027787685 Scheduler time: 0.5121522305998951 Scheduler overhead time: 0.13341065822169185 Adapter cache time: 0.05846558744087815 Engine time: 0.13326752604916692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.8761290409602225,
    "estimated_duration": 3599.4436692669146,
    "input_throughput": 355.0982089019099,
    "output_throughput": 326.8274511543036,
    "total_throughput": 681.9256600562136,
    "itl": 21.32059940667444,
    "ttft": 7425.395523370413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.610375331444715,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8761928719468415. Arrivals time: 0.025545824551954865 Scheduler time: 0.462418062845245 Scheduler overhead time: 0.13428938877768815 Adapter cache time: 0.05243284092284739 Engine time: 0.1342430568765849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8715751369018108,
    "estimated_duration": 3599.440417277949,
    "input_throughput": 355.0985297227385,
    "output_throughput": 326.8277464333308,
    "total_throughput": 681.9262761560693,
    "itl": 21.32252157376297,
    "ttft": 7425.393232328472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.981215721024205,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8716542120091617. Arrivals time: 0.025646643480286002 Scheduler time: 0.45921017858199775 Scheduler overhead time: 0.13302618637681007 Adapter cache time: 0.052194687305018306 Engine time: 0.13394183246418834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8727794520091265,
    "estimated_duration": 3599.428222828271,
    "input_throughput": 355.09973275579915,
    "output_throughput": 326.8288536882226,
    "total_throughput": 681.9285864440217,
    "itl": 21.323230478943742,
    "ttft": 7425.44712958702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.086571653443424,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8730242231395096. Arrivals time: 0.02570610144175589 Scheduler time: 0.461396258790046 Scheduler overhead time: 0.13300157035700977 Adapter cache time: 0.05195647128857672 Engine time: 0.13310219789855182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.8781107771210372,
    "estimated_duration": 3599.4305408528344,
    "input_throughput": 355.09950407243,
    "output_throughput": 326.8286432112312,
    "total_throughput": 681.9281472836612,
    "itl": 21.320603007410824,
    "ttft": 7425.434285894579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7021833053883086,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8782020399812609. Arrivals time: 0.02576770749874413 Scheduler time: 0.46309860120527446 Scheduler overhead time: 0.13370804861187935 Adapter cache time: 0.052202312741428614 Engine time: 0.13583399658091366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8773529180325568,
    "estimated_duration": 3599.448265962329,
    "input_throughput": 355.0977554217685,
    "output_throughput": 326.82703377749056,
    "total_throughput": 681.9247891992591,
    "itl": 21.322473261116883,
    "ttft": 7425.382635126794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.044941100943869,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8774122069589794. Arrivals time: 0.02566051436588168 Scheduler time: 0.4629817418754101 Scheduler overhead time: 0.13397203129716218 Adapter cache time: 0.05253031454049051 Engine time: 0.1346023187506944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.8847670319955796,
    "estimated_duration": 3599.4291672540576,
    "input_throughput": 355.09963958398527,
    "output_throughput": 326.82876793418137,
    "total_throughput": 681.9284075181666,
    "itl": 21.318889547383982,
    "ttft": 7425.308570946582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4856208335514953,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8850360710639507. Arrivals time: 0.02581161563284695 Scheduler time: 0.4594207350164652 Scheduler overhead time: 0.14119000849314034 Adapter cache time: 0.05394015111960471 Engine time: 0.13528072368353605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8904763038735837,
    "estimated_duration": 3599.443277989275,
    "input_throughput": 355.0982475028763,
    "output_throughput": 326.8274866820961,
    "total_throughput": 681.9257341849724,
    "itl": 21.321986671592686,
    "ttft": 7425.353149988416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.012630821391976,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8905698589514941. Arrivals time: 0.025765404803678393 Scheduler time: 0.4633189532905817 Scheduler overhead time: 0.1426588052418083 Adapter cache time: 0.05374450678937137 Engine time: 0.1334511439781636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.7296388850081712,
    "estimated_duration": 3598.3631686491126,
    "input_throughput": 222.44002689158566,
    "output_throughput": 202.45760804446468,
    "total_throughput": 424.89763493605034,
    "itl": 20.640704045243556,
    "ttft": 3310.632820690393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 587,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8814841017546713,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7297014452051371. Arrivals time: 0.021373889176175 Scheduler time: 0.32725271908566356 Scheduler overhead time: 0.13418433303013444 Adapter cache time: 0.04151643277145922 Engine time: 0.13639903534203768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7331436078529805,
    "estimated_duration": 3598.372476366186,
    "input_throughput": 222.43945151789944,
    "output_throughput": 202.45708435822945,
    "total_throughput": 424.8965358761289,
    "itl": 20.64539700742953,
    "ttft": 3310.804452687201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 587,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.297097097546799,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7332587889395654. Arrivals time: 0.02121785655617714 Scheduler time: 0.3306345921009779 Scheduler overhead time: 0.13543851836584508 Adapter cache time: 0.04116146476007998 Engine time: 0.13615830685012043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.735068173147738,
    "estimated_duration": 3598.353954699767,
    "input_throughput": 222.44059647177872,
    "output_throughput": 202.45812645765267,
    "total_throughput": 424.89872292943136,
    "itl": 20.646129901633888,
    "ttft": 3310.7588121839553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.422349122348273,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7351495011243969. Arrivals time: 0.021150247426703572 Scheduler time: 0.3328935138415545 Scheduler overhead time: 0.13388700946234167 Adapter cache time: 0.04149974277243018 Engine time: 0.13699637912213802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.7305570391472429,
    "estimated_duration": 3598.3655310344207,
    "input_throughput": 222.4398808561018,
    "output_throughput": 202.45747512776273,
    "total_throughput": 424.89735598386454,
    "itl": 20.643565218002703,
    "ttft": 3310.79504505342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.020283939931535,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7306175660341978. Arrivals time: 0.0208977609872818 Scheduler time: 0.3284110105596483 Scheduler overhead time: 0.13443303876556456 Adapter cache time: 0.041615660302340984 Engine time: 0.1359948969911784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7298965370282531,
    "estimated_duration": 3598.3745930468813,
    "input_throughput": 222.43932067179637,
    "output_throughput": 202.45696526640316,
    "total_throughput": 424.8962859381995,
    "itl": 20.645805636014998,
    "ttft": 3310.909996777455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 587,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.372021144945206,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7299962530378252. Arrivals time: 0.020995373371988535 Scheduler time: 0.3294721208512783 Scheduler overhead time: 0.1342698964290321 Adapter cache time: 0.04146328684873879 Engine time: 0.13531548413448036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.7270937899593264,
    "estimated_duration": 3598.3580835528182,
    "input_throughput": 222.4403412374429,
    "output_throughput": 202.45789415174153,
    "total_throughput": 424.89823538918444,
    "itl": 20.640033247945084,
    "ttft": 3310.5438274921844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 587,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7473615921148857,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7271829049568623. Arrivals time: 0.021155236987397075 Scheduler time: 0.3285844603087753 Scheduler overhead time: 0.1335793931502849 Adapter cache time: 0.04153733840212226 Engine time: 0.13426613109186292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7282536660786718,
    "estimated_duration": 3598.373557460998,
    "input_throughput": 222.43938468822398,
    "output_throughput": 202.4570235320534,
    "total_throughput": 424.89640822027735,
    "itl": 20.645602746041764,
    "ttft": 3310.890424969405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 587,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.332254647035184,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7283213560003787. Arrivals time: 0.02093790122307837 Scheduler time: 0.32792016258463264 Scheduler overhead time: 0.13422340946272016 Adapter cache time: 0.04123075399547815 Engine time: 0.1347834465559572 
